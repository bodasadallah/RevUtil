{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. It implies that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the dataset used in the study, specifically mentioning that it is artificially created and may contain noise. It suggests that the authors should analyze the quality of the dataset and the amount of noise it might have, particularly regarding the \"pristine\" set of tweets. However, the comment does not specify which part of the paper discusses the dataset or the analysis of its quality, making it weakly grounded. The comment is specific in its suggestion to analyze the dataset quality and noise, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. The reviewer suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment lacks specific examples or references to support the claim about the dataset\"s noise, making it difficult for the authors to fully understand and address the issue. The suggestion to analyze the dataset quality is clear, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the study, noting that it is artificially created and may contain noise, such as misinformation or outofcontext images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. This feedback is 3 as it points out a potential weakness in the study\"s methodology and encourages the authors to address it. However, the comment could be more helpful if it provided specific suggestions or examples of how to analyze the dataset\"s quality or noise. Overall, the comment offers a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not delve into the theoretical aspects of the proposed algorithm, specifically the convergence properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting the inclusion of theoretical analysis or references to relevant literature. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of theoretical analysis, specifically the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the theoretical section, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. This feedback is valuable as it highlights an area where the authors can enhance the depth and rigor of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending relevant literature or methods to explore the convergence properties. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, and it questions the rationale behind the chosen operators. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 261 and 272,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly questions the rationale behind the chosen operators and suggests considering alternatives like the \"and\" operator or elementwise max, which correspond to the ideas of union and intersection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. While the comment raises a valid point about the potential alternatives, it lacks specific examples or references to support the claim that these operators are more appropriate. The reasoning is based on logical inference, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, and it questions the rationale behind the chosen operators. This feedback is 3 as it prompts the authors to consider alternative operators that could be more appropriate for their work. However, the comment could be more helpful if it provided specific suggestions or examples of how these operators could be used or why they might be preferable. Overall, the comment provides a starting point for the authors to explore alternative approaches, but it lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or revise the description of HIERENC. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, noting that using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that using the average of all instantiations of context filled by every possible entity in the vocabulary is a poor approach. The reviewer argues that only one instantiation should be correct, implying that the current method introduces noise. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that this approach is flawed. The reasoning is 3, as it highlights a potential issue with the method, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. This feedback is clear and actionable, as it provides a specific area for improvement and offers a logical reasoning for why the current approach might be problematic. However, the comment could be more helpful if it suggested alternative methods or approaches to address the issue. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While the comment implies that the authors should explain their rationale for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this selection is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in questioning the selection process and its impact, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not provide any supporting evidence, reasoning, or references to justify why this selection might affect the results or how it could be addressed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it identifies a specific area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. The comment lacks depth and actionable feedback, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. The comment explicitly states that the description can be revised by mentioning Li et al. (2019a) earlier, providing a clear and concrete action for the authors to take. This guidance is specific and actionable, allowing the authors to make a direct improvement to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 226238\" and \"Line 242244,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point identifies a discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. The reviewer provides a logical reasoning by pointing out the inconsistency in the description, which is supported by the specific lines mentioned. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks some depth in its justification.", "helpfulness_rationale": "The review comment identifies a discrepancy in the description of the data selection process, specifically noting a contradiction between the mention of raw data in lines 226238 and the assertion of syntactic information in lines 242244. The reviewer suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and recommends revising the description to clarify this point. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and precision of the description. By addressing this issue, the authors can enhance the transparency and accuracy of their methodology, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. It does not explicitly instruct the authors to provide this explanation, but it does imply that they should include a supporting explanation. The action is implicit, as the authors can infer that they need to clarify the purpose of the average duration, but it lacks concrete details on how to implement this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and requests an explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the purpose of the average duration reported in Table 1, without any claim or suggestion that requires verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. This feedback is 3 as it prompts the authors to clarify the meaning and context of the reported duration, which could be important for understanding the results or methodology. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what additional information might be needed. To be more helpful, the comment could suggest including a detailed explanation or justification for the reported duration in the table. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. This is a direct request for additional information, providing the authors with a clear action to take. The comment is explicit and concrete, as it specifies exactly what information is needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the splits used for obtaining the ATIS numbers. The comment provides a direct request for additional information, which is clear and specific. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any claims, opinions, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper that requires clarification, namely Table 4. It asks for more information about the splits used for obtaining the ATIS numbers, which is a direct and actionable request for additional details. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or presentation of the information. While it prompts the authors to address a specific issue, it does not offer comprehensive guidance or insights that could enhance the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should correct the wording \"on par or better\" to address a perceived cognitive bias among NLP researchers. While the comment implies that the authors should make this correction, it does not provide explicit guidance on how to rephrase the results or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number (l.791), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential cognitive bias among NLP researchers and suggesting a correction to the wording. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to map instances where they perform worse to \"on par\" and all the rest to \"better\". While the reviewer provides a rationale for this claim, it lacks specific examples or references to support the assertion. The comment suggests that the authors should correct this wording, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the phrasing of the experimental results, suggesting that the authors might be using a general cognitive bias to categorize their results. It points out that the phrase \"on par or better\" could be misleading and suggests that the authors should correct this wording. While the comment highlights an important issue, it lacks specific guidance on how to rephrase the results or what alternative wording might be more appropriate. The feedback is 3 as it directs the authors\" attention to a potential area of improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks concrete details or actions for the authors to take, leaving them uncertain about what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as the interpretation of results regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. While the comment identifies areas where clarification is needed, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their interpretation. The feedback is 3 as it prompts the authors to clarify their results, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the overall appearance and readability of the tables. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to correct the formatting or improve the tables\" appearance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the presence of spaces between accuracy and standard deviation in some items but not in others, which affects the appearance and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the appearance and readability of the tables. However, the comment does not provide any reasoning, examples, or references to support why this issue is problematic or how it impacts the overall quality of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting the presence of spaces between accuracy and standard deviation in some items but not in others. This observation is relevant as it affects the appearance and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting style or offering alternative solutions. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a grammatical error regarding the phrase \"both tasks\" and suggests that the references should be checked for formatting issues, such as capitalization and bibliographic details. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct the grammatical error or how to ensure proper formatting of the references. The action is implicit, as the authors can infer that they need to check and correct the references, but it lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues, such as capitalization and bibliographic details. However, it does not specify which part of the paper contains the grammatical error or which references need to be checked. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references or sections, and it is not specific enough to guide the authors on how to address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues. However, it does not provide specific examples or detailed reasoning to support the claim that the references are improperly formatted. The comment lacks explicit references or detailed guidance on how to correct the formatting issues, making it difficult for the authors to understand and address the problem. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues, such as capitalization and bibliographic details. While it points out a specific error, the comment lacks depth and does not provide detailed guidance on how to correct the grammatical error or improve the formatting of the references. It does not offer suggestions on how to ensure consistency in formatting or provide examples of proper formatting. As a result, the feedback is 3, as it highlights an issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the lack of novelty in the paper\"s approach, noting that adversarial attacks by perturbing text have been done on many NLP and imagetext models. It suggests that the only new effort is applying similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects they should focus on to differentiate their contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of novelty in the paper\"s approach, specifically mentioning that adversarial attacks by perturbing text have been done on many NLP and imagetext models. It suggests that the only new effort is applying similar ideas to videotext models. However, the comment does not specify which part of the paper this critique pertains to, such as the related work section or the methodology section. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the novelty are lacking or how the authors might enhance their contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks novelty due to the common practice of adversarial attacks by perturbing text on NLP and imagetext models. It references the related work section of the paper, suggesting that the only new effort is applying similar ideas to videotext models. However, the comment does not provide specific examples or detailed reasoning to support the claim that the approach is not novel. The lack of detailed evidence or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper\"s approach, noting that adversarial attacks by perturbing text have been done on many NLP and imagetext models. It suggests that the only new effort is applying similar ideas to videotext models. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or differentiate it from existing approaches. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by dedicating separate paragraphs to each of the lexical and sentencelevel features. This provides a clear and direct action for the authors to take, which is to reorganize the section to improve clarity. The suggestion is concrete, as it specifies the action of adding separate paragraphs, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current organization of the section, suggesting that more separate paragraphs should be dedicated to each of the lexical and sentencelevel features to improve coherence. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested changes would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of explanations in Section 3.2, noting that the current structure is confusing. It provides a clear and actionable suggestion to improve coherence by dedicating separate paragraphs to each of the lexical and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and organization of their paper, making it 4. However, it could be more helpful if it included specific examples of how the current structure is confusing or suggested how the new organization might look. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be a lot of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the paper. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the amount of space dedicated to fleshing out the assumptions, specifically mentioning that it is a \"whole section of the paper plus experimental results.\" This provides some grounding as it indicates a specific part of the paper being discussed, but it does not specify which section or table this refers to, making it weakly grounded. The comment is specific in its critique of the space dedicated to the assumptions, but it lacks detailed guidance on how the authors might address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the amount of space dedicated to fleshing out assumptions, stating that it is \"a lot of space.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is considered excessive. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be excessive. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this concern or improve the presentation of their assumptions. Without additional guidance or examples, the authors are left without a clear direction for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper uses integrated gradients for attribution measurement, which has been studied in existing papers. It also mentions the proposal of postprocessing steps to filter out \"falsepositive\" neurons. However, the comment suggests that the paper does not demonstrate the importance of these postprocessing steps. The reviewer proposes an ablation study as a potential solution to address this issue. While the action is explicit, the comment does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. The authors know they need to conduct an ablation study, but the comment lacks concrete instructions on how to execute it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the use of integrated gradients for attribution measurement and the proposal of postprocessing steps to filter out \"falsepositive\" neurons. It suggests that the paper does not demonstrate the importance of these postprocessing steps and recommends an ablation study. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in suggesting an ablation study to address the lack of demonstration, but without full grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of postprocessing steps to filter out \"falsepositive\" neurons, despite using integrated gradients for attribution measurement. The reviewer suggests that an ablation study may be needed to address this issue. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the postprocessing steps are not important. The suggestion for an ablation study provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the use of integrated gradients for attribution measurement has been studied in existing papers. It also points out the proposal of postprocessing steps to filter out \"falsepositive\" neurons but suggests that the paper does not demonstrate the importance of these steps. The reviewer recommends conducting an ablation study to address this issue. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a clear suggestion for enhancing the paper\"s analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the method proposed by the authors, which involves matching the head of noun phrases. The comment implies that the authors should clarify how they handle situations where the head word is not a pronoun. While the action is not explicitly stated, it is clear that the authors need to address this issue, and the comment provides a specific area for improvement. However, the comment lacks concrete guidance on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the identification of antecedents when the prediction is a pronoun, which is a particular aspect of the paper. It explicitly mentions the method proposed by the authors, which involves matching the head of noun phrases, and questions how this method handles situations where the head word is not a pronoun. This provides full grounding, as the authors can accurately identify the part of the paper being addressed, and it is specific because it clearly specifies the issue with the method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the method proposed by the authors for identifying antecedents, specifically when the prediction is a pronoun. It highlights a potential issue with the method, which involves matching the head of noun phrases, and questions how the method handles situations where the head word is not a pronoun. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors may need to provide additional context or evidence to address this concern effectively. Therefore, the comment is 3, as it provides a clear question but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a specific question about the method proposed by the authors for identifying antecedents, particularly when the prediction is a pronoun. It highlights a potential issue with the method, which involves matching the head of noun phrases, and questions how the method handles situations where the head word is not a pronoun. This feedback is 3 as it identifies a gap in the methodology and prompts the authors to clarify their approach. However, it could be more helpful if it provided suggestions on how to address this issue or offered alternative methods for consideration. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment explicitly suggests including more baselines, it does not provide specific guidance on which baselines to include or how to implement them. The action is somewhat explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The comment also recommends including more baselines based on related work to strengthen the paper. While the comment does not explicitly mention a specific section, it is clear that it pertains to the comparison of models and the inclusion of baselines. The authors can infer that it relates to the methodology or results sections, but the lack of explicit section reference makes it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the comparison to models that only consider different senses and the inclusion of more baselines. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the MST baseline is an appropriate comparison. The suggestion to include more baselines is a logical extension of the critique but remains somewhat vague without detailed guidance on which baselines to include. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement the suggested changes or which baselines to include. The feedback is 3 as it points out a gap in the comparison and suggests a direction for improvement, but it could be more actionable with detailed recommendations or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency mentioned, specifically regarding the evaluation with gold answers being inconsistent with human evaluation. While the comment implies that an example should be given, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to provide an example, but the comment lacks concrete guidance on how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by suggesting that an example of the inconsistency mentioned in the abstract should be given. This feedback is detailed and actionable, providing a clear direction for the authors to enhance their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract could be improved by providing an example of the inconsistency mentioned, specifically regarding the evaluation with gold answers being inconsistent with human evaluation. However, the comment does not provide any specific examples or detailed reasoning to support the claim that an example would be beneficial. Without additional context or evidence, the authors may find it challenging to understand the full impact of this suggestion. Therefore, the comment is considered 2, as it lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and intriguing, which is a positive observation. However, it suggests that the abstract could be improved by providing an example of the inconsistency mentioned, specifically regarding the evaluation with gold answers being inconsistent with human evaluation. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address this issue. The feedback is 3 as it highlights a potential enhancement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks specific instructions or examples of what the authors should do to address the issue, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the selection of frame similarity factors and attributes similarity factors, which are specific elements of the paper. However, it does not specify which part of the paper discusses these factors, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the selection process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the selection of frame similarity factors and attributes similarity factors, but it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors, which is a crucial aspect of the paper\"s methodology. However, it does not provide any suggestions or guidance on how the authors might clarify or improve this aspect. Without actionable feedback or specific recommendations, the comment lacks depth and does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights an issue but does not provide actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN. It also questions how the stable points in probabilistic metric space are obtained, implying that this information is crucial for readers to understand and replicate the results. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to include more detailed discussions, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more detailed explanations on the convergence process and the derivation of stable points. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. This feedback is 3 as it identifies a gap in the paper\"s explanation, which could be crucial for readers to understand and replicate the results. However, the comment lacks specific guidance on how to address this issue or what aspects of the convergence process should be discussed. To be more helpful, the comment could provide examples or references to similar works that address this topic, offering a clearer path for the authors to improve their draft. Therefore, the comment is rated as 3, as it points out an area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2. The comment also raises a question about why the authors did not mention objects in the context of \"latent in verbs.\" These actions are clear and concrete, providing the authors with a specific set of tasks to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). Additionally, it raises a question about why objects are not mentioned in the context of \"latent in verbs.\" This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for improvement, such as discussing results for a specific task and using consistent terminology. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying areas for improvement in the paper. It suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it points out a potential inconsistency in terminology and questions the absence of object mention in the context of \"latent in verbs.\" This feedback is clear and provides the authors with concrete steps to enhance their draft, making it 4. However, it could be more helpful if it offered suggestions on how to discuss these topics or what specific aspects to focus on. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific error in the sentence at line 212, suggesting that the correct way to describe the process is to use a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is explicit and provides a clear action for the authors to take, which is to correct the sentence to accurately reflect the process described in Figure 2. The comment is concrete, as it specifies the exact sentence to be revised and the correct way to describe the process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is not strictly correct and suggests a more accurate description involving a bidirectional encoder. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a more accurate description involving a bidirectional encoder. The reviewer provides a specific correction, \"do a bidirectional encoder that encodes the source sentence into a set of vectors,\" which is a clear and logical suggestion. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to verify the accuracy of the correction themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific error in the sentence at line 212, suggesting that the description of the process is not accurate. It provides a clear and actionable correction by recommending that the sentence should describe the process as a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is valuable as it helps the authors improve the accuracy and clarity of their description, which is crucial for understanding the methodology. However, the comment could be more helpful if it explained why this correction is important or provided additional context on the significance of the bidirectional encoder. Overall, the comment is 4, as it guides the authors toward a more precise and accurate description, but it could be further enhanced with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends adding additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional baselines, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this extension is discussed in, making it difficult for the authors to identify the exact section that needs further development. The comment is specific in suggesting additional baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends adding additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support why these additional baselines are necessary or how they would enhance the paper. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends adding additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement these suggestions. The authors are left with a general idea of what could be added but without actionable steps or examples. Therefore, the comment is 3, as it points out a potential enhancement but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues with the adopted baseline models. First, it points out that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. Second, it mentions that the authors do not compare their work with other domain adaptation methods, such as those cited in Section 8. The comment provides explicit actions for the authors to take, such as including comparisons with Campos et al. (2020) and other domain adaptation methods. These actions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Line 277,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issues with the adopted baseline models, including the lack of comparison with Campos et al. (2020) and the absence of comparisons with other domain adaptation methods. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and lacks comparisons with relevant works. It specifically mentions the absence of comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would improve the paper. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the significance of these comparisons themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the adopted baseline models. First, it points out that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. This lack of comparison limits the paper\"s ability to demonstrate its novelty and effectiveness. Second, the comment notes that the authors do not compare their work with other domain adaptation methods, such as those cited in Section 8. This omission could hinder the paper\"s comprehensiveness and impact. The comment provides clear and actionable feedback, suggesting that the authors should include these comparisons to strengthen their work. However, it could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies weaknesses and offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is an explicit and concrete suggestion, as it provides a clear action for the authors to take. It specifies what needs to be changed and how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the yaxis label, suggesting that it should use \"Exact Match ratio\" directly. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a specific change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio.\" This is a factual statement that does not express an opinion, judgment, or suggestion. It does not require any verification or evidence, as it is a straightforward request for a change in labeling. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the labeling of the yaxis in Figure 5. It recommends using \"Exact Match ratio\" directly, which is a clear and direct improvement to the clarity and accuracy of the figure. This feedback is valuable as it helps the authors enhance the presentation and interpretation of their results, making the comment 4. However, it could be more helpful if it included additional context or reasoning about why \"Exact Match ratio\" is more appropriate. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of the reasoning chains in addressing implicit offensive texts. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what specific steps to take to address the concerns. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of societal biases in knowledge bases and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in its critique of the reasoning chains and the need to address societal biases, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the societal biases in knowledge bases and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence to substantiate the claim, leaving it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not provide specific examples or suggestions on how the authors might address these issues or improve their approach. The comment lacks actionable guidance, leaving the authors without clear steps to take to enhance their draft. As a result, the feedback is not helpful, as it does not offer meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to demonstrate that something, such as attention in a seq2seq multitask learning (MTL) model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to improve its performance. While the comment implies that the authors should investigate the reasons for failure and make necessary changes, it does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the difficulty of demonstrating that attention in a seq2seq multitask learning model is not working and suggests that the value lies in understanding why it fails and making changes to the attention mechanism. However, it does not specify which part of the paper this discussion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to understand why attention fails and make changes, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something, such as attention in a seq2seq multitask learning model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism. This claim is 3 as it provides a logical reasoning that understanding the reasons for failure is valuable. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully grasp the context and implications of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the difficulty in demonstrating that attention in a seq2seq multitask learning model is not working, but it emphasizes the importance of understanding why it fails and making changes to the attention mechanism to improve its performance. This feedback highlights a critical aspect of the paper\"s analysis and suggests a direction for improvement. However, the comment lacks specific guidance or actionable steps for the authors to take to address this issue. While it identifies a valuable area for exploration, it does not provide detailed suggestions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning MCNC and suggesting that the paper should include more comprehensive baselines as in [1]. However, the comment does not provide explicit guidance on how to address this issue or what specific baselines should be included. The authors are left to infer that they need to add more baselines, but the comment lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the lack of strong baselines in MCNC and suggests including more comprehensive baselines as in [1]. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 3 lacks strong baselines, specifically mentioning MCNC and suggesting that the paper should include more comprehensive baselines as in [1]. However, the comment does not provide specific examples or detailed reasoning to support why these baselines are missing or why they are important. The suggestion to include more baselines is vague and lacks concrete evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, particularly those mentioned in [1]. It suggests that the paper should include more comprehensive baselines to provide a more robust comparison. However, the comment does not provide specific guidance on which baselines should be included or how they should be integrated into the table. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully guide the authors in making the necessary improvements."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on supplemental space to contain the paper, noting that this makes the paper less independent. It specifically mentions references to Sup. Fig. 6 in section 3.1 and the model comparison and other details of the span vs. sentence investigation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the paper more independent, but the comment does not offer concrete steps or examples of how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reliance on supplemental space to contain the paper, specifically mentioning references to Sup. Fig. 6 in section 3.1 and the model comparison and other details of the span vs. sentence investigation. This provides some grounding as it allows the authors to identify the relevant sections of the paper. However, the comment does not specify what needs to be addressed or improved in these sections, such as how to make the paper more independent or how to effectively integrate the supplemental material. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, making it less independent. This claim is 3 as it points out specific references to Sup. Fig. 6 in section 3.1 and the model comparison, suggesting that the paper\"s independence is compromised. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide more context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s reliance on supplemental space to contain certain information, such as references to Sup. Fig. 6 in section 3.1 and the model comparison. This highlights a potential problem with the paper\"s independence and comprehensibility. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as recommending ways to integrate the necessary information into the main text or providing alternative solutions. While it points out a critical area for improvement, the feedback is incomplete and does not offer detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a clarification about the input used in the Lample et al. BiLSTMCRF model, specifically mentioning that it is word embeddings. It also questions the figure, asking whether it shows KNs in the source language or in English, as the mentions have been translated to English. The authors have acknowledged the need to correct the figure, indicating that they will address this issue. While the comment provides explicit actions for the authors to take, such as clarifying the input and correcting the figure, it lacks detailed guidance on how to implement these changes. The authors know what needs to be done but may require additional information to fully execute the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the addition of a clarification about the input used in the Lample et al. BiLSTMCRF model and questioning the figure regarding the language of the mentions. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding a clarification about the input used in the Lample et al. BiLSTMCRF model and questions the figure regarding the language of the mentions. The authors have acknowledged the need to correct the figure, indicating that they will address this issue. However, the comment does not provide specific reasoning or evidence to support the need for clarification or the correction of the figure. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors clarify the input used in the Lample et al. BiLSTMCRF model, specifically mentioning that it is word embeddings. Additionally, it questions the figure, asking whether it shows KNs in the source language or in English, as the mentions have been translated to English. The authors have acknowledged the need to correct the figure, indicating that they will address this issue. While the comment identifies areas for improvement, it could be more helpful if it provided additional guidance or suggestions on how to clarify the input or correct the figure. Overall, the comment is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these weaknesses or suggestions for specific changes. The action is implicit and somewhat vague, as the authors can infer that they need to expand the experiments to include more diverse settings and tasks, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks. However, the comment does not specify which part of the paper these weaknesses are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and suggesting potential improvements, but without explicit references to sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are weak due to the limited setting to an extremely lowresource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these weaknesses or expand the experiments to include more diverse settings and tasks. The feedback is 3 as it provides insight into potential limitations, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether treating concept map extraction as a separate task is necessary. It provides a rationale by comparing it to generic summarization systems that build knowledge graphs and generate summaries. However, it does not explicitly instruct the authors to make any changes or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the treatment of concept map extraction, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also mentions the challenge of distinguishing concept maps with a growing number of nodes. However, the comment does not specify which part of the paper this discussion pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its critique of the concept map extraction process, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also discusses the challenge of distinguishing concept maps with a growing number of nodes. While the comment provides a logical reasoning for questioning the necessity of treating concept map extraction separately, it lacks specific examples or references to support the claim. The reasoning is 3, as it provides a basis for the question but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also points out the challenge of distinguishing concept maps with a growing number of nodes, suggesting that general summaries should be more readable. While the comment identifies an interesting point for consideration, it lacks specific suggestions or guidance on how the authors might address this issue or integrate it into their work. The feedback is 3 as it prompts the authors to reflect on the necessity of treating concept map extraction separately, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed set of questions that the authors should address to improve their draft. It explicitly instructs the authors to describe the traits of the experts, justify the need for expert annotation, and provide context on whether the experts were linguistic or domain experts. The comment also asks about the differences between expert and nonexpert annotation and whether it introduced linguistic challenges. These questions are clear and specific, guiding the authors on what information to include and how to address the points raised. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and addressing differences between expert and nonexpert annotation. The comment also raises questions about linguistic challenges introduced by expert annotation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts and the necessity of expert annotation, suggesting that the authors should provide more context. However, it does not provide specific evidence or references to support the claim that expert annotation is necessary or that it introduces linguistic challenges. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment provides a detailed set of questions that the authors should address to improve their draft. It prompts the authors to describe the traits of the experts and justify the need for expert annotation, which is crucial for understanding the methodology and its implications. The comment also raises questions about whether the experts were linguistic or domain experts and whether the annotation process differed from that of nonexperts. These questions are specific and actionable, guiding the authors to provide more detailed and comprehensive information in their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how to justify the need for expert annotation. Overall, the comment is 4 as it directs the authors to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the text, noting that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to correct the misleading statement or what changes should be made. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, noting that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed in the text. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the text, noting that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it points out a potential confusion in the text that the authors should address. By correcting this issue, the authors can improve the clarity and accuracy of their draft. However, the comment could be more helpful if it provided suggestions on how to rephrase the text to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors need to infer that they should include examples of the system in action. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, which implies that it addresses the methodology or results sections of the paper. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples of the system on actual texts, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While this feedback provides a clear direction for improvement, it lacks specificity and does not offer detailed guidance on how to incorporate these examples or what specific aspects of the system should be highlighted. The comment is 3 as it identifies an area for enhancement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or what aspects of these claims need further analysis. Without explicit guidance on which claims to focus on or how to conduct the analysis, the authors are left without a clear understanding of what actions to take. The comment lacks both specificity and directness, making it 1.", "grounding_specificity_rationale": "The comment suggests that certain claims in the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or what aspects of these claims need further analysis. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment does not provide any guidance on how to conduct this analysis or what specific issues should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that certain claims in the paper would benefit from more indepth analysis, but it does not provide any specific examples or reasoning to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or what aspects of these claims need further analysis. This lack of specificity and detail makes it difficult for the authors to identify and address the issues effectively. Without actionable guidance or examples, the comment provides limited value in helping the authors improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, including asking for clarification on the pooling method used for embedding features (line 397) and addressing the clarity of Equation (7) in line 472. It specifies what needs to be clarified or defined, such as whether E_i represents the type or identity of AC i, and suggests that the LHS of equation (7) should be a conditional probability. These actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (397 and 472), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly details what needs to be improved, such as clarifying the pooling method used for embedding features and the interpretation of Equation (7). The comment specifies that E_i should represent the type or identity of AC i and that the LHS of equation (7) should be a conditional probability. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and observations regarding the presentation of the model. It seeks clarification on the pooling method used for embedding features and questions the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i. The comment also points out a potential issue with the interpretation of the LHS of equation (7) as a conditional probability. While the comment raises valid points, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors would need to infer the implications of these questions and address them accordingly. Therefore, the comment is 3, as it provides some guidance but requires additional context or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397), which is crucial for understanding the model\"s architecture. Additionally, it questions the clarity of Equation (7) in line 472, specifically whether E_i represents the type or identity of AC i, and suggests that the LHS of the equation should be a conditional probability. These are clear and actionable points that provide the authors with specific areas to address and improve in their draft. By addressing these issues, the authors can enhance the clarity and comprehensiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer suggests that the paper is misleading and would have preferred a deeper exploration of these topics. However, the comment does not provide specific guidance on how the authors should address this issue or what additional steps they should take to study these hypotheses. The action is implicit and vague, as the authors are left to infer that they need to conduct further research or analysis on the hypotheses, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the hypotheses, noting that they are not studied or discussed again, which is misleading. The comment further suggests that the paper should go deeper into these topics, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer finds this misleading and suggests that the paper should go deeper into these topics. However, the comment does not provide specific examples or references to support the claim that the hypotheses are not tested or discussed, nor does it offer detailed reasoning or evidence to substantiate the suggestion that the paper should delve deeper into these topics. As a result, the claim is 3, as it provides a general observation but lacks detailed justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s hypotheses regarding multilinguality and country/languagespecific bias, noting that they are not studied or discussed again after being raised in lines 078086. The reviewer finds this misleading and suggests that the paper should go deeper into these topics, at least to some extent. This feedback is clear and actionable, as it points out a critical gap in the paper\"s analysis and provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific aspects of the hypotheses could be explored further. Overall, the comment is 4 as it highlights a significant weakness and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of feature engineering and suggests that using the same feature set as Uto et al. (2020) could improve the results. While the comment implies that the authors should consider feature engineering, it does not explicitly instruct them to do so or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore feature engineering and potentially follow up with Uto et al. (2020) for more details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of feature engineering and references Uto et al. (2020) as a system that achieves a QWK of 0.801 using handcrafted features. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area where this suggestion should be addressed. The comment is specific in suggesting that using the same feature set as Uto et al. (2020) could improve the results, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of feature engineering and references Uto et al. (2020) as a system that achieves a QWK of 0.801 using handcrafted features. This provides a specific example of a system that could potentially improve the results of the current work. However, the comment does not offer detailed reasoning or evidence to support the claim that feature engineering would be beneficial or how it could be implemented. The reference to Uto et al. (2020) provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of feature engineering and references a specific study (Uto et al., 2020) that achieved a QWK of 0.801 using handcrafted features. This suggests that the authors might consider using a similar feature set to improve their results. However, the comment does not provide detailed guidance or suggestions on how to implement feature engineering or what specific features might be beneficial. While it identifies an area for potential improvement, the feedback lacks depth and actionable advice, making it 3. The authors are given a direction to explore but are left without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split is used. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the use of the Challenge Set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split is used. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the use of the Challenge Set, which is a specific aspect of the paper. The authors can infer that it relates to the methodology or evaluation section, but the comment does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the use of the Challenge Set in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split is used. This feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the paper. The authors are left with a general understanding of what needs to be clarified but without detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of \"knowledge\" in the context of constituent parse and suggests that it might be misleading. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their claims. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the model generalizes to different knowledge and questions the representation of substructure as a sequence of words. It also questions the use of the term \"knowledge\" in the context of constituent parse, suggesting that it might be misleading. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area needing revision. While the comment is specific in its critique, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" in the context of constituent parse, suggesting that it might be misleading. The reviewer provides a logical reasoning by pointing out that \"knowledge\" is typically used to refer to world or external knowledge, such as a knowledge base of entities, rather than syntax or semantics. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to clarify their understanding of \"knowledge\" in the context of the paper to address this concern fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" in the context of constituent parse, suggesting that it might be misleading. The reviewer provides a logical reasoning by pointing out that \"knowledge\" is typically used to refer to world or external knowledge, such as a knowledge base of entities, rather than syntax or semantics. This feedback is clear and actionable, as it prompts the authors to reconsider their terminology and potentially reframe their claims to avoid confusion. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to clarify the use of \"knowledge\" in the context of the paper. Overall, the comment is 4, as it identifies a significant area for improvement and provides a clear direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It suggests that the authors should provide a better understanding of the gap between the performance of the clustering approach and the oracle GAP for PPDBClus. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance gap, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"nouns\" and \"parts of speech,\" allowing the authors to accurately identify the specific areas being addressed. It also specifies the issue by questioning the generalizability of the clustering approach and the performance gap between TWSI and PPDBClus. The comment is specific in detailing what needs to be addressed, such as understanding the gap in performance and clarifying the generalizability claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable to all parts of speech. The comment provides a logical reasoning based on the observed performance gap, suggesting that the authors should clarify this issue. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable. This feedback is clear and actionable, as it directs the authors to address the performance gap and clarify the generalizability claim. However, the comment could be more helpful if it provided suggestions on how to investigate and resolve these issues. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify why the new model is better than MH. This is a clear and direct action, giving the authors a specific task to perform. The comment also specifies what needs to be addressed, making it 5. The authors know exactly what information is needed to improve their draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is its abstract nature and the lack of clarity on why the new model is better than MH. The request for examples of spurious structures provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is abstract and lacks clarity on why the new model is better than MH. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the discussion is abstract or unclear. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks clarity on why the new model is better than MH. It provides a clear and actionable suggestion by asking the authors to provide examples of spurious structures. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete way to enhance the clarity and understanding of their work. However, the comment could be more helpful if it included additional guidance or examples of what constitutes spurious structures. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It explains that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the comment provides a clear suggestion for a specific baseline to consider, it does not explicitly instruct the authors to implement this suggestion or explain how it would improve their draft. The action is implicit but concrete, as the authors can infer the need to add this baseline and understand the reasoning behind it. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It explains that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the proposed baseline and the reasoning behind it, but without explicit grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It explains that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the suggestion is logical and provides a rationale for adding a baseline, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the potential benefits of this approach, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It explains that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. This feedback is 3 as it provides a specific suggestion for improving the experimental setup by adding a baseline that could help in comparing results. However, the comment could be more helpful if it included additional details on why this baseline is beneficial or how it could enhance the analysis. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While the action is explicit, it lacks concrete details on how this information should be presented or integrated into the paper. The authors know that they need to provide this information, but the comment does not specify where or how it should be included. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the maximum number of tasks done by any annotator. This provides clear guidance on what additional information should be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning, evidence, or examples to support why this information is important or how it could impact the paper. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While this is a specific piece of information that could enhance the transparency and completeness of the paper, it does not provide any context or reasoning as to why this information is important or how it could impact the analysis or interpretation of the results. The feedback lacks depth and does not offer actionable guidance on how to incorporate this information into the paper. Therefore, it is rated as 2, as it provides a suggestion but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the difficulty in understanding the overall message of the paper due to the numerous empirical results and analyses presented. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as clarifying the narrative or structuring the presentation of results. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of their presentation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"paper\" and the \"experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the overall message due to the numerous empirical results and analyses. The comment questions what the experiments reveal about the underlying research question and the specific hypothesis tested, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the overall message of the paper due to the numerous empirical results and analyses. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to address the issue effectively. The comment lacks explicit references or detailed explanations, leaving the authors without a clear path to improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall message of the paper due to the numerous empirical results and analyses presented. It questions the coherence and relevance of these results in relation to the underlying research question and the specific hypothesis tested. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to clarify and structure their presentation to better communicate the significance of their findings. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might enhance the clarity of their narrative. Overall, the comment is 4 as it directs the authors\" attention to a key area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. While the action is explicit, it does not provide specific guidance on how to implement this suggestion, such as which methods should be included or how to present the results. The comment is 3 because it identifies a specific action but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or table. The authors can infer that it relates to Table 1, but this inference is not explicit. The comment is specific in suggesting the inclusion of the hard prompt baseline to demonstrate performance increases, but it lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is a request for additional information, not a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This feedback is specific and actionable, as it provides a clear direction for enhancing the presentation of results in the paper. By including the hard prompt baseline, the authors can better illustrate the effectiveness of their methods and provide a more comprehensive comparison. However, the comment could be more helpful if it explained why the inclusion of this baseline is important or how it could impact the interpretation of the results. Overall, the comment is 4 as it offers a clear suggestion for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. While the comment identifies a gap in the paper, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include numerical results and comparisons, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed instructions.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. However, it does not specify which part of the paper lacks numerical results or where these comparisons should be made. This makes it difficult for the authors to identify the exact sections that need attention. The comment is weakly grounded because it does not provide specific guidance on where to find the numerical results or how to incorporate them. It is also not specific in terms of what needs to be addressed regarding the comparisons with existing DP algorithms. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses curiosity about the application of the method to popular algorithms and their performance compared with existing differential privacy algorithms. However, it does not provide any specific claims, opinions, or suggestions that require verification. The comment is purely descriptive and lacks any claims or evidence that would need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a significant gap in the paper by noting the absence of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and how their performance compares with existing differential privacy algorithms. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback provides a clear direction for the authors to consider, but it could be more helpful with additional details or examples. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are not comprehensive enough and recommends including results for wider backbones like ResNet50 (2x) and ResNet50 (4x) for methods like MoCo and SimCLR. This feedback is explicit, as it directly instructs the authors to expand their experimental comparisons. The suggestion is also concrete, as it specifies which methods and backbones to include. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are not comprehensive enough and recommends including results for wider backbones like ResNet50 (2x) and ResNet50 (4x) for methods like MoCo and SimCLR. While it does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the experimental results or comparisons section. The comment is specific in suggesting which methods and backbones to include, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not comprehensive enough, specifically mentioning methods like MoCo and SimCLR that test results with wider backbones like ResNet50 (2x) and ResNet50 (4x). The reviewer recommends including these wider backbones for the proposed InvP method. This claim is 3 as it provides a specific suggestion for improvement but lacks detailed reasoning or examples to fully substantiate the need for these additional comparisons. The authors would need to infer the importance of these comparisons based on the reviewer\"s suggestion, making the claim 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental comparisons, suggesting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2x) and ResNet50 (4x) to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their experimental setup to include these wider backbones, which could enhance the robustness and relevance of their results. By addressing this suggestion, the authors can strengthen their paper\"s contribution and provide a more thorough analysis of their method\"s performance. Therefore, the comment is 4, as it provides a specific and actionable direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not formal enough and recommends either formalizing this connection or adjusting the language to clarify it. While the action is explicit, it does not provide specific guidance on how to formalize the connection or what aspects of the language should be adjusted. The authors know they need to address the issue but may need additional information to fully implement the suggested changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of the probabilistic connection being drawn in the paper, suggesting that it is not formal enough to be considered more than motivational. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to either formalize the connection or adjust the language to clarify it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not formal enough to be considered more than motivational. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the probabilistic connection in the paper, noting that it is not formal enough to be considered more than motivational. It provides a clear suggestion for improvement by either formalizing the connection or adjusting the language to clarify it. This feedback is actionable and provides the authors with a clear direction for enhancing the clarity and rigor of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to formalize the connection. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for empirical evidence, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. However, the comment does not provide any specific evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. This feedback is 3 as it identifies a specific area where the authors can strengthen their paper by offering concrete evidence. However, the comment lacks depth and does not provide detailed guidance on how to collect or present this evidence. While it points out a potential weakness, it does not offer actionable steps or examples for the authors to follow, limiting its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could consider to improve the scalability of their approach. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. While the authors might infer that it relates to the robust training scheme or experimental results, the lack of explicit grounding makes it challenging to pinpoint the exact area of concern. The comment is specific in detailing the scalability issue, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a logical deduction but lacks detailed justification or data to substantiate the claim. As a result, the comment is considered 2, as it provides some reasoning but requires additional evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback is 3 as it identifies a potential limitation of the approach and provides a specific area for improvement. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or explore alternative approaches. To be more helpful, the comment could include specific recommendations or examples of how to mitigate the scalability problem. Therefore, the comment is rated as 3, as it points out a critical area for consideration but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of datasets and the duration of the study period. It asks whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. While the comment implies that the authors should provide more context or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the dataset choice and the nature of style shifts. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, it does not specify which part of the paper this discussion is related to, such as a particular section or table. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions about the dataset and style shifts, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. This feedback highlights an important aspect that the authors should consider when evaluating their dataset and methodology. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative datasets or methods to study style shifts. While it identifies a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the callout to Table 5 should be directed to Table 3, and it also mentions that the figure 6 callout is not directing properly. This provides clear and specific actions for the authors to take, namely, to correct the direction of the callouts. The feedback is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the callout to Table 5 should be directed to Table 3 and that the figure 6 callout is not directing properly. This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements about the direction of callouts in the paper, specifically mentioning that the callout to Table 5 should be directed to Table 3 and that the figure 6 callout is not directing properly. These are clear and specific observations that do not require additional justification or evidence. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two errors in the paper: the incorrect direction of callouts in Table 5 and Figure 6. By pointing out these issues, the reviewer helps the authors correct potential errors in their manuscript, which is crucial for maintaining the integrity and clarity of the paper. However, the comment could be more helpful if it offered suggestions on how to ensure accurate callouts in the future or provided examples of how to properly direct callouts. Despite this, the feedback is clear and actionable, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern with the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It also suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments, it does not provide explicit guidance on how the authors should address this concern or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to explain the selfcomparisons and consider additional comparisons, but the comment does not offer concrete steps or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the lack of comparisons with external work like SketchRNN. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which experiments are being referred to or what specific issues need to be addressed. The comment is specific in suggesting that comparisons with SketchRNN could be performed, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a concern because they only report selfcomparisons and lack an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue with the experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with SketchRNN provides some direction, but the comment could be strengthened by explaining why this comparison is important or how it would enhance the paper. Therefore, the comment is 3, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant concern with the experiments section of the paper, specifically noting that only selfcomparisons are reported and that there is no explanation for this choice. It also points out the lack of motivation for this approach. The comment suggests that comparisons with external work, such as SketchRNN, could be performed in a generative setting, which could enhance the paper\"s motivation and provide a more comprehensive evaluation. This feedback is clear and actionable, as it highlights a specific area for improvement and offers a concrete suggestion for enhancing the paper\"s experimental design. However, the comment could be more helpful if it provided additional guidance on how to integrate these comparisons or what specific aspects of the experiments should be expanded upon. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that more analysis and comments should be included regarding the performance trend of increasing the number of parameters for ViT (DeiT) in Figure 3. It also expresses disagreement with the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The reviewer provides specific examples and reasoning, such as the DeiTB models not outperforming DeiTT in APTOS2019 and not outperforming DeiTS on multiple datasets. This feedback is explicit and provides concrete guidance on what the authors should address, making it 5. The authors are given clear instructions on how to improve their analysis and presentation of the results, ensuring they know exactly what needs to be done to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trend of increasing the number of parameters for ViT (DeiT) and critiques the authors\" viewpoint regarding the similarity in benefit from increased model capacity between CNNs and ViTs. The reviewer provides specific examples and reasoning, such as the DeiTB models not outperforming DeiTT in APTOS2019 and not outperforming DeiTS on multiple datasets, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a claim that the authors\" viewpoint regarding the similarity in benefit from increased model capacity between CNNs and ViTs is incorrect. The reviewer provides specific examples and reasoning, such as the DeiTB models not outperforming DeiTT in APTOS2019 and not outperforming DeiTS on multiple datasets, which supports the claim. Additionally, the reviewer highlights that CNNs can give consistent model improvements as the capacity goes up, except on the ISIC2019 dataset. This provides a logical and detailed justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include more analysis and comments on the performance trend of increasing the number of parameters for ViT (DeiT) in Figure 3. It also offers a critique of the authors\" viewpoint regarding the similarity in benefit from increased model capacity between CNNs and ViTs, providing specific examples and reasoning to support the disagreement. By pointing out the lack of outperformance in certain datasets and highlighting the consistent improvements of CNNs with increased capacity, the comment offers detailed and constructive feedback that can help the authors refine their analysis and presentation. This feedback is 5 as it not only identifies a potential weakness in the paper but also provides clear guidance on how to address it, enabling the authors to improve their draft significantly."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might clarify or improve the confusing parts, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not specify which parts of the paper are confusing or what aspects need clarification. This makes it difficult for the authors to pinpoint the exact sections that require attention. The comment is weakly grounded because it does not provide specific references or details about the confusing parts, and it is not specific in terms of what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the paper is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issues mentioned. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any details or examples of these confusing parts, nor does it offer suggestions or guidance on how the authors might address these issues. Without actionable feedback or specific examples, the comment lacks the depth and clarity needed to be helpful for the authors. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point challenges the claim that there is no corresponding set of tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly instruct the authors to include these references or to address the claim in their draft. While the action is implied, it lacks concrete guidance on how to incorporate the references or refute the claim. Therefore, the comment is 3, as it provides a direction for the authors to consider but does not specify the exact steps to take.", "grounding_specificity_rationale": "The comment challenges a claim about the absence of corresponding tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or conclusion section, but this inference is not direct. The comment is specific in identifying the claim as false and providing references to support this, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges a claim by providing references that support the existence of corresponding tools for the reinforcement learning setting. This is a strong form of evidence, as it directly contradicts the initial claim with specific examples and references. The use of references adds credibility and substantivity to the counterpoint, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper, specifically questioning the assertion that there is no corresponding set of tools for the reinforcement learning setting. By providing references from the submitted paper and additional sources, the comment offers a counterpoint that supports the existence of such tools. This feedback is valuable as it encourages the authors to revisit their claim and potentially update their draft with relevant references. However, the comment could be more helpful if it explained why the references are relevant or how they support the claim. Overall, the comment is 4 as it prompts the authors to consider and address a potential oversight in their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the results are based on standard techniques but notes that they are not obvious a priori and require a fair degree of technical competency. While it highlights a potential issue with the results, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment lacks actionable details or concrete steps for improvement, leaving the authors uncertain about what specific aspects of the results need clarification or elaboration. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, indicating that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not specify which part of the paper this observation pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the results being not obvious a priori, it lacks grounding as it does not clearly identify the part of the paper being discussed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges that the results are based on \"standard\" techniques but notes that they are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential issue with the results, suggesting that they may not be as straightforward as they appear. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the clarity of their results. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not. While the comment implies that this distinction should be made, it does not explicitly instruct the authors to do so or provide specific guidance on how to implement this distinction. The action is implicit and somewhat vague, as the authors need to infer the need for this distinction and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates to the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. However, the comment does not provide detailed reasoning or examples to support why this distinction is necessary or how it would improve the paper. The mention of specific works provides some context, but the lack of detailed justification or explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. This feedback is 3 as it identifies a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide specific guidance on how to implement this distinction or why it is important. The authors are left with a general suggestion but without detailed instructions on how to apply it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their conclusion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or justification for their conclusions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not specify which part of the paper this analysis is based on, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its critique, it lacks full grounding, as the authors cannot confidently determine the exact section being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed comparisons or statistical analysis. The lack of supporting details or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s conclusion regarding the superiority of the direct model over the endtoend system. It points out that the amount of data used to train the text disambiguation model is significantly lower than that used for the endtoend system, and the difference in performance is only a few percentage points. This raises questions about the validity of the conclusion that the direct model is clearly the better of the two systems. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the paper: the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation. It explicitly states that the paper does not provide evidence or justification for GaRare\"s advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is explicit and provides concrete actions for the authors to take, such as providing theoretical justification and enhancing the algorithmic presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide a clear motivation for using GaRare and lacks evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for a more detailed algorithmic presentation is somewhat vague, as it does not specify what aspects of the algorithm should be clarified. Therefore, the comment is 3, as it provides some guidance but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the paper lacks a clear motivation for using GaRare, suggesting that it does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable, as it directs the authors to strengthen the motivation for their choice of method. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it provides a specific area for the authors to enhance the clarity and comprehensiveness of their work. Overall, the comment is 4 as it identifies clear areas for improvement and provides actionable feedback, but it could be more comprehensive by offering specific examples or references to support the suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions the performance of the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This provides a clear and explicit action for the authors to take, which is to conduct the ablation study and report the results. The comment also offers a specific example of what to investigate, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"visDial dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting an ablation study on the visDial dataset and asking for the result of a specific experiment involving the \"ATT(+H)\" model. This provides clear guidance on what additional analysis is needed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. While the comment provides a clear suggestion for additional analysis, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to conduct the suggested experiment to verify the claim themselves. Therefore, the comment is 3, as it provides a logical suggestion but lacks comprehensive justification or references.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This feedback is clear and actionable, providing a specific direction for the authors to enhance the robustness of their findings. By conducting this ablation study, the authors can better understand the impact of different components on the model\"s performance. However, the comment could be more helpful if it included additional guidance on how to interpret the results or what specific insights the ablation study might uncover. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not provide explicit guidance on how the authors should address this gap or suggest specific ways to incorporate these references into their work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references to strengthen their work\"s connection to existing literature. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. The authors can infer that it relates to the literature review or related work section, but this inference is not explicit. The comment is specific in detailing the missing link to similar work, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a connection to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure and the ability to perform exact inference. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to understand the exact nature of the missing link. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to support the assertion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s literature review by pointing out the absence of references to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These references are relevant because they have a similar structure to the CRF and the ability to perform exact inference. By highlighting this omission, the comment provides a clear direction for the authors to strengthen their work by including these references. However, the comment could be more helpful if it suggested specific ways to integrate these references or discussed how they might impact the paper\"s conclusions. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It also questions the lack of insights into how WPA works, which could be crucial for future research directions. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the model\"s predictions with np.ones input and why Gaussian noise input does not work as well as WPA. The comment further suggests that the authors should provide more insights into how WPA works, which could spark future research directions. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It questions the lack of insights into how WPA works, which could be important for future research directions. However, the comment does not provide specific examples or references to support the claim that Gaussian noise input does not work as well as WPA. The reasoning is based on the observation that Figure 2 suggests this, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by questioning the lack of explanation for why WPA works, particularly with np.ones input. It suggests that the authors should provide insights into the model\"s predictions and why certain inputs, like Gaussian noise, do not work as well as WPA. This feedback is valuable as it highlights an area where the paper could be improved to enhance its comprehensiveness and potential impact. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It requests more clarification on this similarity. While the comment implies that the authors should provide additional details or context to address this similarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is found in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its request for more clarification on the similarity, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It requests more clarification on this similarity. While the comment identifies a potential overlap, it does not provide specific details or examples of where this similarity exists, nor does it offer suggestions on how the authors might address or clarify this issue. This lack of depth and actionable guidance limits the comment\"s helpfulness, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) whether the proposed method is fairly compared with other methods, and (2) whether the proposed technique promotes existing Class incremental semantic segmentation methods. While the questions imply that the authors should consider these aspects in their evaluation, they do not provide explicit guidance on how to address these concerns. The comments are vague and lack concrete suggestions for improvement, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions regarding the proposed method. The first question asks whether the method is fairly compared with other methods, and the second question inquires about the promotion of existing Class incremental semantic segmentation methods. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity in detailing what aspects of the comparison or promotion are being questioned. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions regarding the fairness of comparison and the promotion of existing methods. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the fairness of comparison and the promotion of existing methods. The first question asks whether the proposed method is fairly compared with other methods, which is a valid concern that the authors should address. The second question inquires about the promotion of existing Class incremental semantic segmentation methods, which could be relevant to the broader impact of the work. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their comparison. While it identifies areas for improvement, the feedback is 3 as it points out potential gaps in the evaluation but does not provide detailed advice on how to address them. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental section (Sec. 3) does not discuss how the minimum cluster size and conductance threshold parameters are set, nor does it address the sensitivity of performance with respect to these parameters. This provides a clear and direct action for the authors to take, which is to include this information in the experimental section. The comment is explicit and concrete, guiding the authors on exactly what needs to be added or clarified in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 2.\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of discussion on how the minimum cluster size and conductance threshold parameters are set and how sensitive the performance is with respect to these parameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the minimum cluster size and conductance threshold parameters are set, nor does it address the sensitivity of performance with respect to these parameters. This is a factual statement that does not require verification, as it is based on the absence of information in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the lack of discussion on how the minimum cluster size and conductance threshold parameters are set, as well as the sensitivity of performance with respect to these parameters. This feedback is clear and actionable, as it directs the authors to include this information in their experimental section. By addressing this gap, the authors can provide a more comprehensive understanding of their experimental setup and results. However, the comment could be more helpful if it suggested how to present this information or provided examples of how other studies have handled similar parameters. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written in a concise manner due to space limitations and could benefit from a slower development to make it easier to read. While the comment implies that the authors should expand the section to improve readability, it does not provide specific guidance on what aspects should be expanded or how to achieve this. The action is implicit and somewhat vague, as the authors know they need to expand the section but lack detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is \"tersely written\" and could benefit from a slower development for easier readability. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is written in a concise manner due to space limitations, which could be improved for easier readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or improvements needed. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 4, noting that it is written in a concise manner due to space limitations. It suggests that the section could benefit from a slower development to make it easier to read. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to expand or elaborate on the content. The authors are left with a general idea of what needs to be addressed but without detailed steps or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a personal belief about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train models using gradient descent. However, it does not specify which part of the paper this critique pertains to, nor does it provide detailed guidance on how the authors might address this issue. The lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to improve it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any specific evidence, examples, or reasoning to support this claim. Without actionable feedback or suggestions for improvement, the comment lacks depth and does not offer the authors a clear path to address the issue. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete actions for the authors to take, making the comment 5. The authors know exactly what needs to be done to address the feedback, which is to include a specific table and provide an explanation. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, and that the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how the dataset is balanced across categories. While the comment identifies a potential issue with the paper, it lacks specific examples or references to support the claim that the distribution is crucial for robustness assessment. The suggestion to include a table and explain the dataset\"s balance is a logical response but lacks detailed justification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the distribution of video lengths within the benchmark dataset. It highlights the importance of this distribution for assessing reasoning ability and robustness, which is a critical aspect of the evaluation process. The comment provides a clear and actionable suggestion by recommending the inclusion of a table showing the distribution of video lengths and an explanation of how the dataset is balanced across categories. This feedback is detailed and constructive, offering the authors a straightforward way to enhance the clarity and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It specifically asks how the bilinear layer is different from other approaches, such as the dimensionality of embeddings, and whether the compression of representations using Equation (3) is still done in this case. While the comment does not explicitly instruct the authors to clarify these differences, it provides a clear and specific question that the authors can address to improve their draft. The action is implicit but concrete, as the authors know exactly what information needs to be clarified. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on how the implemented bilinear layer differs from other approaches that use bilinear pooling. The comment questions the differences in dimensionality of embeddings and the swapping of the bilinear layer with the Hadamard product and MCB approaches. Additionally, it inquires about the compression of representations using Equation (3). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks for clarification on the specific differences, such as the dimensionality of embeddings and the swapping of the bilinear layer with other approaches like the Hadamard product and MCB. The comment does not contain any claims or opinions that require verification. It is a request for clarification, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It specifically asks for clarification on how the bilinear layer is different from other approaches, such as the dimensionality of embeddings, and whether the compression of representations using Equation (3) is still done in this case. This feedback is 3 as it prompts the authors to clarify a potential point of confusion in their paper. However, it lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding their contribution until the promised dataset is made publicly available. However, it does not provide explicit guidance on how the authors should proceed or what actions they should take to address this issue. The comment lacks concrete details or suggestions on how to handle the situation, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset not being publicly available, which is a concern regarding the contribution. However, it does not specify which part of the paper discusses the dataset or how it is relevant to the contribution. The authors can infer that it relates to the dataset section or discussion, but this inference is not explicit. The comment is specific in identifying the issue of dataset availability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset promised in the paper is not yet publicly available, suggesting a cautious approach until the dataset is openly accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the availability of the dataset promised in the paper, suggesting a cautious approach until the dataset is openly accessible. This feedback is important as it points out a potential limitation in the reproducibility and accessibility of the research. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the situation. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to consider but does not fully support them in implementing the suggested action."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the limited novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It also points out that the group attention design is related to ResNeSt but is not discussed in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the novelty of their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, noting that it is similar to other attentional modules proposed in previous works. It also mentions the group attention design and its relation to ResNeSt, but it does not specify which part of the paper discusses these aspects. The authors can infer that the comment pertains to the methodology or related work sections, but they cannot pinpoint the exact sections being addressed. The comment is specific in detailing the issue of limited novelty and the similarity to other works, but it lacks full grounding due to the lack of explicit references to specific parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules proposed in previous works. It references specific works [1, 2, 3] and mentions the group attention design\"s relation to ResNeSt [4]. However, the comment lacks detailed justification or specific examples of how the proposed method is similar to these previous works, making it difficult for the authors to fully understand and address the critique. The references provided are not fully elaborated, leaving the authors with a vague understanding of the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It also points out that the group attention design is related to ResNeSt but is not discussed in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it highlights a potential weakness, it does not provide actionable feedback or constructive advice to help the authors improve their draft. Therefore, the comment is 2, as it provides some insight but does not offer actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials and their output cosine similarity will be very high. This feedback is explicit and provides a clear action for the authors to take, as it specifies what needs to be done to improve the presentation of their results. The suggestion is concrete, as it outlines a specific change that would enhance the clarity and effectiveness of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, suggesting that the authors should directly illustrate the results of the latter loss term of Eqn 13, given the high cosine similarity between the preactivation values of two networks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials and their output cosine similarity will be very high. This claim is 3 as it provides a logical reasoning based on the observation of high cosine similarity, which supports the suggestion. However, the comment lacks specific examples or references to external works that could further substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of results in Fig. 3 e, noting that the preactivation values of two networks are the same membrane potentials, which would result in a very high output cosine similarity. It suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, which is a clear and actionable suggestion. This feedback provides the authors with a specific area to improve, enhancing the clarity and effectiveness of their presentation. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4 as it guides the authors towards a specific improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as [AB], which aim to adapt to outofdistribution data. It also questions how to prove that data processing is superior to model parameter adjustment. While the comment implies that a comparison should be made based on experimental results, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and understand how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as [AB], which aim to adapt to outofdistribution data. It questions how to prove that data processing is superior to model parameter adjustment. However, the comment does not specify which part of the paper should include this comparison or where the discussion of data processing and model parameter adjustment is located. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique, it lacks full grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as [AB], which aim to adapt to outofdistribution data. It questions how to prove that data processing is superior to model parameter adjustment. While the comment identifies a potential gap in the paper\"s analysis, it lacks specific examples or references to support the claim that TTA methods are relevant or how they could be compared. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, such as [AB], which aim to adapt to outofdistribution data. It questions how the paper can prove that data processing is superior to model parameter adjustment. This feedback is 3 as it highlights an area for improvement and prompts the authors to consider a comparison that could strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment offers a direction for improvement but lacks depth and detail, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, specifying that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides a clear and direct action for the authors to take, namely to correct the expression. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J(\u03b8), suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This is a factual statement that does not require verification, as it is a matter of correcting a specific mathematical expression. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific error in the mathematical expression for J(\u03b8) in Section 3.2.1, suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This feedback is clear and actionable, providing the authors with a direct correction to make. By highlighting this error, the comment helps the authors improve the accuracy and clarity of their work. However, it could be more helpful if it explained why this correction is necessary or provided additional context on the importance of the expression. Overall, the comment is 4 as it guides the authors in making a specific improvement, but it could be more comprehensive with additional explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should correct the capitalization of various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and explicit action that the authors can take to improve the formatting of their references. The second part of the comment provides specific examples of references that need capitalization, which further clarifies the action. The second part of the comment is 3, as it suggests a specific correction but does not provide detailed guidance on how to apply it. Overall, the comment is 4 due to the explicit and concrete nature of the first part and the specific examples provided in the second part.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.8,\" \"p. 13, supplement, Fig,\" and references, allowing the authors to accurately identify the areas being addressed. It is also specific because it provides detailed feedback on the capitalization of words in the references and suggests corrections for specific examples, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This level of detail helps the authors understand what needs to be revised and how to make the necessary changes. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests capitalization corrections for specific words in the references, which is a clear and explicit action. The second part provides specific examples of references that need capitalization, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This level of detail and specificity supports the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct aspects of the paper. First, it suggests capitalization corrections for various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and direct way to improve the formatting and consistency of the references, which is an important aspect of academic writing. Second, it points out a typographical error in the reference \"Dusenberry et al. (2020) was published in ICML 2020,\" which is a helpful correction. Overall, the comment is 5 as it offers specific and actionable suggestions for improving the paper\"s formatting and accuracy, which can significantly enhance its quality and readability."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the parameter values used in the paper, specifically asking for clarification on the model parameters for task 1, the choice of lambda for the Boltzmann policy, and how the parameters were chosen. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, indicating that the authors know what information is missing and how to address it. The request for maximum likelihood estimates adds a concrete detail on how the parameters were chosen, further enhancing the actionability. Therefore, the comment is 4, as it provides explicit guidance on what needs to be clarified and how to address it.", "grounding_specificity_rationale": "The comment raises questions about specific parameter values and their selection, particularly regarding the Boltzmann policy. However, it does not specify which part of the paper these questions relate to, such as a particular section or table where these parameters are discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its requests for clarification on parameter values and their estimation, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific parameter values and their selection, such as the model parameters for task 1 and the choice of lambda for the Boltzmann policy. It also asks how the parameters were chosen, specifically mentioning maximum likelihood estimates. However, the comment does not contain any claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises specific questions about the parameter values used in the paper, particularly regarding the Boltzmann policy. It asks for clarification on the model parameters for task 1 and the choice of lambda, as well as how the parameters were chosen. This feedback is clear and actionable, as it provides the authors with specific areas to address and questions to answer. However, the comment could be more helpful if it offered suggestions on how to present this information or if it pointed out the potential impact of these parameters on the results. Overall, the comment is 4 as it guides the authors in improving their draft by identifying areas that need clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. However, the comment does not explicitly instruct the authors to perform these comparisons or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons to strengthen their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate this claim. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the results section or the discussion, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the need for comparisons with existing detection methods to substantiate the claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. The reviewer suggests conducting comparisons with existing detection methods to validate this claim. However, the comment lacks specific examples or references to support the claim that the performance is solely due to the first step, making it difficult for the authors to understand and address the critique effectively. The reasoning is somewhat vague and lacks detailed evidence, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate this claim. While the comment identifies a potential issue with the claim, it lacks specific guidance or suggestions on how to conduct these comparisons or what aspects to focus on. The feedback is 3 as it points out a potential weakness in the paper\"s claims, but it could be more actionable and comprehensive to be fully beneficial for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model. It specifically asks the authors to provide insight into why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. While the comment implies that the authors should explain this phenomenon, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm (CBN) to different layers, particularly layer 2 in addition to layers 3 and 4, compared to applying it to layers 4 and 3 only. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically questioning why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this observation or suggest why this might be the case. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, particularly in the context of the GuessWhat?! dataset. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 results in a deterioration of performance compared to applying it to layers 4 and 3 only. The comment is 3 as it identifies a specific area for improvement and prompts the authors to provide an explanation. However, it lacks detailed guidance or suggestions on how to address this issue, such as proposing alternative approaches or analyses. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed method. It also highlights the absence of performance comparison. This feedback is clear and direct, providing the authors with a specific action to take: include a comparison with the method proposed in [1] and perform a performance comparison. The comment is explicit and concrete, giving the authors a clear path forward for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lack of comparison with a highly relevant method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a comparison with a method proposed in [1] and the lack of performance comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning [1] as a method that proposes a similar approach. However, the comment does not provide specific details or examples of how the proposed method in [1] is relevant or how it could be compared to the current work. Without this additional context or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison with a highly relevant method, specifically mentioning [1] as a method that proposes a similar approach. This feedback is clear and actionable, as it directs the authors to include a comparison with this method and perform a performance comparison. By highlighting this omission, the comment provides a concrete step for the authors to take to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it effectively directs the authors to address a critical gap in their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit or implicit guidance on how the authors should address this confusion. The comment lacks actionable steps or suggestions for improvement, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the confusion caused by the implicit call to the Witness oracle, but it lacks grounding as it does not specify the exact location in the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the required implicit call to the Witness oracle is confusing. While it highlights a potential area of confusion, it does not provide any further details or suggestions on how the authors might address this issue or improve the clarity of the explanation. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it provides a starting point for the authors but does not fully address their needs for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to handle headpose. The action is implicit and vague, as the authors are left to infer that they need to explore ways to incorporate headpose conditioning into their NeRF model. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method\"s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the headpose issue or the proposed method\"s limitations, making it weakly grounded. The comment is specific in detailing the issue and referencing a previous work, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, which is deferred to future work. It questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. The comment provides a logical reasoning by comparing the proposed method with a previous work, suggesting that the current method lacks the capability to handle headpose as effectively as the referenced work. However, the comment lacks specific examples or detailed comparisons, making it 3. The authors would need to further explore the reasoning and provide more detailed evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed method, namely its inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. This feedback is 3 as it highlights a potential area for improvement and provides a reference for the authors to consider. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or incorporate headpose conditioning into their NeRF model. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The comment implies that the authors should consider the impact of these rare spurious examples on the trained model. However, it does not explicitly instruct the authors to take any specific action or provide detailed guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of these triggers on their model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples from previous works. The comment specifies what needs to be addressed, namely the impact of rare spurious examples on the trained model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The claim is supported by logical reasoning and references to external works, providing a clear and robust basis for the assertion. This makes the claim 5, as it offers both logical reasoning and specific examples to substantiate the claim. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides references to previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers, highlighting the potential impact of rare spurious examples on the trained model. This feedback is 3 as it points out a potential weakness in the paper and provides references for further exploration. However, it could be more helpful if it offered specific suggestions on how the authors might address this issue or mitigate its impact. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which can be confusing and reduces the contribution. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the originality of the optimization algorithm or provide additional details to enhance the contribution. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is mentioned several times in the paper, indicating that it is a main component. However, it does not specify which part of the paper this component is discussed in, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. This provides clear guidance on what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which is confusing and reduces the contribution. The comment provides a logical reasoning by pointing out the inconsistency between the emphasis on structural optimization and the use of an algorithm from previous works. However, it lacks specific references or examples to support the claim, making it 3. The authors would need to infer the specific parts of the paper being discussed, which adds to the challenge of addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the structural optimization component, noting that it is emphasized as a main component but seems to be directly from previous works. This observation highlights a lack of originality or contribution, which is a significant concern for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3. The authors are left with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the pipeline style method with two models does not yield better average results for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to improve the performance of their models or provide a more detailed explanation of the baseline models. However, the lack of concrete suggestions or steps makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3, as it provides a direction but lacks specific details on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method with two models, noting that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the experiments, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the performance and the lack of introduction of baseline models, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method with two models does not give better average results for both XVNLI and MaRVL, and that the baseline models in the experiments are not well introduced. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references to comparable studies, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the pipeline style method with two models does not yield better average results for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. This feedback is 3 as it points out areas where the paper could be improved, but it lacks depth and specificity. The authors are given a direction to improve their results, but the comment does not provide detailed guidance on how to enhance the performance of the models or how to better introduce the baseline models. To be more helpful, the comment could include suggestions or examples of how to address these issues, such as proposing alternative models or providing more detailed descriptions of the baseline models. Therefore, the comment is rated as 3, as it provides a starting point for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not explicitly instruct the authors to do so or suggest specific alternatives. The action is implicit and somewhat vague, as the authors can infer that they need to improve their methodology but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in its critique of the methodology and the need for improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, referencing the common knowledge that language models reproduce the biases of the corpora on which they are trained. However, the comment lacks specific examples or references to support the claim that the methodology is \"coarse\" or that the observation needs to be made again. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might improve their approach. The feedback is 3 as it points out a potential limitation but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific example of what needs to be included, making it 5. The authors know exactly what action to take and how to implement it, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work on modular networks for VQA\" and references [A], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of related work on modular architectures for VQA in the introduction. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction seems to imply that no one does modular architectures for VQA, but it does not mention related work on modular networks for VQA. This claim is based on the observation that the introduction lacks a specific reference to related work, which could be inferred as a gap in the literature. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of the claim and the need for additional references, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper\"s discussion of related work, noting that it does not mention related work on modular networks for VQA. This is a crucial oversight as it could lead the reader to believe that no one has explored modular architectures for VQA. By pointing out this omission, the comment provides clear and actionable feedback, encouraging the authors to include relevant references or discussions to address this gap. This feedback is valuable as it helps the authors improve the comprehensiveness and accuracy of their literature review, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons to provide a comprehensive analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, it does not specify which part of the paper this suggestion pertains to, such as the related work section or the method description. The authors can infer that it relates to the comparison section, but this inference is not explicit. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not pinpoint a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, the comment does not provide specific examples or references to these methods, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed justification or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the authors primarily focus on a single method, namely SSC, and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is valuable as it encourages the authors to broaden their analysis and provide a more comprehensive comparison, which could enhance the paper\"s depth and relevance. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or what aspects of these methods should be highlighted. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the distinction between training the proposed method with weak supervision versus semisupervised training. It provides a specific example from Table 1 and suggests renaming the column to \"Fully supervised\" to address the confusion. Additionally, it offers a more detailed suggestion to specify the data used to train all parts of each model, proposing the inclusion of two big columns: \"Mixture training data\" and \"Single source data.\" This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a renaming of the column to \"Fully supervised\" and proposes a more detailed approach to clarify the distinction between weak and semisupervised training. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors clarify the distinction between training the proposed method with weak supervision and semisupervised training. It provides a specific example from Table 1 and offers a suggestion for renaming the column to \"Fully supervised.\" Additionally, it proposes a more detailed approach to specify the data used to train each model, which could enhance clarity. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it offers a clear direction for improvement but could benefit from more detailed justification or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semisupervised training, particularly in Table 1. The reviewer offers a constructive suggestion to rename the column to \"Fully supervised\" and proposes a more detailed approach to specify the data used to train each model. This feedback is specific and provides a clear path for the authors to enhance the clarity and comprehensiveness of their paper. By addressing this issue, the authors can improve the understanding of their methodology and its application. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights the small contributions of the paper compared to previous methods, such as NCNet [6] and Sparse NCNet [21]. It also notes that the paper seems to be mostly engineeringfocused and performs similarly to its predecessors. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the identified issues or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific references to previous methods, such as NCNet [6] and Sparse NCNet [21], which provides some grounding as it allows the authors to identify the context of the comparison. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, related work section, or results section. This lack of specificity makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s contributions are small compared to previous methods, such as NCNet [6] and Sparse NCNet [21], and that it is mostly engineeringfocused. However, the comment lacks specific examples or detailed reasoning to support these claims. It mentions that the paper performs similarly to its predecessors, but without further elaboration, it is difficult for the authors to understand the basis of this comparison or how to address it. Therefore, the claim is considered 2, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the assertion.", "helpfulness_rationale": "The review comment highlights the small contributions of the paper compared to previous methods, such as NCNet [6] and Sparse NCNet [21]. It also notes that the paper seems to be mostly engineeringfocused and performs similarly to its predecessors. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these issues or improve their work. Without detailed guidance or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not provide actionable insights for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. It suggests that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. This feedback is clear and direct, providing the authors with a specific action to take: removing those statements. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term is not lowlevel. This feedback is fully grounded as it explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology and suggests removing statements about semantic segmentation being a lowlevel cue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. This claim is 3 as it provides a logical reasoning for the assertion, but it lacks specific examples or references to support the claim fully. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term is not lowlevel. This feedback is clear and actionable, as it provides a direct suggestion to remove statements about semantic segmentation being a lowlevel cue from the paper. By addressing this point, the authors can improve the clarity and accuracy of their terminology. However, the comment could be more helpful if it provided additional context or guidance on why this distinction is important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies a gap in the presentation of the results, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these cases in the tables, but the comment lacks concrete instructions on how to implement this change. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the ablation experiment, specifically mentioning the performance without reinforcement learning and the lack of listing cases where dependency tree and RL are not used. This provides some grounding as it refers to a specific part of the paper, but it does not specify which tables or sections are affected. The comment is specific in identifying the issue with the tables, but the lack of explicit mention of the sections makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree, and the two tables do not list the cases where dependency tree and RL are not used. This claim is 3 as it points out a specific issue with the presentation of results in the tables. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the issue and how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights a gap in the presentation of results, which could be addressed by including these cases in the tables. However, the comment lacks detailed guidance on how to present this information or suggestions for improving the clarity of the experiment. While it provides a starting point for the authors to consider, it could be more helpful with additional context or specific recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific weakness in the paper, namely the limited consideration of datasets in the experiments section. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. The comment provides concrete examples of relevant works and datasets, giving the authors clear direction on how to improve their experimental evaluation. This feedback is explicit and provides detailed guidance on what actions to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the limited consideration of datasets in the experiments, particularly those from Federated learning benchmarks. The comment suggests relevant works for the authors to consider, such as FedProx and FedMAX, providing clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main weakness is the limited consideration of datasets in the experiments section, specifically mentioning the CIFAR10 dataset and suggesting the inclusion of other datasets from Federated learning benchmarks. The comment provides references to relevant works, such as FedProx and FedMAX, which could guide the authors in expanding their dataset evaluation. However, the comment lacks specific examples or detailed reasoning on why these datasets are crucial or how they would enhance the paper. While the references are a step towards verification, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experimental evaluation, which is only conducted on the CIFAR10 dataset. It suggests that the authors should consider a broader range of datasets from Federated learning benchmarks, such as LEAF, to provide a more comprehensive evaluation. The comment also provides specific references to relevant works, FedProx and FedMAX, which could guide the authors in expanding their dataset and model types. This feedback is clear and actionable, offering the authors a concrete path to improve the comprehensiveness and robustness of their experimental evaluation. However, it could be more helpful if it included suggestions on how to integrate these datasets or how to structure the expanded evaluation. Overall, the comment is 4, as it provides valuable insights and actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim that the proposed modules improve accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. While the comment implies that the authors should consider using different datasets for their ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments with different datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, referencing a table. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This level of specificity allows the authors to understand what needs to be addressed, but the lack of grounding makes it challenging to pinpoint the exact section of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. However, the comment does not provide specific evidence or reasoning to support why the current dataset is insufficient or why the proposed modules might not be as effective as claimed. The suggestion to use different datasets is a logical point, but without detailed justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This feedback is 3 as it prompts the authors to consider alternative datasets for their ablation study, which could strengthen the evaluation of their proposed modules. However, the comment could be more helpful if it provided specific reasons why the current dataset might not be sufficient or detailed guidance on how to conduct the suggested evaluation. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It also points out that previous work has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment highlights potential issues and suggests areas for clarification, it does not provide explicit guidance on how the authors should address these concerns or improve the methodology. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It references previous work that has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology and the need for clarification, but without explicit grounding, it is challenging for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. The reviewer points out that previous work has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. The comment also questions the interpretability of the results. While the comment provides some reasoning and references to previous work, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It points out that previous work has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. Additionally, the comment questions the interpretability of the results and suggests that the improvements are marginal. While the comment identifies potential issues with the methodology and results, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it highlights areas for improvement but could be more actionable with detailed recommendations or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It also points out that Theorems 1 and 2 prove the relationship between GCL and a clearer community structure, but the connection between degree bias and this relationship is not intuitive. While the comment identifies an area for improvement, it does not provide explicit guidance on how to address this issue or what specific explanations are needed. The authors are left to infer that they should provide more detailed explanations or examples to clarify the relationship between degree bias and the community structure. Therefore, the comment is 3, as it highlights a specific area for improvement but lacks concrete instructions on how to implement it.", "grounding_specificity_rationale": "The comment addresses the need for more explanations regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which are specific to the paper, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment also specifies what needs to be addressed, namely, the lack of intuition in the relationship between degree bias and the community structure. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which are specific to the paper, providing some context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the relationship between degree bias and the community structure is not intuitive. While the mention of the theorems provides some support, the lack of specific evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which provide a foundation for understanding the relationship between GCL and community structure, but notes that the connection between degree bias and this relationship is not intuitive. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples to clarify this relationship. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided specific examples of what kind of explanations are needed. Overall, the comment is 4 as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect in their paper, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it points out a potential area for clarification but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 182183\" and \"Figure 2.c,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. By addressing this question, the authors can improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the comment is 4 as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. While the comment implies that the authors should provide additional clarification, it does not explicitly instruct them to do so or specify how much detail is required. The action is implicit and somewhat vague, as the authors know they need to clarify the notation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the notation and the split between \"static\" and temporal features, specifically mentioning \"S\" and \"Xt.\" This provides some grounding as it allows the authors to identify the relevant part of the paper, but it does not specify which section or subsection this issue is discussed in. The comment is specific in detailing the confusion and the need for more information about the variables \"S\" and \"Xt.\" However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation and the split between \"static\" and temporal features are confusing, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to address the issue effectively. The lack of detailed justification or references leaves the claim 3, as it requires the authors to infer the exact nature of the confusion and the need for additional information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, noting that it is confusing and requires more information than is provided in the paper. It specifies the need for clarification on what \"S\" and \"Xt\" represent, which is a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it provided examples or detailed guidance on how to improve the notation or split, such as suggesting alternative ways to present this information. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. While the comment implies that more details are needed, it does not explicitly instruct the authors to provide these details or specify how to do so. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not know exactly what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions \"many graph notions\" and suggests that the writing is generally good but could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which sections or parts of the paper are being addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting what needs to be addressed, but the lack of grounding makes it challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that it deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. This feedback is 3 as it points out areas where the paper could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to improve the clarity of their writing, but the comment could be more detailed to be fully actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the originality of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the originality of the paper, stating that the main idea of variable splitting is not new and that the algorithm is also not new. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity in detailing what aspects of the originality are limited or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the originality of the paper by pointing out that the main idea of variable splitting is not new and that the algorithm is also not new. This feedback is clear and actionable, as it identifies a specific area where the authors can enhance the originality of their work. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve the originality of their contribution. While it highlights a potential weakness, it does not offer detailed guidance or examples of how to overcome it. Therefore, the comment is 3, as it provides a starting point for the authors to consider but lacks comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It explicitly asks for quantitative results on testing images, providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies what additional information is needed to strengthen the evaluation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the evaluation on transformations of training images and suggests the need for quantitative results on testing images. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether evaluation on transformations of training images fully proves the point. It suggests the need for quantitative results on testing images. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the evaluation is insufficient. The suggestion for quantitative results on testing images provides some direction but does not fully substantiate the claim. Therefore, the comment is 3, as it highlights a concern but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It suggests the need for quantitative results on testing images, which is a constructive and actionable feedback. This comment helps the authors understand the limitations of their current evaluation and provides a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to conduct these quantitative evaluations or what specific metrics should be used. Overall, the comment is 4 as it identifies a potential weakness and provides a clear direction for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. The comment implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it with the current work would provide a better understanding of the stateoftheart. While the comment explicitly states that the paper should be discussed, it does not provide detailed guidance on how to integrate this paper into the draft or what specific aspects should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to incorporate this paper into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. It implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it with the current work would provide a better understanding of the stateoftheart. However, the comment does not specify which part of the paper this suggestion pertains to, such as a section or a particular discussion. This makes it difficult for the authors to identify the exact area where this related work should be integrated. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, is a related work that was possibly missed by the authors. The comment suggests that this paper deals with hypergraph data and tensors, and it should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment does not provide specific details or examples of how this paper relates to the current work or what aspects should be compared. This lack of detailed justification or examples makes the claim 3, as the authors would need to independently verify the relevance and potential impact of the suggested paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the literature review by suggesting that the authors may have missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati. This paper deals with hypergraph data and tensors, which are relevant to the current work. The comment implies that discussing and comparing this paper with the current work would provide a better understanding of the stateoftheart. While the comment highlights an important omission, it does not provide specific guidance on how the authors should integrate this paper into their draft or what aspects of the paper should be compared. The feedback is 3 as it points out a potential gap in the literature review but lacks detailed actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It explicitly requests the authors to demonstrate the scalability on normal machines with a couple of cores. Additionally, the reviewer asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. This feedback is explicit and provides concrete actions for the authors to take, such as demonstrating scalability and explaining the computation of optimal transport. The comments are clear and actionable, guiding the authors on what specific aspects need clarification or demonstration. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the scalability of the optimal transport method and questions the authors\" claim about the computation time on a 36core machine. It also asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. While the comment does not explicitly mention a specific section, it is clear that it pertains to the methodological aspects of the paper, particularly the optimal transport computation. The authors can infer that it relates to the methodology section, but the comment lacks explicit references to specific parts of the paper. The feedback is specific in detailing what needs to be addressed regarding scalability and computation, making it somewhat grounded and specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It also asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. While the comment identifies potential issues with scalability and computation, it lacks specific examples or references to support these claims. The reasoning is based on general observations about the method\"s scalability and the need for further explanation, making the claim 3. However, the lack of detailed evidence or examples limits the thoroughness of the justification, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises important questions about the scalability of the optimal transport method and the computation time, which are critical aspects for the authors to address. It points out that while the authors claim the method takes seconds to compute on a 36core machine, it is not clear how it scales on normal machines with fewer cores. This feedback is actionable as it prompts the authors to demonstrate the method\"s scalability and provide a detailed explanation of how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. The comment is clear and provides specific areas for improvement, making it 4. However, it could be more helpful if it offered suggestions on how to demonstrate scalability or compute optimal transport. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of their work. There is no guidance on how to simplify the procedures, clarify the evaluations, or present the information in a more accessible manner. Without specific suggestions or steps, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not specify which sections or parts of the paper are particularly challenging to follow, making it weakly grounded. The comment is specific in its feedback, as it clearly identifies the issue of difficulty in understanding the experimental procedures and evaluations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed evidence or explanation makes it difficult for the authors to understand the basis of the difficulty and how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. While it identifies a significant issue with the paper\"s clarity, it does not provide specific suggestions or actionable feedback on how the authors might improve the clarity of their work. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or clarifications are needed to enhance the readability and comprehensibility of their draft. Therefore, the comment is 2, as it highlights a problem but lacks actionable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim in section 2 that the INRs operate on a perdatainstance basis and questions its advantage. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this might not be an advantage because it limits the model to handle only a single time series data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement \"INRs operate on a perdatainstance basis\" is true but questions its advantage. The reviewer provides a logical reasoning by suggesting that a model limited to handling only a single time series data is almost useless. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the notion of a model\"s usefulness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a claim in section 2 regarding the operation of INRs on a perdatainstance basis and questions its advantage. It points out that a model limited to handling only a single time series data is almost useless, which is a valid concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important point, the feedback could be more actionable and comprehensive to be considered 5. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a limitation in the experiments conducted, specifically noting that most of the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It suggests that the authors should investigate the generalizability of their results to differences in model size, objective function, and architecture, including the analysis of GPT2. The comment provides a specific example of what could be included, such as the results of Figure 2 for GPT2. This feedback is explicit and provides concrete guidance on what additional experiments or analyses the authors should consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the limited experiments, suggesting that the results should be generalized to other models adopting learnable APEs and providing examples of what could be included, such as the results of Figure 2 for GPT2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It suggests that the results should be generalized to differences in model size, objective function, and architecture, including the analysis of GPT2. The comment provides a specific example of what could be included, such as the results of Figure 2 for GPT2. This feedback is 4 as it offers a clear suggestion for improvement but lacks detailed references or specific examples to fully substantiate the claim. The authors would need to conduct additional experiments or analyses to fully address the suggestion, making the comment 4.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments conducted, specifically noting that most of the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It suggests that the authors should investigate the generalizability of their results to differences in model size, objective function, and architecture, including the analysis of GPT2. The comment provides a specific example of what could be included, such as the results of Figure 2 for GPT2. This feedback is clear and actionable, offering the authors a path to improve the generalizability of their findings and enhance the robustness of their conclusions. By addressing this suggestion, the authors can significantly strengthen their draft, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to demonstrate generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the parameters in Table 1 are only applicable to image data and ViT models, suggesting that the authors should consider applying the same principles to other areas such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the method might not be generalizable, it does not provide specific examples or references to support this claim. The suggestion is based on a logical assumption that the method\"s performance might not extend beyond the specified domains, but without detailed evidence or reasoning, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate the method\"s generalizability. This feedback is valuable as it encourages the authors to expand their experiments and potentially enhance the applicability of their method. However, the comment could be more helpful if it provided specific suggestions or examples of how to adapt the method to these other areas. Overall, the comment is 4 as it identifies a potential limitation and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an interesting observation about the performance of TTA methods on nonstandard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS [9], could strengthen the paper. While the comment implies that the authors should consider evaluating their methods on additional benchmarks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more conditions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TTA methods, specifically mentioning the observation that using nonstandard benchmarks breaks popular TTA methods. It suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS [9]. However, the comment does not specify which part of the paper this observation is based on, making it weakly grounded. The suggestion to evaluate on additional conditions is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point makes a claim about the performance of TTA methods on nonstandard benchmarks, suggesting that it breaks popular TTA methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. The suggestion to evaluate TTA on more conditions of natural distribution shift, like WILDS [9], is a logical extension but lacks detailed justification or evidence. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods on nonstandard benchmarks, noting that it breaks popular TTA methods. It suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS [9], could strengthen the paper. This feedback is 3 as it points out a potential limitation of the current evaluation and offers a specific direction for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to implement this suggestion or discussed the implications of evaluating TTA on additional conditions. Overall, the comment offers a valuable insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with largescale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the scalability of the learning rate condition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the required condition on the learning rate, noting that it is not scalable and questioning the practicality of having a step size that grows with the sample size. However, it does not specify which part of the paper this condition is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the scalability of the learning rate condition and its potential impact on largescale datasets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with largescale datasets. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. The authors are left to infer the potential impact of this issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. This observation is relevant and could prompt the authors to reconsider their assumptions or approach. However, the comment lacks detailed guidance or suggestions on how to address this issue or improve the scalability of the learning rate condition. While it highlights an important area for consideration, the feedback could be more helpful with additional context or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the utility of tensor networks in representing the PMF of discrete variables and their relevance to machine learning algorithms or analysis. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify the significance of their paper or what specific aspects need to be elaborated upon. As a result, the authors are left without a clear understanding of what changes or additions are necessary to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the utility of tensor networks in representing the PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this critique pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in questioning the utility of the results and the significance of the paper, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results of using tensor networks to represent the PMF of discrete variables are not clear in terms of their utility for machine learning algorithms or analysis. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity regarding the utility of tensor networks in representing the PMF of discrete variables and their relevance to machine learning algorithms or analysis. This feedback highlights a critical area that needs improvement, as it questions the significance of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the clarity of their work. While it points out a potential weakness, it does not provide actionable steps or detailed feedback that could help the authors improve their draft. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting by sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. This is an explicit suggestion that provides a concrete action for the authors to take, which is to replicate the approach used in the referenced work. The comment also explains why this is important, noting that the current dataset is perfectly balanced, which is impractical in realworld applications. This level of detail and specificity makes the comment 5, as it gives the authors a clear and concrete path to follow for improving their draft.", "grounding_specificity_rationale": "The comment addresses the use of unlabeled data from the Amazon review dataset, specifically mentioning the Blitzer version. It points out that the dataset is perfectly balanced, which is impractical in realworld applications, and suggests using a more convincing setting as in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. This provides a clear and specific reference to the part of the paper where this issue is discussed, making the comment fully grounded. The suggestion is also specific, as it offers a concrete example of how to address the imbalance in the dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the Amazon review dataset is perfectly balanced, which is impractical in realworld applications. It suggests using a more convincing setting, referencing a specific paper (Adaptive Semisupervised Learning for Crossdomain Sentiment Classification) as an example. However, the comment lacks detailed reasoning or evidence to support why this imbalance is problematic or how the suggested approach would address it. The reference to the cited paper provides some context, but the claim itself remains 3 due to the need for more detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of unlabeled data in the Amazon review dataset, noting that it is perfectly balanced, which may not reflect realworld scenarios. It suggests using a more convincing setting, such as the one described in the referenced paper (Adaptive Semisupervised Learning for Crossdomain Sentiment Classification), which involves sampling unlabeled data from millions of reviews. This feedback is clear and actionable, as it provides a specific suggestion for improving the dataset\"s realism and relevance. By referencing a relevant paper, the comment offers a concrete example of how to address the issue, making it 5 for the authors to enhance their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could take to improve their sampling method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) on line 130. It also compares this issue to sampling from the leverage score in [3]. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically Equation (10) and the reference to [3]. The comment is specific because it clearly details the problem with sampling from the DPP and compares it to a similar issue with the leverage score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. The reviewer provides a logical comparison, suggesting that sampling from the DPP might be more challenging than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the comparison is relevant, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. This feedback is 3 as it identifies a potential weakness in the sampling method and provides a relevant comparison. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve their sampling method. As it stands, the comment provides a starting point for the authors to consider, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\"s contributions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the generalization of observations to fewshot learners beyond Prototypical Networks, which is a specific aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what needs to be addressed, it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\"s contributions. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated. This observation is important as it highlights an area where the paper could be strengthened. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional analyses or experiments could be conducted to evaluate generalization. While it points out a critical area for improvement, the feedback is 3 as it provides a direction for potential enhancement but does not offer detailed actionable steps. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the handling of different modalities in Equation 3, noting that the equation directly removes the modal subset of all instances. It explicitly asks the authors to address this issue, providing a clear and direct action for them to take. The comment specifies the problem and suggests a potential area for improvement, making it 5. The authors know exactly what needs to be done to address the concern, which is to deal with the problem mentioned above. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the equation deals with the problem of different modalities of different instances having varying contributions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about Equation 3, questioning how it deals with instances where different modalities have varying contributions. The comment suggests that the equation directly removes the modal subset of all instances, implying a potential issue with the handling of different modalities. However, the comment lacks specific examples or detailed reasoning to support the claim that the equation is problematic. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation 3, noting that it directly removes the modal subset of all instances, which could be problematic given the varying contributions of different modalities. It raises a concern about how the equation deals with instances where different modalities have varying contributions, such as instances with good performance of modality A or modality B. The comment provides a clear and actionable suggestion for the authors to address this issue, prompting them to consider how to handle the varying contributions of different modalities. This feedback is valuable as it directs the authors\" attention to a potential weakness in their methodology and offers a specific area for improvement. However, the comment could be more helpful if it provided additional guidance or examples on how to address the issue. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit feedback on the abstract, stating that it does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The authors are aware of what needs to be improved but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the abstract lacks description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract lacks description of how the idea was evaluated and what the outcome was, and mentions minor language issues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it provides a good explanation of the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include more information about the evaluation process and outcomes. Additionally, the comment mentions minor language issues, which can be addressed to improve the clarity and precision of the abstract. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to enhance the abstract further. Therefore, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional suggestions. This aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the lack of experiments on the POMDP problem with nonconvex value functions, specifically mentioning examples like surveillance in museums with thresholded rewards and privacy preserving data collection. The reviewer suggests that the experiments section is not useful due to the absence of experiments on these settings. While the comment highlights a potential issue with the experimental design, it does not provide explicit guidance on how the authors should address this concern or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors can infer that more experiments are needed but are not given clear instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the POMDP problem with nonconvex value functions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the lack of experiments on the examples provided, such as surveillance in museums with thresholded rewards and privacy preserving data collection, and suggests that the experiments section is not useful due to this absence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section is not useful due to this absence. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiments are not useful. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section is not useful due to this absence. While the comment identifies a potential issue with the experimental design, it lacks specific suggestions or guidance on how the authors might address this concern or improve the experimental setup. The feedback is 3 as it points out a gap in the experimental validation, but it could be more actionable with additional details or suggestions for enhancing the experiments. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusing description of the MFDA setting in the Method Section, specifically mentioning the use of \"single target domain with sparse labels\" and the labeling of the target distribution p_T(x, y) with label observation. It also questions the notation for the target domain \u03c7 and references the original MFDA paper (Yue et al., 2021a) for clarification. The reviewer points out that the problem setting description differs significantly from the original paper, leaving the authors with a clear action to take: clarify the description of the MFDA setting and ensure consistency with the original paper. However, the comment does not provide specific guidance on how to resolve the confusion or what aspects of the description need to be clarified. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the description of the MFDA setting, particularly the confusion regarding the labeling of the target domain and the unlabeled data in source domains. The comment references the original MFDA paper (Yue et al., 2021a) for clarification, providing a clear basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) to provide context and suggests that the problem setting description differs significantly from the original paper. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the original paper provides some support, but the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) for clarification, suggesting that the problem setting description differs significantly from the original paper. This feedback is clear and actionable, as it directs the authors to clarify the description of the MFDA setting and ensure consistency with the original paper. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or offered alternative ways to present the information. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It suggests that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it does not explicitly instruct the authors to include this analysis in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion about the potential benefits of epochwise analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to incorporate this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, the comment does not provide specific examples or references to support the claim that epochwise analysis would be beneficial or how it could be implemented. The reasoning is based on logical inference rather than empirical evidence or detailed examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to implement this analysis or what aspects to focus on. The suggestion is 3 as it points out a potential avenue for enhancing the paper\"s analysis, but it lacks detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the perceived incremental nature of the contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It also suggests that the paper should introduce RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to review and possibly expand their literature review, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code and the article, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the contribution being incremental, the lack of citation of key baselines, and the omission of essential RAG algorithms like MedRetriever and KGRAG. The reviewer provides references to specific works, such as GraphRAG, GraphCare, MedRetriever, and KGRAG, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental and consists of a combination of GraphRAG and GraphCare, without providing specific evidence or references to support this claim. The comment also mentions the lack of citation of key baselines and the omission of essential RAG algorithms, but it does not provide detailed examples or references to substantiate these claims. The suggestion to introduce RAG algorithms like MedRetriever and KGRAG is a logical inference but lacks specific justification or evidence. Therefore, the comment is 3, as it provides some reasoning but lacks detailed support or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several areas for improvement. It points out that the contribution is incremental and suggests that the paper is essentially a combination of existing works, such as GraphRAG and GraphCare. The reviewer also notes the lack of citation of key baselines and the omission of essential RAG algorithms, such as MedRetriever and KGRAG. This feedback is valuable as it directs the authors\" attention to areas that need further development and provides specific suggestions for improvement. However, the comment could be more helpful if it offered additional guidance on how to integrate these references or algorithms into the paper. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification and suggests potential issues, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to clarify the classification and the role of local regulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and references specific lines (438441) in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly details the issue with the differentiation between the 3 classes of extreme speech and questions the classification of a particular instance. The comment provides a clear rationale for the confusion and suggests a potential impact on zeroshot crosscountry classification, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the specific issues and how to address them, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the differentiation between the 3 classes of extreme speech, particularly the distinction between derogatory and exclusionary extreme speech. It raises a question about the classification of a particular instance and suggests that the authors need to clarify why it is categorized as exclusionary extreme speech. Additionally, the comment questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. This feedback is clear and actionable, as it provides specific areas for the authors to address and improve their classification framework. However, it could be more helpful if it offered suggestions on how to clarify the classification or address the impact of local regulation. Overall, the comment is 4, as it guides the authors toward improving their draft by identifying specific areas for clarification and potential issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This action is clear and direct, providing a specific and concrete step for the authors to take to address the issue of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. The comment also highlights the importance of this analysis and provides a clear rationale for why it is necessary. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on which part of the paper should be addressed, making it easy for the authors to identify the specific section. The comment is also specific because it details what needs to be addressed, namely, understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. This includes the suggestion to consider algorithms that skip layers or channels, which provides a clear direction for the authors to explore. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. The rationale provided is that this graph would help understand whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet, such as a large fraction of images that can be done with a glance. The comment also mentions that algorithms skipping layers or channels might have an unfair advantage due to lower resolution. While the suggestion is clear, the comment lacks specific examples or references to support the claim about the unfair advantage of algorithms skipping layers or channels. This makes the claim 3, as it provides a logical basis for the suggestion but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This is important because it allows the authors to understand whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the potential unfair advantage of algorithms that skip layers or channels, which is a relevant consideration for the authors to address. By providing a specific and detailed suggestion, the comment offers valuable guidance for improving the draft, making it 4. However, it could be more helpful if it included additional context or examples to further support the reasoning. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct, implying that the authors should revise the content to ensure it aligns with mathematical standards. Additionally, it questions the notation \"L_l\" and suggests that it should be introduced beforehand. While the comment implies that changes are necessary, it does not provide explicit instructions on how to make these changes or what specific aspects need to be revised. The action is implicit and somewhat vague, as the authors can infer the need for changes but lack detailed guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"mathematically correct,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the notation \"L_l\" and suggests that it should be introduced beforehand. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct and questions the notation \"L_l\" without providing specific examples or references to support these claims. The comment lacks detailed reasoning or evidence to substantiate the need for changes or the rationale behind the suggested notation. As a result, the claim is not 5, as it does not provide sufficient justification for the authors to understand or address the issues effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical correctness of the text and suggests that it needs to be revised. It also questions the notation \"L_l\" and recommends introducing it beforehand. However, the comment lacks specific guidance on how to make the changes or what aspects of the notation need to be addressed. While it points out areas for improvement, the feedback is 3 as it provides some direction but does not fully empower the authors to make effective revisions. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions that this limitation prevents the use of single deep neural networks on homomorphically encrypted data. While the comment emphasizes the need for further research, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this limitation further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need to study noise accumulation and its impact on the use of deep neural networks on homomorphically encrypted data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that it is important to study the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a critical issue. Without specific examples, references, or logical reasoning, the claim remains 1. The authors are left without guidance on how to address this issue or why it is significant, making the comment difficult to act upon. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a critical limitation in the study, specifically the impact of noise accumulation in the context of homomorphic encryption on sequential ensembling. It emphasizes the importance of studying this effect, which is a relevant and significant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or what aspects of their work could be improved. While it identifies a crucial area for further exploration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the evaluation of the timeaware model, suggesting that the effectiveness of the proposed methods might be questionable when the training and evaluation timesteps are different. It implies that the authors should consider evaluating their methods under different timestep scenarios to better understand their performance. However, the comment does not explicitly instruct the authors to conduct such evaluations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional evaluations and how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same, suggesting that the authors should consider different scenarios where the timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the timeaware model, suggesting that the effectiveness of the proposed methods might be questionable when the training and evaluation timesteps are the same. The reviewer implies that the results in Figure 5 might not fully demonstrate the proposed method\"s effectiveness. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the timeaware model, noting that similar performance is observed between the baseline and the timeaware model when trained and evaluated with the same timestep. This observation raises questions about the effectiveness of the proposed methods under these conditions. The comment suggests that the authors should consider evaluating their methods under different timestep scenarios to better understand their performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation methodology. However, it could be more helpful if it included specific recommendations or examples of how to conduct these evaluations. Overall, the comment is 4 as it guides the authors towards a more comprehensive evaluation of their methods."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors but does not provide details on how this is realized or guaranteed. The comment explicitly suggests that the authors should clarify this aspect, indicating a clear action for the authors to take. However, it does not provide specific guidance on how to address this issue, such as which sections or methods should be revised. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the realization and guarantee of disentanglement, but it lacks full grounding due to the lack of explicit section references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not provide specific examples or detailed reasoning to support the claim that the disentanglement is not clear. The reference to the \"Broader Impacts and Limitations\" section provides some context, but it does not offer sufficient evidence or explanation to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors, it does not provide details on how this is realized or guaranteed. This feedback is clear and actionable, as it directs the authors to clarify this aspect, which is crucial for understanding the methodology and limitations of the work. However, the comment could be more helpful if it suggested specific ways to address the issue, such as providing additional explanations or examples. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the action is explicit, it does not provide specific guidance on which regularization trick to use or how to implement it. The comment lacks concrete details on the exact steps to follow, making it 3. The authors know they need to incorporate a regularization trick, but the lack of specific instructions on how to do so limits the level of actionability.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding the nature of the regularization trick or how it should be applied. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the comparison. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the comment identifies a potential improvement in methodology, it lacks specificity and does not provide detailed guidance on which regularization trick to use or how it should be applied. This limits the usefulness of the feedback, as the authors are left with a general suggestion but without actionable steps to implement it. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making the necessary changes. This aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This action is clear and direct, providing the authors with a specific task to perform. The comment also specifies what needs to be compared, which is the effect of mean teacher on learning acceleration or deceleration. This level of detail and directness makes the action concrete, allowing the authors to know exactly what changes to make to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the left graph in fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is including a learning curve for a model without mean teacher or pi regularization for comparison. This provides clear guidance on what additional information should be included in the graph. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This is a request for additional information to provide context for the learning curve presented in the graph. The comment does not contain a claim or an opinion that requires verification. It is a factual suggestion for improvement, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity and interpretability of Figure 3 by including a learning curve for a model without mean teacher or pi regularization. This addition would allow the authors to demonstrate the effect of mean teacher on learning acceleration or deceleration, providing a valuable comparison. The feedback is clear and actionable, offering a concrete way for the authors to enhance their draft. However, it could be more helpful if it included additional guidance on how to present this comparison effectively or if it suggested specific metrics or methods for evaluating the learning curves. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed objective equation (Eq. 2) requires optimization over both the parameters of the transformation \u03a6 and the shared model \u03b7_S. It also notes that the impact on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. While the comment identifies a specific area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should discuss the impact on the number of parameters and compare it to prior work. However, the comment lacks concrete details on how to structure this discussion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2\" and \"line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the proposed objective equation requires optimization over both the parameters of the transformation \u03a6 and the shared model \u03b7_S, and that the impact on the number of parameters compared to prior work has not been discussed clearly. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation (Eq. 2) requires optimization over both the parameters of the transformation \u03a6 and the shared model \u03b7_S, and that the impact on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. The comment provides a specific reference to prior work, which helps to ground the claim. However, it lacks detailed reasoning or examples to fully substantiate the claim about the impact on the number of parameters. While the reference to prior work provides some context, the comment could be strengthened with additional analysis or examples to fully support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in the paper. It points out that the optimization process involves both the parameters of the transformation \u03a6 and the shared model \u03b7_S, which could impact the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019). However, the comment does not provide detailed guidance on how the authors should address this issue or what specific aspects of the impact on the number of parameters should be discussed. While it highlights an important area for clarification, the feedback lacks depth and actionable suggestions, making it 3. The authors are given a direction to consider, but they need to further develop the comment to make it more comprehensive and actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provide solutions in the paper. It also mentions that the citation seems disordered. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to improve the organization of their paper and discuss input handling, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests that the authors should present their solutions in the paper. It also mentions that the citation seems disordered. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting the need to discuss input handling and the organization of citations, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provides a suggestion for improvement by mentioning the need to present solutions in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this is important or how it could be addressed. The mention of a \"disordered citation\" is a separate issue that could be addressed independently. Therefore, the claim is 3, as it provides a suggestion for improvement but lacks detailed justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss how to handle different types of inputs, such as biomedical signals or speech, and provide solutions in their paper. This feedback is valuable as it highlights a potential gap in the paper\"s methodology and encourages the authors to address it. Additionally, the comment notes that the citation seems disordered, which is another area for improvement. While the comment provides actionable feedback on both aspects, it could be more helpful if it offered specific suggestions or examples for handling different types of inputs or organizing citations. Overall, the comment is 4 as it guides the authors in enhancing the clarity and organization of their paper."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two separate issues. First, it questions whether Eq. 4 stands, implying that the authors should clarify or address this concern. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, specifically mentioning the marginal improvement on OfficeHome. However, the comment does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue regarding the improvement of the designed solutions, particularly on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the validity of Eq. 4, suggesting that if it stands, it implies a specific outcome for u^l in Eq. 3. This is a factual observation that does not require verification. The second part discusses the improvement of the designed solutions in Table 5, noting that the improvement is marginal on some datasets, such as OfficeHome. This part is 3 as it provides a specific example of a marginal improvement, but it lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises two separate issues. First, it questions the validity of Eq. 4 and suggests that if it stands, it implies a specific outcome for u^l in Eq. 3. This provides a clear and actionable point for the authors to consider and potentially clarify in their draft. Second, the comment points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, particularly mentioning the marginal improvement on the OfficeHome dataset. This feedback is 3 as it highlights areas where the authors might need to provide more detailed explanations or improvements to strengthen their results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provide additional context. Overall, the comment is 3, as it identifies specific areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some stateoftheart references are missing in the face recognition experiment, specifically mentioning Baidu\"s work. It suggests that this work uses the triplet loss and reports results on a dataset similar to Webface, achieving a higher accuracy on LFW. The comment implies that the authors should include this reference in their paper to provide a more comprehensive comparison. However, it does not explicitly instruct the authors to include this reference or provide detailed guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should include the suggested reference. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" which is accessible through the provided URL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the missing reference and provides a comparison with the results reported in Table 3 of the paper, highlighting the potential for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning Baidu\"s work. It provides a specific reference and a URL, which is a clear and direct way to support the claim. Additionally, it compares the results of the suggested reference with those reported in Table 3 of the paper, providing a logical basis for the claim. This level of detail and evidence makes the claim 5, as it offers a clear and comprehensive justification for the assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by pointing out that some stateoftheart references are missing, particularly mentioning Baidu\"s work on face recognition. It provides a detailed comparison, noting that Baidu\"s work uses the triplet loss and reports results on a dataset similar to Webface, achieving a higher accuracy on LFW. This feedback is valuable as it suggests a relevant reference that could enhance the paper\"s comprehensiveness and provide a more robust comparison. However, the comment could be more helpful if it included specific guidance on how to integrate this reference into the paper or discussed the potential impact of including it. Overall, the comment is 4 as it highlights an important omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalization or what steps to take to mitigate the problem. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to question answering, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the question answering process, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue with generalization, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process requires template mapping to transform questions into masked statements, which might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their approach. Without actionable steps or detailed feedback, the authors are left with a general understanding of the problem but without clear directions on how to resolve it. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that utilizing a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a volumetric representation in the deformation field, referencing VolumeDeform [1] as an example. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or related work section, but this inference is not explicit. The comment is specific in pointing out that the idea of using a volumetric representation is not novel, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or analysis to support why this idea is not novel or how it compares to VolumeDeform. The reference to VolumeDeform is a starting point, but without further elaboration or comparison, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the use of a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. This feedback is 3 as it identifies a potential area where the authors might need to clarify or expand upon their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors could address this issue or improve their draft. Without actionable advice or detailed feedback, the comment provides limited value to the authors. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to discuss or acknowledge it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of the ICLHAR on accuracy scores, specifically mentioning the drop from 70.4 to 55.6 on TRIP. However, it does not specify which part of the paper discusses the ICLHAR or the accuracy scores, making it weakly grounded. The comment is specific in detailing the issue with the ICLHAR\"s impact on accuracy, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It specifically mentions a drop in accuracy scores from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment highlights a critical point, it lacks specific guidance on how to address this issue or what aspects of the discussion should be expanded. The feedback is 3 as it points out a significant problem but could be more actionable with additional details or suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"cite the source appropriately\" regarding the rockpaperscissors example, which is inspired by a previous work. This provides a clear and direct action for the authors to take, ensuring that they include proper attribution and citation. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to cite the source appropriately. This provides clear guidance on what needs to be done to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and suggests citing the source appropriately. However, the comment does not provide any specific references or examples of previous work that the example is inspired by, nor does it explain why this is important to cite. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the rockpaperscissors example, noting that it is inspired by previous work. It provides a clear and actionable suggestion for the authors to cite the source appropriately. This feedback is valuable as it helps the authors ensure proper attribution and acknowledges the influence of prior work, which is important for academic integrity and credibility. However, the comment could be more helpful if it provided specific examples of previous work or detailed guidance on how to cite the source. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these limitations or improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or where the limitations are most apparent. The authors may have an idea of where these aspects are discussed, but the comment lacks explicit references to specific sections, making it weakly grounded. The comment is specific in identifying the limitations of the innovations, but without grounding, it is difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, suggesting that the performance is constrained by the performance of the oracle expert. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, noting that the performance is constrained by the performance of the oracle expert. While it points out a potential area for improvement, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance their work. Without actionable feedback or detailed advice, the authors may find it challenging to use this comment to improve their draft. Therefore, the comment is 3, as it highlights a potential issue but does not provide enough depth or direction for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more preferred. It also provides a specific action by recommending that the authors provide the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and provides a concrete path for the authors to follow, making it 5. The authors know exactly what needs to be done to improve their draft, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"comparing the performance of the model only pretrained on synthetic data\" and \"demonstrating that the proposed three projection errors are important,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors provide the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail and specificity makes the comment 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more preferred. The comment provides a logical reasoning by suggesting that the authors should provide the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This reasoning is clear and supports the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of model performance, specifically noting that comparing the model only pretrained on synthetic data is unfair. It suggests that demonstrating the importance of the three projection errors is more appropriate and provides a specific action for the authors to take by recommending that they provide the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by addressing a potential weakness in their methodology. However, the comment could be more helpful if it provided additional context or examples to further support the suggestion. Overall, the comment is 4, as it guides the authors in making a significant improvement to their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides an explicit suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) as an example. This feedback is concrete and provides a clear action for the authors to take, which is to explore the averaging approach as an alternative to using the embedding of the first subword token as the verb embedding. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) as an example. This provides clear guidance on how to address the issue, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point provides a specific reference to a source (Hewitt and Manning, 2019) that discusses averaging over subword representations. This provides a clear and verifiable basis for the claim that averaging is a common practice in similar cases. The reference to the source adds credibility and supports the claim, making it 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that averaging over subword representations is a common practice, as exemplified by a reference to Hewitt and Manning (2019). This feedback is actionable and offers a concrete alternative to the current approach of using the embedding of the first subword token as the verb embedding. By suggesting this alternative, the comment helps the authors enhance their methodology and potentially improve the performance or interpretability of their model. However, the comment could be more helpful if it included a discussion on why averaging might be beneficial or how it could be implemented. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are concrete and provide specific steps for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"clinical scoring system,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of consistency between predicted scores and actual risk, suggesting that related studies should conduct calibration curves to demonstrate this agreement. The comment further recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model\"s AUC may not fully demonstrate its consistency with the actual risk, which is crucial for clinical scoring systems. It recommends conducting calibration curves to show this agreement and suggests proving the feasibility of the generated scoring system. While the comment provides a logical argument for the importance of calibration curves, it lacks specific examples or references to support the claim that the AUC may not be consistent with the actual risk. This makes the claim 3, as it provides a general suggestion but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct calibration curves to demonstrate the consistency between predicted scores and actual risk, which is crucial for clinical scoring systems. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are specific and provide the authors with a clear direction for improving their draft. However, the comment could be more helpful if it included examples or references to similar studies that have successfully demonstrated these aspects. Overall, the feedback is 4 as it offers valuable insights and guidance for enhancing the paper\"s content and impact."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the conditions for DICE are not well discussed, particularly regarding how to ensure that DICE meets the conditions of Lemma 2 and the lack of discussion on the impact of sparsification on the range of ID and OOD. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD is not significantly changed by sparsification, and that Lemma 2 requires approximately identical mean as the assumption. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. This feedback is 3 as it points out areas where the paper could be improved by providing more detailed explanations or discussions. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these issues. To be more helpful, the comment could include more detailed advice or examples on how to ensure that DICE meets the conditions of Lemma 2 or how to address the lack of change in the range of ID and OOD. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. While the comment implies that the authors should consider integrating over all possible environments to make the update meaningful, it does not explicitly instruct them to do so. Similarly, the suggestion to break out the sections into paragraphs is implicit and lacks specific guidance on how to implement this change. The action is somewhat vague, as the authors need to infer the need for both actions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the need to break out the bolded sections into paragraphs for better readability. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. While the comment identifies a potential issue with the text\"s organization, it lacks specific guidance or suggestions on how to address these concerns. The authors are left with a general understanding of the problem but without actionable steps to improve the draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed feedback or suggestions for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experimental setup and the comparison with baselines. It suggests that the experiments are not strong or fair, questioning the use of position kernels as baselines and recommending the use of default settings. Additionally, it points out missing baselines related to Bayesian optimization with discrete and categorical variables and suggests comparing the proposed approach with these baselines. The comment also mentions the need to discuss the limitations and societal impacts of the proposed approach. While the comment provides a clear direction for improvement, it does not specify exactly how to address these issues or what specific changes are needed. The actions are implicit and somewhat vague, as the authors can infer the need for improvement but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the experimental setup, the use of position kernels as baselines, the absence of certain baselines, and the need to discuss limitations and societal impacts. It provides clear guidance on what needs to be addressed, such as questioning the use of position kernels and suggesting the inclusion of specific baselines. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the experimental setup and the use of position kernels as baselines, suggesting that the experiments are not strong or fair. It questions why the default settings of the baselines are not used and mentions the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. The comment also points out the need to discuss limitations and societal impacts. While the reviewer provides a logical basis for their claims, such as questioning the fairness of the experiments and the relevance of the baselines, the comment lacks specific references or detailed reasoning to fully substantiate the claims. This makes the claim 3, as it provides a starting point for the authors to address the issues but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It questions the fairness and strength of the experiments, suggesting that the use of position kernels as baselines may not be justified and recommending the use of default settings from the literature. Additionally, it points out missing baselines related to Bayesian optimization with discrete and categorical variables and suggests comparing the proposed approach with these baselines. The comment also raises concerns about the paper\"s limitations and societal impacts. While the feedback provides valuable insights and suggestions for improvement, it could be more helpful if it offered specific guidance on how to address these issues or provided examples of how to implement the suggested changes. Overall, the comment is 4 as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point observes a drop in correlation after a short period of training, which then increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what steps to consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a specific observation regarding the correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is related to, such as a particular section, figure, or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in response to this observation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point describes an observation about the correlation after a short period of training, which increases with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment observes a drop in correlation after a short period of training, which then increases with more training iterations. While this observation is interesting, it does not provide any actionable feedback or suggestions for the authors to address or improve upon this observation. Without specific guidance or recommendations, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests that the presentation of bits should be clarified as representation bits in Section 4.3. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of \"bits\" as \"representation bits.\" This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of sparsity patterns and suggests that there is a lack of insight into why they perform similarly. It also questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a lack of insight into why all sparsity patterns perform similarly, questioning whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also points out a specific issue with the terminology, suggesting that \"presentation bits\" should be clarified as \"representation bits\" in Section 4.3. While the comment highlights an important area for clarification and improvement, it lacks depth and does not provide specific guidance on how to address these issues. The feedback is 3 as it directs the authors\" attention to a potential area of confusion but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4, and it suggests that this should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, which is to include the temperature \u03c4 in a rigorous manner or to mention it in the paper. The feedback is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the temperature \u03c4 in a rigorous manner or mentioning it in the paper. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4, and it suggests that this should be shown in a rigorous way or that the paper should mention it. This is a factual observation rather than a subjective claim or suggestion. It does not require verification or evidence beyond the mention of the missing element. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Eqn. 3 to Eqn. 4, noting that the temperature \u03c4 is missing. It provides a clear and actionable suggestion for improvement by recommending that the temperature \u03c4 should be shown in a rigorous way or that the paper should mention it. This feedback is valuable as it directs the authors to a specific area that needs clarification, helping them to improve the clarity and rigor of their work. However, the comment could be more helpful if it provided additional context or guidance on how to incorporate the temperature \u03c4 in a rigorous manner. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add a citation on differential privacy, specifically mentioning a standard work like [2]. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is specific and concrete, as it specifies the type of citation needed and provides a reference for the authors to follow. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual statement that does not contain any subjective opinions, judgments, or suggestions. It is a request for additional information, which is a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors should include a citation on differential privacy, specifically mentioning a standard work like [2]. This feedback provides a specific and direct way for the authors to enhance their paper by adding relevant references, which can improve the comprehensiveness and credibility of their work. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how the addition of this citation would benefit the readers. Despite this, the feedback is 4 as it offers a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a clear and explicit action for the authors to consider revising their claim. Second, it identifies a specific error in the inequality on line 310, pointing out that it has the wrong sign and suggesting a comparison with inequality line 227. This part is also explicit and provides a concrete action for the authors to correct the error. Overall, the comment is 5 as it provides clear and specific guidance on both the theoretical claim and the mathematical error, allowing the authors to make direct improvements to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on both the theoretical claim and the mathematical error. The reviewer questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. Additionally, it identifies a specific error in the inequality on line 310 and suggests a comparison with inequality line 227. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a logical reasoning and common knowledge to support the claim, making it 4. The second part identifies a specific error in the inequality on line 310, comparing it with inequality line 227. This part is also 4 as it provides a clear comparison to correct the error. Overall, the comment is 4 due to the logical reasoning and specific examples provided.", "helpfulness_rationale": "The review comment provides valuable feedback by questioning the claim that the methodology requires significant additional assumptions. It points out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This critique is constructive as it challenges the authors to reconsider their claim and potentially revise it to reflect the actual assumptions involved. Additionally, the comment identifies a specific error in the inequality on line 310, suggesting a comparison with inequality line 227. This feedback is actionable and provides clear guidance for the authors to correct the error and improve the accuracy of their mathematical expressions. Overall, the comment is 4 as it offers both theoretical and technical insights that can significantly enhance the draft. However, it could be more helpful if it provided additional context or suggestions for revising the claim. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. Additionally, it recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment explicitly states these actions, it does not provide specific guidance on how to conduct these comparisons or discuss the advantages and disadvantages. The authors are left with a clear understanding of what needs to be done but without detailed instructions on how to implement these suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for experimental comparisons with methods like CaCE and raw gradients, as well as a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. It also recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the comparison with CaCE or raw gradients. The suggestion to discuss the advantages and disadvantages of different methods is a general recommendation that could be improved with more detailed examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s argument for using Shapely value explanations over other methods. It suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their choice. Additionally, the comment recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This feedback is clear and actionable, as it provides specific steps for the authors to take to strengthen their argument and improve the comprehensiveness of their work. By addressing these suggestions, the authors can enhance the rigor and depth of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, making it difficult for the authors to identify the exact section that needs attention. While the authors can infer that it pertains to Section 6, the comment lacks specificity in detailing what specific aspects of the perspective or contributions should be compared. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide any specific examples, references, or reasoning to support why such a comparison would be beneficial or how it could enhance the manuscript. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it identifies a potential area for improvement by highlighting the comprehensiveness of the related work and suggesting a specific way to enhance the manuscript\"s analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could include examples of prior efforts or suggest specific comparisons that would be beneficial. Therefore, the comment is 3, as it points out a potential enhancement but does not fully guide the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests examining the performance with different numbers of scenarios, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the model\"s performance. Without this context, the claim remains 1, as the authors may not understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. This is a constructive suggestion that could help the authors better understand the impact of the number of scenarios on the model\"s performance. However, the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on, which limits its helpfulness. While it offers a direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the ability of the model to predict quality labels, even if it is trained on highquality data. It questions whether disturbances in the training data could affect the model\"s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate or mitigate potential disturbances. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the model\"s performance or evaluation, but without explicit references, it remains unclear. The comment is specific in detailing the concern about disturbances affecting the model\"s ability to generate correct quality labels, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the potential impact of disturbances on the model\"s performance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance, which is a critical aspect to consider for the model\"s reliability. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or investigate potential disturbances in the training data. While it identifies a potential weakness, it does not provide actionable steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve or expand upon their experimental setup or results. As a result, the comment lacks actionable information, leaving the authors without a clear direction for enhancing their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions \"experiments\" and \"CATER,\" but it does not specify which part of the paper these experiments are discussed in or how they relate to the main claims or findings. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in describing the comprehensive nature of the experiments, including architectural mismatches and crossdomain imitation, but it does not provide detailed guidance on what aspects of the experiments need improvement or clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point describes the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment consists solely of factual statements about the experiments, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. This feedback provides insight into the thoroughness of the experimental validation, which is valuable information for the authors. However, the comment lacks specific suggestions or guidance on how the authors might improve or expand upon their experimental setup or results. While it identifies a strength of the paper, it does not offer actionable advice or constructive feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper\"s claim of strategic predictions, noting that the setting is only partially strategic/game theoretic because the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their claims. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s claim of strategic predictions, noting that the setting is only partially strategic/game theoretic because the opponent does not behave strategically. However, it does not specify which part of the paper this critique pertains to, such as a specific section or paragraph. The authors may have to infer that it relates to the introduction or methodology sections where the strategic predictions are discussed. The comment is specific in detailing the issue with the strategic setting, but it lacks grounding as it does not explicitly mention a section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper\"s claim of strategic predictions, noting that the setting is only partially strategic/game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The reasoning is based on a general observation about the opponent\"s behavior, but without detailed evidence or examples, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the paper\"s claim of strategic predictions, noting that the setting is only partially strategic/game theoretic because the opponent does not behave strategically. This feedback is 3 as it identifies a potential weakness in the paper\"s claims. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. The comment highlights a critical aspect of the paper\"s methodology but does not offer actionable advice, leaving the authors with a general insight but no clear path forward for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with Appendix A.2, stating that it does not illustrate the state space representation of the environment clearly. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the clarity of the representation or what specific changes should be made. As a result, the authors are left without a clear understanding of what actions to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Appendix A.2, noting that it does not illustrate the state space representation of the environment clearly. This feedback is clear and actionable, as it directs the authors to a specific area of the paper that needs improvement. However, the comment could be more helpful if it provided suggestions on how to clarify the representation or what aspects of the state space need to be more clearly illustrated. Despite this, the comment is 4 as it highlights a specific area for improvement, allowing the authors to address a concrete issue in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach for largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in identifying the issue of scalability, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. This feedback is 3 as it points out a potential issue that the authors need to consider when scaling their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve their approach for largerscale problems. Without actionable advice or examples, the feedback is incomplete, leaving the authors with a general understanding of the problem but no clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions. While the comment provides valuable information, it lacks actionable guidance on how the authors should utilize this information to improve their draft. Therefore, the comment is 3, as it provides some insight but does not offer clear instructions for implementation.", "grounding_specificity_rationale": "The comment discusses the bounded noise assumption and mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the efforts to extend noise conditions and provides references to relevant works, which helps the authors understand the context and potential improvements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explain why the bounded noise assumption is restrictive or how the referenced works extend these conditions. While the references provide some support, the lack of detailed reasoning or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. This feedback is valuable as it directs the authors to relevant literature that could inform their work. However, the comment does not offer specific guidance on how to incorporate these references or how they might impact the authors\" research. While it provides a starting point for further exploration, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the motivation for using characteristic function regularization. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their explanation. The comment lacks actionable guidance, leaving the authors without a clear direction on how to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation for using characteristic function regularization, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or part of the paper the comment refers to, making it weakly grounded. However, the comment clearly specifies the issue with the lack of clarity in the motivation, providing a specific area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the motivation for using characteristic function regularization is not clear. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify their motivation or improve their explanation. While it points out a critical area for improvement, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, which are standard in contextual linear bandits. The reviewer notes that the combination of these techniques is not surprising and suggests that the contribution may be incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper discusses these techniques or how they are combined, making it weakly grounded. The comment is specific in identifying the techniques and their combination, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s results are a combination of existing techniques and that the combination is not surprising, suggesting that the contribution may be incremental. The reviewer supports this claim by referencing specific works (Lykouris et al., 2018; Zhou et al., 2021) that are mentioned in the paper. However, the comment lacks detailed reasoning or analysis to fully substantiate the claim that the combination is not surprising or incremental. While the references provide some context, the lack of additional explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the results appear to be a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the combination of these techniques is not surprising and may lead to the conclusion that the contribution is incremental. While the comment points out a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referenced. This feedback is clear and direct, giving the authors a specific action to take. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the need for clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It specifies the exact part of the paper that requires further explanation, making it fully grounded. The comment also provides a clear direction for improvement by suggesting that the authors should provide more details in the main paper and acknowledge the structure of other architectures if referenced. This level of specificity allows the authors to understand exactly what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" in the context of multiscale modeling needs further clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a request for more detailed information, which is a factual statement. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It provides a clear and actionable suggestion for the authors to provide more details in the main paper and to acknowledge the structure of other architectures if referenced. This feedback is valuable as it guides the authors on how to enhance the clarity and completeness of their work, making it 4. However, it could be more helpful if it included specific examples or further guidance on how to improve the explanation. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The authors are left without clear instructions on where to focus their efforts or how to correct the identified problems. As a result, the comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment highlights severe writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper contain these issues, making it difficult for the authors to identify the exact areas needing improvement. Without specific references or examples, the comment lacks grounding, as the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address the problems. Without concrete evidence or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights important areas for improvement, it lacks depth and detail, making it 2. The authors are left with a general understanding of the problem but without clear steps to correct it. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests that the figures should include results for untrained networks and clarifies the meaning of \"Random data\" in Figure 3c and Figure 3. The comment also requests examples of random data in the appendix. These actions are clear and concrete, giving the authors a specific set of tasks to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3c\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, such as the meaning of \"Random data\" and whether the nonrandom data is normalized. Additionally, it requests examples of random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additions to the figures and table, as well as a suggestion to include examples of random data in the appendix. These are factual statements that do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas where the paper could be improved. It suggests that the figures should include results for untrained networks, which is a clear and direct action for the authors to take. Additionally, it clarifies the meaning of \"Random data\" in Figure 3c and Figure 3, and requests examples of random data in the appendix. This feedback is detailed and provides the authors with clear steps to enhance the clarity and completeness of their draft. Therefore, the comment is 5, as it offers actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It explicitly asks what \"100 steps\" refers to, whether it is 100 sampled strategies. This question provides a clear and direct action for the authors to clarify the meaning of \"100 steps\" in their draft. The comment is explicit and concrete, as it directly instructs the authors to provide clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It asks whether \"100 steps\" refers to 100 sampled strategies, providing a clear and direct inquiry for clarification. This feedback is actionable as it prompts the authors to clarify a potentially confusing aspect of their draft, which could improve the reader\"s understanding. However, the comment could be more helpful if it suggested how the clarification could be presented or if it pointed out the broader implications of this clarification. Overall, the comment is 4 as it identifies a specific area for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it highlights the similarity between the model\"s motivation and goals to a prior VAE paper. However, it does not specify which part of the paper this observation pertains to, such as the introduction or related work section. The authors might infer that it relates to the motivation or goals section, but this is not explicitly mentioned. The comment is specific in identifying the potential for exploring energy models and the similarity to a prior VAE paper, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the model\"s motivation aligns with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper provides some context, but without detailed examples or references, the claim remains 3. Therefore, the comment is rated as 3, as it requires more detailed support to fully substantiate the claim.", "helpfulness_rationale": "The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model align with a prior VAE paper, suggesting that the authors should consider this related work. However, the comment lacks specific guidance or actionable suggestions on how the authors might integrate this information into their draft or further explore the energy models. While it identifies an area for potential improvement, the feedback is 3 as it provides a direction for the authors to consider but does not offer detailed guidance on implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It suggests repeating the experiments and conducting statistical significance analysis, which provides a clear and explicit action for the authors to take. The suggestion is concrete, as it specifies the steps needed to address the issues, making this comment 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It mentions Table 1 and Fig. 5, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the results and suggests a solution, namely repeating the experiments and conducting statistical significance analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, with a range of 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis. However, the comment lacks specific examples or references to support the claim about the small improvement or the lack of statistical significance. While the suggestion to repeat the experiments and conduct analysis is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the small improvement over previous methods and the lack of statistical significance analysis in the results. It provides specific suggestions for improvement, such as repeating the experiments and conducting statistical significance analysis, which would help the authors address these concerns. However, the comment could be more helpful if it offered additional guidance on how to conduct the statistical analysis or provided examples of similar studies that have successfully addressed these issues. Despite this, the feedback is 4 as it directs the authors to a clear path for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should evaluate their method on a different benchmark, such as Atari, to assess its generalizability to other domains and action spaces. The comment provides a clear and concrete action for the authors to take, which is to conduct additional experiments on a different benchmark. This guidance is explicit and provides detailed instructions on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the evaluation of the method, specifically mentioning that it is evaluated only on tasks from the Meta World domain. It highlights the difficulty in judging generalizability to other domains and suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This provides a clear and specific suggestion for the authors to consider. The comment is fully grounded as it explicitly mentions the Meta World domain and the need for additional experiments on Atari. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the method is limited to a single domain, making it difficult to judge generalizability. The reviewer suggests running experiments on a different benchmark, such as Atari, to address this limitation. The claim is supported by logical reasoning, as it points out the need for broader evaluation to assess the method\"s generalizability. However, the comment could be strengthened by providing specific examples or references to similar studies that have successfully generalized across domains. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on tasks from the Meta World domain. This limits the ability to judge the method\"s generalizability to other domains. The reviewer provides a clear and actionable suggestion by recommending the authors to run experiments on a different benchmark, such as Atari, which is commonly used in the literature. This would not only address the generalizability concern but also test the method\"s performance with discrete action spaces and highdimensional observations. The feedback is detailed and constructive, offering a specific direction for improvement that could significantly enhance the draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be very interesting. However, it does not provide specific guidance on what aspects of the model should be analyzed or how this analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analysis of what the model does is missing, but it does not specify which part of the paper this analysis should be included in. The authors can infer that it relates to the method or experimental results, but the lack of explicit mention of specific sections makes it weakly grounded. The comment is specific in suggesting that an analysis is missing, but without further details, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of what the model does is missing, but it does not provide any specific examples, references, or reasoning to support this claim. The comment lacks detailed justification or evidence to substantiate the need for additional analysis. Without further elaboration, the authors may find it challenging to understand the basis of the suggestion, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges that the method is presented nicely and the experiments are good and complete, which is a positive assessment. However, it suggests that a deeper analysis of what the model does is missing, which could be very interesting. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to conduct this analysis or what aspects should be included. This limits the usefulness of the feedback for the authors, as it does not offer detailed suggestions or examples to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the task setup, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides a clear and direct action for the authors to take, which is to clarify these aspects in their draft. The comment is explicit and concrete, giving the authors a specific direction on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the task setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the task setup, specifically asking about the use of notes in the EHR and the distance between the last note date and outcomes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarity is important or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the task setup. It points out that the authors need to clarify which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the clarity of their draft. By addressing this issue, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how to clarify it. Overall, the comment is 4, as it guides the authors toward improving the clarity of their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the reason why their proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO. It also implies that the authors should explore the theoretical technique differences between DMLCBO and these previous works. While the comment explicitly states the need for discussion and comparison, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit but concrete, as the authors know what needs to be addressed but may need to infer the exact steps to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and references specific previous works, SUSTAIN and MRBO, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, which is its failure to achieve the same convergence rate as previous works using the double momentum technique. The comment suggests that the authors should discuss the reason for this difference and explore the theoretical technique differences between DMLCBO and the referenced works. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works using the double momentum technique, such as SUSTAIN and MRBO. It suggests that the authors should discuss the reason for this difference and explore the theoretical technique differences between DMLCBO and these previous works. While the comment identifies a potential issue with the convergence rate, it lacks specific examples or detailed reasoning to support the claim. The authors are encouraged to provide a detailed explanation of the theoretical differences, but the comment does not offer a comprehensive justification or references to support the claim. Therefore, the comment is 3, as it provides a suggestion for further exploration but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works using the double momentum technique. It suggests that the authors should discuss the reason for this difference and explore the theoretical technique differences between DMLCBO and the referenced works. This feedback is clear and actionable, as it provides a specific area for the authors to investigate and improve upon. By addressing this point, the authors can enhance the theoretical foundation of their work and potentially strengthen its contribution to the field. Therefore, the comment is 4, as it guides the authors towards a meaningful area of improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the \"approach section is missing in the main paper\" and suggests that the supplementary material should be used as additional information rather than an extension to the paper. The reviewer provides a specific reference to a previous comment and indicates that the score has been increased from 3 to 5. This feedback is clear and provides a direct action for the authors to take, which is to ensure that the approach section is included in the main paper and that the supplementary material is used appropriately. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach section\" and the \"main paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach section is missing and that the supplementary material should be used as additional information rather than an extension to the paper. The comment provides a clear and specific direction for improvement, making it 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the \"approach section is missing in the main paper\" and suggests that the supplementary material should be used as additional information rather than an extension to the paper. The reviewer provides a reference to a previous comment, which indicates that the score has been increased from 3 to 5. However, the current comment does not provide additional justification or explanation for why the approach section is missing or why the supplementary material should be used differently. The lack of detailed reasoning or specific examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"approach section is missing in the main paper.\" It provides a clear and actionable suggestion by recommending that the approach section should be included in the main paper, as the supplementary material should serve as additional information rather than an extension to the paper. The reviewer also references a previous comment, indicating that the score has been increased from 3 to 5. This feedback is clear and provides a direct action for the authors to take, making it 5. It empowers the authors to improve their draft by ensuring that all necessary information is included in the main paper, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. It points out that backpropagation is widely accepted as biologically implausible. However, the comment does not provide specific guidance on how the authors should address this issue or improve the statement. The action is implicit, as the authors need to infer that they should strengthen the statement or provide additional context, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, citing the widespread acceptance of backpropagation as biologically implausible. This claim is supported by logical reasoning, as it relies on the common knowledge that backpropagation is widely recognized as biologically implausible. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is 4, as it provides a logical basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This feedback is valuable as it points out a common misunderstanding or lack of clarity in the literature, which could be addressed to strengthen the introduction. However, the comment could be more helpful if it provided specific suggestions on how to improve the statement or clarify the biological implausibility of backpropagation. Overall, the comment is 4 as it highlights an area for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the scalability aspect, but it lacks concrete steps or recommendations on how to mitigate the potential scalability problem. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the modulator, which is a specific element of the paper, providing a clear reference to the part of the paper being discussed. It also raises a concern about scalability and the potential need for tedious hyperparameter tuning for diverse training data. This provides a specific issue for the authors to address, making the comment fully grounded. However, it lacks detailed guidance on how to address the scalability issue or suggestions for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the modulator, noting that it is heuristically designed and suggesting that there might be scalability concerns. It raises a concern about the need for tedious hyperparameter tuning for diverse training data, which is a valid point that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the modulator design. While it highlights an important area for consideration, the feedback could be more helpful with actionable advice or examples. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experiments incorporating a significant amount of domain knowledge, which may make it challenging for less informed f_R/f_P to learn effectively. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments and the incorporation of domain knowledge into their structure, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge of using less informed f_R/f_P, which requires a significant amount of data to learn. However, it lacks detailed guidance on how the authors might address this issue or improve their approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments incorporate a great deal of domain knowledge, which may make it challenging for less informed f_R/f_P to learn effectively. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, noting that the incorporation of a great deal of domain knowledge into their structure may make it challenging for less informed f_R/f_P to learn effectively. This feedback is 3 as it points out a potential limitation that the authors should consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable advice, the feedback does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should conduct such experiments, but it lacks concrete details or steps on how to implement them. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the need for experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, as it clearly outlines the need for additional experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data when applying imitation learning. This is a relevant and important point that could impact the validity and applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or methods to explore this aspect. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the authors acknowledge this in the conclusion, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their paper. The action is implicit and vague, as the authors are left to infer that they should clarify this connection in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the connection between overparameterization, robust memorization, and generalization, specifically questioning whether the necessary conditions have stronger implications if they are connected to generalization bounds. It also notes that the paper does not clearly address whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment does not explicitly mention a specific section, it is clear that it pertains to the discussion of overparameterization and generalization. The authors can infer that it relates to the conclusion or a section on generalization, but the comment does not provide explicit references. The specificity is clear as it identifies a specific area of concern regarding the paper\"s claims and reasoning. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the connection between overparameterization, robust memorization, and generalization, questioning whether the necessary conditions have stronger implications if they are connected to generalization bounds. The reviewer acknowledges that the authors address this in the conclusion but finds the question serious. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the necessary conditions are not connected to generalization bounds. This makes the claim 3, as the authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the connection between overparameterization, robust memorization, and generalization. It questions whether the necessary conditions have stronger implications if they are connected to generalization bounds, noting that the paper does not clearly address this issue. The comment acknowledges that the authors address this in the conclusion, but it suggests that this is a serious question that needs further exploration. While the comment identifies a significant gap in the paper\"s argument, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential weakness in the paper\"s logic, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand their analysis to other NLP tasks, but it lacks concrete details or actionable steps on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on contrastive learning in code search tasks and suggests that it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper discusses the proposed method or how it could be expanded to other tasks. The authors can infer that the discussion on the proposed method is relevant, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the need for broader exploration of the method\"s implications, but without explicit references or examples, it remains underspecific. Therefore, this comment is weakly grounded and underspecific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant as it highlights an area where the authors could expand their analysis to enhance the generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as which other NLP tasks could be explored or how to structure this exploration. While it points out an important area for improvement, the feedback could be more actionable and comprehensive to be considered 5. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative terminology or providing a rationale for why the term \"certificate\" is being used in this context. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. While this observation is relevant, it lacks specific guidance or suggestions on how the authors might address this issue or clarify the term. Without actionable advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights a potential problem but does not offer actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their OOD experiments. It also implies that the authors should ideally compare their method with those untrained neural networks. While the comment explicitly states the actions to take, it does not provide detailed guidance on how to integrate this information into the paper or what specific comparisons to make. The authors are given a clear direction but may need to infer the exact implementation details. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Regarding the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al., and ideally compare their method with those class of methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention untrained neural networks, such as the deep image prior by Ulyanov et al., in the context of their OOD experiments. It provides a logical reasoning by pointing out that untrained networks have been shown to be effective in solving inverse problems across a wide class of images. However, the comment lacks specific references or examples to support the claim that mentioning these untrained networks would be beneficial. While the suggestion is reasonable, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al., in the context of their OOD experiments. This is a constructive suggestion as it provides a relevant comparison that could enhance the paper\"s context and understanding of the results. However, the comment could be more helpful if it included specific examples or references to how this comparison could be made or what aspects of the comparison would be most beneficial. Overall, the comment is 4 as it offers a clear direction for improvement but lacks detailed guidance on implementation. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include real data, as barycenters have applications in various realworld problems. While the comment implies that the authors should consider including real data in their experiments, it does not provide explicit instructions on how to do so or what specific realworld problems to address. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include real data, indicating that the current focus on toy data is limiting. However, it does not specify which part of the paper discusses the experiments or where the authors should make these changes. This lack of explicit grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in suggesting the inclusion of real data, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and proposes expanding them to include real data, where barycenters can be used. However, the comment does not provide specific examples or references to support the claim that real data would be more appropriate or beneficial. The suggestion is based on a general observation about the potential applications of barycenters, but without detailed reasoning or evidence, it remains somewhat vague. Therefore, the comment is categorized as 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that the experiments are limited to toy data. It suggests that the authors should expand their experiments to include real data, as barycenters have applications in various realworld problems. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and applicability of their work. By addressing this suggestion, the authors can significantly improve the scope and impact of their study. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors conduct additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. The explicit mention of references and the suggestion to explore deeper networks and other network structures provides clear guidance on what the authors should do to strengthen their paper. The comment is concrete in its suggestion and provides specific examples of relevant works, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. However, the comment does not specify which part of the paper these experiments should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, as it points out the need for additional experiments and provides references for inspiration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, are needed to strengthen the paper. It provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This provides a clear and specific suggestion for further experimentation, making the claim 4. However, the comment could be strengthened by explaining why these specific references are relevant or how they would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to further strengthen the paper. It provides specific references to relevant works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This feedback is clear and actionable, offering the authors a concrete path to improve their draft by expanding their experimental setup. By following this suggestion, the authors can demonstrate the robustness and generalizability of their approach across different network architectures. Therefore, the comment is 5, as it provides detailed guidance on how to enhance the paper\"s impact and credibility."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the sample selection mechanism need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim that the mechanism is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. While it identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing the draft. Therefore, it is rated as 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. While it acknowledges the thoroughness of the analysis, it does not provide explicit guidance on how the authors should address this limitation. The comment lacks specific suggestions or actions for the authors to take, such as recommending the inclusion of more recent or larger models, or discussing the implications of using only two models. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation of models, specifically noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the issue with the evaluation, it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim that the models are \"old\" or \"small,\" making it difficult for the authors to fully understand and address the issue. Additionally, the comment does not provide suggestions on how to improve the evaluation or include more relevant models. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential limitation in the evaluation of models, noting that only two relatively old and small models are evaluated. While it identifies a specific area for improvement, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation. It does not offer alternative models to consider or discuss the implications of using only two models. As a result, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. While the comment implies that the authors should consider this reformulation, it does not explicitly instruct them to make this change or explain how it would affect the motivation of Algorithm 1. The action is implicit and somewhat vague, as the authors need to infer the need for this reformulation and understand its implications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. The reviewer provides a logical reasoning by suggesting a reformulation that could affect the motivation of the algorithm. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to explore the suggested reformulation to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1 by suggesting that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation unclear. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify or reframe their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires further explanation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific claim about the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but without explicit references to the paper, the authors may struggle to pinpoint the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be valuable for the authors to consider. However, the comment lacks depth and does not offer actionable advice or suggestions on how the authors might incorporate this insight into their work. It does not provide specific guidance on how to explore or leverage this equivalence, leaving the authors with limited actionable feedback. Therefore, the comment is 3, as it identifies an interesting aspect but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more recent works on dynamicpruning methods and provide results on largescale datasets, such as ImageNet, to better verify the effectiveness of the proposed method. While the comment implies that the authors should update their work to include these recent works and results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to update their paper, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should include more recent works on dynamicpruning methods and provide results on largescale datasets, such as ImageNet, to better verify the effectiveness of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more recent works on dynamicpruning methods and provide results on largescale datasets, such as ImageNet, to better verify the effectiveness of the proposed method. However, the comment does not provide specific examples of recent works or detailed reasoning to support why these additions are necessary. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should include more recent works on dynamicpruning methods and provide results on largescale datasets, such as ImageNet, to better verify the effectiveness of the proposed method. This feedback is clear and actionable, as it directs the authors to update their work to include relevant recent research and datasets, which would enhance the comprehensiveness and impact of their study. However, the comment could be more helpful if it provided specific examples of recent works or detailed guidance on how to incorporate these results. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results (table 5). This is a clear and direct action, as it specifies what information the authors need to include to address the issue. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results (table 5) and requests clarification on why the performance degrades when using additional information about missing, wrong, or redundant data. This feedback is clear and actionable, as it directs the authors to provide a detailed explanation of the observed performance degradation. By addressing this question, the authors can enhance the transparency and understanding of their results, which is beneficial for improving the draft. However, the comment could be more helpful if it suggested potential causes or methods for addressing the issue. Overall, the comment is 4 as it provides a clear direction for improvement but lacks depth in terms of suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the first two sections of the paper, noting that the author stacked a number of previous approaches but failed to explain each method clearly. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide explicit guidance on how to address these issues or suggest specific changes to improve clarity. The authors are left to infer that they need to clarify the explanations, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" This level of detail helps the authors understand what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of specific questions and observations about the clarity of the paper, particularly regarding the explanation of methods and the interpretation of figures. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide detailed reasoning or references to support why these statements are unclear or how they could be improved. While the questions are specific, the lack of detailed justification or examples makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the paper, particularly in the first two sections. It points out that the author stacked a number of previous approaches but failed to explain each method clearly. The comment provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" This feedback is 3 as it highlights areas where the authors need to improve the clarity of their explanations. However, it could be more helpful if it offered suggestions on how to clarify these points or provided examples of how to improve the explanations. Overall, the comment provides a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. The first comment instructs the authors to make the captions more descriptive, which is a clear and direct action. The second comment requests a better explanation of the scramble network, again providing a specific and explicit action. Both comments are concrete and provide clear guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses two separate issues: the need for more descriptive captions and the explanation of the scramble network. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be improved, such as making the captions more descriptive and providing a better explanation of the scramble network. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two separate comments, each addressing a specific issue with the paper. The first comment suggests that the captions are not descriptive enough, making it difficult for readers to understand the figures without referring to the text. The second comment requests a better explanation of the \"scramble network,\" which is not clearly defined in the paper. While the comments identify areas for improvement, they do not provide specific examples or references to support the claims, making them 3. The authors would need to infer the exact issues from the comments, which limits the level of support provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. The first suggestion is to make the captions more descriptive, which is a clear and actionable point. This feedback helps the authors understand the need to enhance the clarity of their figures, making it easier for readers to interpret them without having to search for additional information. The second suggestion is to explain the \"scramble network\" better, which is also a direct and constructive piece of advice. By addressing these specific areas, the comment offers valuable guidance for the authors to improve their draft. However, the comment could be more helpful if it provided examples or further details on how to make the captions more descriptive or explain the scramble network better. Overall, the comment is 4, as it provides clear directions for improvement, but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It asks why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. However, the comment does not explicitly instruct the authors to include such an explanation or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks why this particular dimension of difficulty is interesting. This provides clear guidance on what aspect of the paper needs further explanation or justification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that the authors should provide a rationale for why this particular dimension of difficulty is interesting. However, the comment does not provide any specific reasoning or evidence to support the claim that this choice is not well motivated. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It questions why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. This feedback is 3 as it prompts the authors to consider and articulate the significance of their choice, which could enhance the clarity and impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the issue or if it offered alternative approaches to consider. Overall, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to adjust the font size of the text in the figure to match the manuscript text. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the text is too small to read without zooming, and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, suggesting that they should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the text inside the figure and the labels, noting that they are too small to be read without zooming. It provides a clear and actionable suggestion by recommending that the text size should be roughly the same as the manuscript text. This feedback is valuable as it helps the authors improve the accessibility and clarity of their figures, which is an important aspect of effective communication in academic writing. However, the comment could be more helpful if it included specific recommendations on how to achieve this size adjustment or if it pointed out other similar issues in the manuscript. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a clear and direct action for the authors to take, which is to revise the introduction. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction needs revision or what aspects of the motivation are unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references to specific sections, and it is not specific enough to guide the authors in addressing the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow, which is a clear and actionable feedback. However, the comment does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. While it highlights a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a significant issue but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the intuition behind including multiple local prompts, noting that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity in detailing what aspects of the paper need to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. This observation highlights a potential limitation or area for improvement in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their approach. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not provide sufficient guidance for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the alignment of relabeled reward data with human annotator judgments, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to validate this alignment or what specific steps should be taken to improve it. The comment lacks actionable details, leaving the authors without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue with the alignment, but without grounding, it is difficult for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved, namely the validation of the alignment between relabeled reward data and human annotator judgments. However, it lacks actionable guidance or suggestions on how the authors might address this issue or improve the validation process. Without detailed advice or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to improve the presentation of their model in section 4. It suggests replacing some natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This feedback is concrete and provides specific steps for the authors to take, making it 5. The authors know exactly what changes to make to enhance the clarity and comprehensibility of their presentation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation, suggesting the use of notation and breakout diagrams to illustrate attention mechanisms. This detailed feedback gives the authors a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model is complicated and requires careful reading, possibly with reference to the supplement. It proposes improvements by suggesting the use of notation and breakout diagrams to illustrate attention mechanisms. However, the comment lacks specific examples or detailed reasoning to support the claim that the model is complicated or how the suggested improvements would enhance clarity. The mention of the supplement provides some context, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a general suggestion but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area of improvement in the presentation of the model, noting that it is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides actionable suggestions for enhancing the presentation by recommending the use of notation and the inclusion of breakout diagrams to illustrate attention mechanisms. These suggestions are clear and provide the authors with a concrete path to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these suggestions or provided examples of similar approaches. Overall, the feedback is 4 as it directs the authors toward specific improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their experiments to a broader range of molecules or exploring ways to generalize the method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the limited number of molecules and the indistribution testing provided. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation of the method, suggesting that it might be limited if it requires training for each molecule individually. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value would be limited if it requires training for each molecule individually, suggesting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental setup, noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. It suggests that this limitation could restrict the value of the method if it requires training for each molecule individually. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the symbols used in the paper are complicated and take a long time to understand. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting ways to simplify the symbols or improve their clarity. Without specific guidance or suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take a long time to understand, but it does not specify which symbols or sections are problematic. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its critique of the symbols being complicated, but without clear references to the paper, it remains weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that symbols are complicated and take a long time to understand, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of symbols used in the paper, noting that they take a long time to understand. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might simplify or clarify these symbols. Without actionable feedback or detailed advice, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the origin of the test data used in Figure 3, specifically regarding the red line. It explicitly asks for clarification on the source of the test data and whether there is a ground truth available. This feedback provides a clear and direct action for the authors to take, which is to clarify the source of the test data and ensure that a ground truth is available. The request for clarification is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking for clarification on the source of the test data and whether a ground truth is available. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the origin of the test data used in Figure 3, specifically regarding the red line. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the origin of the test data used in Figure 3, particularly regarding the red line. It prompts the authors to clarify whether the test data has a ground truth, which is a critical aspect for understanding the results presented in the figure. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and interpretability of their results. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to clarify the source of the test data. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it does not provide explicit guidance or suggestions on how the authors might address this issue or what steps they should take to explore this further. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the impact of periodicity on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment does not explicitly mention a specific part of the paper, it is clear that it relates to the experimental results and the comparison between models. The authors can infer that it pertains to the results section or the comparison between models, but the comment lacks explicit grounding. The specificity is clear as it questions the extent of periodicity\"s impact on the results and suggests a potential solution. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it does not provide specific evidence or references to support the claim that the results are solely due to periodicity. The reasoning is based on the comparison between models and the observed relationships in the experiments, but without further elaboration or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It highlights a potential limitation of the comparison model, which cannot capture periodic relationships, and notes that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then suggests that adding periodicity to the spectral kernel might allow it to capture these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the impact of periodicity on their results and suggests a potential avenue for further exploration. However, the comment could be more helpful if it provided specific guidance on how to investigate this issue or what experiments might be necessary to address it. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes that there are issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance or suggestions on how to improve these aspects. The authors are left without clear instructions on what changes to make or how to enhance the writing and presentation. As a result, the comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are affected, making it difficult for the authors to identify the exact areas needing improvement. The lack of specific guidance or examples of what needs to be addressed further limits the usefulness of the comment. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence, such as specific sentences or sections that are unclear or poorly written, which would help the authors understand where improvements are needed. Without detailed justification or examples, the claim remains 1, as it does not provide the authors with actionable feedback to address the issue.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific suggestions or actionable feedback on how to improve the writing or presentation. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects need improvement or how to address the issues. As a result, the comment is not helpful, as it does not provide the authors with the necessary information to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction need to be expanded or how to make it more detailed. The action is implicit, as the authors can infer that they need to provide more information about orthogonality, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction or Part 2 is being addressed, making it weakly grounded. The comment is specific in its suggestion to provide more detail on orthogonality, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a specific area for improvement, it lacks specificity and does not provide any guidance on what aspects of the introduction need to be expanded or how to make it more detailed. Without actionable feedback or examples, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, suggesting that prior work already theoretically shows samplewise multiple descent in linear regression. It implies that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings. The reviewer questions whether this is the case and suggests that the paper should better highlight the novelty of their results in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be clarified or improved. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s contribution, specifically questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty of the results, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper but finds the claims plausible. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of their results in relation to prior results. While the comment identifies a potential issue with the novelty of the paper\"s contribution, it lacks specific guidance or suggestions on how the authors might address this concern or improve the clarity of their results. The feedback is 3 as it points out a potential weakness but does not provide detailed actionable advice, leaving the authors with limited direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and have little inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the connection between the methods. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically the contrastive training objective and contrastive search, but does not specify which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment highlights a potential issue with the lack of connection between the methods, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and have little inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed methods, specifically the contrastive training objective and contrastive search, noting that they are independent and have little inner connection in terms of intuition and algorithm. This feedback highlights a gap in the paper that the authors need to address. However, the comment lacks specific suggestions or guidance on how to improve the connection between the methods or enhance their integration. While it points out a critical area for improvement, it does not provide actionable steps or detailed advice, making it 3. The authors are left with a general understanding of the issue but without clear direction on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the goal of the paper, specifically regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors should clarify whether their claim is that this is a foundation model or a proof of concept, and if it is the latter, to justify a future useful application. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so, such as suggesting specific comparisons or justifications. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically mentioning the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the introduction or methodology sections where the goal and comparison are discussed. The authors can infer the relevant parts but may need to make an educated guess. The comment is specific in detailing what needs to be addressed regarding the goal and comparison, making it somewhat grounded and specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, specifically mentioning PhaseNetDas as one of them. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. While the comment identifies a gap in the paper, it lacks specific examples or references to other relevant works, making it 3. The authors would need to infer the need for more detailed comparisons and justifications, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. This feedback is clear and actionable, as it provides a specific direction for the authors to address the lack of comparison and justification in their work. By addressing this concern, the authors can enhance the relevance and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights similarities between the current analysis and prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR10 models on various distributions, which were studied in RobustBench and other works. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment provides a detailed critique of the analysis, comparing it to prior works and suggesting that the results are not particularly surprising due to similarities with existing studies. It references specific examples, such as the robustness of CIFAR10 models on various distributions, which were studied in RobustBench and other works. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in detailing the similarities and comparisons with prior works, providing a clear basis for the critique. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that similar analyses are present in prior works and that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR10 models on various distributions, which were studied in RobustBench and other works. The comment also references specific studies by Croce et al. (2021) and A, B, which further substantiate the claim. This provides a robust foundation for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the analysis presented in the paper, noting that similar analyses are already present in prior works. It provides specific examples, such as the robustness of CIFAR10 models on various distributions, which were studied in RobustBench and other works. This feedback is 3 as it highlights a potential weakness in the originality of the research. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. As it stands, the comment provides a basis for reflection but lacks actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that the authors should provide more discussions. While the comment implies that the authors should address this issue by adding more discussions, it does not specify what kind of discussions are needed or how they should be structured. The action is implicit and somewhat vague, as the authors know they need to provide more discussions but are not given clear guidance on what those discussions should entail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the simplicity of the subtasks and the need for more discussions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for the bAbi task and suggests that the authors should provide more discussions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the subtasks are simplistic or why more discussions are necessary. Without specific justification or references, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. While it points out a potential weakness in the experimental setup, it lacks specific guidance or suggestions on how the authors might address this issue or what kind of discussions would be beneficial. The comment provides a general direction for improvement but does not offer detailed feedback or actionable steps, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. While the comment implies that the authors should consider this limitation and potentially address it, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about the potential for extension, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a purely factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. This question prompts the authors to consider the scope and potential improvements of their method, which could lead to a more comprehensive approach. However, the comment does not provide specific guidance or suggestions on how to address this limitation or extend the method, leaving the authors with a general direction but no actionable steps. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns. First, it questions the meaning of \"sqeuence of episodes\" and suggests that the authors clarify this term. This is an explicit action that the authors can take to address the confusion. Second, the comment points out the lack of related work, suggesting that the paper seems related but does not address this aspect. This is an implicit action that the authors can infer, as it implies they should include relevant related work to strengthen their contribution. However, the comment does not provide specific guidance on which related works to include or how to integrate them into the paper. While the actions are clear, they are somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the meaning of \"sqeuence of episodes\" and suggesting the inclusion of related work. This provides clear guidance on what the authors need to clarify or include in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two concerns: the definition of \"sqeuence of episodes\" and the lack of related work. The first part of the comment questions the meaning of a term used in the paper, which is a logical and reasonable inquiry that requires clarification. The second part suggests that the paper lacks related work, which is a subjective claim that could be supported by references to similar studies or discussions of related literature. However, the comment does not provide specific examples or references to substantiate this claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important points. First, it questions the meaning of \"sqeuence of episodes,\" suggesting that the authors clarify this term. This is a clear and actionable suggestion that helps the authors improve the clarity of their paper. Second, the comment points out the lack of related work, noting that the paper seems related but does not address this aspect. This feedback is valuable as it prompts the authors to consider including relevant related work to strengthen their contribution. However, the comment could be more helpful if it provided specific examples or references of related work that the authors should consider. Overall, the comment is 4 as it identifies areas for improvement and provides some guidance, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the characterization of the study as an \"ablation\" study, stating that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might reframe their study or what specific aspects need to be addressed to align with the concept of an ablation study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table where the study is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique, as it clearly identifies the issue with the characterization of the study, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study about different subdomain sizes is not an \"ablation\" study because it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or evidence to fully support it.", "helpfulness_rationale": "The review comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This feedback is 3 as it identifies a potential misinterpretation of the study\"s methodology. However, it lacks depth and does not provide specific guidance on how the authors might address this issue or improve their characterization. Without actionable advice or suggestions, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. While the comment implies that the authors should consider this idea, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they should explore this possibility, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. However, it does not provide any reasoning, evidence, or references to support why this suggestion is necessary or beneficial. The lack of justification or examples makes it difficult for the authors to understand the basis of the claim and how it could improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This feedback is 3 as it provides a potential direction for expanding the scope of the work by integrating AccNet into a more comprehensive system. However, the comment lacks specific guidance on how to implement this suggestion or what benefits it might bring to the research. To be more helpful, the comment could include more detailed reasoning or examples of how this integration could enhance the paper. Therefore, the comment is rated as 3, as it offers a potential direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on which datasets to use or how to conduct the additional testing. The action is implicit and somewhat vague, as the authors can infer the need for further testing but lack specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This provides some grounding as it refers to the testing of the metric, but it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional testing on multiple datasets to validate the metric\"s effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This feedback is valuable as it highlights a potential limitation in the evaluation of the metric, suggesting that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment lacks depth and does not provide specific guidance on which datasets to use or how to conduct the additional testing. While it points out a critical area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these additional comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this evaluation is in or where these comparisons should be made. The authors can infer that it relates to the evaluation section, but the lack of explicit mention of specific sections or figures makes it weakly grounded. The comment is specific in suggesting additional comparisons to strengthen the evaluation, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons would be beneficial or how they would enhance the evaluation. The lack of detailed justification or references makes it difficult for the authors to understand the full context and significance of the suggestion. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential improvement in the evaluation section by suggesting that the base DA methods should be compared with and without the architectural competitors, such as AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for enhancing the evaluation by including direct comparisons with relevant competitors. By following this suggestion, the authors can strengthen their analysis and provide a more comprehensive understanding of the performance of their proposed TransferNorm architecture. However, the comment could be more helpful if it included specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two specific issues: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as [1] S. Zhang et al, [2] Z. Ding et al, and [3] T. Wang et al, which could help the authors understand the context and potential improvements. However, the comment does not explicitly instruct the authors to define these abbreviations or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should define these abbreviations and provide references to the literature. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"NE\" on L73 and superscript notation in Eq 6, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on the issue of undefined abbreviations and the lack of definition for superscript notation, which is crucial for understanding the context. Additionally, the comment includes references to relevant literature, which further supports the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies two specific issues: the lack of definition for the abbreviation \"NE\" and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as [1] S. Zhang et al, [2] Z. Ding et al, and [3] T. Wang et al, which could help the authors understand the context and potential improvements. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim that these issues hindered understanding. While the references are helpful, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as [1] S. Zhang et al, [2] Z. Ding et al, and [3] T. Wang et al, which could help the authors understand the context and potential improvements. However, the comment does not offer detailed guidance on how to address these issues or suggest specific changes to improve the clarity of the definitions. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the evaluation or what specific steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the issue with the baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation is weak because the baselines used in the paper are not designed for fair classification. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. This feedback is valuable as it points out a potential weakness in the methodology that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the setting in the first three paragraphs of section 2 needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback provides a clear and direct action for the authors to take, which is to clarify the setting. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first three paragraphs, which is the need for clearer explanation of the setting. The comment highlights a potential issue with the authors implying a greater generality than what is presented, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of section 2 need to be clarified, suggesting that the authors may be implying a greater generality than what is actually presented. This claim is 3 as it provides a logical reasoning for the need for clarification, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact issues with the generality implied, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It points out that the authors may be implying a greater generality than what is actually presented, which could lead to confusion. This feedback is clear and actionable, as it directs the authors to clarify the setting to avoid any potential muddling of the exposition. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what could be clarified. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the convincing nature of the experiments, specifically questioning the choice of the old baseline like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the experiments being not quite convincing, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its suggestion to explore alternative approaches and questions the advantages of the proposed method compared to these approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of old baselines like R3D and C3D for the experiments, suggesting that more recent and computationally efficient approaches like X3D and SlowFast should be considered. The reviewer provides a logical reasoning by pointing out that many papers have proposed these 3D CNNs, implying that the proposed method should also be tested on them. However, the comment lacks specific references or examples to support the claim that these recent approaches are more efficient or advantageous. This makes the claim 3, as it provides a logical basis but requires additional evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the convincing nature of the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. This feedback is 4 as it provides clear and actionable suggestions for improvement, encouraging the authors to explore alternative and more efficient baselines. However, the comment could be more helpful if it included specific recommendations or examples of how to implement these suggestions. Overall, the comment offers valuable guidance for enhancing the experimental section of the paper, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on how the attention module is attached to the ResNet20 architecture and how many attention modules are used. It also inquires about their placement, whether after each block or stage. This feedback provides a clear and direct action for the authors to take, which is to clarify these aspects in their draft. The request is specific and actionable, as it outlines what information needs to be added or clarified to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the attention module is attached to the backbone architecture, including questions about the number of attention modules and their placement. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the implementation of the attention module within the ResNet20 architecture. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information to enhance the clarity of the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the implementation of the attention module within the ResNet20 architecture. It questions the number and placement of attention modules, which is crucial for understanding the methodology and reproducibility of the work. By asking for clarification on these aspects, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, it could be more helpful if it suggested ways to address the issue or provided examples of how to clarify this aspect. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions the precision of the bitrate range used for BDrate comparison, and second, it suggests a related work for discussion or comparison. The first part of the comment is 3 as it prompts the authors to clarify the specific bitrate range used in their comparison. However, the second part is more explicit and concrete, as it provides a specific suggestion for additional discussion or comparison. Overall, the comment is 4, as it offers a clear direction for the authors to address the first issue and a specific suggestion for the second issue.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s performance at different bitrates, specifically noting that it performs better at high bitrates but is close to the baselines at low bitrates. It also suggests a related work for discussion or comparison, mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. However, the comment does not specify which part of the paper discusses the bitrate comparison or the related work, making it weakly grounded. The suggestion for discussion or comparison is specific, but the lack of grounding makes it challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. Second, it recommends a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. While the comment provides a specific suggestion for additional discussion or comparison, it lacks detailed reasoning or evidence to fully substantiate the claim about the precision of the bitrate range. The suggestion for related work is clear and specific, but the initial claim about the precision of the bitrate range is not fully supported. Therefore, the comment is 3, as it provides a clear suggestion but lacks comprehensive justification for the first part.", "helpfulness_rationale": "The review comment raises two points. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. This feedback is 3 as it prompts the authors to provide more detailed information about their experimental setup, which could enhance the clarity and reproducibility of their results. Second, the comment suggests a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. This suggestion is 5 as it provides a specific reference for the authors to consider, potentially enriching their discussion and offering a broader perspective on their work. Overall, the comment offers valuable insights and suggestions that can help the authors improve their draft, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this distinction. The authors may infer that it pertains to the discussion or results sections, but this is not explicitly mentioned. The comment lacks specificity in terms of what needs to be addressed, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is necessary or how it would impact the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While this is a valid point, the comment lacks specificity and does not provide detailed guidance on how the authors should make this distinction or why it is important. Without actionable advice or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, it does not provide specific guidance or suggestions on what additional analysis or improvements the authors should undertake. The comment lacks explicit instructions or concrete details on how the authors might address this issue, leaving the authors uncertain about the exact steps to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements made by the paper over previous works and selfimplemented baselines, noting that these improvements are marginal. However, it does not specify which tasks or experiments are being discussed, making it difficult for the authors to pinpoint the exact parts of the paper that need further analysis. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is not specific about what additional analysis is needed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. While it identifies a potential issue with the paper\"s results, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The comment provides a general direction but does not offer actionable steps or detailed feedback, making it 3. The authors are aware of the need for further analysis but are left without clear direction on how to proceed. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. While it identifies a specific issue with the clarity of the proof, it does not provide explicit guidance on how the authors should address this problem. The comment lacks concrete suggestions or actions for the authors to take, such as recommending ways to improve the clarity of the proof or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the theorem is buried in the appendix and its proof is unclear. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and suggests that the authors should clarify or improve the clarity of the proof. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as recommending alternative ways to present the proof or suggesting improvements to enhance its clarity. As a result, the feedback is 3, as it highlights a critical area for improvement but does not fully support the authors in making the necessary changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific feedback on two issues: the accuracy of the claim about the Walkman algorithm being solved by ADMM and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. The first point is fully grounded as it references specific sections of the paper (Page 2, second paragraph in Related Work) and provides a clear correction. The second point is also fully grounded, as it references a specific section (Section 3, first paragraph) and highlights a lack of clarity. Both points are specific, allowing the authors to accurately identify the areas needing revision. Therefore, this comment is 5, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the claims about the Walkman algorithm and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of two claims. The first claim is that the statement \"However, these works are all based on the simple SGD for decentralized optimization\" is inaccurate because the Walkman algorithm is solved by ADMM, with two versions. This claim is 3 as it provides a specific reference to the Walkman algorithm and its solution by ADMM, but it lacks detailed reasoning or examples to fully substantiate the claim. The second claim is that the reference for the \"it\" in the first paragraph of Section 3 is unclear. This is a factual observation that does not require verification. Therefore, the overall verifiability of the comment is 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues. First, it corrects a claim about the Walkman algorithm, pointing out that it is solved by ADMM, not SGD, and provides two versions. This feedback is valuable as it helps the authors ensure the accuracy of their claims in the related work section. Second, the comment identifies a lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3, suggesting that the authors need to clarify this reference. Both pieces of feedback are clear and actionable, offering the authors a path to improve the clarity and accuracy of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation of the theoretical result, which only provides utility guarantees under the assumption of Gaussian features and noise. It suggests that this is a strong requirement on the data and that the authors should compare their rates to existing rates in the literature. While the comment implies that the authors should address this limitation and provide comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical result in the paper, specifically noting that it provides utility guarantees only under the assumption of Gaussian features and noise. This is a strong requirement on the data, and the reviewer suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the theoretical results section. The comment is specific in detailing the issue with the assumption and the need for comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical result in the paper provides utility guarantees only under the assumption of Gaussian features and noise, which is a strong requirement on the data. The reviewer also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This claim is 3 as it points out a limitation of the theoretical result and suggests a comparison to existing work. However, it lacks specific references or examples to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the theoretical result of the paper, which provides utility guarantees only under the assumption of Gaussian features and noise. This is a strong requirement on the data, and the reviewer suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This feedback is clear and actionable, as it directs the authors to address a critical limitation and provides a specific suggestion for improvement. By highlighting this issue and offering a constructive suggestion, the comment is 5, as it empowers the authors to significantly enhance their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. While the comment implies that such a comparison would be useful, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, it does not specify which part of the paper this comparison should be made in, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs to be addressed. The comment is specific in its suggestion to compare with the original approach, but the lack of grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a comparison with a relevant existing work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific aspects of the original approach should be examined. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works ([1, 2, 3]) that address similar questions, implying that these comparisons should be included to provide a more comprehensive evaluation. While the comment explicitly states the action needed, it does not provide detailed guidance on which specific aspects of the proposed method should be compared or how to integrate these additional comparisons into the experimental section. The action is concrete but could be more detailed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue, which is the lack of additional experimental comparisons to demonstrate the effectiveness of the proposed method. The comment references specific works ([1, 2, 3]) that address similar questions, providing a clear direction for the authors to expand their experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method, referencing specific works ([1, 2, 3]) that address similar questions. This provides a clear rationale for the claim, as it highlights the need for more comprehensive experimental validation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional comparisons would enhance the paper\"s impact. Despite this, the claim is 4 due to the logical reasoning and references provided, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s experimental section, suggesting that the authors should include additional comparisons with other relevant works. It provides a clear rationale by referencing specific works ([1, 2, 3]) that address similar questions, indicating that these comparisons would enhance the paper\"s effectiveness. This feedback is actionable and provides a clear direction for the authors to improve their draft by expanding their experimental validation. However, the comment could be more helpful if it offered suggestions on how to integrate these additional comparisons or which specific aspects of the proposed method should be compared. Overall, the comment is 4 as it guides the authors towards a significant enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with error bars under different random seeds, which is a clear and direct action. It also provides a rationale for why this is important, stating that the current results on the dev set may not be convincing. This feedback is concrete and actionable, as it gives the authors a specific task to perform to enhance the credibility and robustness of their results. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Tables 1 and 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the current results, suggesting that the authors should present the average results on the test set with error bars under different random seeds. This provides clear guidance on what needs to be addressed to improve the paper\"s credibility and robustness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results reported in Tables 1 and 2 are not convincing because they are based on the dev set and the hyperparameter search and model selection are also done on the dev set. The reviewer suggests presenting the average results on the test set with error bars under different random seeds to enhance the credibility of the results. This claim is 4 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to conduct additional experiments or provide more detailed analysis to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the current results reported in Tables 1 and 2, specifically noting that the results are based on the dev set and the hyperparameter search and model selection are also done on the dev set. The reviewer suggests presenting the average results on the test set with error bars under different random seeds, which is a clear and actionable suggestion. This feedback is valuable as it provides a specific and constructive way to enhance the credibility and robustness of the results. By following this suggestion, the authors can improve the reliability of their findings and make their paper more convincing. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct an ablation study on the parameter \u03b1, which is currently only set to three values with a large gap between 1e4 and 1e1. The reviewer recommends providing additional values, specifically 1e2 and 1e3. This feedback is clear and direct, providing a specific action for the authors to take to improve their study. The suggestion is concrete, as it specifies the additional values to consider. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study on \u03b1, noting that it is only set to three values with a large gap between 1e4 and 1e1. The reviewer recommends providing additional values, such as 1e2 and 1e3, to improve the study. This level of detail and specificity makes it clear what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ablation study on \u03b1 is insufficient, as it only considers three values with a large gap between 1e4 and 1e1. The reviewer suggests providing additional values, such as 1e2 and 1e3, to improve the study. This claim is 3 as it provides a logical reasoning for the need for additional values, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact impact of these additional values, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by pointing out an insufficient ablation study on the parameter \u03b1. It highlights that \u03b1 is only set to three values with a large gap between 1e4 and 1e1, suggesting that providing additional values, such as 1e2 and 1e3, would enhance the study. This feedback is clear and actionable, as it directs the authors to conduct a more comprehensive analysis by including additional parameter values. By addressing this suggestion, the authors can strengthen their experimental validation and provide a more robust evaluation of their results. Therefore, the comment is 4, as it provides a specific and actionable recommendation for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the study, including the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, allowing the authors to infer that they need to include this information in their paper. The action is concrete, as it specifies what needs to be addressed, but it is implicit because it is not explicitly stated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the dataset used in the study, specifically regarding the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment does not explicitly mention specific sections of the paper, it is clear that it pertains to the dataset description and analysis sections. The authors can infer that it relates to the methodology or results sections, but they cannot pinpoint the exact part of the paper being addressed. The comment is specific in detailing what information is missing or unclear, such as the number of topics and the size of the dataset. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the study, specifically regarding the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also requests that the main paper describe the number of documents in the train/test sets and the vocabulary size. While the questions are logical and seek clarification, they do not contain any claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the dataset used in the study, specifically regarding the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment identifies areas where the paper lacks clarity and provides specific questions for the authors to address, it does not offer detailed guidance or suggestions on how to improve the draft. The feedback is 3 as it points out gaps in the paper\"s description but could be more comprehensive by offering actionable advice or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment identifies a potential issue with the analysis, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete suggestions on which specific approaches to include or how to conduct the additional comparisons. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically mentioning that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which sections or figures are affected. The comment is specific in pointing out the lack of comparison with other NAS approaches, which is a clear issue. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This claim is 3 as it identifies a specific limitation in the analysis, but it lacks detailed examples or references to other NAS approaches that could have been included. The comment suggests that the authors should expand their analysis, but it does not provide specific guidance on which approaches to include or how to conduct the additional comparisons. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific limitation in the analysis on BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This feedback is 3 as it points out a potential gap in the analysis, suggesting that the authors should expand their comparison to include a broader range of NAS approaches. However, the comment could be more helpful if it provided specific suggestions on which NAS approaches to include or how to conduct the additional comparisons. Overall, the comment offers a direction for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve the focus of their paper. Without specific suggestions or directions, the authors are left without a clear understanding of what changes might be necessary. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the zeroshot version and its connection to density estimation, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, the comment does not provide specific reasoning or evidence to support why these aspects are considered distracting or how they impact the main point. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper, which is the ability to learn effective prototypes for fewshot learning. While the comment identifies a potential issue, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern or improve the focus of their paper. Without detailed guidance or examples, the authors are left without a clear understanding of how to enhance the clarity and coherence of their work. Therefore, the comment is 2, as it highlights a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed on the translation and filtering methodology used to create the Arabic climate change QA dataset. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the process. The comment specifies what information is lacking, making it explicit and concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of details regarding the filtering process used to create the Arabic climate change QA dataset. It specifies that more information on the translation and filtering methodology is needed to assess the dataset quality. However, it does not explicitly mention which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, which is the lack of information on the filtering process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, and more information on the translation and filtering methodology is needed to assess the dataset quality. This claim is 3 as it identifies a specific area where the paper lacks detail, but it does not provide specific examples or references to support the claim. The authors would need to infer the exact nature of the missing information, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. However, it could be more helpful if it offered suggestions on how to improve the dataset description or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that requires attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for these additions but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact areas that need attention. Additionally, the comment lacks specificity in detailing what specific aspects of the experiment results should be enriched or how the thresholds should be varied. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas where the experiment results can be enriched: the inclusion of attacks with different strengths and the exploration of how different thresholds affect detection performance. This feedback is clear and actionable, providing the authors with concrete steps to enhance their experimental analysis. By suggesting these additions, the comment offers valuable guidance on how to improve the depth and robustness of the results. However, it could be more helpful if it provided examples or specific recommendations on how to implement these changes. Overall, the comment is 4 as it directs the authors towards meaningful enhancements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific action for the authors to take to evaluate their claim of reducing exposure bias. It explicitly states that training a discriminator on generations from the learned model is needed to confirm this claim, similar to the approach depicted in Figure 1. The comment also clarifies that this is different from Figure 4, where the discriminator is coadapting with the generator during training. This provides clear guidance on what the authors should do to substantiate their claim, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias, similar to Figure 1. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific action for the authors to take to evaluate their claim of reducing exposure bias. It implies that training a discriminator on generations from the learned model is necessary to confirm this claim, similar to the approach depicted in Figure 1. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim that this approach is necessary. While the suggestion is logical, it lacks specific evidence or references to support the claim that this method is essential for confirming the reduction of exposure bias. Therefore, the comment is 3, as it provides a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It explicitly instructs the authors to train a discriminator on generations from the learned model, similar to the approach depicted in Figure 1, to confirm the effectiveness of their method. This feedback is specific and offers a concrete way for the authors to substantiate their claim, making it 5. By following this guidance, the authors can significantly improve the verifiability and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to know the extent of the performance difference resulting from using different image sizes and different variations of ResNets. While the comment implies that the authors should investigate and report this difference, it does not provide explicit instructions on how to conduct this analysis or what specific metrics or methods should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is understanding the performance difference resulting from using different image sizes and ResNet variations. This provides clear guidance on what the authors should investigate and report. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for more information, specifically asking for clarification on the performance difference resulting from using different image sizes and ResNet variations. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is 3 as it identifies a specific area where the authors could provide more information, namely the performance difference resulting from using different image sizes and ResNet variations. This feedback prompts the authors to consider including this information in their analysis, which could enhance the comprehensiveness of their study. However, the comment lacks depth and does not provide specific guidance on how to measure or report this difference, leaving the authors with a general suggestion rather than a detailed action plan. Therefore, the comment is 3, as it points out an area for improvement but does not fully guide the authors in making the necessary enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not provide specific guidance on what aspects of the algorithm should be detailed or how the description should be structured. The action is implicit, as the authors need to infer that they should provide a detailed description of the algorithm, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or subsection. Without explicit references to the paper, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be detailed or how the description should be structured. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to enhance understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. While this feedback highlights an area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the description or what aspects of the algorithm should be detailed. Without additional details or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s mention of using Chebyshev polynomials for speedup, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014adding a runtime comparison at test time\u2014to further explore the potential speedup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. While the comment implies that such a comparison would be beneficial, it does not provide specific reasoning or evidence to support why this is necessary or how it would enhance the paper. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a specific comparison that could enhance the paper\"s analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. To be more helpful, the comment could include specific suggestions or examples of how such a comparison could be made or what insights it might reveal. Therefore, the comment is rated as 3, as it points out a potential enhancement but does not fully guide the authors in implementing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or whether they should consider expanding the scope of their method to include natural images. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not specify which part of the paper discusses the method\"s applicability or how it is currently limited to digit or text images. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its critique of the method\"s applicability, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. This is a relevant point as CIFAR10 is a widely used dataset in computer vision with broader applications than digit or text images. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or expand the scope of their method. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to reorganize the prompts or what specific changes should be made. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve the organization of the prompts. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Tables 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not wellorganized and that sentences squeeze together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or provided examples of better organization. Overall, the comment is 4 as it directs the authors to a specific area needing attention but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is clear and direct, providing the authors with a specific action to take: to clarify the figures and ensure that all modules are labeled correctly. The comment is explicit and concrete, giving the authors a clear path forward for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the figures, such as the confusion in the relation of subfigures and the lack of labeling for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. However, the comment does not provide specific examples or detailed reasoning to support the claim that the figures are confusing or unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that they are not clear and providing examples of confusion, such as the relation of 3 subfigures and the lack of labeling for certain modules like CMAF, L_BT, and VoLTA. This feedback is clear and actionable, as it directs the authors to improve the clarity of their figures by addressing these specific issues. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figures or offered alternative ways to present the information. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. It implies that the authors should explore this possibility or acknowledge that it is an open problem. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include a specific reference or discussion on this topic. The action is implicit but concrete, as the authors know what needs to be done to address the suggestion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and references a specific issue discussed in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it suggests exploring existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment provides a clear direction for improvement by suggesting that the authors either explore this possibility or acknowledge that it is an open problem. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment implies that there might be alternative methods or approximations that could be explored. However, it does not provide specific references or examples of such work, making it 3. The authors would need to conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even if it is an approximation. This feedback is valuable as it provides a direction for the authors to explore alternative approaches or acknowledge the limitations of their current methodology. By suggesting that the authors might need to add a line or two to acknowledge the absence of a solution, the comment enhances the paper\"s transparency and clarity. This feedback is 4 as it offers actionable advice for improvement, but it could be more comprehensive by providing specific examples or references of relevant work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies questionable design choices, specifically mentioning the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not provide explicit guidance on how to control these factors or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should address the control of domain drift. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific design choices, particularly the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not explicitly mention which part of the paper discusses these design choices, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not precise. The comment is specific in detailing what needs to be addressed regarding the control of domain drift, providing clear guidance on the issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, questioning how factors like domain drift are controlled. The comment suggests that while perplexity relates to the original task, domain drift is a separate aspect that could be relevant. However, the comment lacks specific examples or references to support the claim that domain drift is a separate issue or how it is controlled. This makes the claim 3, as it provides a logical basis for the concern but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, suggesting that there may be separate aspects of domain drift that are not adequately addressed. This feedback is 3 as it points out a potential weakness in the methodology and encourages the authors to consider additional factors. However, the comment lacks specific suggestions or guidance on how to address these issues, such as proposing alternative measures or methods to control domain drift. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How does the number of images impact the model performance, and (2) whether more training images make the performance worse or better. Additionally, it suggests that BYOL should be explained in the abstract for its first appearance. While the questions provide some guidance on what the authors should consider, they do not explicitly instruct the authors to conduct specific experiments or analyses to address these points. The suggestion to explain BYOL in the abstract is somewhat vague, as it does not specify how this explanation should be structured or what aspects should be emphasized. Therefore, the comment is 3, as it provides some direction but lacks detailed guidance on how to implement the suggestions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions about the impact of the number of images and the need for an explanation of BYOL, but without grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions and a suggestion for clarification. The questions are logical and seek clarification on the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions or the suggestion. Without additional context or justification, the authors may find it challenging to understand the basis of these questions and how they relate to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. While these are valid points that could contribute to the improvement of the paper, the comment lacks specific guidance or suggestions on how the authors might address these issues. It identifies areas for clarification but does not provide actionable steps or examples for the authors to follow. As a result, the comment is 3, as it points out areas that need attention but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should include more detailed explanations, it does not explicitly instruct them to do so or provide specific guidance on how to structure these explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"L_pixel\" component, which is a specific part of the paper, providing full grounding. It also specifies the issue by asking for stronger arguments or intuitions to explain why these particular losses are \"bound to help.\" This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding why the method works, specifically regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current explanation is unclear. This lack of detailed justification makes the claim 3, as the authors would need to infer the nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of improvement regarding the clarity of the explanation for why the method works, particularly focusing on the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and provide more detailed reasoning. However, the comment could be more helpful if it offered specific suggestions or examples of how to strengthen the arguments or intuitions. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods in the Related Work section, specifically focusing on longcontext language models. It suggests including discussions on sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is clear and provides specific guidance on what additional information should be included to enhance the paper. The authors are given a concrete action to take, which is to expand the related work section with detailed discussions on these methods. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what should be included in the section, such as discussing sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods for handling very long documents. This level of detail helps the authors understand exactly what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"Related Work section\" is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations in the context of longcontext language models. The comment provides specific examples of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods that should be included. This level of detail and specificity makes the claim 4, as it provides clear guidance on what additional information is needed to enhance the related work section. However, it could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the \"Related Work\" section, which is lacking details. It provides a clear and actionable suggestion by recommending that the paragraph on longcontext language models should provide a more comprehensive overview of existing methods and their limitations. The comment specifies what additional information should be included, such as discussions on sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is detailed and actionable, offering the authors a clear path to enhance the depth and relevance of their work. Therefore, the comment is 5, as it provides specific guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors might address this concern, such as suggesting additional data collection or analysis. The action is implicit and somewhat vague, as the authors can infer that they need to justify the sufficiency of their dataset, but the comment lacks concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset size being insufficient to capture a wide range of user traits and personalities across different content topics. It questions the sufficiency of 44k dialogues in comparison to the vast amount of data typically used to train LLMs. The comment is fully grounded as it explicitly mentions the dataset size and the comparison to trillions of tokens, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dataset size and the need for a larger dataset to cover varied domains. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer provides a logical reasoning by comparing the dataset size to the scale of data used in LLM training, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains, which is a valid point. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or analysis. While it identifies a potential weakness, the feedback could be more helpful with actionable advice. Therefore, the comment is 3, as it provides insight but lacks depth and actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the justification of using binary classification as a baseline metric, particularly regarding its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The action is implicit and vague, as the authors are left to infer that they need to reconsider their choice of baseline metrics or provide a more detailed justification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the baseline metrics or the TAL task, making it weakly grounded. The comment is specific in its critique of the binary classification\"s limitations, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. The reviewer acknowledges the importance of the TAL task but expresses uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that binary classification is not suitable for assessing finegrained errors. This makes the claim 3, as the authors would need to infer the basis of the concern and potentially conduct further analysis to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative metrics or approaches. However, the comment lacks specific suggestions or guidance on how to address this concern, such as proposing alternative metrics or methods. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the work, noting that it only uses binary features and questioning the applicability of the method to real and categorical features. While the comment highlights an area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this limitation. The action is implicit, as the authors need to infer that they should consider the applicability of their method to real and categorical features. However, the comment lacks concrete details on how to implement this change, making it vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions the applicability of the method to real and categorical features. However, it does not specify which part of the paper discusses the use of binary features or how the authors should address the applicability to real and categorical features. This makes it difficult for the authors to identify the exact section that needs revision. The comment is weakly grounded because it does not provide specific guidance on where to find this information, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work only uses binary features. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the work, noting that the method only uses binary features and questioning its applicability to real and categorical features. This feedback is 3 as it points out an area where the authors might need to expand their method to be more generalizable. However, the comment lacks specific suggestions or guidance on how the authors could address this limitation, such as recommending the inclusion of real or categorical features. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors might improve it. Without explicit instructions or concrete examples, the authors are left without a clear understanding of what changes to make or how to address the issues. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or what specific issues need to be addressed. Without explicit references to sections, figures, or specific points, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding the nature of the unclear points, making it difficult for the authors to understand what needs to be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples or reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed feedback or evidence, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they might be clarified. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to improve their draft. This lack of detail and specificity makes the comment 2, as it does not effectively support the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors use other metrics, such as BERTScore, to evaluate the results. While the action is explicit, it does not provide specific guidance on how to incorporate these metrics or what aspects of the results they should evaluate using BERTScore. The suggestion is concrete in terms of the action to take, but the lack of detailed instructions on implementation makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or specific tables or figures. Without explicit references to the sections or elements being addressed, the authors may find it challenging to determine where to apply this suggestion. Additionally, the comment lacks specificity regarding what aspects of the results should be evaluated using BERTScore or how this metric should be incorporated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning, evidence, or examples to support why BERTScore would be more appropriate or why the current metrics are insufficient. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. While this is a specific and actionable suggestion, it does not provide any context or reasoning as to why BERTScore might be more appropriate or how it could improve the evaluation. The comment lacks depth and does not offer detailed guidance on how to incorporate these metrics or what specific aspects of the results should be evaluated using BERTScore. As a result, the feedback is 3, as it provides a direction for improvement but does not fully address the authors\" needs for enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench. It also questions the conditions under which SynTextBench should be used over other metrics. While the comment implies that the authors should conduct this comparison, it does not provide explicit instructions on how to perform the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and references \"other metrics proposed in the literature,\" such as MMLU and Big Bench. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison of SynTextBench to other metrics. The comment is also specific because it questions the conditions under which SynTextBench should be used over other metrics, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there has been a large amount of work on LLM evaluation and that some metrics do not satisfy the proposed desiderata. It suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, and questions the conditions under which SynTextBench should be used over other metrics. While the comment provides a logical basis for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance of the comparison and the conditions for using SynTextBench. Therefore, the comment is 3, as it provides a basis for the claim but requires additional details for full verification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench. This comparison could provide a more comprehensive evaluation of the proposed metric. The comment also questions the conditions under which SynTextBench should be used over other metrics, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the feedback is 4 as it offers a clear direction for improvement but lacks detailed instructions, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. While the comment identifies a lack of novelty, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the algorithm for constructing coresets, stating that it is not novel as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper this critique pertains to, such as a specific section or subsection. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the lack of novelty in the algorithm, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This claim is 3 as it provides a logical reasoning that the algorithm is an extension rather than a novel contribution. However, the comment lacks specific references or examples to support the claim, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the algorithm for constructing coresets, noting that it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This feedback is 3 as it points out a potential weakness in the originality of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without actionable advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses dissatisfaction with the writing and annotations, stating that they are \"a little hard to follow.\" However, it does not provide specific suggestions or guidance on how the authors might improve their writing or annotations. Without actionable advice or examples of what needs to be changed, the authors are left without a clear understanding of how to address the issue. As a result, the comment lacks actionable guidance, making it 1.", "grounding_specificity_rationale": "The comment mentions \"Poor writing and annotations,\" but it does not specify which sections or parts of the paper are affected. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is specific in its critique of the writing and annotations being \"a little hard to follow,\" but without explicit references, it remains weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a subjective observation about the writing and annotations being \"a little hard to follow.\" It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks actionable feedback or suggestions on how the authors might improve these aspects. Without detailed guidance or examples, the authors are left without a clear understanding of what specific changes are needed to enhance the clarity and readability of their work. As a result, the comment is 3, as it points out a potential area for improvement but does not provide enough detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the discrepancy in achieving the best overall F1 score but not the best F1 score in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or what specific improvements are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and possibly improve the performance of the proposed method across all evaluation metrics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that only 8 out of 14 evaluation metrics achieve SOTA performances and questioning the discrepancy in achieving the best overall F1 score but not the best F1 score in all single types under a specific setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions why the proposed method achieves the best overall F1 score but not the best F1 score in all single types under a specific setting. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors may need to provide additional context or analysis to fully understand and address the concern. Therefore, the comment is 3, as it provides a basis for further investigation but requires more detailed support.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the discrepancy in achieving the best overall F1 score but not the best F1 score in all single types under a specific setting. This feedback is 3 as it highlights a potential weakness in the evaluation of the proposed method and prompts the authors to investigate and possibly improve the performance across all evaluation metrics. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered specific guidance on what aspects of the evaluation could be improved. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative approach they should consider. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to respond. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in questioning the rationale behind the choice, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle if all reports were included. This feedback prompts the authors to reconsider their experimental setup or data selection criteria, which could lead to a more comprehensive understanding of the dataset and its implications. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the proposed solution is an incremental step based on the relaxation proposed by Guzman. et al. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks any guidance or suggestions on how the authors might improve or expand upon their work. Without specific instructions or examples, the authors are left without a clear understanding of what changes or additions are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the proposed solution is an incremental step based on the relaxation proposed by Guzman. et al. However, it does not specify which part of the paper this incremental step is discussed in or how it relates to the relaxation proposed by Guzman. et al. This lack of grounding makes it difficult for the authors to identify the specific section of the paper being addressed. The comment is specific in its recognition of the incremental step but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point acknowledges that the proposed solution is an incremental step based on the relaxation proposed by Guzman. et al. However, it does not provide any additional context, reasoning, or evidence to support this claim. The comment lacks specific details or references to the work by Guzman. et al., making it difficult for the authors to understand the basis of the claim. Without further elaboration, the authors may find it challenging to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the proposed solution is an incremental step based on the relaxation proposed by Guzman. et al., but it does not provide any specific suggestions or feedback on how the authors might improve or expand upon their work. The comment lacks actionable guidance or detailed insights that could help the authors enhance their draft. Without specific suggestions or examples, the authors are left without a clear understanding of what aspects of their work need further development or clarification. Therefore, the comment is rated as 2, as it provides a recognition of the incremental nature of the work but does not offer meaningful feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific areas where the paper could be improved: the discussion of scalability bounds and the lack of clarity regarding memory requirements and computational complexity. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to expand their discussion on scalability and provide more detailed analysis of memory requirements and computational complexity. However, the lack of specific suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Scalability Bounds\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the lack of discussion on the upper limits of scalability and the absence of a clear discussion on memory requirements and computational complexity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the upper limits of FedDES\"s scalability and lacks a clear discussion of memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on scalability bounds and the absence of a clear discussion on memory requirements and computational complexity. This feedback is clear and actionable, as it points out a gap in the paper\"s analysis that the authors can address to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to expand the discussion or what specific aspects of scalability and computational complexity should be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should generate more instances with constraints and variables to address the concern about the ability of LLMs to model problems with large instance sizes. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to generate these instances or what specific steps to follow. The action is somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate more instances with constraints and variables, particularly noting that only a few instances in the paper have more than 7 variables. This implies a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific in terms of what the authors should do to address the concern, but without explicit grounding, the authors may struggle to pinpoint the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should generate more instances with constraints and variables, particularly noting that only a few instances in the paper have more than 7 variables. This raises a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not provide specific examples or references to support the claim that LLMs struggle with large instance sizes. The suggestion is based on a general observation about the number of variables in the instances, but without further justification or evidence, it remains somewhat vague. Therefore, the comment is categorized as 3, as it provides some reasoning but lacks detailed support or examples.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s instances, noting that only a few have more than 7 variables. It suggests that generating more instances with constraints and variables could help address concerns about the ability of LLMs to model problems with large instance sizes. This feedback is 3 as it points out a specific area for improvement and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to generate these instances or what specific aspects to consider when doing so. Overall, the comment provides a useful suggestion for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests several improvements to the results presentation, including labeling the yaxis in Figure 2 and 3 as \"performance\" and clarifying that the runtime is not represented in those figures. It also recommends using a scatter plot with x/y axes representing runtime/performance to enhance understanding and interpretation of the results. Additionally, the comment suggests highlighting the best results in tables. These suggestions are explicit and provide concrete guidance on how the authors can improve their results presentation. The authors know exactly what changes to make and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as labeling the yaxis as \"performance,\" clarifying the absence of runtime representation, and suggesting the use of a scatter plot with x/y axes representing runtime/performance. Additionally, it recommends highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests improvements to the results presentation, specifically mentioning the labeling of the yaxis in Figures 2 and 3 as \"performance,\" which is ambiguous, and the absence of runtime representation. It also recommends using a scatter plot with x/y axes representing runtime/performance to enhance understanding and interpretation of the results. Additionally, it suggests highlighting the best results in tables. These suggestions are based on logical reasoning and common sense, as they aim to improve the clarity and interpretability of the results. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the results presentation in the paper. It identifies two main issues: the ambiguity of the yaxis label in Figures 2 and 3, and the lack of representation of runtime in those figures. The reviewer suggests using a scatter plot with x/y axes representing runtime/performance to enhance the reader\"s understanding and interpretation of the results. Additionally, the comment recommends highlighting the best results in tables, which is a valuable suggestion for improving the clarity and impact of the paper\"s findings. This feedback is clear and provides the authors with concrete steps to improve their draft, making it 4. However, it could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the impact of the base node, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the topic. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential area for clarification but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer implies that the authors should clarify this aspect, but the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation or justification for the direction of the arrow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This provides clear guidance on what needs to be clarified or explained in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer suggests that the main purpose of the figure is to influence n^(i), implying that the current direction is confusing or incorrect. However, the comment lacks specific reasoning or evidence to support why this direction is problematic or how it affects the understanding of the figure. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a logical question but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). This feedback highlights a potential confusion or misinterpretation in the figure, which could impact the reader\"s understanding of the main purpose of the figure. By pointing out this issue, the comment provides a clear direction for the authors to clarify or correct the figure, thereby helping them improve the clarity and effectiveness of their draft. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context for the figure. Overall, the comment is 4 as it identifies a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. While the comment points out the lack of definition for abbreviations, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to define all abbreviations used in the paper, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3, as it highlights a specific area for improvement but does not provide detailed instructions on how to execute the action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of definition for abbreviations, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and causes confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any additional context, reasoning, or examples to support why this is a significant issue or how it affects the clarity of the paper. Without further elaboration or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many abbreviations lack definition and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it highlights a concrete area where the authors can improve the clarity of their work by defining abbreviations. However, the comment could be more helpful if it suggested how the authors might define these abbreviations or provided examples of how to do so. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it does not provide explicit guidance or suggestions for the authors to follow. The comment implies that the authors should consider other technical aspects when using advantage, but it does not specify what these aspects might be or how they should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it does not explicitly mention a specific part of the paper, the authors can infer that it relates to the methodology or analysis section. The comment is specific in questioning the technical basis for using advantage, which provides some guidance on what needs to be addressed. However, the lack of explicit mention of a section or part of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. It acknowledges that using advantage is more common in practice but seeks clarification on other technical aspects that might influence this choice. The comment does not make a claim or express an opinion, as it is purely inquisitive. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it seeks clarification on other technical aspects that might influence this choice. This feedback is 3 as it prompts the authors to consider additional factors in their analysis, but it lacks depth and does not provide specific guidance or suggestions for improvement. The authors are left with a general question that requires further exploration, making the comment 3 but incomplete."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the setting of Unsupervised Online Adaptation, noting that it seems strange because the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the description of the setting. The action is implicit and vague, as the authors are left to infer that they need to clarify or reframe the description of the adaptation process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. The comment provides a logical reasoning by pointing out the contradiction between the unsupervised nature of the setting and the need for annotations in the training set. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the issue and how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of the Unsupervised Online Adaptation setting, noting that it seems strange because the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. This feedback is 3 as it points out a specific area of confusion or misinterpretation in the paper. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might clarify or reframe the description to better align with the intended unsupervised nature of the adaptation process. Therefore, the comment is rated as 3, as it provides a starting point for improvement but does not fully address the authors\" needs for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the performance comparison in Table 1, specifically noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This implies that the comparison is unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the fairness of the comparison. The authors are left to infer that they need to adjust the comparison or provide additional context to justify the differences in sample weights. While the action is implied, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to differences in sample weights used by VINS compared to other baselines. The reviewer provides a specific example of how VINS sets different sample weights, while most baselines set all sample weights as 1. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This observation highlights a potential unfairness in the comparison, which could impact the validity of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the fairness of the comparison. While it points out a critical aspect of the analysis, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or optimizations. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not specify which part of the paper discusses the reply buffer or the time complexity, making it weakly grounded. The comment is specific in identifying the potential issue with the reply buffer and its impact on time complexity, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning.\" However, the comment does not provide detailed reasoning or evidence to support why this is a concern or how the referenced paper relates to the issue. The claim is 3 as it references an external source, but it lacks specific examples or detailed explanation, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. This is a relevant observation that could impact the efficiency and scalability of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the efficiency of their algorithm. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail to be fully actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment implies that the authors should consider these suggestions, it does not provide explicit instructions or concrete guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative baselines and methods for comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact areas where these suggestions should be applied. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact nature of the suggestion. The lack of detailed examples or references limits the verifiability of the claim, as it does not provide a clear basis for the authors to follow the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a direction for the authors to enhance their work by considering additional baselines. However, the comment lacks specificity and does not offer detailed guidance on how to implement these suggestions or which specific baselines to include. To be more helpful, the comment could provide examples of relevant baselines or a more detailed explanation of how these suggestions could improve the paper\"s analysis. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion of the article and a summary of the paper\"s contributions need to be provided. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to improve the draft. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion of the article and a summary of the paper\"s contributions need to be provided. However, it does not specify which part of the paper these should be included in, making it weakly grounded. The comment is specific in its request for a conclusion and summary, but without explicit references to sections, it is challenging for the authors to pinpoint where these should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and summary of the paper\"s contributions are needed. However, it does not provide any reasoning, examples, or references to support why these additions are necessary or how they would enhance the paper. Without specific evidence or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that a brief conclusion and a summary of the paper\"s contributions need to be provided. This feedback is clear and actionable, as it directs the authors to address a gap in their draft that could enhance its completeness and clarity. However, the comment could be more helpful if it provided examples of how a conclusion and summary could be structured or what specific points should be included. Despite this, the feedback is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the synthetic experiment in a nonseparable case, referencing Figure 1. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the ability of the neural network to handle a nonseparable data distribution, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthetic experiment in a nonseparable case, questioning the ability of the neural network to handle a nonseparable data distribution as illustrated in Figure 1. This feedback is 3 as it points out a potential weakness in the experimental setup, prompting the authors to consider whether their results are robust or if there are limitations in the experimental design. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or improve the experiment. Therefore, it is rated as 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a comparison with a method designed to defend against multiple attacks, which provides some guidance on what the authors could do to improve their paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This is a logical suggestion that could enhance the paper\"s relevance and comprehensiveness. However, the comment does not provide specific examples or references to support the claim that such a comparison would be meaningful or necessary. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This is a constructive suggestion that could enhance the paper\"s relevance and comprehensiveness by providing a more comprehensive evaluation of the proposed framework. The comment also acknowledges the paper\"s interesting study on defending against increasing malicious perturbations, which adds a positive perspective. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or which existing methods to consider. Overall, the feedback is 4 as it offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. It also questions the reason for presenting the results in this way. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the presentation of results. The action is implicit and vague, as the authors are left to infer that they need to clarify or reorganize the results to address the safety violations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and specifies the issue with the presentation, particularly regarding the disregard of safety violations in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details what needs to be addressed, namely, the convoluted presentation and the need to clarify the reason for presenting the results in this manner. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support the claim that the presentation is convoluted or why the safety violations are disregarded. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard the safety violations of the agent in the first 1000 episodes. It questions the reason for presenting the results in this way, which is a valid concern for the authors to address. However, the comment lacks actionable guidance or suggestions on how the authors might improve the presentation or address the safety violations. While it highlights an important area for improvement, the feedback could be more helpful if it provided specific recommendations or examples of how to present the results more effectively. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \u03c7_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is defining the bounds for \u03c7_i^l to improve understanding of the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the bounds for \u03c7_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, providing a specific request for the authors to define the bounds for \u03c7_i^l. This is important for understanding the timewarp function, which is a critical aspect of the paper. By addressing this request, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional context or suggestions on how to define these bounds or why they are important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment points out these errors, it does not provide explicit instructions on how to correct them. The authors are left to infer that they need to revise the text to fix these errors, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. However, the comment does not specify what needs to be addressed in terms of correcting these errors or improving the writing. It lacks specificity regarding the nature of the writing errors or how to address them. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. These are factual statements that do not require verification or evidence. They are clear and specific, allowing the authors to easily identify and correct the errors. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific instances where the text needs correction. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on improving the overall writing style. Despite this, the feedback is 4 as it directs the authors to address specific issues in their draft, allowing them to improve the clarity and professionalism of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should elaborate more on why the statement in line 134 holds, particularly in the context of the RNN compared to the URNN. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed reasoning. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is to elaborate on why the statement holds, particularly in the context of the RNN compared to the URNN. This provides clear guidance on what additional explanation is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should elaborate on why a statement in line 134 holds, particularly in the context of the RNN compared to the URNN. While the comment implies that the authors should provide additional explanation, it does not provide specific reasoning or examples to support the claim. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by elaborating on a statement about the RNN and URNN. It suggests that the authors should provide more explanation on why the statement holds, particularly in the context of the RNN compared to the URNN. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing point in their paper. However, the comment could be more helpful if it provided specific examples or references to support the elaboration. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the efficiency or whether there are alternative methods to consider. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the pairwise matching are inefficient or how they can be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the assertion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific guidance or suggestions on how to improve the allocation of Figure 1 or the editing of the main paper. The authors are left with a vague understanding of what needs to be addressed, making it difficult to know how to implement the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not specify which part of the main paper needs editing or provide details on what aspects should be improved. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment does not provide any guidance on how to address these issues, leaving the authors without clear direction. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment lacks specificity and does not provide actionable guidance on how to improve the allocation of Figure 1 or the editing of the main paper. Without detailed suggestions or examples, the authors are left with a vague understanding of what needs to be addressed, making the feedback 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the planbased method requiring manual design based on the ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans based on Table 2. The comment suggests that the proposed method may be difficult to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue and provides some insight, it does not offer explicit guidance or suggestions on how the authors might address this concern or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the need for manual design based on the ground truth, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the planbased method or the learned plan methods, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in detailing the issue with the planbased method and its generalizability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on the ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the learned plan methods being comparable. The suggestion about generalizability is somewhat supported by the mention of Table 2, but the claim remains 3 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the planbased method, noting that it requires manual design based on the ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, suggesting potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. This feedback is clear and actionable, as it highlights a critical limitation of the method and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or alternative approaches to consider. Overall, the comment is 4 as it directs the authors\" attention to a significant weakness in their methodology and encourages them to explore potential solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the sentence needs to be rewritten. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for a specific action, namely to rewrite the first sentence of the abstract. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it directly instructs the authors to rewrite the first sentence of the abstract. This feedback provides a clear direction for improvement, which is valuable for the authors to enhance the clarity and effectiveness of their abstract. However, the comment does not offer additional guidance or suggestions on how to improve the sentence or what specific changes should be made. While it is clear and actionable, it could be more helpful if it included more detailed advice or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. While the comment implies that this action is necessary, it does not explicitly instruct the authors to do so. The suggestion is concrete in terms of what needs to be done, but the action is inferred rather than explicitly stated. Therefore, the comment is 3, as it provides a clear direction but lacks explicit guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of a single heldout test set in most experiments, and suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. The comment also provides a rationale for why this is important, given the size of the datasets considered in the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. The reviewer acknowledges that the size of the datasets considered in the work may make this process timeconsuming but still encourages the authors to carry out this exercise. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that multiple splits are necessary. This makes the claim 3, as it provides a basis for the suggestion but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the reporting of results, specifically noting that the experiments are based on a single heldout test set. It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance, which is a common practice in papers on Gaussian Processes (GPs). The comment acknowledges that the size of the datasets considered in the work may make this process timeconsuming but still encourages the authors to carry out this exercise. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the robustness and reliability of the results. However, it could be more helpful if it included additional guidance on how to implement this suggestion or examples of how it might be done. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method might be more complex than necessary and implies that there could be a simpler underlying principle responsible for the quality gains. However, it does not provide any explicit guidance or suggestions on how the authors might simplify the method or identify this underlying principle. The action is implicit and vague, as the authors are left to infer that they should look for a simpler approach or principle, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more involved than necessary and implies that there might be a simpler underlying principle responsible for the quality gains. However, it does not specify which part of the paper this critique pertains to, such as a specific section or method description. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the method\"s complexity and the potential for a simpler principle, but without explicit references to the paper, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle responsible for the quality gains. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the method might be more complex than necessary and implies that there could be a simpler underlying principle responsible for the quality gains. While this observation is insightful, it lacks specific guidance or suggestions on how the authors might simplify the method or identify this underlying principle. The comment provides a direction for improvement but does not offer actionable steps or detailed feedback, making it 3. The authors are left to infer that they should look for a simpler approach or principle, but without concrete guidance, the feedback remains incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this idea or whether it should be considered a significant contribution. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the idea of adding a method on top of other methods to improve transferability, but it does not specify which part of the paper this suggestion is related to. The authors cannot confidently determine which section or method this comment pertains to, making it weakly grounded. The comment is specific in its critique, suggesting that the idea is good but not significant, which provides some guidance on the evaluation of the contribution. However, without explicit grounding, the comment is challenging for the authors to address effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this idea is not significant. Without specific examples or detailed explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any further explanation or reasoning why this idea is not considered a significant contribution. The comment lacks depth and actionable feedback, leaving the authors without specific guidance on how to address this issue or improve their draft. As a result, the comment is not helpful, as it does not offer meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses a concern about the hGRU architecture, stating that it seems adhoc and not well motivated. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the motivation of the hGRU architecture. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the hGRU architecture, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this architecture is discussed in, making it weakly grounded. The comment is specific in its critique, as it points out that the architecture seems adhoc and not well motivated. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc\" and not well motivated. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the hGRU architecture, stating that it seems adhoc and not well motivated. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the motivation of the architecture. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is not helpful, as it lacks the depth and specificity needed to guide the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. First, it suggests a correction in the algorithm description, specifically questioning the use of \"s_t\" instead of \"s_n\" on Line 8. This is an explicit and concrete action that the authors can take to correct the draft. Second, it raises a curiosity about the asymptotic performance of the proposed method and suggests that the authors provide average return results with more environment steps. This part is also explicit, as it gives a clear request for additional information. Overall, the comment provides explicit and concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of \"s_n\" instead of \"s_t\" and expressing curiosity about the asymptotic performance of the proposed method. Additionally, it suggests providing average return results with more environment steps, which further clarifies the request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the use of \"s_n\" instead of \"s_t\" on Line 8 of Algorithm 1, which is a factual observation that does not require verification. The second part raises a curiosity about the asymptotic performance of the proposed method and suggests providing average return results with more environment steps. This part is 3 as it requests additional information, but it lacks specific examples or references to support the claim about the asymptotic performance. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment provides two actionable suggestions. First, it points out a potential error in the algorithm description, specifically questioning the use of \"s_t\" instead of \"s_n\" on Line 8. This feedback is clear and actionable, allowing the authors to correct the draft accurately. Second, the comment raises a curiosity about the asymptotic performance of the proposed method and suggests that the authors provide average return results with more environment steps. This request for additional information is also clear and actionable, as it encourages the authors to include more detailed results that could enhance the paper\"s comprehensiveness. Overall, the comment is 4 as it identifies specific areas for improvement and provides clear guidance for the authors to enhance their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their approach and Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to clarify the challenges and differences, but it lacks concrete guidance on how to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the analysis of Adam under the (L0,L1)smoothness condition. It questions the clarity of the challenges and suggests that the authors should explain these challenges, particularly in relation to Zhang et al. This provides some level of grounding as it refers to a specific part of the paper, but it does not specify which section or part of the analysis is unclear. The comment is specific in its suggestion to explain the challenges and differences, but it lacks full grounding because it does not explicitly mention the section or figure being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly in relation to Zhang et al. The comment implies that the analysis could be more straightforward and that the authors should provide additional explanation. However, it does not provide specific examples or references to support the claim that the analysis is unclear or how it differs from Zhang et al. This makes the claim 3, as it lacks detailed evidence or examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It questions the clarity of the challenges and suggests that the authors should explain these challenges, particularly in relation to Zhang et al. This feedback is 3 as it points out a potential area of improvement in the paper\"s clarity and provides a specific direction for the authors to address. However, the comment could be more helpful if it offered suggestions on how to clarify the challenges or provided examples of what aspects of the analysis are unclear. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, implying that the authors should reconsider the phrasing. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. While the first part is somewhat vague, it does provide a clear direction for the authors to consider revising their language. The second part is explicit and concrete, offering specific suggestions for improvement. However, the overall comment lacks detailed guidance on how to tone down the statement or how to address the grammatical errors, making it 3. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"34\" and the specific statement about the neural network memorizing critical points. This allows the authors to accurately identify the part of the paper being addressed. Additionally, the comment is specific because it provides clear feedback on the phrasing of the statement and suggests ways to improve the method section, such as compressing it and correcting grammatical errors. The suggestion to doublecheck plurals and articles is also specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, which is a subjective claim that requires the authors to reconsider their language. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors. This part is more verifiable as it offers concrete suggestions for improvement. However, the first part lacks detailed justification or examples, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a mix of feedback. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and actionable suggestion for improving the clarity of the text. Additionally, it offers feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. This feedback is clear and provides the authors with concrete steps to improve their draft. However, the comment could be more helpful if it included specific examples of grammatical errors or suggested ways to compress the method section. Overall, the comment is 4 as it offers actionable advice for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that most person reID methods are based on pedestrian detectors and that there are endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate this information into their work or whether it is relevant to their research. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment discusses the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not specify which part of the paper this information is relevant to, nor does it provide specific guidance on how the authors should address this point. The authors may infer that it relates to the methodology or related work section, but this inference is not explicit. The comment lacks specificity in detailing what needs to be addressed or improved, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point makes a factual statement about the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. This statement is descriptive and does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation that does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual observation about the methods used in person reID, noting that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not offer any specific guidance or suggestions on how this information might be relevant to the authors\" work or how it could be incorporated into their research. Without actionable feedback or insights, the comment lacks the depth and specificity needed to be helpful. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce the content of Section 3.2. This is a clear and direct action for the authors to take, as it provides a specific and concrete instruction on how to improve the draft. The comment does not leave any ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the content of the section. This provides clear guidance on what needs to be done to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2, which is a clear and direct request for clarification. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors add a first sentence to introduce Section 3.2. This is a specific and direct piece of feedback that can help the authors improve the clarity and organization of their draft. By providing a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their work. However, it could be more helpful if it explained why adding a first sentence is important or how it could enhance the section. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector is perfect, no additional work is needed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what steps to consider. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the context or the implications of this statement. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. This feedback is 3 as it prompts the authors to clarify the meaning of this statement, which could be important for understanding the context and potential implications of their work. However, the comment lacks depth and does not provide specific guidance or suggestions for improvement. It does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a specific suggestion for improving the clarity of the text by updating the statement to clarify the representation of epistemic model uncertainty in the prior distribution. It specifies that the uncertainty is based on the posterior distribution, which is a direct and explicit action for the authors to take. The comment also provides a clear explanation of how this change would enhance the understanding of the concept. This level of detail and specificity makes the action concrete and actionable, allowing the authors to directly apply the suggested change. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper being addressed, which is the definition of uncertainty. It specifies that the uncertainty is defined based on the posterior distribution and suggests updating the text to clarify that the epistemic model uncertainty is represented in the prior distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests a clarification regarding the representation of uncertainty in the paper. It proposes that the uncertainty should be defined based on the prior distribution, which upon observing data, can be updated to yield the posterior distribution. This change is supported by logical reasoning, as it aligns with standard Bayesian principles. The comment provides a clear explanation of the suggested change, making it 4. However, it could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the text regarding the representation of uncertainty. It suggests updating the text to clarify that the epistemic model uncertainty is represented in the prior distribution and that upon observing data, these beliefs can be updated in the form of a posterior distribution, yielding model uncertainty conditioned on observed data. This feedback is clear and provides a direct way for the authors to enhance the understanding of their work. By offering a specific correction, the comment is 5, as it empowers the authors to make a meaningful improvement in their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and second, it asks about the number of questions created for the zeroshot intent classifier and the accuracy of the system. While the comment explicitly mentions these areas of concern, it does not provide specific guidance or suggestions on how the authors should address these issues. The questions are clear and direct, but the lack of actionable advice or concrete steps for improvement makes the comment 3. The authors know what information is needed but not how to obtain it or how to incorporate it into their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as questioning the experimentation with domain ontologies and asking for details about the number of questions and the accuracy of the zeroshot intent classifier. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions seeking clarification on specific aspects of the paper, such as whether domain ontologies were used to avoid placeholders and the number of questions and accuracy of the zeroshot intent classifier. These questions do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions that are relevant to the paper\"s methodology and results. The first question asks about the use of domain ontologies to avoid placeholders in the evaluated responses, which is a critical aspect of the experimental setup. The second question seeks clarification on the number of questions created for the zeroshot intent classifier and the accuracy of the system. These questions provide clear and actionable feedback, prompting the authors to clarify and potentially expand on their experimental methodology and results. However, the comment could be more helpful if it suggested how the authors might address these issues or provided additional context. Overall, the comment is 4 as it directs the authors to important areas for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks citations to set it in context with other MARL work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This feedback is clear and provides concrete guidance on what needs to be added to the paper to enhance its context and relevance. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MARL work\" and provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including to set their work in context. This level of detail allows the authors to accurately identify the parts of the paper that need to be revised. The comment is also specific, as it clearly specifies what needs to be addressed in terms of citations and context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to set it in context with other MARL work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. The comment provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This provides a clear and specific basis for the claim, making it 5. The authors can easily understand the need for these citations and the relevance of the mentioned papers, allowing them to effectively address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks context by pointing out the absence of citations to set it in the context of other MARL work, particularly recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides concrete references to enhance the paper\"s context and relevance. By addressing this feedback, the authors can significantly improve the quality and comprehensiveness of their draft. Therefore, the comment is 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. While the comment implies that such a comparison would be beneficial, it does not provide explicit instructions on which specific methods to include or how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. The authors may infer that it relates to the comparison section, but this inference is not explicit. The comment is specific in its suggestion to compare with noncontrastive methods, but without grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any specific examples or reasoning to support why this comparison would be beneficial or how it would enhance the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable piece of feedback as it encourages the authors to broaden their scope of comparison, potentially leading to a more comprehensive evaluation of their approach. However, the comment lacks specificity regarding which noncontrastive methods should be considered or how the comparison should be conducted. While it provides a direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. It explicitly requests clarification on this aspect. While the comment does not provide a direct action, it clearly identifies an area that needs further explanation. The authors are given a specific question to address, which provides a clear direction for improvement. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difference between the abstention process and a decision threshold used by the models, and it requests clarification on this distinction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking how it differs from a decision threshold used by the models. This question is relevant and prompts the authors to clarify a potentially confusing aspect of their work. By addressing this question, the authors can provide a more detailed explanation of their abstention process, which could enhance the clarity and understanding of their methodology. However, the comment does not offer suggestions or guidance on how to improve the clarity of the abstention process or provide additional context. While it identifies an area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors\" claim of parameter efficiency and asks for clarification on the experimental setup, specifically why the authors switched the types of BPE vocabulary. While the comment identifies areas for improvement and raises questions, it does not provide explicit guidance on how the authors should address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the overrating of this comparison. It also raises a concern about the parameter efficiency claim and asks for clarification on the experimental setup, specifically the switch in BPE vocabulary types. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the comparison and the need for clarification, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the overrating of the comparison with Megatron and questions the parameter efficiency claim. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size. The reviewer also asks for clarification on the experimental setup, specifically why the authors switched the types of BPE vocabulary. While the comment provides some reasoning and questions, it lacks detailed justification or references to support the claim about overrating. The suggestion for clarification on the experimental setup is a logical inquiry but does not fully substantiate the initial claim. Therefore, the comment is 3, as it provides some reasoning but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the overrating of the comparison with Megatron and questions the parameter efficiency claim. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size. The comment also asks for clarification on the experimental setup, specifically why the authors switched the types of BPE vocabulary. While the comment identifies a potential issue with the comparison and raises a question about the experimental setup, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for improvement but could be more comprehensive and actionable to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific example from the histogram in Figure 3, where the GSP50 model has a smaller class selectivity score, indicating that it shares more features with ResNet50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should improve the analysis or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should strengthen their analysis or provide additional context. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of convincing analysis and provides a specific example from the histogram in Figure 3. The comment further clarifies the hypothesis about the GSP50 model and suggests that additional context might improve the analysis. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific example from the histogram in Figure 3, where the GSP50 model has a smaller class selectivity score, indicating that it shares more features with ResNet50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that the analysis is not convincing. While the example and hypothesis provide some support, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a detailed explanation using the histogram in Figure 3, highlighting the GSP50 model\"s smaller class selectivity score, which indicates that it shares more features with ResNet50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment could be more helpful if it offered suggestions on how the authors might strengthen their analysis or provide additional context. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and mentions several references, including [R1], [R2], and [R3], which demonstrate the potential of featurereplay methods in continual learning. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to strengthen their conclusions. While the feedback is specific in terms of the claim and references, it lacks explicit instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some conclusions are not convincing\" and provides a specific example of a claim that is not supported by evidence. It also references several external works, including [R1], [R2], and [R3], which provide examples of featurereplay methods in continual learning. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several external works, including [R1], [R2], and [R3], which demonstrate the potential of featurereplay methods in continual learning. This provides a logical basis for the claim, as it compares the paper\"s conclusions with established works in the field. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it offers a reasonable basis for the claim but lacks some depth in its justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that they are not convincing. It provides a detailed critique by pointing out a particular claim, namely that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The comment suggests that the results might be influenced by limited exploration of combination methods and references several external works, including [R1], [R2], and [R3], which demonstrate the potential of featurereplay methods in continual learning. This feedback is 4 as it provides the authors with a clear direction for improvement by highlighting a specific area where their conclusions could be strengthened through further exploration and referencing relevant literature. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional guidance on how to incorporate these references into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of meaningful baselines in the paper, noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare their work with a chainofthought prompting approach. This feedback is clear and provides a concrete action for the authors to take, which is to include more meaningful baselines in their comparisons. The suggestion is specific and actionable, giving the authors a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors could compare their work with a chainofthought prompting approach. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with a chainofthought prompting approach provides some direction but does not fully explain why this comparison would be meaningful or how it would enhance the paper. Therefore, the comment is 3, as it provides a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of meaningful baselines. It points out that while the authors mention various model criticism techniques in Section 2, they limit their comparisons to simple naive baselines. The comment suggests that the authors could compare their work with a chainofthought prompting approach, which could provide a more robust evaluation. This feedback is clear and actionable, offering a specific direction for improvement that would enhance the paper\"s rigor and comprehensiveness. However, the comment could be more helpful if it provided additional context or examples of how the chainofthought prompting approach could be integrated. Overall, the comment is 4, as it effectively guides the authors towards a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment does not explicitly instruct the authors to make a change, it does provide a clear question that prompts the authors to clarify their pretraining methodology and its implications for generalization. The action is implicit but concrete, as the authors can directly address the question by providing the necessary information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the pretraining process and its implications for generalization, providing clear guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. The comment does not contain any claims or opinions that require verification. It is purely factual and consists of questions seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it prompts the authors to consider the implications of their pretraining methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore rather than a concrete path to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are hardware or software dependent, or how this dependency might impact the paper. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be contextspecific. However, the comment lacks specificity and does not provide any guidance or examples on how this dependency might affect the paper or what implications it has for the authors. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to address this issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended, leaving the authors without guidance on how to address them. Without specific suggestions or directions, the authors are left to infer potential actions, such as conducting further analysis or providing additional context. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions about the accuracy of the ground truth and the significance of the differences, but without clear references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any guidance or suggestions on how the authors might address these concerns or improve their analysis. The questions are openended and lack actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of important experimental details and the lack of explanations or interpretations in the Appendix, specifically mentioning the PCA experiments in Figures 3, 7, and 8. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text or appendices. However, the lack of concrete guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and experiments (PCA), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the absence of explanations or interpretations in the Appendix, particularly regarding the PCA experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. This claim is 3 as it identifies specific areas where the paper could be improved, such as the PCA experiments in Figures 3, 7, and 8. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to infer the exact details that need to be addressed, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed information to enhance the comprehensibility and transparency of their work. By addressing this issue, the authors can improve the clarity and impact of their paper. However, the comment could be more helpful if it provided suggestions on how to improve the explanations or interpretations. Overall, the comment is 4, as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that no new evaluation metrics are proposed and that existing metrics are only linearly combined. It also suggests that there should be an indepth exploration of the reasons behind the experimental results in the analysis section. While the comment identifies areas for improvement, it does not explicitly instruct the authors to propose new metrics or provide specific guidance on how to explore the reasons for the results. The action is implicit and somewhat vague, as the authors can infer the need for new metrics and deeper analysis but lack concrete steps on how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics, specifically mentioning the experimental analysis section. This provides some grounding as it directs the authors to the relevant part of the paper. However, it does not specify which specific evaluation metrics are missing or how the existing metrics should be combined, leaving the authors with a general idea of what needs to be addressed but without detailed guidance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are only linearly combined. This is a factual statement that does not require verification, as it is based on the observation that no new metrics are introduced. However, the comment suggests that there should be an indepth exploration of the reasons for the experimental results, which is a request for further analysis rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of new evaluation metrics and the linear combination of existing ones. It highlights the need for an indepth exploration of the reasons behind the experimental results, suggesting that the authors should provide a more detailed analysis. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed steps or examples to follow. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks actionable advice, such as suggesting alternative notations or recommending a consistent use of \"K.\" As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This provides some grounding as it refers to specific lines in the paper (L166 and L176), allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity as it does not explain why this ambiguity is problematic or suggest how the authors might resolve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused in the paper, being used ambiguously to represent both a known kernel function and the number of layers. This is a factual observation that does not require verification, as it is based on the reviewer\"s understanding of the text. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This is a clear and actionable observation that highlights a potential source of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or suggesting ways to clarify the usage of \"K.\" While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the practical relevance of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical nature of the weak recovery problem and questions the practical impact of the AMP algorithm, particularly in nonGaussian problems. However, it does not specify which part of the paper this critique pertains to, such as a specific section or result. The authors might infer that it relates to the discussion of the weak recovery problem or the AMP algorithm, but this inference is not explicit. The comment is specific in its critique of the practical impact, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the practical relevance of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. This critique highlights a potential limitation of the work, which is important for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the practical applicability of their findings. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general understanding of the issue but without clear steps to address it, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific points need clarification. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" admission that the problem is reductionist and does not allow for bargaining and negotiation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition in light of the problem\"s limitations and suggests that the authors need to provide more citation for comparison against \"previously appreciated\" aspects. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment lacks specific examples or references to support the claim that behavioral economists would ignore these aspects, making it 3. The authors would need to provide more detailed reasoning or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation, which are commonly used by behavioral economists. The comment questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. The reviewer also recommends providing more citations to support the claim and to compare it with \"previously appreciated\" aspects. This feedback is clear and actionable, as it prompts the authors to clarify their stance and provide additional context or references to strengthen their argument. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or what additional information should be included. Overall, the comment is 4, as it provides valuable insights and guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, it does not provide specific guidance on how to address this issue or suggest alternative wording. The authors are left without clear instructions on how to improve the phrasing or tone of their writing. As a result, the comment is 1, as it lacks actionable advice for the authors to follow.", "grounding_specificity_rationale": "The comment addresses the issue of overly exaggerated wording in the conclusion, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" This provides some grounding as it refers to a specific part of the paper, but it does not specify which sections or sentences are affected by this issue. The comment is specific in identifying the problem with the word choice, but it lacks full grounding because it does not pinpoint the exact location of the exaggerated wording. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant. This feedback is 3 as it points out a potential problem with the writing style, which could be addressed to improve the clarity and professionalism of the conclusion. However, the comment lacks depth and does not provide specific suggestions or guidance on how to revise the language to achieve a more appropriate tone. Without actionable advice or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying what needs to be done and how to implement it. The feedback is concrete and actionable, allowing the authors to understand exactly what modifications are necessary to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison should be emphasized or how the results should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a logical suggestion for the authors to consider, as it provides a way to evaluate the performance of their method relative to existing approaches. However, the comment does not provide specific examples or references to support the claim that these comparisons are necessary or how they would enhance the paper. The lack of detailed reasoning or references makes the claim 3, as the authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and offers a concrete way for the authors to enhance their work by providing a comparative analysis that could strengthen the evaluation and understanding of their method. However, the comment could be more helpful if it included additional guidance on how to structure these experiments or what specific aspects of the comparison would be most informative. Overall, the comment is 4 as it directs the authors towards a meaningful enhancement of their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of comparison to simple feature acquisition baselines, such as expected utility, which is a significant weakness of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment also mentions writing style and other issues, but these are not elaborated upon. As a result, the authors are left without clear instructions on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment also mentions writing style and other issues, but these are not elaborated upon, leaving the authors without specific guidance on how to address them. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility, which is a significant weakness. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s credibility and impact. However, the comment does not provide specific suggestions or guidance on how the authors might conduct these comparisons or which baselines would be most appropriate. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests that the authors should address the strangeness of Fig. 5a by providing more explanations. Additionally, it asks for clarification on how the authors dealt with DVS input when the input is in aer format. Lastly, it recommends analyzing energy consumption, similar to reference [15], to strengthen the paper. Each of these actions is clear and specific, giving the authors a clear path forward in improving their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing more explanations for Fig. 5a and clarifying how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference [15] did to strengthen the paper. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several claims and suggestions. It claims that Fig. 5a is strange and suggests providing more explanations. It also questions how the authors dealt with DVS input when the input is in aer format and recommends analyzing energy consumption as reference [15] did. While the suggestions are clear, the comment lacks specific examples or detailed reasoning to fully substantiate the claims. The references to \"strangeness\" and \"energy consumption\" are not fully explained, leaving the authors to infer the exact issues. Therefore, the comment is 3, as it provides some guidance but requires more detailed justification or examples to be fully actionable.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It highlights the need for more explanations in Fig. 5a and questions how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference [15] did, which could enhance the paper\"s solidification. These specific and actionable points offer the authors clear directions for improving their draft, making the comment 5. However, the comment could be more helpful if it provided more detailed guidance or examples on how to implement these suggestions. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifies that the text mentions separate embedding and addition with positional encoding but lacks details on how these embeddings are combined and fed into the CSCM. This provides a clear and direct action for the authors to take, which is to provide additional explanation or details on this process. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of how historical observations are combined with inputs known over all time, given differences in sequence lengths. The comment provides a clear direction for the authors to improve their draft by offering a specific area for additional explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It requests clarification on how this is achieved, specifically mentioning separate embedding and addition with positional encoding. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for clarification. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, given differences in sequence lengths. It highlights the need for clarification on how these elements are combined and fed into the CSCM, which is a critical aspect of the paper. By pointing out this gap in the explanation, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have handled similar challenges. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment does not specify which part of the paper discusses these approaches or where the critique is most relevant. The authors may have to infer that it pertains to the introduction or related sections, but this inference is not explicit. The comment is specific in its critique but lacks grounding, as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains 1, as it does not provide sufficient justification for the authors to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies a potential issue with the novelty of the approach, it does not provide actionable feedback or constructive advice for the authors to enhance their draft. As a result, the comment is 2, as it highlights a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should perform more experiments but are not given detailed guidance on what specific tasks or domains to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in detailing the concerns and suggestions for further experimentation, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current experiments are insufficient or that additional experiments would be beneficial. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It highlights a specific area of concern regarding the training of similar nodes or graphs with features that converge excessively, potentially discarding their unique features. Additionally, it questions the effectiveness of selecting positive samples without introducing perturbation noise, which could lead to lower generalization performance. The comment suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the feedback identifies critical areas for improvement, it lacks specific guidance on how to design or conduct these additional experiments. The authors are left with a clear direction for further investigation but without detailed instructions on implementation. Therefore, the comment is 3, as it provides valuable insights but could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide any specific guidance on what aspects of the discussion should be expanded. The authors may have an idea of where this discussion could fit, but the comment lacks grounding and specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question and an expression of desire for more discussion on the power of different architectures. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the discussion should be expanded or how to enhance the paper. Therefore, the comment is 2, as it provides a starting point but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their methods across different splits of trainvaltest rather than just different initialization seeds to obtain robust results. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations across different splits. The comment also offers concrete guidance on how to improve the robustness of the results, making it 5.", "grounding_specificity_rationale": "The comment suggests evaluating the methods across different splits of trainvaltest rather than just different initialization seeds to obtain robust results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results section, but this inference is not explicit. The comment is specific in its suggestion to evaluate across different splits, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest would provide more robust results than just different initialization seeds. This claim is 3 as it provides a logical reasoning for why different splits are more beneficial for obtaining robust results. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that evaluating the methods across different splits of trainvaltest would provide more robust results than just different initialization seeds. This feedback is clear and actionable, as it provides a specific recommendation for improving the robustness of the results. By conducting evaluations across different splits, the authors can ensure that their findings are not dependent on a single split and are more generalizable. This suggestion is valuable as it offers a straightforward way to enhance the reliability and validity of the study\"s results. However, the comment could be more helpful if it provided additional context or examples of how different splits can impact the results. Overall, the comment is 4, as it guides the authors towards a significant improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is an explicit action that the authors can take to improve their draft by streamlining the presentation of their contributions. The suggestion is concrete, as it specifies which parts of the introduction need to be combined. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This provides full grounding as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what needs to be addressed, namely the combination of the first two points about contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is a straightforward suggestion for improving the organization of the introduction, and it does not contain any subjective opinions, claims, or requests for changes. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is a clear and actionable suggestion that can help the authors streamline their presentation and improve the clarity of their contributions. By following this advice, the authors can enhance the organization and flow of their introduction, making it more effective for readers. However, the comment could be more helpful if it provided additional context or reasoning for why combining these points would be beneficial. Overall, the feedback is 4 as it offers a specific and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or where in the paper they should be addressed. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations/social norms (e.g., physical/psychological safety) in the main paper. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the lack of clarity but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, noting that the types of situations/social norms (e.g., physical/psychological safety) are not clear. This feedback is valuable as it highlights a potential gap in the paper\"s clarity, which could impact the reader\"s understanding. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing additional explanations or examples. While it points out a critical area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community and appreciates its focus on a specific problem. However, it raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these trends or what specific recent trends to refer to. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on a specific problem that somewhat differs from general segmentation problems and appreciates its potential benefit to the neuroscience community. It raises a question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. However, the comment does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to refer to recent trends in the vision community, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the paper\"s focus on a specific problem and its potential benefit to the neuroscience community. However, it raises a question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a potential area for improvement, it lacks specific examples or references to recent trends in the vision community that the authors should consider. This makes the claim 3, as it provides a general direction but lacks detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s focus on a specific problem and its potential benefit to the neuroscience community. It raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. This feedback is 3 as it identifies a potential area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it offered specific examples or references to recent trends in the vision community that the authors should consider. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include more baselines for comparison and test more domains. It also points out that the choices of weighting and learning density functions are not strongly motivated, requiring stronger empirical results. The comment provides clear and concrete actions for the authors to take, such as adding more baselines and testing in additional domains. This level of detail and specificity makes the feedback 5, as it gives the authors a clear path to follow for improving their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"more baselines to be compared\" and \"more domains to be tested,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the current choices of weighting and learning density functions, requiring stronger empirical results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more baselines and test more domains, and it questions the motivation behind the choices of weighting and learning density functions. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for more baselines to be compared and more domains to be tested, which is a constructive suggestion for improving the robustness and comprehensiveness of the study. It also points out that the choices of weighting and learning density functions are not strongly motivated, requiring stronger empirical results to support these decisions. This feedback is clear and actionable, providing the authors with specific areas to address to enhance the quality and rigor of their work. However, the comment could be more helpful if it offered suggestions on how to select appropriate baselines or additional domains to test. Overall, the comment is 4 as it guides the authors in improving their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to address the comment. By specifying which figures need clarification, the comment provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"fig. 2AB and 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is also specific as it clearly requests the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the definition of dashed lines in specific figures. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly requests the authors to define the dashed lines in specific figures (fig. 2AB and 4B). This feedback provides a direct and specific direction for improvement, allowing the authors to address a potential source of confusion or misinterpretation in their figures. By following this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the dashed lines effectively. Overall, the comment is 4 as it guides the authors in improving their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the comparability of their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not specify which part of the paper discusses the results or the proposed methods, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in detailing what aspects of the results are not comparable or what specific methods are being referred to. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods may lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references to existing methods or detailed explanations of why the results are not comparable, the authors are left without guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not provide any specific examples or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited novelty of the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide explicit guidance on how the authors might address the lack of novelty or unique challenges. The feedback lacks concrete suggestions or actionable steps for the authors to enhance the originality and depth of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items. However, it does not specify which part of the paper this critique applies to, making it weakly grounded. The comment is specific in identifying the lack of novelty and unique challenges, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer supports this claim by noting that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment provides some context, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of different penalty coefficients for users and items provides some context but does not fully address the novelty claim. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights that the main contribution is the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it lacks depth in terms of providing specific suggestions or guidance on how the authors might address the lack of novelty or unique challenges. The feedback is 3 as it points out a potential issue but does not offer actionable steps for improvement, leaving the authors with limited guidance on how to enhance the originality and depth of their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies specific issues with the figure, it does not provide explicit guidance on how to address these ambiguities or clarify the symbols. The authors are left to infer that they need to improve the clarity of the figure and possibly investigate the issue of information redundancy. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that some symbols are not explained clearly and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references leaves the claim 3, as the authors would need to infer the nature of the ambiguity and the potential redundancy themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a specific area for improvement in the paper\"s presentation and raises a relevant question that could impact the understanding of the methodology. However, the comment could be more helpful if it provided suggestions on how to clarify the symbols or address the potential redundancy issue. Overall, the comment offers some guidance but lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is reasonable for popular Gaussian kernels but notes that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their results. The action is implicit and vague, as the authors are left to infer that they should consider including a broader range of kernels or discuss the implications of this limitation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the paper regarding the assumption of the spectrum of a kernel being subgaussian. It highlights that this assumption is reasonable for popular Gaussian kernels but notes that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. This provides a clear indication of the part of the paper being addressed, making the comment fully grounded. However, the comment lacks specificity as it does not detail how the authors might address this limitation or suggest alternative approaches. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper\"s results are limited because the authors assume a subgaussian spectrum for kernels, which is reasonable for popular Gaussian kernels but not for other popular kernels like Matern kernels. The reviewer provides a logical reasoning for this claim, explaining that the assumption of a subgaussian spectrum is valid for Gaussian kernels but not for Matern kernels, which decay polynomially. This reasoning is clear and provides a basis for understanding the limitation. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of the results. Therefore, the comment is 4, as it provides a strong logical basis but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is reasonable for popular Gaussian kernels but notes that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. This observation highlights a potential restriction in the applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their results. While it points out an important issue, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance. It suggests that the authors should focus more on the pretraining method in the main paper. While the comment explicitly states the action needed (focusing more on the pretraining method), it does not provide specific guidance on how to implement this suggestion, such as which aspects of the pretraining method should be emphasized or how to structure the discussion. The action is concrete but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining in the main paper and suggesting that it is more important than other modules presented in the paper. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it lacks specific examples or detailed reasoning to support why this is the case. The comment also suggests that the main paper should focus more on the pretraining method, but it does not provide a clear rationale or evidence for this suggestion. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the basis of the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance as indicated in Table 4. It suggests that the authors should focus more on the pretraining method in the main paper, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to structure the discussion or which aspects of the pretraining method should be emphasized. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises an important consideration, it does not explicitly instruct the authors to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of this choice and potentially adjust their methodology accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in detailing the issue with the choice of ELM and the need for accuracy calculation after using a gender detection model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the accuracy should be calculated after using a gender detection model. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is valuable as it highlights an important consideration that could impact the methodology and results of the study. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the implications of this choice on the overall accuracy and reliability of the results. Despite this, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide specific guidance on how to simplify the writing or which parts of the paper are particularly challenging to follow. The authors are left with a general understanding of the issue but without concrete steps to address it. As a result, the comment is 3, as it identifies a problem but lacks detailed instructions on how to resolve it.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which parts of the paper are particularly challenging to follow or provide examples of where the writing is unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to simplify the writing or what specific changes should be made. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand which parts of the writing are problematic or how to address them. Without detailed feedback or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing, noting that it is difficult to follow in many places. However, it lacks actionable guidance or suggestions on how to simplify the writing or improve its clarity. Without detailed feedback or examples, the authors are left with a general understanding of the problem but without a clear path to address it. This makes the comment 3, as it points out a potential area for improvement but does not provide the necessary depth or specificity to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived lack of technical depth or what specific changes could be made to improve the paper. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper are lacking in terms of technical depth or substance. Without specific references or examples, the authors cannot confidently determine which parts of the paper need improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to [31]. However, it does not provide any specific details or examples of what aspects of the paper are lacking in terms of technical substance or how the new loss contributes to the field. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the critique. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors provide some intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It also asks how certain distributions $P^*$ might make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the proof and the determination of $P^*$. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing intuition for the proof and questioning the invertible function $f^*$, which depends on the fixed $P^*$. The comment further asks about the ease of determining $f^*$ for certain distributions $P^*$ and how to determine which $P^*$ to fix in practice. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment raises valid questions about the proof and the invertible function, it does not provide specific examples or references to support these claims. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors provide more intuition for the proof of Theorem 1. It also raises questions about the invertible function $f^*$, which depends on the fixed $P^*$, and asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. This feedback is clear and actionable, as it directs the authors to address specific areas of the paper that lack clarity and provides a clear path for improvement. By addressing these points, the authors can enhance the comprehensibility and depth of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the difference between Eqs. (7) and (10), specifically why one uses X and the other uses H^(1). While it raises a valid concern about the consistency in notation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what changes should be made or how the authors can ensure consistency in their notation. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the difference in notation between the two equations, specifically why one uses \"X\" and the other uses \"H^(1). This provides clear guidance on what needs to be addressed in terms of notation consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the consistency in notation between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1). While the comment raises a valid concern about notation consistency, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the consistency in notation between Eqs. (7) and (10), noting that one uses \"X\" while the other uses \"H^(1). This feedback is clear and actionable, as it prompts the authors to clarify or justify their choice of notation. By addressing this issue, the authors can improve the clarity and consistency of their presentation. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or if it pointed out the potential impact of this inconsistency on the reader\"s understanding. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to demonstrate that the proposed model captures these phenomena. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to obtain or present this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\"s capture of these phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or result. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to provide empirical evidence, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that empirical evidence is needed to demonstrate the model\"s capture of these phenomena. However, the comment does not provide specific examples or references to support the claim that the model is not applicable or lacks empirical evidence. The lack of detailed reasoning or examples makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes, which is a significant aspect of the paper\"s relevance and impact. It suggests that the authors provide empirical evidence to demonstrate the model\"s capture of these phenomena, which is a constructive and actionable suggestion. However, the comment could be more helpful if it offered specific guidance on how to obtain or present this evidence, such as which types of empirical data or methods would be most effective. Overall, the comment is 4 as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is explicit, it is somewhat vague as it does not specify which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The authors are given a clear direction to improve their work, but the lack of specific guidance on the number or types of datasets limits the level of concreteness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper discusses the method or the datasets used, making it weakly grounded. The comment is specific in its suggestion to test on more datasets, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any specific reasoning, examples, or references to support why more datasets are necessary or how they would improve the evaluation. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. While this is a logical and constructive suggestion, it lacks specificity and does not provide guidance on which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The comment identifies a potential area for improvement but does not offer actionable advice or detailed feedback, making it 3. The authors are given a direction to improve their work, but the lack of specific guidance limits the comment\"s effectiveness. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma in the equation. The reviewer suggests clarifying these points. The comment provides explicit actions for the authors to take, such as clarifying the description and the equation, which are concrete and actionable. However, it does not specify how to address the issue of numerical instability, which could be addressed with additional suggestions. Overall, the comment is 4 due to its clear and concrete guidance on what needs to be clarified.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issues with the description and equation, particularly regarding the absence of the term r^q and the unclear meaning of sigma. The comment provides a clear suggestion to clarify these aspects, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma. The reviewer suggests clarifying these aspects, which is a logical and specific request for improvement. However, the comment does not provide detailed reasoning or references to support the claim that the equation is illconditioned or numerically unstable due to multiplying two sigmoid activations. While the suggestion is clear, the lack of detailed justification for the numerical instability claim makes the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q, which is the question representation, and the unclear meaning of sigma in the equation. The reviewer suggests clarifying these aspects, which is a clear and actionable feedback. Additionally, it raises a concern about the numerical stability of multiplying two sigmoid activations, which is a relevant point for the authors to consider. However, the comment could be more helpful if it provided suggestions on how to clarify the description or equation or offered alternative approaches to address the numerical stability issue. Overall, the comment is 4 as it provides specific and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the main contribution of combining attention with other linear mechanisms is not novel and mentions that alternatives exist. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their contribution. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of combining attention with other linear mechanisms, noting that it is not a novel contribution and that alternatives exist. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in terms of what aspects of the contribution are not novel or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. While it identifies a potential issue with the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. The comment provides a general observation but does not offer actionable feedback or constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a plot showing how different weights of the model move, specifically suggesting a plot of relative weight change after unlearning to identify which layers are most affected. This is a clear and direct action for the authors to take, providing them with a specific and concrete way to improve their draft. The comment does not leave any ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"each layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014providing a plot of how different weights of the model move, such as plotting the relative weight change after unlearning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing how different weights of the model move, specifically after unlearning. This is a request for additional analysis or visualization, which is a logical suggestion based on the method\"s application on each layer. However, the comment does not provide specific examples or references to support why this plot is necessary or how it would enhance the paper. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the importance of this plot themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It identifies a specific area where the authors can enhance their analysis by suggesting the inclusion of a plot showing how different weights of the model move, particularly after unlearning. This feedback is valuable as it offers a concrete way for the authors to visualize and potentially interpret the results of their method, which could provide additional insights or support their claims. However, the comment could be more helpful if it included specific examples or references to similar plots in other studies, which would further guide the authors in implementing this suggestion effectively. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance or suggestions on how the authors might address this concern. The feedback lacks actionable steps or concrete advice on how to enhance the novelty or improve the methodology. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment lacks specific examples or detailed reasoning to support the claim that the decomposition part is a significant contribution. The mention of [10] provides some context, but without further elaboration, the claim remains 3. The authors would need to investigate the reference [10] and the specific aspects of the decomposition part to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps or detailed advice on how to improve the paper\"s originality. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere but not mentioned in the paper. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the domain of the inputs in their paper. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, specifically noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact location where this information should be included. While the comment is specific in questioning the domain of the inputs, it lacks grounding as it does not provide explicit references to the paper\"s sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This feedback is 3 as it directs the authors to clarify an important aspect of their work that may have been overlooked. However, the comment lacks depth and does not provide guidance on how to address this issue or what specific information should be included to clarify the domain of the inputs. To be more helpful, the comment could suggest ways to improve the clarity or provide examples of how this information could be integrated into the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in [A]. While the comment implies that such a comparison is necessary, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a performance comparison but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions \"proproses a CLN (region proposal generation algorithm)\" and suggests a performance comparison with work [A]. However, it does not specify which part of the paper this proposal is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting a performance comparison with [A], but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a performance comparison with a CLN (region proposal generation algorithm) proposed in [A]. However, it does not provide any specific reasoning, examples, or references to support why such a comparison is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of this suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in [A]. While this is a logical suggestion for improving the paper\"s comprehensiveness, it lacks specificity and actionable guidance. The comment does not provide details on why such a comparison is important or how it could enhance the paper\"s contribution. Without additional context or suggestions, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the presentation is too equationdriven and the notation, particularly in chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure would be beneficial to help clarify the key concepts in section 3. This feedback is clear and provides a direct action for the authors to take, which is to include an illustrative figure to improve the clarity of their presentation. The suggestion is concrete and actionable, as it specifies what needs to be done to enhance the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the presentation is too equationdriven and the notation is convoluted, making it clear what needs to be improved. Additionally, the comment suggests including an illustrative figure to help clarify the key concepts in section 3. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and the notation is convoluted, making it hard to follow. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks concrete evidence or references to substantiate the assertion that the presentation is too equationdriven or convoluted. Without additional context or examples, the authors may find it challenging to understand the specific issues and make improvements accordingly. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and the notation is convoluted, making it hard to follow. It provides a clear suggestion for improvement by recommending the inclusion of an illustrative figure to help clarify the key concepts in section 3. This feedback is actionable and provides a concrete step for the authors to take to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to create an effective figure or what specific concepts should be illustrated. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example, mentioning \"Z'\" and \"the empty set,\" to illustrate the issue. However, the comment does not explicitly instruct the authors to address this conflict or suggest how to resolve it. While the action is implicit, it is concrete because the authors can infer that they need to clarify or correct the definition of minimal conditional dependence. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, providing a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, as illustrated by a specific example involving \"Z'\" and the empty set. The reviewer provides a clear explanation of the issue, which is supported by logical reasoning and a specific example. This makes the claim 4, as the authors can follow the reasoning and understand the basis of the conflict. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the second rule in Lemma 2, highlighting a potential conflict between the definition of minimal conditional dependence and the equation (7). By providing a clear example involving \"Z'\" and the empty set, the comment effectively points out a logical inconsistency that needs to be addressed. This feedback is actionable and provides the authors with a clear direction for revising their draft to resolve the conflict. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided additional context. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. While it implies that the authors should improve the visual presentation, it does not provide specific guidance on how to achieve this enhancement, such as suggesting changes to the font size, color, or layout. The action is implicit and somewhat vague, as the authors know they need to improve the visual presentation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, which need enhancement for better readability and aesthetic appeal. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. The comment lacks specific guidance or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it directs the authors to focus on improving the visual elements of their figures. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the visual presentation. Overall, the comment is 4 as it highlights a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the distinction between the two methods. Without actionable suggestions or explicit directions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the difference between Online Normalization and Batch Normalization, particularly their bias and unbiased nature. It raises a question about why Online Normalization is unbiased and Batch Normalization is biased, which is a clear and specific point. However, the comment does not explicitly mention which part of the paper discusses these normalization techniques, making it weakly grounded. Despite this, the comment is specific in detailing the issue, so it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It suggests that the authors clarify why Online Normalization is unbiased and Batch Normalization is biased. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the question effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the difference between Online Normalization and Batch Normalization, particularly regarding their bias and unbiased nature. It highlights a potential area of confusion in the paper and suggests that the authors clarify this distinction. While the comment identifies a relevant issue, it lacks depth and does not provide actionable feedback or suggestions for how the authors might address this confusion. The authors are left with a question but without guidance on how to improve their draft. Therefore, the comment is 3, as it points out a potential area for clarification but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9page paper limit is grounds for rejection. While the comment identifies a specific issue with the paper\"s formatting, it does not provide any guidance or suggestions on how the authors might address this problem or improve the paper. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of reduced whitespace in the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. However, it does not specify which sections or figures are affected, making it weakly grounded. The comment is specific in identifying the problem with the formatting, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This claim is supported by the observation that these issues could lead to a violation of the 9page paper limit, which is a clear and logical reasoning. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the lack of detailed evidence makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9page paper limit is grounds for rejection. While the comment highlights a critical issue that could impact the paper\"s presentation and adherence to guidelines, it lacks actionable suggestions or guidance on how the authors might address this problem or improve the paper\"s formatting. The feedback is 3 as it points out a specific area for improvement, but it does not provide detailed advice or examples, leaving the authors with limited actionable steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without specific suggestions or directions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not specify which sections or parts of the paper are lacking in detail or how they could be improved. The authors might infer that the technical details and formulations are discussed in specific sections, but this inference is not explicit. The comment lacks specificity in identifying what needs to be addressed, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide specific suggestions or guidance on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment highlights an area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should address the clarity of the concept, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its inquiry about the definition of local interactions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks any justification or examples to help the authors understand the issue or how to address it. As a result, the claim is not verifiable, as it does not provide the necessary information for the authors to improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. This feedback highlights an area of confusion in the paper, which is important for the authors to address to ensure their work is well understood by readers. However, the comment does not provide any suggestions or guidance on how the authors might clarify this concept or improve its presentation. While it identifies a potential issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy. The authors are left to infer that they need to investigate and possibly revise their results or methodology, but the lack of specific actions or directions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the paper\"s claim of better results in the Molecule generation experiment, noting that adding the proposed constrained method actually results in lower validity and diversity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim of better results in the Molecule generation experiment is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. This feedback is 3 as it points out a potential issue that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this discrepancy or improve their results. To be more helpful, the comment could include additional analysis, suggestions for further investigation, or alternative approaches to address the observed problem. Therefore, the comment is rated as 3, as it provides a starting point for the authors but does not fully support their efforts to improve the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the update of archetype positions after initialization in Algorithm 2. It explicitly requests clarification from the authors on this aspect. While the comment does not provide a direct action, it clearly identifies a specific area that needs further explanation. The authors are given a clear direction to address the issue, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the archetype positions are updated after initialization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the update of archetype positions after initialization in Algorithm 2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update of archetype positions after initialization in Algorithm 2. It provides a clear and direct question, asking the authors to clarify this aspect. This feedback is actionable as it prompts the authors to address a potential gap in their explanation, which could improve the clarity and understanding of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include missing information about the empirical study in the supplement, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. These actions are direct and concrete, providing clear guidance on what needs to be added or clarified. The authors know exactly what information to include and where to place it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplement\" and specifies the missing information that should be included, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that there are important details missing from the empirical study that should be mentioned in the supplement, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded. It also recommends mentioning the number of regions in the parcellation in the main text. While the comment identifies areas that need clarification, it does not provide specific examples or references to support these claims. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks important information that should be included, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. These are specific and actionable suggestions that would help the authors provide a more comprehensive and detailed account of their empirical study. By addressing these points, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided examples or further guidance on how to present this information effectively. Overall, the feedback is 4, as it directs the authors to important areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, specifically the variability across datasets. It suggests that the paper lacks crossdataset experiments to test the generalization of the work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer that they should perform crossdataset experiments but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and references the cooccurrence of AU1 and AU12, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential risk of methods exploiting relationships between action units and the variability across datasets. The comment suggests a specific action, namely performing crossdataset experiments, to test the generalization of the work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units can have varying correlations across datasets, using examples of AU6 and AU1 and AU12. It suggests that the paper lacks crossdataset experiments to test the generalization of the work. The claim is 3 as it provides examples of action units and their varying correlations across datasets, which supports the assertion. However, the comment could be strengthened by providing more detailed examples or references to specific datasets to further substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential risk in methods that exploit relationships between action units, specifically the variability across datasets. It highlights the importance of crossdataset experiments to test the generalization of the work, which is a critical aspect for validating the findings. The comment provides a clear and actionable suggestion for the authors to conduct crossdataset experiments, which would significantly enhance the robustness and applicability of their results. However, the comment could be more helpful if it offered specific guidance on how to design and execute these experiments or which datasets to consider. Overall, the feedback is 4 as it directs the authors towards a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to include this description or specify how much detail is required. The action is implicit and somewhat vague, as the authors need to infer that they should add more description and where it should be placed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not specify which part of the paper this description should be included in, nor does it provide any details on what aspects of the Starcraft environment need more description. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not provide any specific reasoning or evidence to support why this additional description is necessary or how it would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While this feedback acknowledges a potential area for improvement, it lacks specificity and does not offer detailed guidance on what aspects of the environment should be described or how this additional information could enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to implement it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that overparametrization leads to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that supports the benefits of overparametrization in supervised learning of deep neural networks. However, the comment does not explicitly instruct the authors to address this claim or provide a specific action to take. The suggestion to include references to theoretical work is implicit and somewhat vague, as it does not specify which references to include or how to incorporate them into the paper. Therefore, the comment is 3, as it provides a direction for the authors to consider but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the claim that overparametrization leads to overfitting and worse performance, providing references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or further elaboration on the theoretical work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This feedback is valuable as it encourages the authors to reconsider their assumptions and potentially revise their claims. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or address the challenge to the claim. Overall, the comment is 4 as it prompts the authors to consider a different perspective and provides a direction for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. It explicitly states that the shape model is trained in a pixel level and independently on all font images and characters, and that the parsing model is a highorder factor graph with four types of factors. However, the comment does not provide specific guidance on how to improve the efficiency or which existing work to compare with. While the action is clear, the lack of detailed instructions on how to implement the suggested improvements makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this is not explicit. The comment is specific in detailing the issue of processing efficiency and the need for comparison with existing work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is trained in a pixel level and independently on all font images and characters, which is timeconsuming. It also mentions that the parsing model is a highorder factor graph with four types of factors, which could affect processing efficiency. However, the comment does not provide specific evidence, examples, or references to support these claims or explain how they impact the efficiency of training and testing. Without detailed reasoning or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. This feedback is clear and actionable, as it points out a specific area for improvement and provides a direction for the authors to enhance their draft. However, the comment could be more helpful if it offered specific suggestions or examples of existing work to compare with. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should consider alternative domain adaptation methods, it does not explicitly instruct them to do so or provide specific examples of these methods. The action is implicit and somewhat vague, as the authors need to infer that they should explore and implement more advanced domain adaptation techniques. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the combination of existing techniques to create a framework without innovation, specifically mentioning the use of adversarial attack or correction methods and domain adaptation methods. It also points out that the adopted domain adaptation method is an old and simple method proposed eight years ago. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue with the use of outdated domain adaptation methods, suggesting that the authors should consider more recent and effective methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. The claim is supported by logical reasoning, as it points out the lack of innovation in combining existing techniques and highlights the outdated nature of the domain adaptation method used. However, the comment could be strengthened by providing specific examples of more recent and effective domain adaptation methods or references to support the suggestion. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach, noting that the authors combine existing techniques without innovation. It points out that the adversarial attack or correction method and the domain adaptation method used are proposed by prior work and that the adopted domain adaptation method is outdated. The comment suggests that the authors should consider using more recent and effective domain adaptation methods to improve the performance of their framework. This feedback is clear and actionable, as it directs the authors to explore and implement more advanced techniques, which could significantly enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific examples or references to these more recent methods. Overall, the comment is 4, as it provides a clear direction for improvement but could be further enhanced with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source in the paper. While the action is explicit, it does not provide specific guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but lack detailed instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the prompt dataset creation and its source, specifically for the fewshot case. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the prompt dataset creation and its source, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this discussion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation and its source should be included, specifically for the fewshot case. However, the comment does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that a discussion on the prompt dataset creation and its source should be included, specifically for the fewshot case. While this is a relevant suggestion, it lacks specificity and does not provide detailed guidance on how to structure this discussion or what aspects should be included. The authors are aware of the need for this discussion but may find it challenging to implement without additional context or examples. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the motivation or address the perceived incremental nature of the work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. However, it does not specify which part of the paper is being discussed or what aspects of the motivation are unclear. This lack of grounding makes it difficult for the authors to identify the specific sections or elements that need clarification. The comment is specific in its critique of the paper\"s motivation and incremental nature, but without clear grounding, it is not actionable. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and describes it as an incremental engineering paper. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide specific examples or suggestions for improvement, leaving the authors without actionable guidance on how to enhance the clarity and impact of their work. The feedback lacks depth and does not offer constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, specifically mentioning a scenario where the authors\" method underperforms due to repetitive background sounds in the game. While the comment implies that an ablation study could be beneficial, it does not explicitly instruct the authors to conduct this study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for an ablation study but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the authors\" method underperforms due to repetitive background sounds in the game. This provides some grounding as it mentions a specific part of the paper (the weighting method) and a relevant scenario (repetitive background sounds). However, the comment does not explicitly mention which part of the paper discusses the weighting method or the crossentropy loss, making it weakly grounded. It is specific in suggesting an ablation study to address the issue of underperformance, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the authors\" method underperforms due to repetitive background sounds in the game. The reviewer provides a logical reasoning by suggesting that the weighting method might have helped remedy this issue. However, the comment lacks specific examples or references to support the claim that the weighting method could have improved performance in this scenario. While the reasoning is plausible, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, specifically mentioning a scenario where the authors\" method underperforms due to repetitive background sounds in the game. This is a relevant suggestion as it highlights a potential area for improvement and provides a specific context for the ablation study. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for further investigation but lacks detailed instructions, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It highlights that the paper addresses a specific problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or incremental nature of the work, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions the problem addressed, which is the design of semantic parsers for TexttoSQL, and highlights the design of a new dataset as a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, based on the work addressing a particular problem of column operations in designing semantic parsers for TexttoSQL. It mentions the design of a new dataset as a different train/test split of an existing dataset SQUALL and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim that these elements lack novelty or are incremental. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the critique. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without specific guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include more game environments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not specify which part of the paper discusses the experiments or which game environment is being used. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not provide any specific reasoning, examples, or references to support why more experiments are necessary or how they would improve the study. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary to provide a broader perspective or validation of the findings. While the comment highlights an important area for improvement, it lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. The feedback is 3 as it points out a potential weakness in the study, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests using solid examples to support this explanation. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be done and how to implement it, ensuring the authors know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"removing some of the assumptions like bounded variance and bounded gradients,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the importance of explaining why these assumptions are removed and providing solid examples to support this explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples or reasoning to support why these assumptions are significant or how their removal impacts the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, suggesting that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It provides a clear direction for the authors to enhance their paper by offering a rationale for the removal of these assumptions. However, the comment could be more helpful if it included specific examples or guidance on how to present this explanation effectively. Overall, the feedback is 4 as it directs the authors to a critical aspect of their work that requires further development, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the resulting accuracy. However, the comment does not explicitly instruct the authors to address this issue or suggest how to improve the implementation. While the information is detailed, the lack of a direct action or guidance on how to resolve the problem makes the comment 3. The authors know that the issue exists but may need to infer the steps to take to improve the implementation.", "grounding_specificity_rationale": "The comment addresses the claim that the authors have implemented ImageNet for the first time, but it does not specify which part of the paper this claim is made in. The authors can infer that it relates to the implementation section, but this inference is not explicit. The comment provides specific details about the slowness and low accuracy of the implementation, mentioning the time taken to test an ImageNet picture using AlexNet and ResNet18 and the resulting accuracy. However, it does not specify what needs to be addressed in terms of improving the implementation or accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" claim of implementing ImageNet for the first time is inaccurate, as it is slow and has low accuracy. The reviewer provides specific examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the resulting accuracy, which is around 70%. This provides a clear and detailed justification for the claim, making it 5. The reviewer uses logical reasoning and specific data to support the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the resulting accuracy, which is around 70%. This level of detail is helpful as it allows the authors to understand the extent of the problem and the impact on their results. However, the comment could be more helpful if it suggested potential causes for the slowness and low accuracy or provided guidance on how to address these issues. Overall, the comment is 4 as it provides valuable insights into a critical aspect of the implementation, but it could be more comprehensive with additional suggestions or analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding a few more sentences explaining the experimental setting for continual learning. Second, it asks for clarification on Fig 3, specifically requesting an explanation of the correspondence between the learning curves and MPHATE, as well as why the authors want the reviewer to look at the learning curves. It also questions whether worseperforming models always result in structural collapse and asks for the accuracy number for the last task. These actions are clear and concrete, providing the authors with specific guidance on what to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3\" and \"continual learning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be addressed, such as adding more explanation for the experimental setting in continual learning and clarifying the correspondence between the learning curves and MPHATE in Fig 3. The comment also raises questions about the accuracy number and the structural collapse, providing clear guidance on what additional information is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests adding more explanation for the experimental setting in continual learning, which is a request for additional information. The second part questions the correspondence between the learning curves and MPHATE in Fig 3, asking for clarification on why the authors want the reviewer to look at the learning curves and whether worseperforming models always result in structural collapse. This part of the comment is 3 as it raises specific questions that require further explanation or evidence to be fully addressed. However, it lacks detailed reasoning or references to support the claim about the correspondence between the learning curves and MPHATE, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two specific actions for the authors to take. First, it suggests adding more explanation for the experimental setting in continual learning, which is a clear and actionable suggestion. Second, it raises questions about Fig 3, specifically asking for clarification on the correspondence between the learning curves and MPHATE, as well as why the authors want the reviewer to look at the learning curves. It also questions whether worseperforming models always result in structural collapse and asks for the accuracy number for the last task. These questions and suggestions are clear and provide the authors with specific areas to address, making the comment 4. However, it could be more helpful if it offered additional guidance or examples to support the suggestions. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. The reviewer provides references to existing works in the field, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could guide the authors in exploring this idea further. However, the comment does not explicitly instruct the authors to incorporate labeled data into their consistency training or suggest specific steps to do so. While the suggestion is clear, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the use of labeled data for consistency training in graph anomaly detection, specifically mentioning the potential benefits of using exact labels. It references two papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or method. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to consider using labeled data for consistency training, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It references two papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not provide specific reasoning or evidence to support the claim that labeled data would be beneficial for consistency training. The references are not fully utilized to substantiate the claim, leaving the authors without a clear understanding of how to address the suggestion. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training the model. The comment provides references to existing works in the field, which could guide the authors in exploring this idea further. However, the comment does not offer specific guidance or suggestions on how to incorporate labeled data into the consistency training process or what impact it might have on the model\"s performance. While it prompts the authors to consider an alternative approach, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific guidance on what should be included in the experimental suggestions. This includes highlighting the superiority of the method and suggesting improvements based on the characteristics of the article. The feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"experimental part\" and \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, such as reorganizing the content to better highlight the superiority of the method. This provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved, but it does not provide specific examples or detailed reasoning to support why this is necessary. The comment lacks concrete evidence or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section of the paper, suggesting that it needs to be reorganized and improved to better highlight the superiority of the method. It provides a clear and actionable suggestion by specifying what should be included in the experimental suggestions, such as highlighting the method\"s characteristics. This feedback is valuable as it offers a concrete direction for the authors to enhance the clarity and effectiveness of their experimental presentation. However, the comment could be more helpful if it included specific examples or detailed guidance on how to reorganize the content. Overall, the comment is 4, as it provides a clear path for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the classification error of the proposed network and suggests that it may not be universally as good as the standard softmax network. It questions the authors\" claim of better detecting outofdistribution samples without compromising classification accuracy. The reviewer explicitly requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. This feedback is explicit and provides concrete actions for the authors to take, such as reporting classification accuracy and offering theoretical justifications. The request for reporting classification accuracy is clear, and the suggestion for theoretical justifications adds depth to the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the classification network proposed by the authors and questions the universality of its classification error compared to the standard softmax network. It also raises concerns about the potential loss of classification accuracy when building a new model for better detecting outofdistribution samples. The reviewer suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the proposed classification network and its performance. The authors can infer that it relates to the methodology or results section, but the comment is specific in detailing what needs to be addressed, such as reporting classification accuracy and providing theoretical justifications. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network compared to the standard softmax network. It questions the universality of the proposed network\"s classification error and suggests that building a new model for better detecting outofdistribution samples could compromise its classification accuracy. The reviewer requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the proposed network\"s classification error is universally as good as the softmax network. The request for reporting classification accuracy and theoretical justifications provides some direction for the authors, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the universality of the proposed classification network\"s classification error compared to the standard softmax network. It questions the authors\" claim of better detecting outofdistribution samples without compromising classification accuracy. The reviewer suggests reporting the classification accuracy of the proposed classifier on ImageNet data and provides a theoretical justification for the issue. This feedback is clear and actionable, as it directs the authors to provide specific evidence to support their claims and offers a constructive suggestion for improvement. By addressing this concern, the authors can enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to consider the feasibility of their approach and potentially revise their argument. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the feasibility of the argument regarding recognition lists being recalled based on items. It provides a detailed explanation of the issue, particularly in the context of old vs new judgments, where new items comprise the list of all items available in memory. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies the issue with the exhaustive list and the difficulty in testing concrete predictions with simulations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. The authors might find it challenging to address the issue without additional context or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It points out that in the most common case of recognition, new items comprise the list of all items available in memory, which makes the exhaustive list challenging to implement and test with simulations. This feedback is 3 as it identifies a potential weakness in the argument and highlights a practical issue that the authors should consider. However, the comment could be more helpful if it provided suggestions on how to address this concern or offered alternative approaches to support the argument. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the experimental comparison, suggesting that the proposed method was pretrained before finetuning, which may not be the case for the compared methods. It implies that the authors should ensure that the compared methods were also pretrained or initialized with similar models. The comment provides a clear action for the authors to take, which is to clarify the pretraining conditions of the compared methods. This guidance is explicit and concrete, allowing the authors to address the issue directly. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, specifically noting that the proposed method was pretrained before finetuning, while the compared methods may not have been initialized with the same or similar pretrained models. This provides clear guidance on what needs to be addressed in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to differences in pretraining initialization between the proposed method and the compared methods. The reviewer provides a specific example from Table 1, where the proposed method without SSL performs inferior to most compared methods. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically noting that the proposed method was pretrained before finetuning, while the compared methods may not have been initialized with the same or similar pretrained models. This observation is important because it could affect the fairness of the comparison. The comment provides a clear and actionable suggestion for the authors to ensure that the compared methods were also pretrained or initialized with similar models. This feedback is valuable as it helps the authors address a potential weakness in their experimental setup, potentially leading to a more robust and fair comparison. However, the comment could be more helpful if it offered additional guidance on how to achieve this or provided examples of how to implement this suggestion. Overall, the comment is 4, as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for zeroshot learning on the CUB dataset, referencing a specific table and paper for comparison. It provides a concrete action by recommending a specific table and paper to refer to, and it also includes a followup update that thanks the authors for their response. This feedback is explicit and provides clear guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that better metadata embeddings options are available and references a specific table and paper for comparison. The comment is specific in detailing what needs to be addressed, namely the use of \"attribute\" metadata and the potential improvement with better embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison but implies that better metadata embeddings are available. It references a specific table and paper for comparison, providing a logical basis for the claim. However, the comment lacks detailed reasoning or specific examples of how the proposed method would perform with better metadata embeddings, which could strengthen the verifiability. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of better metadata embeddings for zeroshot learning on the CUB dataset. It references a specific table and paper for comparison, offering a clear direction for enhancing the performance of the proposed method. The comment is actionable and provides a concrete way for the authors to improve their draft, making it 5. However, it could be more helpful if it included more detailed guidance on how to implement the suggested changes or if it discussed the potential impact of these improvements. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific action for the authors to take, which is to include a plot comparing the flexibility of SGC with LoRA. The comment provides a clear and concrete suggestion on what type of plot should be included, specifying the axes and the information to be displayed. This guidance gives the authors a clear idea of what needs to be done to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Limited Applicability,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of a plot comparing the flexibility of SGC with LoRA, which would demonstrate the practical performance benefits of SGC at different sparsity levels. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff, but it does not provide specific examples or references to support this claim. The suggestion to include a plot comparing SGC with LoRA is a logical step to demonstrate the practical performance benefits of SGC at different sparsity levels, but without further justification or evidence, the claim remains 3. The authors would need to infer the basis of the claim and the reasoning behind the suggestion, which makes the comment 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the applicability of the paper\"s claims, specifically regarding the flexibility and finegrained tradeoff of SGC compared to PEFT methods. It suggests a specific visualization, a plot with sparsity on the xaxis and performance on the yaxis, to directly compare the flexibility of SGC with LoRA. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s analysis and presentation. By including this plot, the authors can more effectively demonstrate the practical performance benefits of SGC at different sparsity levels. However, the comment could be more helpful if it included additional guidance on how to interpret the results or what specific insights the plot should highlight. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide explicit instructions on how to address the question or what specific aspects of the training time should be examined. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the training time and potentially publish the code. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not specify which part of the paper this question pertains to, such as a specific experiment or section. The authors may infer that it relates to the experimental results or methodology, but this inference is not explicit. The comment is specific in questioning the training time and suggesting code publication, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide any specific reasoning or evidence to support the claim that the training time is unreasonable or to justify the suggestion to publish the code. The lack of detailed explanation or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue or what aspects of the training time should be examined. The feedback is 3 as it prompts the authors to consider publishing the code, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD). It does not explicitly request additional experiments but rather points out a lack of clarity regarding what additional information CD captures beyond Predictive Uncertainty. The reviewer also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" While the comment implies that the authors should address these issues, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as describing alternate formulations for Confidence Diversity (CD) and questioning the use of entropy as a measure of \"amount of spreading of teacher predictions.\" The comment provides clear guidance on what additional information is needed to clarify the paper, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the paper regarding Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It suggests that the paper should describe alternate formulations for CD and questions the use of entropy as a measure of \"amount of spreading of teacher predictions.\" However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the authors describe possible alternate formulations for Confidence Diversity (CD). This feedback is actionable as it provides a clear direction for enhancing the clarity and depth of the paper. The comment also raises questions about the relationship between CD and Predictive Uncertainty, as well as the suitability of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" By addressing these points, the authors can improve the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided specific examples or references to support the suggested formulations or the critique of entropy. Overall, the comment is 4 as it guides the authors towards enhancing their draft with actionable suggestions and critical insights."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It suggests that this makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. Additionally, the comment points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. However, the comment does not provide specific guidance on how the authors should address this issue or improve the presentation of the human baseline. The feedback is explicit in identifying the problem but lacks concrete suggestions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It also points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the human baseline and the potential misrepresentation in the abstract, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings compared to the full 15 hours. This claim is 3 as it provides a specific comparison between the amount of speech recordings used by the human and the model baselines. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as how the difference in speech recordings affects the performance of the human baseline. Additionally, the mention of \"misleading\" in the abstract suggests a potential issue with the presentation, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This discrepancy makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. While the comment highlights a significant issue, it does not provide detailed guidance on how the authors might address this problem or improve the presentation of the human baseline. The feedback is 3 as it directs the authors\" attention to a critical area for improvement but lacks depth and actionable suggestions, leaving the authors with a general understanding of the issue but no clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a strong assumption regarding the termination states of instructions and notes that labeling a large number of data manually is expensive in the general case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the assumption but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption regarding the termination states of instructions is strong and expensive to label a large number of data manually in the general case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. This feedback highlights a critical area for improvement, as it points out a limitation that could impact the validity of the assumptions made in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or refine their assumptions. While it provides a starting point for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, it is rated as 3, as it offers some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the description of the contribution regarding ECE_sweep, specifically noting that it amounts to autotuning a hyperparameter. The reviewer suggests that the paper should be upfront about this contribution. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to clarify this point or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the contribution but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the description of the contribution regarding ECE_sweep, specifically noting that it amounts to autotuning a hyperparameter. This feedback is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need for the paper to be upfront about the contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the nature of the contribution with respect to ECE_sweep is not clearly described, suggesting that it amounts to autotuning a hyperparameter. The reviewer provides a logical explanation, stating that this is not fundamentally different from other estimators. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the contribution from the reviewer\"s reasoning, which adds to the complexity of understanding and addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the nature of the contribution with respect to ECE_sweep. It points out that the description is not clear, suggesting that it amounts to autotuning a hyperparameter, which is not fundamentally different from other estimators. The reviewer provides a logical explanation and offers a constructive suggestion for the paper to be more upfront about its contribution. This feedback is clear and actionable, as it guides the authors to clarify their contribution and improve the clarity of their description. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to rephrase the contribution. Overall, the comment is 4, as it effectively directs the authors to enhance the clarity of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. While the comment identifies a potential issue with the lack of baseline comparisons, it does not provide explicit guidance on how the authors should address this. The action is implicit, as the authors need to infer that they should include these methods as baselines, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the related work section, specifically mentioning the discussion of methods for training NMT models beyond MLE, such as RL methods. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the absence of these methods as baselines, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This claim is 3 as it identifies a potential gap in the paper\"s methodology. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper\"s methodology by noting that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This observation is important as it highlights a missing comparison that could strengthen the paper\"s evaluation. However, the comment does not provide specific suggestions on how the authors might include these methods as baselines or what benefits this might bring to the analysis. While it points out a potential weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding whether the authors are referring to a specific efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" is not a recognized entity, implying that the authors may be referring to a general concept of efficient proxies. However, the comment does not provide explicit guidance on how the authors should clarify this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"Efficient Proxy\" or provide a more precise definition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It points out that it is unclear whether the authors are referring to a particular efficient proxy or a family of efficient proxies. This feedback is fully grounded as it explicitly mentions the term \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the ambiguity in the term and suggests that the authors clarify whether they are referring to a specific proxy or a family of efficient proxies. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"Efficient Proxy,\" suggesting that it is unclear whether the authors are referring to a specific efficient proxy or a family of efficient proxies. The comment provides a logical reasoning by pointing out the ambiguity in the term, which could lead to confusion for the reader. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to clarify the term to address the issue, but the comment does not provide explicit guidance on how to do so. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of terminology in the paper, specifically regarding the term \"Efficient Proxy.\" It points out that the term is ambiguous, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. By addressing this ambiguity, the authors can improve the clarity and precision of their work. However, the comment could be more helpful if it suggested how the authors might resolve the ambiguity or provided examples of how to clarify the term. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the methods used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, and the subsequent use of a classical method, DBSCAN, for clustering. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or improve their methodology. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific methods, \"Mirzasoleiman et al., 2020\" and \"Grouplearning setting,\" which allows the authors to identify the part of the paper being addressed. However, it does not specify what aspect of these methods is problematic or how they should be improved. The comment lacks detail on what needs to be addressed, making it 2. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the methods used in the paper are stacked from Mirzasoleiman et al., 2020 and the Grouplearning setting, and then use a classical method, DBSCAN, for clustering. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the methods used in the paper, noting that the methods from Mirzasoleiman et al., 2020 and the Grouplearning setting are stacked and then clustered using a classical method, DBSCAN. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or specific recommendations, the authors are left without a clear path for enhancing their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors should investigate the resilience of the metric to the choice of random projection. While the comment explicitly states the need for further analysis, it does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the results, namely the variability in results with the chosen random projection matrix. It suggests that the authors should investigate the resilience of the metric to the choice of random projection, which is a concrete suggestion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or the appendix, but this is not explicitly mentioned. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. While the reviewer acknowledges that this is unlikely with random projections, they suggest that it would be helpful to see the resilience of the metric to the choice of random projection. The comment is 3 as it provides a logical reasoning for the concern but lacks specific examples or references to support the claim. The authors would need to investigate further to address this concern fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors should investigate the resilience of the metric to the choice of random projection, which is a relevant and constructive suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Overall, the feedback is 3 as it identifies an area for improvement but lacks detailed actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It requests an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly mentioning the model used in the paper. These actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing an example of synthetic data, clarifying the meaning of \"support data\" and \"predicted training count data,\" and explicitly mentioning the model used. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification, such as asking for an example of synthetic data and clarifying the meaning of \"support data\" and \"predicted training count data\" in Figure 1. These are not claims or opinions but rather questions seeking clarification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It requests an example of synthetic data, which can help readers understand the concept better. Additionally, it clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, which is crucial for understanding the results presented. The suggestion to explicitly mention the model used in the paper is also valuable, as it provides a clear path for the authors to enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how to clarify these concepts. Overall, the feedback is 4 as it guides the authors in improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just being used in the ablation study. While the comment implies that the authors should consider using FGT for performance evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the use of FGT for performance evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited use of FGT for performance evaluation, suggesting that it should be used to evaluate both the proposed method and comparative methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide specific examples or reasoning to support why this is necessary or how it would improve the evaluation. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the proposed method, specifically regarding the use of FGT. It suggests that FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the evaluation and understanding of the proposed method. However, the comment could be more helpful if it included additional details or examples on how to implement this suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the model is simple, which can be both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the simplicity of the model or whether it should be considered a feature or a bug. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why the model is considered simple or why it is both a feature and a bug. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model\"s simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it provides some insight but does not offer the level of detail or actionable steps needed for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. The comment lacks actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the focus of the work, specifically mentioning that it is narrow in terms of the task (climate change QA) and the language (Arabic). However, it does not specify which part of the paper discusses this focus, making it weakly grounded. The comment is specific in identifying the narrow focus and its potential impact, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it affects the broader impact of their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, noting that it is focused on a narrow task (climate change QA) in a specific language (Arabic). This observation is relevant as it highlights a potential scope for broader impact. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without specific recommendations or examples, the feedback does not provide the authors with a clear path to improve their draft. Therefore, the comment is 3, as it points out an area for consideration but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the originality of their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate the novelty of their approach or findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the originality of the paper, specifically questioning the novelty of using the winnertakeall property, which has been widely used in previous works. It highlights that most of the findings have been reported in previous works, particularly in Sec 5. However, the comment does not specify which part of the paper discusses the winnertakeall property or the findings in Sec 5, making it weakly grounded. The comment is specific in questioning the originality of the paper\"s contribution, but without explicit references to sections or findings, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the winnertakeall property has been widely used in previous works, such as NNbased clustering algorithms, and questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. The comment provides a logical reasoning by referencing previous works and suggesting that the paper lacks originality. However, it lacks specific examples or references to the previous works, making it 3. The authors would need to conduct further research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it identifies a potential issue, it lacks actionable feedback, making it 2. The authors are left to infer that they need to demonstrate the novelty of their approach or findings, but without explicit guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are explicit and provide clear guidance on what the authors should include in their draft to enhance its motivation and applicability. The actions are concrete, as they specify exactly what information should be added and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of runtimes in the experiments. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to include computational cost and runtime examples, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of runtimes in the experiments. However, the comment does not provide any specific reasoning or evidence to support why this information is important or how it would enhance the motivation of the method. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper, which could help motivate the method. It also recommends including a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are clear and actionable, providing the authors with specific ways to enhance the motivation and applicability of their work. By addressing these points, the authors can improve the clarity and impact of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends the authors to elucidate the procedure in greater detail, specifically regarding the role of the spatial arrangement of EEG sensors in the EEG token quantization process. This feedback is clear and provides a concrete action for the authors to take, making it 5. The reviewer also suggests that understanding the spatial arrangement could be insightful, further guiding the authors on what aspects to focus on. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the ambiguity in interpreting EEG topography plots and suggesting that the authors elucidate the procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to ambiguity in interpretation. The reviewer suggests that the authors elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to elucidate the procedure is a logical step, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it presents EEG topography plots for both the input and output during the EEG token quantization process, which may lead to ambiguity in interpretation. The reviewer provides a clear and actionable suggestion by recommending that the authors elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. This feedback is valuable as it guides the authors on how to improve the clarity and interpretability of their results, making the comment 4. However, it could be more helpful if it included specific examples or suggestions on how to elucidate the procedure. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section being discussed. The comment is specific in identifying the issue with the approach but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not provide any supporting evidence or reasoning to justify why this approach is not addressing the problem in a direct way. The comment lacks specific examples, references, or detailed explanations to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach taken by the authors, specifically regarding the complexity of checking on the Witness oracle, which is polynomial time in the tabular case. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach. Without additional guidance or examples, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is 2, as it points out a potential weakness but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks a discussion on using moment matching instead of quantile regression for distributional reinforcement learning (DRL). It specifically mentions a relevant literature source, NguyenTang et al. (AAAI\u201921), which discusses moment matching. The comment implies that the authors should include this discussion when presenting various approaches to DRL. While the action is explicit, it is somewhat vague because it does not provide detailed guidance on how to integrate this discussion into the paper. The authors know they need to address the lack of discussion on moment matching, but the comment does not specify exactly how to do so, such as which sections to include this information in or how to structure the discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion on using moment matching instead of quantile regression for DRL, referencing a specific literature source (NguyenTang et al. AAAI\u201921). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression for DRL, referencing a specific source (NguyenTang et al. AAAI\u201921). This claim is 3 as it provides a specific reference to a relevant literature source, which could help the authors understand the point better. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to consult the referenced literature to fully understand the critique and its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the discussion of distributional reinforcement learning (DRL). It points out that the paper lacks a discussion on using moment matching instead of quantile regression, referencing a relevant literature source (NguyenTang et al. AAAI\u201921). This feedback is valuable as it highlights an area where the paper could be improved by providing a more comprehensive overview of DRL approaches. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their code completion task with existing commercial applications like Copilot. It provides a specific action by recommending a comparison with these stateoftheart code completion systems. The comment also suggests testing on a smaller subset of RepoEval, which adds concrete details on how to implement the comparison. This level of specificity and directness makes the action clear and actionable for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their code completion task with existing commercial applications like Copilot. It provides a specific suggestion for comparison, which is a concrete action. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors can infer that it pertains to the experimental section or discussion of baselines, but this inference is not explicit. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their code completion task with existing commercial applications like Copilot. This is a logical suggestion based on the current state of the field, as it provides a benchmark for evaluating the performance of the proposed method. However, the comment does not provide specific examples or references to support the claim that Copilot is a stateoftheart code completion system, nor does it explain why this comparison is essential. The lack of detailed justification or references makes the claim 3, as the authors would need to conduct additional research to fully understand the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a missing element in the paper by suggesting that the authors should compare their code completion task with existing commercial applications like Copilot. This is a constructive suggestion that provides a clear direction for enhancing the paper by including a relevant baseline for comparison. The comment is specific and actionable, as it not only points out a gap in the current analysis but also offers a concrete example of a stateoftheart system to compare with. This feedback is valuable as it helps the authors improve the comprehensiveness and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more context or explore additional benchmarks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or consider alternative benchmarks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB), which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the section being addressed. The comment is also specific because it questions the generalizability of the evaluation and suggests that the authors should clarify the criteria behind the selection and consider whether other tasks or datasets might yield different insights. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about generalizability. The suggestion to consider other tasks or datasets is a logical extension but is not fully substantiated. Therefore, the comment is 3, as it provides a basis for questioning the evaluation but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is constructive as it prompts the authors to reflect on the scope and generalizability of their evaluation, which is crucial for understanding the broader applicability of their findings. However, the comment could be more helpful if it provided specific suggestions or examples of alternative tasks or datasets that could be considered. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the introduction regarding what is being modelled, specifically mentioning the second paragraph where it discusses modelling curves. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the modelled entity. The action is implicit, as the authors need to infer that they should provide more context or explanation about what is being modelled. The comment is vague because it does not offer concrete steps or suggestions for improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding what is being modelled, particularly in the context of tumour growth. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning \"modeling curves.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modeling curves but does not clarify what is being modeled, particularly in the context of tumor growth. This feedback is clear and actionable, as it directs the authors to provide more context or explanation about the model being discussed. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to clarify the model. Overall, the comment is 4 as it highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. This feedback is explicit and provides a clear action for the authors to take, which is to include this performance evaluation in their draft. The suggestion is concrete, as it specifies what needs to be added to the paper to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of the performance of the model and baselines on test samples from the observational (in) distribution, specifically questioning the reason for the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ) . It suggests that the authors should demonstrate this performance on test samples from the observational distribution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific as it clearly outlines what the authors need to demonstrate to address the concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the performance of the model and baselines on test samples from the observational (in) distribution, specifically regarding the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ). The reviewer suggests that the authors should demonstrate this performance on test samples from the observational distribution. While the comment raises a valid concern about the performance of the model, it lacks specific examples or references to support the claim that shift=0 is much better than shift~ N ( 0 , \u03c3 2 ). The suggestion to show performance on test samples from the observational distribution is a logical step to address the concern, but the initial claim about the better performance of shift=0 is not fully substantiated. Therefore, the comment is 3, as it provides a suggestion for improvement but lacks detailed justification for the initial claim.", "helpfulness_rationale": "The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically regarding the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ). It suggests that the authors should demonstrate this performance on test samples from the observational distribution, which is a clear and actionable feedback. This feedback helps the authors understand where their results might be lacking and provides a specific direction for improvement. However, the comment could be more helpful if it included additional context or examples to further explain the issue or suggested ways to address it. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the experimental description, suggesting that providing more clarity would greatly benefit the reader\"s understanding and judgment of the results. It also directs the authors to the \"Questions\" section for further details. While the comment explicitly states the need for increased clarity and provides a reference to additional information, it does not offer specific guidance on what aspects of the experimental description need more detail or how to improve them. The action is implicit but concrete, as the authors know what needs to be done but may need to infer the exact details. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment highlights a lack of detail in the experimental description, suggesting that providing more clarity would benefit the reader\"s understanding and judgment of the results. However, it does not specify which part of the manuscript lacks detail, making it weakly grounded. The comment is specific in its suggestion to increase clarity and provides a reference to the \"Questions\" section for further details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental description lacks detail, making it difficult for the reader to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to sections or aspects of the experimental description that are lacking detail, making it difficult for the authors to address the issue effectively. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that the experimental description lacks detail, which makes it difficult for the reader to judge the results. It provides a clear and actionable suggestion to increase clarity in the experimental description, which would significantly benefit the manuscript. However, the comment could be more helpful if it offered specific examples or guidance on what aspects of the experimental description need more detail. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more explanation to clarify the \"expected\" result and that the main contribution of the paper, the CBR, should be discussed in more detail. It specifically asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or just the first term. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. The authors are given a clear direction on what additional information or discussion is required, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"expected\" and \"Eq 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, providing more explanation and discussion on the CBR, different optimization strategies, and their results. This includes asking about the impact of minimizing both inter and intra terms or just the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation for the \"expected\" result and discusses the main contribution of the paper, the CBR. It asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or just the first term. While the comment provides a logical basis for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance and importance of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely, the need for more explanation regarding the \"expected\" result. It suggests that the paper should provide a clearer discussion on the contributions, particularly focusing on the CBR and its optimization strategies. The comment is specific in asking for a discussion on the impact of minimizing both inter and intra terms in Equation 3 or just the first term. This feedback is actionable and provides clear guidance for the authors to enhance the clarity and depth of their paper. However, it could be more helpful if it included specific examples or references to support the discussion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors to include such a definition or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a definition and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or theorem where the definition might be relevant. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the definition should be included or how it would improve the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is 3 as it identifies a potential area for improvement by highlighting the importance of the treewidth concept. However, the comment lacks specificity and does not provide guidance on how to incorporate this definition or what aspects of the proofs might benefit from it. To be more helpful, the comment could specify which proofs or sections would be enhanced by a definition of treewidth or offer suggestions on how to present it. Therefore, the comment is 3, as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. While the comment implies that this analysis would be beneficial, it does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the quality of local minima produced by the algorithm, including the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on improving in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. However, the comment does not provide specific examples or references to support the claim that this analysis is necessary or beneficial. The suggestion is based on a logical assumption that the quality of local minima is an important aspect to consider, but without detailed reasoning or evidence, it remains somewhat vague. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the analysis of Algorithm 1 should include an examination of the quality of local minima, specifically the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and potentially improve the robustness of their findings. However, the comment could be more helpful if it included additional details or examples to guide the authors in conducting this analysis. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand certain parts of the main paper, which is necessary for reproducibility. It also explicitly requests the authors to release the source code of their experiments to facilitate reproduction. While the comment identifies the need for additional material and a request for source code, it does not provide specific guidance on how to improve the selfcontainment of the paper or what aspects of the main paper need further explanation. The action is explicit but lacks concrete details on how to address the issues, making it 3.", "grounding_specificity_rationale": "The comment highlights that the paper is not selfcontained and requires the supplementary material to understand certain parts of the main paper, which is necessary for reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which parts of the main paper are not selfcontained or what specific sections require additional explanation. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper, which is necessary for reproducibility. It also requests the release of the source code to facilitate reproduction. While the comment highlights a potential issue with the paper\"s selfcontainment, it does not provide specific examples or detailed reasoning to support the claim. The request for source code release is a direct suggestion but lacks detailed justification. Therefore, the comment is 3, as it provides a general claim but lacks sufficient evidence or explanation to fully substantiate the need for the requested actions.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the main paper is not comprehensive enough to be understood without the supplementary material. This highlights a critical aspect that could hinder the paper\"s accessibility and reproducibility. Additionally, the comment explicitly requests the authors to release the source code of their experiments, which is a constructive suggestion for improving the paper\"s reproducibility. While the comment effectively points out a weakness in the paper\"s structure and provides a clear request for additional resources, it could be more helpful if it offered suggestions on how to improve the selfcontainment of the main paper or provided examples of what specific sections might benefit from additional explanation. Overall, the comment is 4 as it identifies a significant issue and offers a clear request for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically asks for clarification on how this redundancy is built into these algorithms. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this question or what specific details they should include to clarify the implementation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the algorithms. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. However, it does not explicitly mention which part of the paper this sentence is located in, making it weakly grounded. The comment is specific in asking for clarification on how the redundancy is built into the algorithms, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. While the comment identifies a gap in the paper\"s explanation, it does not provide any actionable feedback or suggestions on how the authors might address this issue or improve the clarity of their explanation. The lack of specific guidance or direction limits the usefulness of the comment, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the model\"s design choice involving multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific experiments or analyses could be conducted to explore this issue. The action is implicit and vague, as the authors are left to infer that they should conduct additional experiments or analysis to determine the importance of the design choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific feature of the model, the use of multiple INs at different speeds in the dynamics predictor, which is a novel aspect of the model. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the importance of this design choice and whether one IN would suffice, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is important or why it might be better to use a single IN. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. This feedback is 3 as it prompts the authors to consider the significance of their design choice and potentially conduct further analysis or experimentation to justify its necessity. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue or what additional experiments might be necessary. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experiments, specifically noting that the opponent can be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experiments. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiments, specifically noting that the opponent can be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a clear rationale by mentioning that the opponent maximizes classical SE and AE instead. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experiments, specifically noting that the opponent can be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is based on a logical deduction but lacks detailed evidence or examples, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, specifically noting that the opponent can be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a logical explanation by mentioning that the opponent maximizes classical SE and AE instead. This feedback is 3 as it highlights a potential weakness in the experimental design and suggests an area for improvement. However, it could be more helpful if it offered suggestions on how the authors might address this issue or provide additional context to support the claim. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly instruct the authors to include this rationale. The comment is explicit in its suggestion but vague on how to implement it, as it does not specify the exact details or context of the comparison. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly mention which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not specify the exact section or part of the paper being addressed. The comment is specific in its suggestion to provide a rationale for the choice of algorithms, but it is not fully grounded due to the lack of explicit reference to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not specify the exact reasons or context. While the comment identifies a potential area for improvement, it lacks depth and specificity, leaving the authors with a general suggestion rather than actionable guidance. The feedback is 3 as it points out a potential gap in the paper\"s explanation, but it does not offer detailed advice on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this confusion or what steps they should take to clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This feedback is 3 as it points out a potential issue that the authors might need to address. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might clarify or address this confusion. To be more helpful, the comment could include specific suggestions or examples to help the authors better understand and resolve the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper does not provide insight into this aspect and assumes morphological segmentation to be invariant. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to conduct a thorough analysis. The action is implicit and somewhat vague, as the authors can infer that they need to explore the differences in morphological segmentation across domains, but the comment lacks concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper does not provide insight into this aspect and assumes morphological segmentation to be invariant. However, the comment does not specify which part of the paper discusses morphological segmentation or where these questions should be addressed. The authors can infer that it relates to the domain adaptation section, but this inference is not explicit. The comment is specific in detailing the issues with the assumption of invariant morphological segmentation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper assumes morphological segmentation to be invariant, which is a claim that requires justification. The comment does not provide specific examples, references, or detailed reasoning to support the claim that morphological segmentation should be domainspecific. Without additional evidence or explanation, the claim remains 1, making it difficult for the authors to address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises important questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It highlights a potential gap in the paper\"s analysis, suggesting that the authors did not provide insight into this aspect and assumed morphological segmentation to be invariant. This feedback is valuable as it prompts the authors to consider the implications of domainspecific segmentation and encourages them to explore this area further. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue, such as recommending additional experiments or analyses. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results that exclude the mixup technique from the proposed method. This action is clear and direct, as it specifies what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides a concrete and actionable suggestion, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from their proposed method to demonstrate its pure contribution. This claim is 3 as it provides a logical reasoning for the inclusion of such results, but it lacks specific examples or references to support the necessity of this inclusion. The authors would need to infer the importance of this suggestion based on the context of the paper, making the claim 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include experimental results that exclude the mixup technique from their proposed method. This is important because it allows the authors to demonstrate the pure contribution of their method without the influence of the mixup technique. By following this suggestion, the authors can better understand the impact of the mixup technique on their results and provide a more comprehensive analysis. The feedback is specific and actionable, offering a clear path for improvement. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention process, specifically asking whether it is performed on the image or on a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the object detectionbased attention process, specifically asking whether it is performed on the image or on a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the object detection or attention mechanisms discussed in the paper. The authors can infer that it relates to sections where these concepts are introduced or discussed, but the comment does not provide explicit references. The comment is specific in detailing what needs clarification, making it somewhat grounded and specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the object detectionbased attention process, specifically asking whether it is performed on the image or on a convolutional feature map. It also inquires about rescaling based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. The comment does not contain any claims or opinions that require verification. It is purely a request for clarification, making it a normal statement without a claim. Therefore, it aligns with the label \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention process, specifically asking whether it is performed on the image or on a convolutional feature map. It also inquires about rescaling based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their work, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this omission. The comment suggests that the authors should include a discussion of these related works, but it lacks concrete details on what aspects of the Set Transformer or other works should be discussed. As a result, the authors are left with a general understanding of what needs to be added but without specific instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of a discussion about the Set Transformer and other related works that use summary tokens. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for a discussion on related works, but without explicit references or examples, the authors may find it challenging to pinpoint the exact sections that require revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific examples or references to these works, nor does it explain why this omission is problematic or how it affects the paper\"s comprehensiveness or contribution. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that use summary tokens. This is a valuable observation as it highlights an area where the authors could enhance the comprehensiveness and relevance of their work. However, the comment lacks specific guidance on how the authors should address this omission, such as suggesting which related works to include or how to integrate them into the discussion. While it points out a significant gap, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. While the comment implies that the authors should address this gap in their theoretical analysis, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed analysis of the theoretical support for Fourier features. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the theoretical section or discussion on Fourier features, but this inference is not precise. The comment is specific in questioning the theoretical support for Fourier features, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed, which is an important consideration for the theoretical underpinnings of the work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional analysis might be necessary. While it identifies a potential gap in the theoretical analysis, it lacks actionable feedback, making it 3. The authors are given a direction to explore, but the comment could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue regarding the methodology, specifically questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific steps they should take to clarify this aspect of their methodology. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the methodology of the paper, specifically asking for details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is 3 as it highlights a potential gap in the paper\"s explanation, prompting the authors to clarify their methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional details or references. As a result, while it identifies a critical area for improvement, it does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other relevant details. While the comment does not explicitly instruct the authors to provide this information, it is clear that the authors need to address these aspects to fully understand the experiment setup. The action is implicit but concrete, as the authors know exactly what needs to be clarified. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on the experiment setup, including data augmentation methods, learning rate, and other relevant details. The mention of \"BadNets\" provides a specific reference to a related work, which further enhances the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other details. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the experiment setup in Section 3.3, asking for clarification on data augmentation methods, learning rate, and other relevant details. This feedback is valuable as it prompts the authors to provide more detailed information about their experimental setup, which is crucial for reproducibility and understanding the results. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about potential errors in the initial calibration steps of the algorithm, which might explain the speed disparities observed between the RSPs and FDs. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should investigate the calibration steps, but it lacks concrete steps or detailed advice on what specific actions to take. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III\" of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what the authors need to investigate. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there might be an error in the initial calibration steps of the algorithm, which could explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to revisit the original algorithm described in Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper. It raises a concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This feedback is actionable and provides a clear direction for the authors to investigate and potentially correct any issues in their algorithm. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address the identified problem. Overall, the comment is 4 as it directs the authors to a specific area for improvement but lacks detailed guidance on the resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more than other techniques like backpropagation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their work based on this observation. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment discusses the comparison between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more than other techniques like backpropagation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or discussion. The authors may infer that it relates to the comparison of methods or results, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the comparison are arguable or why it is not more significant than other techniques. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more than other techniques like backpropagation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more than other techniques like backpropagation. However, it does not provide any specific evidence, examples, or reasoning to support this claim. The comment lacks actionable feedback or suggestions for the authors to improve their work. Without detailed guidance or constructive criticism, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the closeness of the numbers when comparing the proposed method with baselines and suggests that the authors might have performed a statistical significance test. However, the comment does not explicitly instruct the authors to conduct a statistical significance test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform a statistical significance test but are not given specific instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, it does not specify which part of the paper this comparison is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to perform a statistical significance test, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that a statistical significance test is necessary. Without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. This feedback is 3 as it points out a potential issue that could affect the interpretation of the results. However, the comment lacks specificity and does not provide guidance on how the authors might conduct a statistical significance test or what specific results might be affected. To be more helpful, the comment could include suggestions on how to perform the test or what specific results might be affected by the closeness of the numbers. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a specific area of inquiry, it does not provide explicit guidance or suggestions on how the authors should address this question or what additional information or analysis is needed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of emission distributions on inference tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is specific and provides a clear direction for the authors to explore, making it fully grounded. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks can be computed exactly or approximately with an NPSPECHMM. This question is logical and seeks clarification on a specific aspect of the paper, but it does not contain any claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is valuable as it prompts the authors to clarify and potentially expand on the capabilities of their model. However, the comment does not provide any suggestions or guidance on how the authors might address this question or what additional analysis or discussion is needed. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results to understand the reasons behind the observed performance. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for a more detailed analysis but are not given concrete steps on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of analysis of the underlying reasons for the poor performance of the scope prompting method on GPT3.5turbo. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a specific issue with the analysis but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to conduct a more detailed analysis to understand the reasons behind the observed performance. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider expanding the comparison to the remaining 110 datasets. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to conduct this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider expanding the comparison to the remaining 110 datasets. However, the comment does not specify which part of the paper this discussion is related to, such as a specific section or table where the comparison is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the rationale behind the dataset selection, but without explicit grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a factual inquiry seeking clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It suggests that the authors should consider expanding their analysis to include the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this expanded analysis or what insights might be gained from it. The feedback is 3 as it points out a limitation in the current dataset selection but does not provide detailed advice on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation in the introduction about lowrank factorization is unnecessary, given that the main result is about polytopes. It also requests that the implications of the result for lowrank matrix factorization be explicitly discussed. While the comment implies that the authors should remove the unnecessary motivation and discuss the implications, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address both the unnecessary motivation and the implications for lowrank matrix factorization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation section in the introduction, specifically mentioning the lowrank factorization and its relevance to the main result about polytopes. It suggests that the motivation is unnecessary if the result does not have implications for lowrank matrix factorization and requests that these implications be discussed explicitly. However, the comment does not specify which part of the introduction this feedback pertains to, making it weakly grounded. The feedback is specific in its critique and suggestion, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation in the introduction about lowrank factorization is unnecessary given that the main result is about polytopes. It also suggests that the implications of the result for lowrank matrix factorization should be discussed explicitly. The comment provides a logical reasoning by pointing out the relevance of the main result to lowrank matrix factorization, which could be a significant aspect of the work. However, the comment lacks specific examples or references to support the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the introduction, suggesting that the motivation about lowrank factorization is unnecessary given the main result about polytopes. It also provides a constructive suggestion by asking the authors to explicitly discuss the implications of their result for lowrank matrix factorization. This feedback is clear and actionable, as it guides the authors to focus on the most relevant aspects of their work and provides a direction for enhancing the clarity and impact of their introduction. However, the comment could be more helpful if it offered specific examples or guidance on how to discuss the implications effectively. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify the labels for each dataset in Section 4.1, specifically questioning whether they come from the dataset itself or from other sources. The comment provides a clear and direct action for the authors to take, which is to explicitly state the origin of the labels. This guidance is concrete and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification on the origin of the labels for the datasets, particularly for caspealr1 and mugshot. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the origin of labels for specific datasets mentioned in Section 4.1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to clarify the origin of the labels for specific datasets mentioned in Section 4.1. This is a specific and direct request for additional information, which is important for ensuring the clarity and completeness of the paper. By addressing this question, the authors can provide more detailed information about their dataset, enhancing the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of how to clarify the labels. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper is incremental with respect to [31] and describes the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this incremental nature or improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions \"with respect to [31],\" indicating that it is referring to a specific reference or work, but it does not specify which part of the paper this relates to. The authors can infer that it pertains to the architecture or methodology, but the lack of explicit reference to a section or figure makes it weakly grounded. The comment is specific in pointing out that the paper is incremental with respect to a particular work, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to [31], suggesting that the authors have adapted an existing architecture for the multiperson case. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment points out that the paper is incremental with respect to a specific reference, [31], and describes the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. While it identifies a potential issue with the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the originality of their contribution. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the sensitivity of performance and sample efficiency to the lambda parameter, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, including [1], [2], and [3], which could help the authors address these issues. However, the comment does not explicitly instruct the authors to use these references or provide specific guidance on how to improve their explanations. While the feedback is somewhat specific, it lacks direct actionability, as the authors need to infer the steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific page numbers and line numbers, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the lambda parameter and the lack of understanding of how lambda is computed. Additionally, it questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment and provides references to relevant literature. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to the lambda parameter and the process of calculating lambda. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, such as [1], [2], and [3], which could help the authors address these issues. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims about the sensitivity of performance and sample efficiency to the lambda parameter. While the references provide some context, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas of concern: the sensitivity of performance and sample efficiency to the lambda parameter, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, which could be beneficial for the authors to explore and potentially incorporate into their work. However, the comment lacks detailed guidance on how to address these issues or improve the explanations. While it highlights important areas for clarification, it does not offer specific suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used for solving the minmin problem, which is mentioned as an alternating direction method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify which specific method is being used, provide more details about the method, or explore alternative methods. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"minmin problem\" and the \"alternating direction method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to solve the minmin problem, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. While it identifies a gap in the paper\"s description, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment highlights potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the effectiveness of their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the effectiveness of lower bound double qlearning and the performance decrease of Clipped DDQN in certain environments. The comment further highlights the potential overestimation of the true maximum value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment provides some reasoning and examples, it lacks detailed evidence or references to support the claim fully. The authors may find it challenging to address these concerns without additional context or specific examples. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the effectiveness of their approach. The feedback provides some insight into areas for improvement but does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve the novelty of their work. Without actionable suggestions or explicit directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may infer that it relates to the interpretation of predictions or model interpretation, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the approach are considered limited or how the authors might address this critique. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the approach is limited, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. While it identifies a potential issue with the novelty of the work, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the critique or enhance the originality of their approach. Therefore, the comment is 2, as it points out a concern but does not offer constructive feedback or actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to clarify their results. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation or justification for the observed performance trend. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, and it provides an expectation that the performance should approach that of vanilla methods from above but from below. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. This feedback is 3 as it identifies a potential issue with the results and prompts the authors to clarify or explain this observation. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or provide a clearer explanation. To be more helpful, the comment could include additional context, references, or specific recommendations for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with earlier research work from 2020, noting that the authors have justified this in the author response. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be made. The comment suggests that the authors have compared their results to earlier systems with worse performances, but it does not offer concrete advice on how to improve this aspect of the paper. The action is implicit and vague, as the authors are left to infer that they should include comparisons with more recent work, but without specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of comparison with earlier research work from 2020, specifically mentioning that the authors have explained their reasons for not doing so in the author response. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in pointing out the absence of comparisons with recent work and the justification provided in the author response. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not compare the results with earlier research work from 2020, despite the authors explaining their reasons in the author response. However, the comment does not provide specific examples or references to the earlier work that should have been compared, nor does it offer detailed reasoning or evidence to support the claim. The lack of specific examples or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment points out a significant gap in the paper\"s analysis by noting the absence of comparisons with earlier research work from 2020. It acknowledges the authors\" explanation in the author response but highlights that the paper has only compared results to earlier systems with worse performances. This feedback is 3 as it identifies a potential weakness in the paper\"s evaluation and suggests that the authors should consider including comparisons with more recent work. However, the comment could be more helpful if it provided specific suggestions or examples of earlier research that should be included for comparison. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, to compare samples generated from the same input. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to make this change. The action is somewhat implicit, as the authors can infer that they should explore the use of a paired test setting, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the testing is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a change in the testing approach, but without grounding, it is difficult for the authors to know where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, the comment does not provide specific reasoning or evidence to support why the current choice of testing is incorrect or why the proposed test setting is more appropriate. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. This feedback is 3 as it points out a specific area for improvement in the methodology section of the paper. However, the comment lacks depth and does not provide detailed guidance on why the current choice of testing might be incorrect or how the proposed test setting would address this issue. To be more helpful, the comment could include a rationale for why the current choice is problematic and how the proposed test setting would enhance the analysis. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this comprehensiveness or generalization. The authors are left to infer that they need to expand the scope of their experiments or consider more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not specify which parts of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the limitations of the model size and baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, the comment does not provide specific examples or detailed reasoning to support why these limitations are problematic or how they could be addressed. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to improve their experiments accordingly. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. This feedback is 3 as it identifies a specific area for improvement, namely the need for more extensive experimentation. However, the comment lacks detailed guidance on how to achieve this comprehensiveness or generalization, such as suggesting additional experiments or baselines to consider. Without specific actionable steps, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to elaborate on the concept of Hoeffding\"s bound and its application in stochastic algorithms. It highlights the importance of conditioning on the previous iterate to guarantee the Hoeffding inequality. While the comment does not explicitly instruct the authors to elaborate on this, it is clear that the suggestion is related to the discussion of Hoeffding\"s bound in the paper. The action is implicit but concrete, as the authors know exactly what aspect of the paper needs further explanation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is elaborating on the concept of Hoeffding\"s bound and its application in stochastic algorithms. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Hoeffding\"s bound holds true for any w as long as the samples are drawn independently, and stochastic algorithms impose conditioning on the previous iterate to guarantee the Hoeffding inequality. The comment provides a logical explanation for why this is the case, which is a form of reasoning that supports the claim. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the literature or provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, focusing on the discussion of Hoeffding\"s bound and its application in stochastic algorithms. It provides a clear and actionable suggestion for the authors to elaborate on this topic, particularly regarding the conditioning on the previous iterate that guarantees the Hoeffding inequality. This feedback is valuable as it guides the authors to enhance their understanding and presentation of this important concept, which could significantly improve the clarity and depth of their work. However, the comment could be more helpful if it included specific examples or references to support the elaboration. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While the comment implies that the authors should consider incorporating these approaches, it does not provide explicit instructions on how to implement them or why they would be beneficial. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the potential benefits of adding these approaches. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of the paper this table is in or provide any context about the table itself. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in suggesting the addition of a particular approach, but without grounding, it is challenging for the authors to understand the context or relevance of this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, the comment does not provide any justification or reasoning for why these approaches should be included or how they would improve the paper. Without specific examples, references, or logical reasoning, the claim lacks verifiability. The authors are left without guidance on how to address the suggestion or why it is relevant, making the comment 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it identifies a potential enhancement to the paper by suggesting a specific approach that could be included. However, the comment lacks detail on why this approach would be beneficial or how it could be integrated into the existing framework. Without additional context or guidance, the authors may find it challenging to fully understand the suggestion and apply it effectively. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks an ablation study to explain why the chosen prompt is effective, particularly mentioning the potential benefits of fewshot examples for CoT. While the comment implies that an ablation study should be conducted to justify the choice of prompt, it does not explicitly instruct the authors to perform this study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and understand the specific aspects to consider. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of fewshot examples for CoT. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment provides a clear suggestion for what could be improved, it lacks full grounding as it does not explicitly mention a section or table. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of fewshot examples for CoT. However, the comment does not provide any specific examples or detailed reasoning to support why this is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of the suggestion, leaving the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain the choice of prompt. It provides a clear and actionable suggestion by mentioning the potential benefits of fewshot examples for CoT, which could enhance the paper\"s understanding and justification. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from temporal relationships. This feedback is clear and direct, providing a specific action for the authors to take. It gives them a clear understanding of what needs to be addressed and how to correct it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that \"causality is different from temporal relationship,\" providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"causality is different from temporal relationship,\" which is a factual statement rather than a claim or suggestion. It does not require verification or evidence, as it is a clear and accurate statement of fact. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out a potential confusion in terminology regarding \"causal mechanisms\" and \"causality\" on page 1. It instructs the authors to use these terms carefully, emphasizing the distinction between causality and temporal relationships. This feedback is specific and actionable, helping the authors to improve the clarity and accuracy of their terminology. However, it could be more helpful if it included examples or further explanation of why this distinction is important. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what additional evidence or analysis could be provided to strengthen their claim. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence from the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. The reviewer raises a valid concern about the evidence provided, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. While it identifies a potential weakness in the paper, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve their demonstration. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights an area for improvement but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the relationship with the referenced work, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for improvement by pointing out a relevant reference that could be discussed in the paper. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this discussion or what aspects of the results should be highlighted. To be more helpful, the comment could specify which parts of the results are relevant to this discussion or how the inclusion of this reference could enhance the paper. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and actionable details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider the assumptions met when using PCA. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the significance of their results. The action is implicit and vague, as the authors are left to infer that they need to justify the assumptions and the significance of their findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider the assumptions met when using PCA. However, the comment does not specify which part of the paper discusses PCA or the interaction count reduction, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the assumptions and the significance of the results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions made in the paper. However, the comment lacks specific details or examples of how the assumptions are met or how the results are significant. While the reference provides a starting point for further exploration, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper\"s results. It provides a reference to a relevant paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions made in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve the significance of their results. While it identifies an area for improvement, it does not offer actionable feedback or detailed advice, making it 3. The authors are left to infer that they need to justify the assumptions and the significance of their findings, but without explicit guidance, the comment remains incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the fewshot RC models considered in the paper are not stateoftheart, and it suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the fewshot RC models considered in the paper and suggests comparing their performance to relation extraction/generation models in fewshot settings. However, it does not specify which part of the paper discusses these models, making it weakly grounded. The comment is specific in suggesting a comparison to relation extraction/generation models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart, suggesting a comparison to relation extraction/generation models in fewshot settings. However, the comment does not provide specific examples or references to support the claim that the models are not stateoftheart. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart. It suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. This feedback is 3 as it points out an area for improvement and provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included specific suggestions on how to conduct the comparison or what aspects of the models should be evaluated. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the results in section 4, stating that they apply only to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or what steps they should consider to expand the scope of their results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a limitation in the results, stating that they apply only to shallow fullyconnected ReLU networks. This provides clear guidance on what aspect of the results needs further exploration or clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the results presented in section 4, specifically noting that they are restricted to shallow fullyconnected ReLU networks. This feedback is 3 as it points out a potential scope limitation that the authors should consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their results. Without actionable advice or further elaboration, the comment provides only a partial insight into the draft\"s weaknesses, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While the comment implies that these actions should be taken, it does not specify which parts of the paper need more background or how the description of related literature should be structured. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it difficult for the authors to identify the exact areas that need attention. The comment lacks specificity in terms of what specific aspects of the background knowledge or related literature should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, the comment does not provide any specific examples, reasoning, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While this feedback acknowledges the need for improvement in the paper\"s organization, it lacks specificity and actionable guidance. It does not specify which parts of the paper need more background or how the description of related literature should be structured. This limits the usefulness of the comment for the authors, as it does not provide clear direction on how to enhance the draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the related work section. Without explicit references to specific sections or elements, the authors may find it challenging to pinpoint where the comparison is lacking. Additionally, the comment lacks specificity regarding what aspects of these models should be compared or how they should be integrated into the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included or why their exclusion is problematic. Without additional context or explanation, the authors may find it difficult to understand the significance of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s comparison by pointing out that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is valuable as it highlights an area where the authors can enhance the comprehensiveness and relevance of their work. However, the comment lacks specific guidance on how to integrate these models into the comparison or what aspects of these models should be emphasized. While it provides a clear direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. While the comment implies that the authors should include results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide results, but the comment lacks specific guidance on how to present these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the discussion on using sequential MCB vs a single MCT layers for the decision head. It is fully grounded as it explicitly mentions the part of the paper being discussed, allowing the authors to accurately identify the section. The comment is also specific because it requests additional information about what was observed in this discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing results for the discussion on using sequential MCB vs a single MCT layers for the decision head. This feedback is clear and actionable, as it directs the authors to include results that would enhance the discussion and provide more insight into the topic. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific observations should be included. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their choice of distribution sets and consider the impact of selecting a limited number of sets. However, the comment lacks concrete details on how to implement these clarifications, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table where this choice is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the choice of distribution sets and their impact, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification or the potential impact of the choice of distribution sets. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it relates to the overall quality of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern regarding the experimental setup, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it prompts the authors to consider the implications of their choice of distribution sets, but it does not provide actionable steps or detailed advice for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluative framework is limited in scope, specifically mentioning the consideration of only three QuestionAnswering tasks and two language models. It raises questions about the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies a potential limitation, it does not provide explicit guidance on how the authors should address this issue. The feedback is vague and lacks concrete suggestions for improvement, leaving the authors uncertain about how to expand the scope of their framework. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning the limitations in scope, which is restricted to three QuestionAnswering tasks and two language models. It raises questions about the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology section, but this is not explicitly mentioned. The comment is specific in detailing the limitations of the framework, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, specifically mentioning the consideration of only three QuestionAnswering tasks and two language models. The reviewer questions the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment raises a valid concern about the scope of the evaluation, it lacks specific examples or references to support the claim. The reasoning is based on the limited number of tasks and models considered, but without further elaboration, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it provides a logical basis for the claim but requires additional details to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, specifically noting that it is restricted to only three QuestionAnswering tasks and two language models. This feedback highlights a potential area for improvement, as it questions the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. By pointing out this limitation, the comment provides a clear direction for the authors to expand the scope of their evaluation. However, the comment could be more helpful if it offered suggestions on how to address this limitation or examples of how to incorporate additional tasks or models. Overall, the comment is 3 as it directs the authors\" attention to a specific area for improvement but lacks depth in actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models instead of the obsolete ngram HMM and RNN models. This action is clear and concrete, as it provides a specific direction for the authors to improve their draft by aligning it with current NLP trends. The comment offers a clear and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of perplexity experiments with obsolete language models, specifically mentioning ngram HMM and RNN. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the use of perplexity experiments. The comment is also specific because it clearly specifies the need to use transformerbased models to improve alignment with current trends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of perplexity experiments with obsolete language models (ngram HMM and RNN) is outdated and recommends using transformerbased (masked) language models to better align with current NLP trends. The reviewer provides a logical reasoning by stating that transformerbased models are more prevalent and relevant in the current NLP landscape. However, the comment lacks specific references or examples to support the claim that these models are obsolete or outdated, which could strengthen the justification. Therefore, the claim is 3, as it provides a logical basis but could benefit from additional evidence or references.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the use of perplexity experiments with obsolete language models (ngram HMM and RNN). It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more aligned with current NLP trends. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and currency of their work. By following this suggestion, the authors can significantly improve the alignment of their research with contemporary practices in the field. However, the comment could be more helpful if it included additional context or examples to further support the recommendation. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical or toy experiments should be conducted to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and referencing specific work. The comment is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, suggesting that more empirical or toy experiments are needed to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result from Kaplan et al. 2020. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as additional experiments and references to existing work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests additional empirical or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The comment provides a logical reasoning by suggesting that more experiments are needed to support the claims made in the theoretical analysis. However, it lacks specific examples or references to external works that could further substantiate the claim. While the suggestion is reasonable, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the current experimental setup, noting that the experiments are insufficient. It provides a clear and actionable suggestion by recommending additional empirical or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also references a specific work (Kaplan et al. 2020) for potential citations, which adds depth to the feedback. This detailed guidance empowers the authors to enhance their draft by conducting more comprehensive experiments and referencing relevant literature, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify the estimation of mu. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the estimation of mu, which is the proportion of missing observations. However, it does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the estimation of mu, but it lacks detailed guidance on how the authors might address this issue or what aspects need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the estimation of mu, which is the proportion of missing observations. However, it does not provide any supporting evidence, reasoning, or references to justify why this estimation is unclear or problematic. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific concern about the estimation of mu, which is the proportion of missing observations. It questions the clarity of how mu can be estimated, suggesting that it is not entirely clear how this estimation is achieved. This feedback is 3 as it identifies a potential area of confusion or lack of clarity in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Therefore, the comment is rated as 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific action for the authors to take, which is to present the performance as a function of the distance of initialization. It provides a detailed method for doing so, including the steps to vary the distance, sample initial matrices, and report the performance accordingly. The comment also offers an expectation of how the mean error and variance should behave as the quality of initialization decreases. This level of detail and specificity makes the action explicit and concrete, allowing the authors to clearly understand and implement the suggested improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests a specific action for the authors to present the performance as a function of the distance of initialization. It provides a detailed method for doing so, including the steps to vary the distance, sample initial matrices, and report the performance accordingly. This level of detail and specificity allows the authors to accurately identify the part of the paper where this suggestion would be relevant, such as the experimental section or results. The comment is fully grounded as it explicitly mentions the action to be taken and provides clear guidance on how to implement it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a method for presenting the performance as a function of the distance of initialization, which is a specific and detailed suggestion. However, it does not provide any evidence, reasoning, or references to support why this method is necessary or how it would improve the paper. The claim lacks context or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of the performance results, focusing on the sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization, which is a novel and detailed approach. The comment includes a method for varying the distance and sampling initial matrices, providing a clear and actionable way for the authors to enhance their results section. This feedback is 5 as it offers a concrete and constructive suggestion for improving the clarity and depth of the paper, allowing the authors to make a significant enhancement to their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the absolute value operation in the definition of the Frobenius norm is unnecessary since tensor entries are real numbers. This observation is explicit and provides a clear action for the authors to take, which is to remove the absolute value operation. The comment is concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, noting that it is unnecessary since tensor entries are real numbers. This provides clear guidance on what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that aligns with common mathematical knowledge. The reviewer provides a clear explanation of why the absolute value operation is redundant, which is a wellsupported argument. However, the comment could be strengthened by providing a specific reference or example to further substantiate the claim. Therefore, the comment is 4, as it provides a strong logical basis but lacks full detail in its justification.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically noting that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their definition. By addressing this point, the authors can enhance the precision of their mathematical notation, which is beneficial for the overall quality of the paper. However, the comment could be more helpful if it provided additional context or suggestions for how to present the corrected definition. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds instead of only bounds in expectation. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement them, such as which specific ensemble methods to use or how to calculate error bars. The authors are given a clear direction but may need to further explore the suggested methods to fully implement the changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"highprobability bounds\" and \"ensemble methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of ensemble methods to achieve highprobability bounds and adding measures of robustness like error bars or standard deviation to the experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and questions whether highprobability bounds could be obtained. It proposes using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed examples of how ensemble methods or robustness measures have been successfully applied in similar contexts. This makes the claim 3, as the authors would need to explore the suggested methods further to fully understand and implement the changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that only bounds in expectation are provided, suggesting that highprobability bounds could be more informative. It offers a specific suggestion to use ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to improve their work. By addressing these suggestions, the authors can enhance the robustness and reliability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the author is not an expert in pruning but finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to improve the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation for pruning and the results, but it does not specify which part of the paper these aspects are discussed in. The authors can infer that it relates to the motivation section or the results section, but this inference is not explicit. The comment is specific in suggesting that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a subjective opinion about the motivation for pruning and the results being less impressive. It also suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion to evaluate results from additional aspects is a general observation rather than a claim that requires verification. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges the author\"s expertise in the area of pruning and finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it lacks specific guidance or actionable suggestions on how to address these concerns. The feedback is 3 as it points out potential weaknesses but does not provide detailed advice on how to enhance the paper\"s quality. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their model to enforce diversity. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the paper\"s focus on diversity, as indicated by the title, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the introduction or methodology sections, but this inference is not explicit. The comment is specific in detailing the concern about the lack of explicit diversity enforcement in the model, which is a clear issue. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, as indicated by the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the model does not enforce diversity. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s focus on diversity, as indicated by the title, but the lack of explicit diversity enforcement in the model. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s methodology that the authors need to address. By pointing out this inconsistency, the reviewer provides a clear direction for the authors to improve their draft, specifically by suggesting that they should explicitly enforce diversity in their model. This constructive feedback is valuable as it guides the authors in enhancing the rigor and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which sections or parts of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without explicit references to the paper\"s sections, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence impacts the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the absence of experiments involving contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these experiments effectively. Overall, the comment is 4 as it highlights a critical gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to include in the comparisons, making it 5. The authors know exactly what changes to make to enhance their work based on the feedback provided.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of FIDs and DinoV2 Frechet Distances, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by suggesting the use of DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that FIDs are being widely used for evaluation but have clear flaws, and suggests using DinoV2 Frechet Distances instead. The comment provides a rationale by referencing a specific work [C] that highlights the flaws in FIDs and the use of Inception networks. This provides some support for the claim, but it could be strengthened by offering more detailed reasoning or examples. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs (Frechet Inception Distances) for evaluation, noting that there have been clear flaws associated with them and the simplicity of the Inception network. It suggests using DinoV2 Frechet Distances as an alternative, which is a specific and actionable recommendation. This feedback is valuable as it provides the authors with a clear direction for improving their evaluation metrics, enhancing the robustness and reliability of their results. However, the comment could be more helpful if it included further explanation or justification for the recommendation, such as why DinoV2 Frechet Distances are more suitable or how they might address the flaws in FIDs. Despite this, the feedback is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point questions the novelty of the paper, suggesting that it seems incremental. It asks the authors to clarify how their work differs from a previous publication, specifically mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This question implies that the authors should provide a detailed comparison or explanation of the differences between their work and the referenced publication. However, the comment does not explicitly instruct the authors to make these comparisons or provide specific guidance on how to address the novelty claim. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the novelty of the paper, suggesting that it seems incremental. It asks the authors to clarify how their work differs from a specific publication, mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This provides some grounding as it references a specific paper, but it does not explicitly mention which part of the paper this question pertains to, such as a particular section or methodology. The comment is specific in its request for clarification on the differences between the current work and the referenced publication. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the novelty of the paper, suggesting that it seems incremental. It asks the authors to clarify how their work differs from a specific publication, implying that the methodology is similar. However, the comment does not provide specific examples or detailed reasoning to support the claim that the novelty is incremental. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the paper, questioning whether it offers incremental improvements over a previous publication. By asking the authors to clarify the differences between their work and the referenced publication, the comment prompts a detailed comparison or explanation of the unique contributions. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and impact of their paper. However, the comment could be more helpful if it offered specific suggestions or examples of how to highlight the novelty or differentiate the work. Overall, the comment is 4 as it directs the authors to address a critical aspect of their paper\"s originality."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what steps they should consider to resolve it. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results of the ablation studies on the CUB and SOP datasets, highlighting a discrepancy where the complete loss function performed worse than those with some terms missing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or additional context, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential inconsistency but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to conduct an experiment where the image is occluded, simulating irregularities in neural/behavioral data and allowing the model\"s longrange inference capacity to be inspected. The reviewer also suggests that these experiments are reasonably easy to run and should be included in the final version of the paper unless the authors provide a convincing reason otherwise. This feedback is clear and direct, providing a specific action for the authors to take. The request is concrete, as it outlines the exact experiment to be conducted and its potential benefits. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Finally,\" and \"similarly to above,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of an experiment where the image is occluded to simulate irregularities in neural/behavioral data and to inspect the model\"s longrange inference capacity. The comment provides clear guidance on what additional experiments should be conducted and why they are important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment where the image is occluded to simulate irregularities in neural/behavioral data. The reviewer explains the rationale behind this suggestion, stating that it would allow for the inspection of the model\"s longrange inference capacity. The comment also notes that these experiments are reasonably easy to conduct. While the suggestion is logical and provides a clear rationale, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for an additional experiment that could enhance the paper\"s findings. It suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data, and allowing the model\"s longrange inference capacity to be inspected. This feedback is specific and provides a rationale for why such an experiment would be valuable, aligning with the suggestion of including these experiments in the final version of the paper. The comment is 4 as it offers a clear direction for improvement, but it could be more helpful if it included specific details on how to conduct the experiment or what results to expect. Overall, the comment is 4, as it provides a clear and actionable suggestion for enhancing the paper\"s experimental design."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is problematic because it implies negative rates, which is not accurate. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment explicitly states the issue and provides a clear suggestion for improvement, it does not offer specific guidance on how to implement the suggested changes. The authors know what needs to be done but may need to consult additional resources or examples to fully understand the suggested visualization. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the implication of negative rates, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is \"a bit awkward\" because it implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use a second yaxis or another visualization provides a direction for improvement but does not offer a comprehensive explanation of why the current figure is problematic. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not accurate. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can implement to enhance the clarity and accuracy of their figure. However, the comment could be more helpful if it offered additional guidance on how to implement the suggested changes or provided examples of alternative visualizations. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear direction for addressing the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that introducing inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. While the comment identifies a potential area for further exploration, it does not explicitly instruct the authors to conduct these tests or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental scope to include other embedding models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that introducing inverse triples might be applicable to other embedding models besides CP, but it does not specify which part of the paper this observation pertains to. The authors can infer that it relates to the discussion or experimental section, but this inference is not explicit. The comment is specific in suggesting that the authors should test such cases in their experiments, but it lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be applicable to other embedding models besides CP, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific references or detailed explanations, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or justification, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment suggests that introducing inverse triples might be applicable to other embedding models besides CP, but the authors did not test such cases in their experiments. This feedback is 3 as it points out a potential limitation in the scope of the experiments and suggests an area for further exploration. However, the comment lacks specific guidance or suggestions on how the authors might expand their experiments to include other embedding models, which would make it more actionable. Therefore, the comment is 3, as it identifies a potential improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the abstract, noting that the statement \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions\" is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. While the comment points out a specific area of confusion, it does not provide explicit guidance on how to clarify the statement or what aspects of the abstract should be made more highlevel. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the abstract without providing detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which is its unclear nature due to the technicalities mentioned. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technicalities are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that the abstract should be more highlevel. The comment provides a logical reasoning by pointing out that the technicalities mentioned are not necessary for a highlevel understanding. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact technicalities that are unclear, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggesting that the abstract should be more highlevel. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to simplify the abstract. By addressing this issue, the authors can enhance the readability and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to rephrase the abstract to make it more highlevel. Overall, the comment is 4, as it directs the authors to a specific area for improvement and provides a clear direction for action."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. The comment lacks explicit instructions or concrete details on what aspects of the algorithm\"s complexity could be enhanced or how to make those improvements. Without actionable advice, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not specify which part of the algorithm or the paper this complexity is being discussed in. The authors cannot confidently determine which part of the paper the comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the complexity need improvement or how to achieve it. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what aspects of the algorithm\"s complexity could be enhanced or how to make those improvements. This lack of specificity and actionable advice makes the comment 2, as it does not effectively guide the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, it does not provide explicit guidance on how to incorporate these results or what specific languagerelated tasks should be considered. The comment is vague and lacks concrete details on how to implement the suggested changes, making it 3. The authors can infer that they should consider including results in other modalities, but the lack of specific guidance on how to do so limits the actionability.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider other modalities and the importance of OOD performance, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, the comment does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The suggestion is somewhat vague and lacks detailed reasoning or evidence, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from including results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. This feedback is 3 as it provides a direction for expanding the scope of the paper\"s results, which could enhance its relevance and applicability. However, the comment lacks specific guidance on which languagerelated tasks to include or how to measure OOD performance, leaving the authors with a general suggestion rather than detailed instructions. Therefore, the comment is rated as 3, as it offers a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, particularly in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment implies that the authors should address these issues, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the justification of the work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fewshot learning\" and \"graph link prediction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the motivation, such as the lack of consideration for effectively using \"fewshot\" and the need to guarantee generalization to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, particularly in the context of fewshot learning. It suggests that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment identifies a potential issue, it lacks specific examples or references to support the claim. The authors would need to infer the exact points that need clarification or improvement, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper\"s motivation, specifically in the context of fewshot learning. It points out that while the paper defines and creates a fewshot situation for graph link prediction, it does not consider how to effectively use \"fewshot\" or how to guarantee the trained model\"s generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to address a significant gap in their work. By providing specific areas for improvement, the comment offers valuable guidance that can help the authors enhance the clarity and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of Gaussian Process (GP) in the paper, stating that it is \"naive\" and referring to the GP community\"s extensive investigation of dynamical modeling, starting with the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their use of GP or incorporate more sophisticated approaches. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Process (GP) in the paper, stating that it is \"naive\" and referring to the GP community\"s extensive investigation of dynamical modeling, starting with the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. The authors cannot confidently determine the exact part of the paper being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the GP use are naive or how the authors might improve their approach. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is \"naive\" and refers to the extensive investigation of dynamical modeling in the GP community, starting with the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide specific examples or detailed reasoning to support why the use of GP is naive or how it compares to more advanced approaches. The reference to NIPS 2005 provides some context but does not substantiate the claim. Without additional explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Process (GP) in the paper, stating that it is \"naive\" and refers to the extensive investigation of dynamical modeling in the GP community, starting with the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide specific examples or detailed reasoning to support why the use of GP is naive or how it compares to more advanced approaches. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It also points out that this is not consistent with the author\"s experience, suggesting that the baseline models may not be properly regularized. The reviewer further asks if dropout is applied to the hidden states in addition to the embeddings. While the comment identifies a potential issue and provides a specific question for the authors to consider, it does not explicitly instruct them to address this concern or provide guidance on how to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization of their models and possibly clarify the statement in the supplemental section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for LM compared to the GAN model, suggesting that this is not consistent with the author\"s experience. The comment further asks if dropout is applied to the hidden states in addition to the embeddings, providing a clear direction for the authors to investigate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. 2014, which suggests that the baseline models may not be properly regularized. The comment also asks if dropout is applied to the hidden states in addition to the embeddings, which could be relevant to the discussion. While the comment provides a specific example and a question for the authors to consider, it lacks detailed reasoning or references to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It provides a counterexample from Zaremba et al. 2014, suggesting that the baseline models may not be properly regularized. The reviewer also asks if dropout is applied to the hidden states in addition to the embeddings, which could be relevant to the discussion. While the comment identifies a potential issue and provides a specific question for the authors to consider, it lacks detailed guidance on how to address the concern or improve the draft. The feedback is 3 as it prompts the authors to reconsider their claims and possibly provide additional evidence or clarification, but it could be more comprehensive with more detailed suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to find. The action is implicit and vague, as the authors are left to infer that they need to improve the organization or clarity of the ablation sections. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not specify which sections or ablations are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of specific guidance or examples makes it challenging for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s organization, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback highlights a potential weakness in the paper\"s structure, which could hinder the reader\"s understanding. However, the comment lacks actionable suggestions or guidance on how the authors might improve the organization or make the ablations more accessible. While it points out a problem, it does not provide concrete steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends that the online algorithm and robustness be highlighted as novel and interesting, and that the experimental results in the appendix be moved to the main paper. While the comment provides clear guidance on what needs to be improved and where the focus should be, it does not specify how the authors should clarify the differential privacy application or how to present the online algorithm and robustness more effectively. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think through it more clearly. It also mentions the online algorithm and robustness as novel and interesting, and suggests moving the experimental results from the appendix to the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application or the online algorithm, making it weakly grounded. The feedback is specific in its critique and suggestions, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the application is \"halfbaked.\" The suggestion to move the experimental results is clear, but without further explanation, it remains somewhat vague. Therefore, the comment is categorized as 3, as it provides some support but lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, suggesting that the differential privacy application is \"halfbaked\" and recommending that the authors clarify it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, suggesting that the experimental results in the appendix should be moved to the main paper. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to clarify the differential privacy application or how to present the online algorithm and robustness more effectively. Overall, the comment is 4 as it guides the authors towards enhancing the clarity and impact of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this comparison or what specific aspects of the multilingual chainofthought could be improved. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not specify which part of the paper this comparison is based on, nor does it provide any details on what aspects of the multilingual chainofthought are incremental or how they compare to the villa chainofthought. Without specific references or detailed feedback, the authors cannot determine which part of the paper this comment pertains to or what specific issues need addressing. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how it impacts their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this comparison or improve their work. Without actionable feedback or guidance, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general would be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the applicability of their methodology to bimanual manipulation. The feedback is vague because it lacks concrete steps or examples of how to make the methodology more specific. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is specific to bimanual manipulation or if robotic manipulation in general would be more appropriate. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors may have to infer that it pertains to the methodology section or the introduction, but this inference is not explicit. The comment is specific in its critique of the methodology\"s applicability, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be specific to bimanual manipulation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general would be more appropriate. This feedback is 3 as it identifies a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a gap in the paper\"s clarity but does not offer actionable steps or examples to help the authors enhance their draft. Therefore, the comment is rated as 3, as it provides a starting point for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide METEOR results, which are mentioned in recent works. This is a clear and direct action for the authors to take, as it specifies what additional information should be included in their draft. The comment is explicit and provides concrete guidance on how to address the feedback, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"METEOR results,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of METEOR results, which are mentioned in recent works. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide METEOR results, which are reported in recent works. However, it does not provide any specific references or examples of these recent works, making it difficult for the authors to understand the basis of the claim. Without detailed references or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to include METEOR results, which are mentioned in recent works. This feedback is specific and provides a direct way for the authors to enhance their draft by aligning with established practices in the field. However, the comment could be more helpful if it explained why METEOR results are important or how they should be integrated into the paper. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can significantly enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the comparability of results. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the comparability of their findings. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the results are not comparable. This lack of detailed evidence or justification makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this concern. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take to enhance the comparability of their findings. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the consistency of the advantage of UNIFORM over other procedures, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors are left to infer that they need to provide a theoretical explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the advantage of UNIFORM over other procedures, specifically mentioning the tables that show UNIFORM\"s performance in the 1shot setting. It also suggests that the authors should provide a theory to explain why the method is not as effective in this setting. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the results and theory sections. The comment is specific in detailing what needs to be addressed, namely, the theory behind the method\"s effectiveness in the 1shot setting. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as shown in the tables. It suggests that the authors should provide a theory to explain why the method is not as effective in the 1shot setting. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide a theory is a logical step but is not fully supported by the evidence provided. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the advantage of UNIFORM over other procedures, particularly in the 1shot setting. It highlights that the tables show UNIFORM does not always offer a clear advantage, suggesting that the authors should provide a theory to explain this observation. The comment acknowledges that the clarity and design of the experiments are well done, but it focuses on a critical area for improvement. While the feedback is clear and points out a specific area for enhancement, it could be more helpful if it offered suggestions on how to develop a theory or what aspects of the method might be contributing to its performance in the 1shot setting. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. However, the comment does not explicitly instruct the authors to include this theory or provide specific guidance on how to integrate it. The action is implicit and somewhat vague, as the authors need to infer that they should explore existing linguistic theory and potentially include it in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it suggests that the authors consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. However, it does not provide specific references or examples of such theories, making it difficult for the authors to understand or address the suggestion. The lack of detailed support or references makes the claim 3, as the authors would need to conduct additional research to find relevant theories themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. This feedback is 3 as it points out a potential area for improvement by suggesting the inclusion of relevant linguistic theory. However, the comment lacks specific guidance on which theories to explore or how to integrate them into the paper, leaving the authors with a general direction but no detailed actionable steps. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should spend more time discussing the potential benefits of using AutoML approaches, such as extracting hints that can be reused in the design of new network architectures. It implies that the authors should provide more detailed comments on the findings of the study, particularly regarding the most significant takeaways from the discovered architecture. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed comments on the findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what specific aspects of the findings should be highlighted or discussed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, suggesting that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s value and contribution. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might address this issue. To be more helpful, the comment could include suggestions on what specific aspects of the findings should be highlighted or discussed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This implies that the authors should clarify or redefine T_a(t) in Section 3.1 to ensure consistency and proper understanding. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a discrepancy in the usage and definition of T_a(t) in the paper. It specifies that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides full grounding as the authors can accurately identify the sections being addressed. The comment is also specific because it clearly details the issue with the inconsistency in usage and definition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This observation is factual and does not require any supporting evidence or reasoning. It is a straightforward statement of a potential issue in the paper, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4, which could lead to confusion for readers. This feedback is clear and actionable, as it highlights a potential inconsistency that the authors should address to improve the clarity and coherence of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending the redefinition of T_a(t) in Section 3.1 or clarifying its usage throughout the paper. Overall, the comment is 4 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise. It also recommends including empirical results. While the comment implies that the authors should make these changes, it does not provide specific guidance on how to achieve this conciseness or what empirical results should be included. The action is implicit and somewhat vague, as the authors know they need to make the introduction more concise and include empirical results, but the comment lacks detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which part of the main part or the introduction is being addressed, making it weakly grounded. The comment is specific in suggesting that empirical results should be included, but without further details, the authors may struggle to pinpoint the exact sections needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise. It also recommends including empirical results, which is a constructive suggestion for improving the clarity and depth of the paper. However, the comment lacks specific guidance on how to achieve conciseness or what empirical results should be included. While it provides a direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it identifies areas for enhancement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests additional clarification on the empirical analysis in Figure 3, specifically asking for an explanation of how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment notes that Equations (9) and (10) have large spacing from the preceding text and references a specific paper for further context. This feedback provides clear and specific actions for the authors to take, such as providing additional clarification and addressing the spacing issue. The request for clarification and explanation is explicit, and the authors are given concrete steps to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the clarification of how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. Additionally, it requests an explanation of why these adjustments are effective in enhancing the model\"s performance. The comment also notes the spacing issue in Equations (9) and (10) and references a specific paper for further context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the empirical analysis in Figure 3 and requests additional clarification. It specifically asks for an explanation of how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The reviewer also seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. While the comment identifies a potential issue with the clarity of the analysis, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The reference to a specific paper is helpful but does not directly address the issue at hand. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely, the empirical analysis in Figure 3. It requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The comment also seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, it notes that Equations (9) and (10) have large spacing from the preceding text and references a specific paper for further context. This feedback is clear and actionable, providing the authors with specific areas to clarify and improve in their draft. By addressing these points, the authors can enhance the clarity and comprehensiveness of their paper. Therefore, the comment is 5, as it offers detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the recent related work CoCoOp [1] should be compared in the experiments. It provides a clear and direct action for the authors to take, which is to include CoCoOp in their experiments. This feedback is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the recent related work CoCoOp [1] is not compared in the experiments,\" which provides full grounding as it clearly identifies the specific part of the paper being addressed\u2014the experiments. It also specifies what needs to be addressed by suggesting that the authors should compare their work with CoCoOp, which is a recent and relevant related work. This level of detail and specificity allows the authors to accurately understand the feedback and make the necessary adjustments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp [1] should be compared in the experiments, despite being a CVPR\"22 work that is published after the NeurIPS deadline. The reviewer provides a specific reference to CoCoOp, which is a recent and relevant related work. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by explaining why the comparison with CoCoOp is necessary or how it would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting that the recent related work CoCoOp [1] is not compared in the experiments, despite being a relevant and recent work. It provides a clear and actionable suggestion by recommending that the authors include CoCoOp in their experiments. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation and offers a concrete way for the authors to strengthen their work by comparing it with a relevant and recent related work. However, the comment could be more helpful if it provided additional context or reasoning about why the comparison with CoCoOp is important. Overall, the comment is 4 as it guides the authors towards a specific improvement that could enhance the paper\"s rigor and relevance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by providing a better representation of the processing pipeline, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the need to show where model training is being used to optimize the selection modules. While the comment implies that these improvements should be made, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact modifications required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the figure, such as enhancing the representation of the processing pipeline, including prompt generation, manual check, demonstration selection, and automatic scoring. Additionally, it suggests showing where model training is being used to optimize the selection modules. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by providing a better representation of the processing pipeline, including various components such as prompt generation, manual check, demonstration selection, and automatic scoring. However, the comment does not provide specific examples or detailed reasoning to support why these improvements are necessary or how they would enhance the figure. Without additional context or justification, the claim is 3, as it lacks the depth and specificity needed for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting ways to improve Fig. 1, which is crucial for effectively illustrating the processing pipeline. It highlights the need for better representation of key components, such as prompt generation, manual check, demonstration selection, and automatic scoring, as well as the integration of model training to optimize selection modules. This feedback is clear and detailed, offering the authors a clear path to enhance the clarity and effectiveness of their figure. However, it could be more helpful if it included specific suggestions on how to improve the figure or examples of how these components could be better integrated. Overall, the comment is 4 as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experiments were conducted only on two typical games and questions the performance of ReBeL on more complex problems, particularly those with larger depths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting additional experiments or methods to evaluate ReBeL on more complex problems. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically questioning the limited scope of the experiments conducted on only two typical games. It highlights a concern about the performance of ReBeL on more complex problems, particularly those with larger depths, which could lead to significant input sizes for value and policy functions. However, the comment does not specify which part of the paper this critique pertains to, such as the experimental section or specific results. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity in detailing what specific improvements or additional experiments are needed to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the limited scope of the experiments conducted on only two typical games, questioning the performance of ReBeL on more complex problems, particularly those with larger depths. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient or that the performance on complex problems is a significant issue. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental setup, specifically questioning the scope of the experiments conducted on only two typical games. It highlights a concern about the performance of ReBeL on more complex problems, particularly those with larger depths, which could lead to significant input sizes for value and policy functions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand their experiments to better evaluate ReBeL\"s performance on complex problems. While it points out a potential weakness, the feedback is vague and does not provide actionable steps for improvement, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that abbreviations like \"MoCo\" should not appear in the section header because a reader might not know what it means. This provides a clear and direct action for the authors to take, which is to avoid using abbreviations in the section header that are not fully explained. The comment is explicit and concrete, giving the authors a straightforward task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of abbreviations like \"MoCo\" in the section header, suggesting that they should be avoided to prevent confusion for the reader. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that abbreviations like \"MoCo\" should not appear in the section header because a reader might not know what it means. This is a logical claim based on common writing practices, as abbreviations can be confusing without proper context or explanation. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning behind the suggestion, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations like \"MoCo\" in the section header, noting that readers might not be familiar with the abbreviation. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending that abbreviations should be avoided or explained in the header. By addressing this issue, the authors can enhance the clarity and accessibility of their paper for readers. However, the comment could be more helpful if it provided examples of how to explain the abbreviation or suggested alternative phrasing. Overall, the comment is 4 as it guides the authors in improving the clarity of their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any explicit or implicit actions for the authors to take to clarify the technical contribution or address the standard nature of the analysis. The comment lacks guidance on how to improve the technical contribution or what specific aspects need to be clarified. As a result, the authors are left without a clear understanding of what changes or additions are necessary to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is unclear or where the standard analysis is located. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific in its critique of the technical contribution and the standard nature of the analysis, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors are left without guidance on how to address the issue or improve their technical contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s technical contribution, noting that most of the analysis is standard. This feedback is valuable as it highlights a potential weakness in the paper\"s originality and innovation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide explicit guidance on how the authors should strengthen their claims or what specific evidence or arguments are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in identifying the need for more substantial evidence or arguments to establish this as a significant contribution, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment lacks specificity and does not provide detailed guidance on what constitutes \"more substantial evidence\" or how the authors might strengthen their claims. While it highlights an area for improvement, it does not offer actionable steps or suggestions for the authors to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not provide specific guidance or suggestions on how the authors might address these concerns or enhance the novelty of their work. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. As a result, the feedback is 1.", "grounding_specificity_rationale": "The comment critiques the improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is not specific about what aspects of the paper need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. While it identifies a potential issue with the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is vague and does not provide actionable steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on the theoretical guarantee, but the comment lacks concrete details or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the theoretical guarantee as a missing element, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location where this discussion should be added. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a critical aspect that should be addressed in the paper, as it provides a theoretical foundation for the hierarchical strategy. However, the comment does not offer any suggestions or guidance on how the authors might address this issue, such as recommending specific references or methods to include in the discussion. While it highlights an important gap, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant area for improvement but does not provide detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of quantitative measures to evaluate the generated VCEs, noting that the evaluation is primarily based on visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to introduce quantitative measures or suggest specific metrics to use. The action is implicit, as the authors can infer that they need to incorporate quantitative evaluation methods, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a general issue with the paper, specifically the lack of quantitative measures to evaluate the generated VCEs. However, it does not specify which part of the paper this issue is related to, such as the methodology section or the results section. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in identifying the need for quantitative evaluation, but it lacks grounding as it does not specify where in the paper this issue is present. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of the generated VCEs is primarily based on visual inspection, lacking quantitative measures. This claim is 3 as it highlights a specific area of concern, but it lacks detailed examples or references to support the assertion that quantitative measures are necessary. The comment suggests that the authors should consider incorporating quantitative measures, but it does not provide specific guidance or examples of what those measures might be. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation process, specifically the lack of quantitative measures to assess the generated VCEs. It points out that the evaluation is primarily based on visual inspection, which is subjective and may not provide a comprehensive understanding of the results. This feedback is valuable as it highlights an area that could be improved to enhance the rigor and objectivity of the evaluation. However, the comment could be more helpful if it suggested specific quantitative measures or metrics that could be used to address this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While the comment points out a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their performance claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not specify which part of the paper this observation is based on, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not significant. The reviewer provides a logical reasoning by comparing the improvements to the error bars, which supports the claim. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is clear, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range. It highlights that the error range is high, suggesting that the performance differences between methods are not very significant. This feedback is 3 as it points out a critical area for improvement, namely the need to clarify or justify the performance claims. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their results. To be more helpful, the comment could provide additional context or examples to support the claim or offer actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights issues with the generated videos, noting significant artifacts and a belowaverage action recognition performance compared to the stateoftheart on the UCF dataset. It also mentions the use of more complex architectures in the stateoftheart. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the performance. The authors are left without clear actions to take, such as identifying the root cause of the artifacts or proposing ways to enhance the action recognition performance. As a result, the comment lacks actionable content, making it 1.", "grounding_specificity_rationale": "The comment addresses the issue of significant artifacts in the generated videos and the belowaverage action recognition performance compared to the stateoftheart on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the problem areas, such as the artifacts and the performance gap, but lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the stateoftheart on the UCF dataset. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the generated videos, noting that they have significant artifacts and that only some of the beach videos are convincing. It also points out that the action recognition performance is below the stateoftheart on the UCF dataset, which uses more complex architectures. However, the comment lacks actionable feedback or suggestions on how to address these issues or improve the performance. While it identifies a critical area for improvement, it does not provide specific guidance or steps for the authors to take, making it 2. The authors are left with a general understanding of the problem but without clear direction on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, and it questions how to select representative images. While the comment identifies a specific area of improvement, it does not provide explicit guidance or suggestions on how to achieve this diversity or representativeness. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of the evaluation set, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3, as it points out a specific area for improvement but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the issue of making the new proposed evaluation set more diverse and representative than the previous method, specifically questioning how to select representative images. However, it does not specify which part of the paper discusses the evaluation set or the selection of images, making it weakly grounded. The comment is specific in its request for guidance on how to improve the diversity and representativeness of the evaluation set, but without explicit references to sections or figures, it is challenging for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the diversity and representativeness of the new proposed evaluation set compared to the previous method, specifically asking how to select representative images. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to improve their draft accordingly. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed evaluation set, questioning its diversity and representativeness compared to the previous method. It highlights a lack of clarity on how to select representative images, which is a critical aspect of evaluating the proposed method. While the comment points out a potential weakness, it does not provide actionable suggestions or guidance on how to address this issue. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of their evaluation set, but the comment lacks detailed advice or examples. Therefore, the feedback is 3, as it directs the authors to an area needing improvement but does not fully support them in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section on the RL framework, specifically mentioning the need to introduce elements such as the MDP, trajectories, and policy. This action is clear and direct, providing the authors with a specific task to improve their draft. Additionally, the comment suggests including a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This further guidance on what needs to be included makes the feedback 5. The authors know exactly what changes are needed to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section on the RL framework and the original DPO algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included in the background section, such as elements of the MDP, trajectories, and policy, as well as the need for a brief overview of the original DPO algorithm. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section on the RL framework and provide an overview of the original DPO algorithm to clarify the context and distinguish the proposed modifications. The claim is supported by logical reasoning, as it highlights the importance of context for understanding the subsequent sections and the need for clarity in distinguishing the modifications. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying specific areas where the paper could be improved. It suggests including a background section on the RL framework to clarify the context and introduce key concepts like the MDP, trajectories, and policy. Additionally, it recommends providing an overview of the original DPO algorithm to distinguish the proposed modifications in the methods section. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and comprehensiveness of their draft. By addressing these suggestions, the authors can significantly improve the readability and understanding of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may encounter issues if users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggestions for potential solutions. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. However, it does not specify which part of the paper discusses the method or the model capacity, making it weakly grounded. The comment is specific in identifying the issue of limited capacity and its potential impact on the method, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation if users continuously add new languages due to limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. This is a valid concern that the authors should consider. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or improve the method\"s scalability. Without specific recommendations or examples, the feedback is 3 as it points out an area for potential improvement but does not provide the authors with a clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify this point, provide additional context, or address the relevance of the term in their work. Without any actionable advice or direction, the authors are left without a clear understanding of how to respond to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim, providing a clear direction for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this concern or improve their draft. The comment lacks actionable advice or specific recommendations, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it highlights a potential issue but does not offer actionable feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their experiments. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not specify which part of the paper discusses the experiments or where this limitation is most apparent. The authors may infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in identifying the limitation but lacks grounding, as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset, suggesting that the scope of the study is narrow. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, noting that they are limited to MNIST and a single realworld dataset. This feedback is valuable as it highlights an area where the authors could expand their work to make it more comprehensive. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve their experiments. While it points out a potential weakness, it does not provide actionable advice or examples of how to overcome this limitation. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. It suggests that the kernel height/width remaining the same would result in more parameters. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length, but it requests more details on the parameters. While the comment identifies a potential issue and suggests an area for improvement, it does not provide explicit guidance on how to address this concern or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that more details on parameters are expected, but they may not know exactly what information is required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters not changing despite the increase in depth, and it suggests that the kernel height/width remaining the same would result in more parameters. The comment also points out the need for more details on parameters and acknowledges the potential for efficiency improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. It suggests that if the kernel height/width remains the same, the depth would increase, leading to more parameters. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length but requests more details on the parameters. While the comment identifies a potential issue and suggests an area for improvement, it lacks specific examples or references to support the claim about the number of parameters. The reasoning is logical, but the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the S2D structure, questioning why the number of parameters does not change despite the increase in depth. It suggests that if the kernel height/width remains the same, the depth would increase, resulting in more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length but requests more details on the parameters. This feedback is clear and actionable, as it identifies a potential area for improvement and provides a specific suggestion for further exploration. However, it could be more helpful if it offered additional guidance or examples on how to address the issue. Overall, the comment is 4 as it directs the authors\" attention to a specific aspect that needs clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the proposed method and another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It questions why [10] cannot use these side information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their method. The action is implicit and vague, as the authors are left to infer that they should explore the possibility of incorporating these features into their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions a specific reference, [10], which suggests a comparison with another approach. However, it does not specify which part of the paper this comparison is relevant to, making it weakly grounded. The comment is specific in questioning why the method in [10] cannot use certain side information, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is similar in spirit to another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, the comment lacks specific reasoning or evidence to support why this is the case, such as detailed comparisons or examples. The claim is 3 as it points out a potential similarity but does not provide enough detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a similarity between the proposed method and another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It questions why [10] cannot use these side information, implying that the authors should consider this aspect in their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their method. While it identifies a potential area for enhancement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. It suggests that this makes it difficult to interpret the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, analyze them differently, or provide additional context. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game results are limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. This observation is relevant as it highlights a potential weakness in the paper\"s evaluation methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the interpretation of the results. While it points out an area for improvement, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general understanding of the issue but without clear steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It suggests that this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest alternative approaches to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider adding a sparsity constraint, but the comment does not offer concrete steps or examples on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. It provides a clear explanation of how this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not explicitly mention which part of the paper discusses the proposed method or the sparsity constraint, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not clearly specified. The comment is specific in detailing the issue with the lack of a sparsity constraint and its potential impact, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increasing number of factors and increased computation with more tasks. The comment provides a logical reasoning based on the comparison with a factorized model with an IBP prior, suggesting that the proposed method might not be incentivized to use fewer factors. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the implications of this lack of sparsity constraint on the model\"s performance and computational efficiency. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It explains that this could lead to an increasing number of factors and increased computation with more tasks. While the comment highlights a relevant concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the model\"s efficiency. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, leaving the authors with a general insight but no clear path for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. While the comment explicitly states what needs to be addressed, it does not provide detailed guidance on how to reiterate this point or what specific aspects should be emphasized. The action is clear but somewhat vague, as it lacks concrete steps on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, which is the lack of comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not favorable to the authors because they do not comment on why the GPC (benchmark) performs better than BPC (their method). The reviewer suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. While the comment identifies a potential issue with the presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to reiterate the reasons for the performance difference is a logical step, but the comment could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a specific area for improvement and offers a clear direction for the authors to enhance their explanation. By addressing this point, the authors can better clarify their results and improve the clarity of their presentation. Therefore, the comment is rated as 5, as it effectively guides the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is explicit and provides a clear action for the authors to take, which is to quantify and clarify the claim. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying a claim about ReLUs not working well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides full grounding as it explicitly mentions the AlexNet paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, quantifying and clarifying the claim about ReLUs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides a logical basis for the claim, as it references a wellknown paper and its practices. However, the comment could be strengthened by including specific references or data to further substantiate the claim. Therefore, the comment is 4, as it offers a clear rationale but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim about ReLUs not working well in very deep or convolutional networks would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to support their claim. By doing so, the authors can enhance the clarity and substantiation of their argument, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores. It explicitly asks the authors to clarify how perplexity was calculated. This direct request for clarification provides a clear and concrete action for the authors to take, allowing them to address the discrepancy and provide a detailed explanation of their methodology. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the reported perplexities being over 30 and the better BLEU scores, prompting the authors to clarify how perplexity was calculated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores. The reviewer asks for clarification on how perplexity was calculated. While the comment highlights a discrepancy, it does not provide specific reasoning or evidence to support the claim that the perplexity is too high or how it contradicts the BLEU scores. The request for clarification is logical and reasonable, but without additional context or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the reported perplexities in Figure 1, which are over 30, and the better BLEU scores. It raises a question about how perplexity was calculated, suggesting that the high perplexity contradicts the better scores. This feedback is 3 as it points out a potential issue that the authors should address, but it lacks depth and does not provide specific guidance on how to resolve the discrepancy or improve the calculation of perplexity. The authors are left with a general understanding of the problem but without detailed steps on how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, as it specifies what additional experiments are required to improve the evaluation. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include additional experiments, but without grounding, the authors may struggle to identify the exact sections that need to be addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section, suggesting that experiments on distributed deployment and a larger model are needed. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work. By addressing these suggestions, the authors can strengthen their evaluation and potentially improve the robustness and generalizability of their findings. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct these experiments. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be addressed and offers a concrete suggestion on how to implement it, ensuring the authors know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns\" and references the concept of \"orbit counting in GSN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of explanation regarding why rooted patterns are important and how they are chosen. Additionally, it suggests that a brief discussion should be included in the main text or, alternatively, in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. The comment suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a brief discussion on why rooted patterns are important and how they are chosen. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and depth of their work. By addressing this suggestion, the authors can better explain the significance of rooted patterns and improve the comprehensibility of their approach. However, the comment could be more helpful if it provided additional context or examples to further support the importance of rooted patterns. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more explanations regarding the consistency between training and inference, which is mentioned in the paper. However, it does not specify what aspects of the explanations are lacking or how the authors should expand on this topic. The action is implicit and somewhat vague, as the authors need to infer the exact details of what needs to be added or clarified. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) in the paper where the authors discuss the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the need for more explanations regarding the consistency between training and inference, particularly due to the smoothness of neural models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanations regarding the consistency between training and inference, particularly due to the smoothness of neural models. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, particularly due to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to provide additional context or elaboration on this topic. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of explanations would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the authors\" claim of achieving superior performance with significantly fewer parameters. It suggests that the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The reviewer asks for improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear and concrete action for the authors to take. This feedback is explicit and actionable, as it guides the authors on how to strengthen their claim by demonstrating improvements with larger parameter sizes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding their model\"s performance and parameter efficiency. It questions the basis of the claim by suggesting that the authors in [1] might have tested their model with standard parameter settings. The reviewer asks for improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear direction for the authors to address. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed regarding the claim of superior performance with fewer parameters. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the authors\" claim of achieving superior performance with significantly fewer parameters compared to a baseline. It questions whether the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The reviewer asks for improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear direction for the authors to address the concern. However, the comment lacks specific examples or references to support the claim that the authors in [1] tested with standard parameter settings, making it 3. The authors would need to provide additional evidence or context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim of achieving superior performance with significantly fewer parameters compared to a baseline. It questions whether the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The reviewer suggests that the authors should demonstrate improvements when the proposed model uses larger word embeddings and LSTM parameters. This feedback is clear and actionable, as it provides a specific direction for the authors to strengthen their claim by showing improvements with larger parameter sizes. However, the comment could be more helpful if it included specific suggestions or examples of how to demonstrate these improvements. Overall, the comment is 4 as it guides the authors on how to substantiate their claim, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue with the hyperparameters, it does not provide explicit guidance on how to address this problem or suggest specific actions to take. The authors are left to infer that they need to consider the availability of the environment or a good OPE method for finetuning, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance.", "grounding_specificity_rationale": "The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that this issue is related to the experimental setup or methodology, but the comment lacks explicit grounding. It is specific in identifying the need for finetuning and the potential dependencies, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method for this finetuning. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out a potential weakness, it does not provide actionable steps or detailed feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the regularization approach used for the LN model compared to previous models, such as the GLM by Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment does not provide specific guidance on how to reproduce these features or what aspects of the previous models need to be replicated. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization approach used in the LN model and compares it to previous models, specifically mentioning the GLM by Pillow et al. This provides some grounding as it refers to a specific model and comparison, but it does not explicitly mention which part of the paper this discussion is in, making it weakly grounded. The comment is specific in detailing the discrepancy in regularization methods and suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the regularization approach used in the LN model compared to previous models, such as the GLM by Pillow et al. The reviewer notes that the LN model needed regularization but then applies regularization in the form of a cropped stimulus to both LN models and GLMs. The reviewer suggests that the comparison is not fair because the GLM did not crop the image but used L1 regularization for the filters and a lowrank approximation for the spatial filter. The comment provides a logical reasoning for the need to make the comparison fair by reproducing the main features of previous models. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the regularization approach used for the LN model compared to previous models, such as the GLM by Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. This feedback is 3 as it points out a potential issue with the methodology and encourages the authors to ensure a fair comparison. However, the comment could be more helpful if it provided specific guidance on how to reproduce the main features of previous models or detailed examples of what these features might be. Overall, the comment offers a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including some failure cases and related discussion would be beneficial. However, it does not provide explicit guidance on which specific failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add failure cases and discuss them, but the comment does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this feedback pertains to. The authors may have an idea of where this discussion could be integrated, but the comment lacks explicit references to specific sections, figures, or tables. Additionally, the comment does not provide detailed guidance on what specific failure cases should be discussed or how they should be integrated into the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including some failure cases and related discussion would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this would be important or how it could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including some failure cases and related discussion would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific failure cases should be discussed or how they could be integrated into the paper. This limits the usefulness of the feedback, as it does not offer actionable steps for the authors to take. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. While the comment implies that an ablation study would be beneficial, it does not explicitly instruct the authors to perform the study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to clarify its necessity. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in its request for an ablation study to address the question, providing clear guidance on what needs to be done. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this encoding is unclear or unnecessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct the ablation study or what aspects to focus on. The feedback is 3 as it points out a potential weakness in the methodology but does not provide detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the variable \u03b5 should be introduced when discussing equation (11) in Section 4.1, as it is not used in equation (10). This provides a clear and direct action for the authors to take, which is to introduce \u03b5 in the appropriate section. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the use of \u03b5 in equations (10) and (11), suggesting that introducing \u03b5 when discussing equation (11) might improve clarity. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the variable \u03b5 is not used in equation (10) but is used in equation (11). It proposes that introducing \u03b5 when discussing equation (11) might improve clarity. While the comment identifies a potential issue with the use of \u03b5, it lacks specific reasoning or examples to fully substantiate the claim. The suggestion to introduce \u03b5 is a logical one, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the variable \u03b5 in equations (10) and (11) in Section 4.1. It suggests that introducing \u03b5 when discussing equation (11) might improve clarity. This feedback is clear and actionable, as it provides a specific recommendation for enhancing the clarity of the text. By addressing this suggestion, the authors can improve the readability and understanding of their work. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes.\" This provides a clear and direct action for the authors to take, specifying what needs to be added or elaborated upon. The comment also suggests a specific area for improvement, namely the computational complexity of counting homomorphisms, which is not adequately discussed in the current draft. This feedback is concrete and actionable, allowing the authors to understand exactly what changes are needed to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, despite making brief statements about it. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The suggestion to add upper bounds and empirical runtimes provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a more detailed discussion of the computational complexity of counting homomorphisms. It highlights that the current discussion is brief and suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs further development. By addressing this suggestion, the authors can enhance the depth and comprehensiveness of their paper. However, the comment could be more helpful if it provided additional context or examples to support the need for this improvement. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It identifies specific errors in the text, such as correcting the letter \"f\" to \"g\" in line 108 and removing the extra period in line 115. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question implies that the authors should provide more details or evidence to support their claim of convergence. The feedback is clear and actionable, guiding the authors on what specific corrections and clarifications are needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (line 108 and line 115), allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as correcting the letter \"f\" to \"g\" and removing the extra period, providing clear guidance on what needs to be revised. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured convergence of the networks. This question adds specificity to the feedback, as it prompts the authors to provide more detailed information about their methodology. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts: a correction of a typographical error, a suggestion for removing an extra period, and a question about the convergence of networks in the baseline MCL with deep learning. The first two parts are factual statements that do not require verification. The third part is a question seeking clarification, which does not contain a claim or suggestion that requires verification. Therefore, the overall comment is composed of factual statements and a question, making it \"No.\"", "helpfulness_rationale": "The review comment is 4 as it provides specific and actionable feedback. It identifies two typographical errors in the text, which are corrected by suggesting the replacement of \"f\" with \"g\" and removing the extra period. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question prompts the authors to provide more detailed information or evidence regarding the convergence of their networks, which is a critical aspect of their methodology. While the comment does not fully address the question about convergence, it still offers valuable insights and guidance for improvement. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. While the action is explicit, it does not provide specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are aware of what needs to be done but may need to infer the details of implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. The authors can infer that it relates to the methodology or results section, but this inference is not explicit. The comment is specific in its suggestion to include a study of inference time, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The suggestion is based on a general observation about the relevance of inference time in the context of pose estimation methods, but without detailed justification or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are aware of the suggestion but may need to infer the details of implementation. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific questions about the Theorem A.3 proof. The first question asks how the input x has two indices when it is a vector, not a matrix. The second question questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. These questions are explicit and provide clear guidance on what the authors need to address in their draft. The authors are directed to revisit the proof and clarify the notation and equation, which is a concrete action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the notation and equation in the proof, providing clear guidance on what needs to be addressed. The authors can confidently determine the section being discussed and understand what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions regarding the Theorem A.3 proof. The first question addresses the notation of the input x, questioning whether it should be a vector or a matrix. The second question challenges the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. These questions are based on logical reasoning and common knowledge of mathematical notation and equations, providing a clear basis for the claims. However, the comment could be strengthened by providing specific references or examples to support the suggested corrections. Therefore, the comment is 4, as it provides a strong foundation for the claims but lacks full detail in its justification.", "helpfulness_rationale": "The review comment identifies two specific issues in the Theorem A.3 proof. It questions the notation of the input x, pointing out that it should be a vector, not a matrix, and challenges the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. This feedback is clear and actionable, as it provides the authors with specific points to address in their draft, namely, correcting the notation and equation. By addressing these issues, the authors can improve the clarity and accuracy of their proof. Therefore, the comment is 5, as it guides the authors in making significant improvements to their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the accuracy of the results and the reliability of the entities and relationships plugged in, particularly in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and highlights the need for clarification regarding the percentage of correct entities/relationships. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to improve the clarity or accuracy of their results. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the concerns regarding the accuracy of results and the reliability of entities and relationships plugged in, particularly in light of the 77% result list containing the ground truth logical forms. The comment provides a clear direction for the authors to address these issues, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the accuracy of results and the reliability of entities and relationships plugged in, particularly in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and highlights the need for clarification regarding the percentage of correct entities/relationships. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are not as accurate as claimed. The authors are left to infer the nature of the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific concerns regarding the accuracy and reliability of results in sections 4.3 and 4.4. It questions the use of terms like \"somewhat\" and \"good generative ability\" and highlights a potential issue with the accuracy of the results, particularly regarding the percentage of correct entities and relationships. The comment provides a clear direction for the authors to address these concerns by seeking clarification or providing more detailed explanations. However, it could be more helpful if it suggested specific ways to improve the clarity or accuracy of the results. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim regarding evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicitly mentioned. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but without explicit grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. The reviewer provides a comparison with Batch Normalization, which standardizes the variance and centers the activation. This comparison offers some logical reasoning to support the claim, but it lacks specific examples or references to external works that could further substantiate the argument. The claim is 3, as it provides a basis for the critique but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and points out its limitations, suggesting that it only increases the variance of lowvariance units. It also compares this with Batch Normalization, which standardizes the variance and centers the activation. The comment highlights the need for explicit discussion of these limitations, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be emphasized. Overall, the comment is 4 as it directs the authors\" attention to an important area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the reliance of FedPCL on the selection of pretrained models, which limits its applications. It also notes that the model accuracy is sensitive to these models. However, the comment does not provide specific guidance or suggestions on how the authors might address this limitation or improve the applicability of their framework. While it acknowledges the authors\" efforts to develop a lightweight federated learning framework and integrate pretrained models, it lacks actionable advice on how to enhance the framework or expand its applicability. As a result, the authors are left without clear direction on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the reliance of FedPCL on pretrained models and the sensitivity of model accuracy to these models, as demonstrated in Table 4. It also mentions the authors\" efforts to develop a lightweight federated learning framework and integrate pretrained models for federated aggregation. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the discussion of pretrained models and their impact on performance, but the lack of specific section references makes it challenging to pinpoint. The comment is specific in detailing the issue of model sensitivity and the authors\" efforts to address it, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of FedPCL is heavily reliant on the selection of pretrained models, limiting its applications to more widespread areas. It also notes that the model accuracy is sensitive to the pretrained models, as demonstrated in Table 4. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The mention of \"adequately addressed\" suggests that the authors have made efforts to mitigate this limitation, but without further elaboration, the comment remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of FedPCL, which is heavily reliant on the selection of pretrained models, limiting its applicability to broader areas. It also notes that the model accuracy is sensitive to these models, as demonstrated in Table 4. The comment acknowledges the authors\" efforts to develop a lightweight federated learning framework to reduce computation and communication costs and integrate pretrained models for federated aggregation. However, the comment lacks specific suggestions or actionable advice on how the authors might address this limitation or expand the applicability of their framework. While it highlights an important issue, the feedback could be more helpful if it provided concrete steps or examples for improvement. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to include the tentative attention maps in the qualitative figures, in addition to the retrieved and final attentions. While the comment implies that the authors should consider including these maps, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include the tentative attention maps, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which is a specific suggestion for improvement. However, it does not specify which figures or sections of the paper should include these maps, making it weakly grounded. The authors can infer that the suggestion pertains to the qualitative figures, but the lack of explicit reference to specific parts of the paper limits the grounding. The comment is specific in its suggestion to include tentative attention maps, but the lack of grounding makes it challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include tentative attention maps in the qualitative figures, but it does not provide any justification or reasoning for why this would be beneficial or how it would enhance the paper. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. Without additional context or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include tentative attention maps in the qualitative figures, in addition to the retrieved and final attentions. This feedback is 3 as it provides a specific suggestion for enhancing the qualitative figures, which could potentially improve the paper\"s clarity and understanding of the attention mechanism. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of the tentative attention maps should be included. To be more helpful, the comment could provide examples of how tentative attention maps could be incorporated or what specific insights they might offer. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution should be described or how to enhance the description. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the contribution without being given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper, but it does not specify which part of the paper this contribution is discussed in or what aspects of the contribution need more description. This lack of specificity makes it difficult for the authors to identify the exact sections that require additional detail. The comment is 1 because it does not provide specific references or details about the contribution, leaving the authors without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution need more detail or how to enhance the description. This lack of specificity and actionable advice limits the usefulness of the comment for the authors. Without detailed feedback or examples, the authors may struggle to understand how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of minor comments and suggestions for improvement. It explicitly suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide specific guidance on how the authors can improve their draft. The comments are explicit and concrete, allowing the authors to directly address each point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses several minor points, including suggestions for organizing the main contributions, describing the layerwise attention mechanism, and referencing normalization or feature scaling. However, it does not specify which sections or parts of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its suggestions, providing clear guidance on how to improve the organization and clarity of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, such as recommending the separation of contributions and the description of attention mechanisms. These suggestions are based on logical reasoning and common sense, as they aim to enhance the structure and flow of the paper. However, the comment lacks specific examples or references to support the suggestions, making it 3. The authors would need to infer the exact changes needed to address these suggestions, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a list of minor suggestions for improving the organization and clarity of the paper. It suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and actionable, offering the authors specific ways to enhance the structure and presentation of their work. However, the comment could be more helpful if it provided examples or further guidance on how to implement these suggestions effectively. Overall, the feedback is 4 as it directs the authors towards improvements that can significantly enhance the clarity and organization of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue or what specific changes need to be made. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that either the reviewer does not understand the figure or that the labels are incorrect. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not contain any claims, opinions, or suggestions that require verification. Instead, it presents a factual observation about the figure, which is descriptive and does not require evidence or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, either stating that the reviewer does not understand it or that the labels are incorrect. This feedback is clear and actionable, as it highlights a potential area of confusion or error that the authors need to address. By pointing out this issue, the reviewer provides the authors with a clear direction for improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to clarify the figure or correct the labels. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It further recommends including such baselines to provide a comparison with selfsupervised methods. This feedback is clear and direct, providing the authors with a specific action to take: adding supervised baselines to their experiments. The comment also offers a rationale for why this addition would be beneficial, making it 5. The authors know exactly what needs to be done to improve their draft, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supervised baselines\" and \"datasets of scale ~100k images,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests the inclusion of supervised baselines to provide a comparison with selfsupervised methods, which is a clear and actionable recommendation. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests that the absence of supervised baselines is a significant oversight, especially considering the scale of the datasets used in the experiments. The reviewer provides a logical reasoning by noting that datasets of scale ~100k images are reasonable to assume full annotation in practice, and even if not, it would be informative to include such baselines for comparison. This reasoning is clear and supported by common knowledge about dataset sizes and annotation practices, making the claim 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have included supervised baselines for comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a logical rationale for why the inclusion of such baselines is important, especially considering the scale of the datasets used. By suggesting that full annotation is reasonable for datasets of this scale and offering the inclusion of supervised baselines as an informative baseline, the comment offers clear and actionable feedback. This guidance empowers the authors to enhance their draft by providing a more comprehensive comparison of their selfsupervised methods against supervised baselines. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the minimal performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It also references a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly instruct the authors to address these issues or suggest specific actions to improve their work. The feedback is somewhat vague, as it does not provide detailed guidance on how to resolve the identified problems or enhance the paper\"s performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It references a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or discussion, but this inference is not precise. The comment is specific in detailing the issue with the performance differences and suggesting a potential solution, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal and suggests that the benchmarks are outdated and likely saturated. It provides a reference to a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which could offer a potential solution. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the minimal performance differences and the saturation of the benchmarks. While the reference provides a potential direction for improvement, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the performance differences between methods, noting that they are minimal across evaluations, often less than 1 percentage point. It also points out that the benchmarks used may be outdated and likely saturated, suggesting that the results may be influenced by random variation. The comment provides a reference to a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which could offer a potential solution. This feedback is valuable as it highlights a critical area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on how to address the identified issues or how to incorporate the referenced paper\"s findings. Overall, the comment is 4, as it provides actionable insights but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics to assess its empirical efficacy. Second, it questions why BEAR is missing from the baselines. While the comment identifies areas for improvement and suggests additional evaluations, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should consider evaluating the method on nondeterministic domains and include BEAR in the baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics to assess its empirical efficacy. Second, it questions why BEAR is missing from the baselines. While the comment does not explicitly mention specific parts of the paper, it is clear that it pertains to the discussion or results section where the method\"s performance is evaluated. The authors can infer that it relates to the experimental setup and results, but the comment lacks explicit references to specific sections or figures. The questions are specific in nature, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics to assess its empirical efficacy. Second, it asks why BEAR is missing from the baselines. The comment does not provide specific reasoning or evidence to support these claims, making it difficult for the authors to understand the basis of the questions. The lack of detailed justification or references leaves the authors without a clear path to address the concerns. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two important questions that could help the authors improve their draft. First, it questions the relevance of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This feedback encourages the authors to broaden their experimental scope and consider the applicability of their method in more complex environments. Second, the comment questions the absence of BEAR as a baseline, which could provide a more comprehensive comparison. By addressing these points, the authors can gain a deeper understanding of their method\"s strengths and limitations, leading to a more robust evaluation. However, the comment could be more helpful if it provided specific suggestions on how to evaluate the method on nondeterministic domains or why BEAR was excluded from the baselines. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. While the comment implies that these techniques are important for performance, it does not explicitly instruct the authors to include this justification. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. However, the comment does not provide specific guidance on how to structure this justification or what aspects to focus on. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its request for a theoretical justification, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed explanation or evidence to substantiate the need for a theoretical justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. This is a valuable suggestion as it highlights the importance of understanding the underlying principles of the techniques used in the study. However, the comment lacks specificity and does not provide detailed guidance on how to develop this justification or what aspects of the theoretical framework should be emphasized. While it identifies a potential area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it points out a relevant area for enhancement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in section 4, the term \"X\" should be a multiset instead of a set, as it is currently defined. The reviewer provides a rationale for this suggestion, explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent the graph with repeated vertex or edge labels. This feedback is explicit and provides a clear action for the authors to take, which is to revise the definition of \"X\" to reflect a multiset. The suggestion is concrete, as it specifies the change needed and its rationale, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current definition of \"X,\" suggesting that it should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a rationale for this suggestion, making the comment detailed and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that in section 4, the term \"X\" should be a multiset instead of a set, as it is currently defined. The reviewer provides a rationale for this claim by explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent graphs with repeated vertex or edge labels. This explanation is logical and provides a clear reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of \"X\" in section 4, suggesting that it should be a multiset rather than a set. The reviewer provides a rationale for this suggestion, explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and actionable, as it guides the authors to make a specific change to improve the accuracy and clarity of their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or if it pointed out other potential issues in the section. Overall, the comment is 4, as it provides valuable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" derivation, stating that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, stating that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this critique pertains to, such as a specific section or equation. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the derivation\"s reliance on classical learning theorybased bounds, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides a rationale by stating that Bayesian considerations are necessary for realistic bounds. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" derivation, stating that it relies on classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback highlights a potential limitation in the authors\" approach and suggests that incorporating Bayesian considerations could improve the validity of the bounds. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details should be included, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that more information is needed, but it lacks concrete guidance on how to present this information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for additional information about the method, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these details are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that more details about the proposed method should be presented. It highlights the need for clarification on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides the authors with a specific direction for enhancing the clarity and depth of their method description. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have addressed similar issues. Overall, the comment is 4 as it guides the authors towards improving their draft by providing a clear direction for additional detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, such as the example \"introduce a sports celebrity to me.\" It suggests that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. While the comment identifies a potential weakness, it does not provide explicit guidance on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example \"introduce a sports celebrity to me.\" This provides some grounding as it refers to a specific type of response that could pose a challenge. However, it does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the challenge of identifying shared information for consistency checking in openended responses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, such as the example \"introduce a sports celebrity to me.\" The comment provides a specific example to illustrate the challenge, which helps to ground the claim. However, it lacks detailed reasoning or evidence to fully substantiate the claim, such as explaining why this particular example is particularly challenging or how the method might fail in such cases. While the example provides some context, the lack of detailed reasoning or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides a specific example, \"introduce a sports celebrity to me,\" to illustrate the challenge of identifying shared information for consistency checking. This feedback is 3 as it highlights a critical area for improvement and offers a concrete example to consider. However, the comment could be more helpful if it suggested ways to address this issue or provided additional context on how to mitigate it. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about the label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to take. It specifies what needs to be verified and where to focus, making the comment 5. The authors know exactly what needs to be done to address the issue, which is to conduct the verification on the specified datasets and models. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the theoretical findings relate to realworld deep learning models and recommends verifying the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper this relates to, making it weakly grounded. The comment is specific in suggesting a verification on MNIST and CNN, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in relation to realworld deep learning models and recommends verifying the conclusion about label noise and model size on MNIST and CNN. However, the comment does not provide specific reasoning or evidence to support why these findings are unclear or how the verification would clarify the relationship. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a key area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors should verify their conclusions about label noise and model size on specific datasets like MNIST and CNN. This feedback is clear and actionable, providing a specific direction for the authors to improve their work by conducting additional verifications. However, the comment could be more helpful if it included more detailed guidance on how to conduct these verifications or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part acknowledges the paper\"s good organization and writing, which is not actionable. The second part identifies specific weaknesses and suggestions for improvement. It suggests drawing a table to compare different CoT prompting methods across dimensions and questions the assumption about \"questions of all the wrong demonstrations fall into the same frequenterror cluster.\" It also questions the selection criteria in section 4.2 and asks why certain questions and rationales are chosen. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these suggestions. The authors are left to infer the actions needed to address these points, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.2\" and \"questions with more than 60 tokens and rationales with more than 5 reasoning steps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the writing, suggesting the inclusion of a table to compare CoT prompting methods and questioning the assumptions and selection criteria in section 4.2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a subjective opinion that the writing is good and most of the content is clear, which does not require verification. The second part, however, raises specific questions and concerns about the writing, such as the need for a table to compare CoT prompting methods and the assumption about \"questions of all the wrong demonstrations.\" These questions are logical and require further explanation or justification, but they do not constitute a claim in the traditional sense. Therefore, the comment is 4, as it provides some support for the questions but lacks detailed reasoning or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\"s good organization and writing, which is a positive aspect. However, it also identifies specific areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across dimensions. Additionally, the comment questions the assumptions made about \"questions of all the wrong demonstrations\" and the selection criteria in section 4.2. While the comment highlights potential weaknesses, it does not offer detailed guidance on how to address these issues or improve the paper. The feedback is 3 as it provides some insight into areas that need attention but lacks comprehensive suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that p(y|Hf\u2010(tn)) must be chosen Gaussian for Kalman Filtering and Smoothing and CVI to be possible. It also notes that this assumption is made later in the ELBOs. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest any specific changes to their draft. The action is implicit and vague, as the authors are left to infer that they need to ensure the Gaussian assumption is made clear and consistent throughout the paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific technical aspect of the paper, namely the assumption that p(y|Hf\u2010(tn)) must be chosen Gaussian for certain methods to be applicable. It also notes that this assumption is made later in the ELBOs. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the technical requirement and its implications, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that p(y|Hf\u2010(tn)) must be chosen Gaussian for Kalman Filtering and Smoothing and CVI to be possible. It also notes that this assumption is made later in the ELBOs. While the comment provides a logical reasoning for the necessity of the Gaussian assumption, it lacks specific references or examples to fully substantiate the claim. The authors may find it challenging to fully understand and address the issue without additional context or detailed explanation. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific technical requirement for the Gaussian assumption of p(y|Hf\u2010(tn)) for the application of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is made later in the ELBOs. While the comment highlights an important aspect of the methodology, it lacks depth and does not provide actionable guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential limitation, but it does not offer detailed suggestions or examples on how to implement the Gaussian assumption or where it should be addressed in the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it 1. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. The comment points out that cosine similarities for such large weight decay strengths are not reported, and the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is 3 as it highlights a specific area where the authors might need to address or clarify their results. However, the comment lacks detailed guidance on how the authors should investigate or resolve this issue, such as suggesting specific experiments or analyses to conduct. While it provides a starting point for the authors to consider, the feedback could be more comprehensive and actionable to be rated as 5. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. It suggests that this issue must be fixed for publication. The reviewer acknowledges that they did not have time to review the supplementary material due to the constraints of the review process, but emphasizes the importance of addressing this issue. The comment provides a clear and direct action for the authors to take, which is to ensure that the title, abstract, introduction, and discussion accurately reflect the unsupervised nature of the random forests results. This guidance is explicit and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation regarding the unsupervised nature of the random forests results. The comment further emphasizes the importance of addressing this issue for publication and provides a rationale for why it is a serious omission. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The reviewer provides a rationale for why this is important, stating that casual readers might remember the wrong conclusions if this information is not included. The comment also acknowledges that the reviewer did not have time to review the supplementary material due to the constraints of the review process, which adds context to the concern. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the omission and its potential impact on readers. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the title, abstract, introduction, and discussion sections of the paper, specifically noting that they do not explain that the results are for unsupervised random forests. This is a critical omission that could lead to misinterpretation by readers. The reviewer emphasizes the importance of addressing this issue for publication, as it could affect the credibility of the results. While the comment highlights a clear area for improvement, it does not provide specific suggestions or guidance on how to correct this issue. The authors are left with a general understanding of the problem but without detailed steps on how to resolve it. Therefore, the comment is 3, as it points out a significant weakness but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests that qualitative experiments should be conducted to demonstrate the validity of the conditional independence model, specifically recommending the use of illustrative experimental results to show the superiority of minimizing HSICcondi over minimizing HSIC_HOOD. Additionally, it suggests providing visualization results or schematic diagrams to enhance the understanding of the new test metric. These actions are clear and provide specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lack of qualitative experiments\" and provides specific suggestions for improvement, such as providing illustrative experimental results and visualization results or schematic diagrams. This allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to support the claim that minimizing HSICcondi performs better than minimizing HSIC_HOOD. Additionally, it points out the absence of a correctness test for the new test metric and recommends comparative experiments with other metrics. The comment provides specific suggestions for improvement, such as using a toy dataset to demonstrate separability and providing visualization results. However, it lacks detailed examples or references to support the claim about the superiority of HSICcondi over HSIC_HOOD, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting that illustrative experimental results could be provided to support the claim that minimizing HSICcondi performs better than minimizing HSIC_HOOD. This feedback is actionable and provides a clear direction for the authors to enhance their work. Second, it notes the absence of a correctness test for the new test metric and recommends comparative experiments with other metrics, along with the suggestion to provide visualization results or schematic diagrams to aid understanding. These suggestions are detailed and constructive, offering the authors a path to improve the clarity and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity with other methods, providing a clear and direct action for the authors to take. The comment also highlights the impracticality of training multiple iterations/epochs with large models and datasets, which adds context to the comparison. This level of specificity and directness makes the comment 5, as it gives the authors a clear path to follow in addressing the issue. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the claim that the proposed method requires much more computation than other methods, suggesting that it is impractical to train multiple iterations/epochs with large models and datasets. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in questioning the computational complexity of the method compared to others, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification or improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It questions whether the method requires much more computation than other methods and suggests comparing the computational complexity with other methods. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the proposed method is computationally more demanding. This lack of detailed evidence or justification makes the claim 3, as the authors would need to conduct further analysis to address the concern fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the computational complexity of the proposed method compared to other methods, suggesting that it may require much more computation than other methods. It also points out the impracticality of training multiple iterations/epochs with large models and datasets. This feedback is 3 as it identifies a potential weakness in the computational efficiency of the proposed method, which could be important for the authors to address. However, the comment lacks specific suggestions or guidance on how to compare computational complexity or improve efficiency, leaving the authors with a general area for improvement. Therefore, the comment is rated as 3, as it provides a direction for the authors to consider but does not fully support them in making actionable improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment explicitly identifies the need for significance testing, it does not provide detailed guidance on how to conduct this testing or which specific tests to use. The authors are left with a clear action to take but without explicit instructions on how to execute it, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of significance testing to support claims of method differences. The comment provides a detailed example of a claim that lacks supporting evidence, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment provides a logical argument for the need for significance testing, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear rationale but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s methodology and provides a specific example of where significance testing is needed. However, the comment could be more helpful if it offered suggestions on how to conduct the significance testing or which specific tests to use. Overall, the comment is 4, as it effectively guides the authors in addressing a significant weakness in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach description in Section 3 is difficult to follow and should be revised. It also suggests that the additional page in the cameraready version should be used to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach description is difficult to follow and suggests using the additional page in the cameraready version to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approach description is difficult to follow and suggests that the additional page in the cameraready version should be used to extend the approach description rather than adding more experiments. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is difficult to follow or how extending the description would improve it. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the additional page in the cameraready version be used to extend the approach description rather than adding more experiments. This feedback is valuable as it guides the authors on how to improve the clarity and depth of their approach description, which is crucial for enhancing the comprehensibility and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to revise the approach description or what additional details should be included. Overall, the comment is 4, as it provides clear direction for improvement but could be expanded for full comprehensiveness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, and the absence of comparison with other stateoftheart methods that might not rely on gyrostructures. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more interpretive insights and compare their methods with a broader range of stateoftheart techniques. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issues with the related discussion, such as the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights into why the proposed gyrostructures outperform existing methods and that the paper lacks comparison with other stateoftheart methods. The comment provides a logical reasoning by suggesting that the absence of such comparisons makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the comparison that should be made, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper\"s experimental section. It points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, suggesting that more detailed explanations are needed. Additionally, the comment notes the absence of comparison with other stateoftheart methods that might not rely on gyrostructures, which could provide a more comprehensive evaluation of the proposed approach. By highlighting these gaps, the comment offers actionable feedback that can help the authors enhance the interpretability and robustness of their results. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues, such as recommending certain methods for comparison or suggesting ways to interpret the results. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. While the comment implies that additional evidence or analysis should be provided, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to include more supporting evidence, but it lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. The authors can infer that it relates to the dataset description or experimental results, but this inference is not explicit. The comment is specific in its request for additional evidence and analysis, but without full grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, the comment does not provide specific examples, references, or detailed reasoning to justify why this is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional supporting evidence or analysis. However, the comment could be more helpful if it offered suggestions on how to gather or present this evidence, such as which specific aspects to focus on or what types of analysis would be beneficial. Overall, the comment is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study only focuses on CATER for Englishcentric datasets and recommends extending CATER to other languages in the future. This feedback is clear and provides specific actions for the authors to take, such as adding more details about the baselines and considering the extension to other languages. The comment is explicit and concrete, offering a direct path for improvement. Therefore, it is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figure is hard to comprehend and suggesting the need for more details about the two baselines presented. Additionally, it points out the limitation of the study, which only focuses on CATER for Englishcentric datasets, and recommends extending CATER to other languages. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study only focuses on CATER for Englishcentric datasets, which is a limitation. The reviewer suggests extending CATER to other languages in the future. While the comment identifies a potential issue with comprehensibility and suggests an area for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to extend CATER to other languages is a logical extension but not explicitly supported by evidence or references. Therefore, the comment is 3, as it provides some reasoning but could benefit from more detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is hard to comprehend and suggesting that the authors provide more details about the two baselines presented. It also points out a limitation of the study, which only focuses on CATER for Englishcentric datasets, and recommends extending CATER to other languages in the future. This feedback is clear and actionable, as it provides specific suggestions for improvement and expansion of the study. By addressing these points, the authors can enhance the comprehensibility and scope of their work. However, the comment could be more helpful if it offered additional guidance on how to present the details or how to extend CATER to other languages. Overall, the comment is 4, as it provides valuable insights and actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review in the paper needs improvement, specifically noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and direct, giving the authors a specific action to take: to enhance the clarity and comparative analysis of the literature review. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and specifies the issue with it, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly outlines what needs to be improved, such as providing a more explicit and comparative analysis of related work. This level of detail helps the authors understand what aspects of the literature review need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and lacks clarity on the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issues and how to address them. This lack of detailed justification or evidence makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It provides a clear and actionable suggestion for improvement, recommending that the paper should provide a more explicit and comparative analysis of related work. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete way to enhance the clarity and impact of their work. However, the comment could be more helpful if it provided examples of how to achieve this improvement or suggested specific references for comparison. Overall, the comment is 4, as it effectively guides the authors towards improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests eliminating section 3.2, stating that readers are presumed to know about the GumbelSoftmax/Concrete distribution. While the comment implies that the section is redundant, it does not provide explicit guidance on how to eliminate it or what to include instead. The action is implicit and somewhat vague, as the authors need to infer that they should remove the section and possibly restructure the paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests eliminating section 3.2, implying that readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper this section is in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion to eliminate the section, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment does not provide any reasoning or evidence to support why this section is redundant or unnecessary. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential redundancy in the paper, it lacks specific guidance or suggestions on how to improve the content or structure of the paper. The comment does not provide any alternative suggestions or detailed reasoning for why this section is unnecessary, leaving the authors with limited actionable feedback. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\"s performance, suggesting that the finetuning without earlystopping may lead to high variances. It implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a potential issue, it does not explicitly instruct the authors to conduct ablation studies or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the potential regularization effects influencing the improvements observed in the teacher\"s performance. It explicitly mentions the case where the student distills knowledge to the teacher, which is a clear reference to a specific part of the paper. The comment is specific in detailing the concern about the potential regularization effects and suggests the need for proper ablation studies to verify the distillation effect. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\"s performance, suggesting that the finetuning without earlystopping may lead to high variances. The reviewer provides a logical reasoning by pointing out that the finetuning on GLUE without validation earlystopping usually has very high variances. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to conduct further analysis or experiments to fully address the concern, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the interpretation of the results, suggesting that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation. It points out that the finetuning is performed for 10 epochs without earlystopping, which could lead to high variances. The comment implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a critical area for further investigation, it does not provide specific guidance or suggestions on how to conduct these studies or what aspects to focus on. This limits the comment\"s helpfulness, as it offers a valuable insight but lacks actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific actions for the authors to consider. The first action suggests adding performance metrics on word similarity and sentence translation tasks, referencing the MUSE paper as an example. This is a clear and explicit suggestion, providing a concrete way for the authors to enhance the credibility of their framework. The second action suggests including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is also a specific and actionable suggestion. Both actions are clearly stated and provide detailed guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two clear actions for improvement: adding performance on word similarity and sentence translation tasks, and including experiments with morphologically rich and lowresource languages. This provides detailed guidance on what needs to be addressed in the experiments section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding performance metrics on word similarity and sentence translation tasks, as well as including experiments with morphologically rich and lowresource languages. These suggestions are based on the reviewer\"s knowledge of the field and the expectation that such additions would enhance the credibility and robustness of the framework. However, the comment does not provide specific references or examples to support these claims, making it 3. The authors would need to infer the relevance and importance of these suggestions based on their own understanding of the field. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the paper. The first suggestion is to include performance metrics on word similarity and sentence translation tasks, which would enhance the credibility of the framework by demonstrating its robustness and effectiveness. The second suggestion is to include experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which would broaden the scope of the evaluation and provide a more comprehensive assessment of the framework. These suggestions are clear and provide concrete steps for the authors to take to improve their draft, making the comment 5. However, it could be more helpful if it included more detailed guidance on how to implement these suggestions or examples of how they might be integrated into the paper. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions. The first question asks about the utility of node importance in the 1shot scenario, which is a specific and concrete action for the authors to address. The second question points out the absence of the 1shot setting in the experiments, suggesting that the authors should include this setting in their experiments. Both questions provide clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment raises two specific questions about the paper. The first question addresses the utility of node importance in the 1shot scenario, which is a direct and concrete issue that the authors can address by providing clarification or evidence. The second question points out the absence of the 1shot setting in the experiments, which is also a specific issue that the authors can address by including this setting. The comment is fully grounded as it explicitly mentions the sections or aspects being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions that seek clarification and explanation. The first question asks about the utility of node importance in the 1shot scenario, which is a logical inquiry that requires the authors to provide context or reasoning. The second question questions the absence of the 1shot setting in the experiments, noting that related works like RALE include this setting. While the comment does not contain subjective opinions or claims, it seeks clarification and explanation, which are common in academic reviews. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions that are relevant to the paper\"s methodology and experimental design. The first question asks about the utility of node importance in the 1shot scenario, which is a critical aspect of the paper\"s approach. The second question points out the absence of the 1shot setting in the experiments, noting that related works like RALE include this setting. By addressing these questions, the authors can provide more clarity and depth to their work, enhancing its comprehensiveness and impact. However, the comment could be more helpful if it offered suggestions on how to incorporate the 1shot setting or provided additional context for the node importance in the 1shot scenario. Overall, the comment is 4 as it directs the authors to important areas for clarification and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of the LLMs\" performance should be discussed or how to address the problems. The action is implicit and somewhat vague, as the authors need to infer the details of what needs to be included in the discussions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to address the issue of LLMs\" performance with finegrained constraints, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any specific examples, references, or reasoning to support why these discussions are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more discussions about why large language models (LLMs) struggle with finegrained hard constraints and how to address these problems. This feedback is 3 as it identifies a specific area for improvement in the paper, which could enhance the depth and comprehensiveness of the discussion. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the LLMs\" performance should be discussed or how to address the problems. To be more helpful, the comment could include examples or references to specific issues or solutions. Therefore, the comment is 3, as it points out an area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more insights into why this approach is valuable. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that more explanation is required but are not given concrete steps on how to address this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and questions the necessity of selfsupervised learning on 360 video data with spatial audio. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in questioning the need for selfsupervised learning on this type of data, but without grounding, the authors may struggle to identify the exact section where this critique applies. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of selfsupervised learning on 360 video data with spatial audio, suggesting that more insights are needed. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is valuable or why more insights are required. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of explanation regarding the necessity of selfsupervised learning on 360 video data with spatial audio. It questions why this approach is valuable and suggests that more insights are needed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of insights are required. While it identifies a gap in the paper, it lacks actionable feedback, making it 3. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. This implies that the authors should clarify this connection in the text or figures. Second, it requests that labels be included for subfigures in Figs 3 and 4, which is a specific and direct action. Both actions are clear and provide concrete guidance on how the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely, the need for labels in the figures and a more explicit explanation of the link between IP and the terms/equations. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figs 3 and 4. While the comment provides a clear request for improvement, it lacks specific reasoning or examples to support why these changes are necessary. The suggestion is 3 as it points out a potential area for improvement, but it does not provide detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improvement. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear direction for the authors to enhance the clarity of their work. Second, it requests the inclusion of labels for subfigures in Figs 3 and 4, which is a direct and specific recommendation for improving the presentation of the figures. These suggestions are clear and provide the authors with concrete steps to improve their draft, making the comment 4. However, it could be more helpful if it offered additional guidance or examples on how to achieve these improvements. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to improve the robustness and reliability of their results. The comment does not leave any ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or result section. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in suggesting a method to improve the results, but without grounding, it is difficult for the authors to know where to apply this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and reasonable suggestion, as it aligns with common practices in statistical analysis to ensure the reliability of results. However, the comment does not provide specific examples or references to support the claim, which could make it more robust. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of this suggestion based on their own understanding of statistical analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the robustness and reliability of the results by recommending that they be averaged over multiple runs to determine statistical significance. This feedback is valuable as it offers a specific and effective method for enhancing the analysis, which the authors can implement to strengthen their findings. However, the comment could be more helpful if it included additional guidance on how to determine the appropriate number of runs or how to interpret the results of this averaging. Despite this, the feedback is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that while the paper covers the SimCLR case, it lacks an analysis of the projection head, which is considered an important aspect of the approach (as evidenced by SimCLRv2 and other recent papers). However, the comment does not provide explicit guidance on how the authors should address this omission. It suggests that the authors should include an analysis of the projection head, but it does not specify how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the projection head, which is considered an important aspect of the approach (as evidenced by SimCLRv2 and other recent papers). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the projection head, which is considered an important aspect of the SimCLR approach. However, the comment does not provide specific references or examples of recent papers that emphasize the importance of the projection head, nor does it explain why this omission is significant. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that while the SimCLR case is covered, there is no analysis of the projection head, which is considered an important aspect of the approach (as evidenced by SimCLRv2 and other recent papers). This feedback is clear and actionable, as it directs the authors to include an analysis of the projection head, which could significantly enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects of the projection head should be examined. Overall, the comment is 4 as it highlights a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions are currently hidden in the experimental section and recommends that the paper highlight these observations and conclusions. This feedback provides a clear and explicit action for the authors to take, which is to make these observations and conclusions more prominent in the paper. The suggestion is concrete, as it specifies what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While it does not explicitly mention a specific section, the authors can infer that it pertains to the experimental section. The comment is specific in its suggestion to highlight the observations and conclusions, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors may infer that the observations and conclusions are indeed hidden, but the comment could be strengthened with more detailed evidence or examples to support the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific recommendation for improving the clarity and accessibility of the paper\"s findings. However, the comment could be more helpful if it offered additional guidance on how to effectively highlight these observations or provided examples of how this could be achieved. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This is an explicit action that the authors can take to address the feedback. The comment also provides a clear direction on what needs to be done, namely, conducting ablation experiments. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing ablation experiments to validate the model performance further, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. However, the comment does not provide any specific reasoning or evidence to support why these ablation experiments are necessary or how they would improve the validation of the model performance. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it directs the authors to conduct specific experiments to strengthen their work. However, the comment could be more helpful if it provided additional guidance on which specific modifications to focus on or how the ablation experiments should be structured. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It also questions whether it is possible to show a comparison of performance on datasets with a decision space beyond binary. While the comment highlights an issue and suggests a potential comparison, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include such a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of showing a comparison of performance on datasets with a decision space beyond binary, as mentioned in Zhang et al. [44]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It references Zhang et al. [44] as an example of a situation where this might not be a problem, suggesting that a comparison of performance on datasets with a decision space beyond binary could be beneficial. However, the comment lacks specific details or examples to fully substantiate the claim, making it 3. The authors would need to conduct further research or analysis to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It references Zhang et al. [44] as an example of a situation where this might not be a problem, suggesting that a comparison of performance on datasets with a decision space beyond binary could be beneficial. This feedback is 3 as it identifies a potential limitation and suggests a comparison that could enhance the paper\"s analysis. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment offers a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While the questions are clear, they do not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to investigate these aspects and possibly provide additional analysis or discussion. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions regarding the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the proposed method being pipelining. These questions are factual inquiries seeking clarification or explanation, rather than claims or opinions. Therefore, they do not contain claims that require verification, aligning with a classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While these questions are relevant and could lead to valuable insights, they are not accompanied by suggestions or guidance on how the authors might address these issues or what specific aspects to focus on. The feedback lacks depth and actionable advice, leaving the authors with a general understanding of areas to explore but without clear direction on how to improve their draft. Therefore, the comment is 3, as it identifies potential areas for investigation but does not fully support the authors in making meaningful improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include content in Appendix A and clarify the purpose of Proposition B.1, but without detailed instructions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of content in Appendix A and the unclear purpose of Proposition B.1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition might only illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. However, the comment lacks specific examples or references to support the claim that the \"proof\" is missing. While the comment identifies potential issues, it does not provide detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the issues and how to address them, which limits the clarity and effectiveness of the feedback.", "helpfulness_rationale": "The review comment identifies two specific issues with the appendices of the paper. It points out that Appendix A is left blank, which is a significant oversight, and that the purpose of Proposition B.1 in Appendix B is unclear. The comment also questions whether the proposition is merely illustrative of a wellknown concept in machine learning, the classic partitioning principle of Kmeans, and notes that the authors\" \"proof\" is missing. This feedback is 3 as it highlights areas that need attention and provides some insight into potential issues with the appendices. However, it could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on what constitutes a \"proof\" in this context. Overall, the comment is 3, as it directs the authors\" attention to specific areas that require clarification or elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, as they are instructed to include these types of experiments to enhance the comprehensiveness of their work. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that these experiments should be added to the experimental section, the comment lacks full grounding. It is specific in identifying the missing elements but not fully grounded, as it does not specify the exact sections or provide detailed guidance on how to implement these experiments. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples or references to support the claim, nor does it explain why these experiments are necessary or how they would improve the paper. Without detailed reasoning or evidence, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly instructs the authors to include these types of experiments to enhance the comprehensiveness and robustness of their work. By highlighting these specific areas for improvement, the comment provides the authors with a clear path to strengthen their draft. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what specific comparisons or analyses would be beneficial. Overall, the comment is 4 as it effectively guides the authors in improving their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several approximations introduced by the authors and points out the need to address the possible vulnerability associated with these approximations. It suggests that the authors should expand their discussion to reassure readers that this is not a real concern. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to expand the discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors know they need to address the vulnerability but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the approximations introduced by the authors and points out the possible vulnerability associated with them. It suggests that the authors should expand their discussion to reassure readers that this is not a real concern. However, the comment does not specify which approximations are being referred to or where in the paper these approximations are discussed. This lack of specificity makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the approximations introduced by the authors leave loose ends and that the possible vulnerability needs to be expanded to reassure readers. The comment provides a logical reasoning by acknowledging the necessity of approximations to derive clean results but suggesting that the authors should address the potential vulnerability. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact approximations being referred to and the specific vulnerabilities that need to be addressed, which adds to the ambiguity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the approximations used in the paper, noting that they leave loose ends and potentially introduce vulnerabilities. It acknowledges the necessity of approximations to achieve clean results but suggests that the authors should expand their discussion to address these vulnerabilities and provide reassurance to readers. This feedback is clear and actionable, as it directs the authors to address a significant concern that could impact the credibility of their work. By providing a specific area for improvement, the comment offers valuable guidance for enhancing the draft. However, it could be more helpful if it included suggestions on how to expand the discussion or what specific vulnerabilities should be addressed. Overall, the comment is 4, as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the paper\"s contribution appears limited and that the proposed model is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve their contribution. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions might be necessary. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the paper\"s contribution and the proposed model, suggesting they appear limited and incremental. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution or model are perceived as limited or incremental. Without specific references to sections, figures, or tables, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the paper\"s contribution appears limited and that the proposed model is incremental. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the perceived limitations or improve the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the paper\"s contribution appears limited and that the proposed model is incremental. However, it does not provide any specific feedback, suggestions, or examples to support this opinion or guide the authors on how to address these concerns. Without actionable advice or detailed critique, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to conduct a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed model on various benchmarks, specifically mentioning that it demonstrates impressive performance. However, it does not specify which benchmarks are considered \"old\" or provide details about the \"data curation\" process. This lack of specificity makes it difficult for the authors to pinpoint the exact part of the paper that needs improvement. While the authors can infer that it relates to the experimental results section, the comment is not fully grounded. It is specific in suggesting that more details about the evaluation procedures would be helpful, but this does not fully address the initial claim about the \"old\" benchmarks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model\"s impressive performance on benchmarks might be due to data curation, implying that the data might have been indirectly seen by the model. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks, suggesting that the data might have been indirectly seen by the model through the \"data curation\" process. This observation is important as it highlights a potential limitation in the evaluation methodology. The comment also recommends providing more details about the evaluation procedures, which could help the authors address this concern and improve the transparency and robustness of their results. While the comment points out a specific area for improvement, it lacks detailed guidance on how to conduct a more thorough analysis or provide additional information. Therefore, the feedback is 3, as it directs the authors to an important aspect of their work that needs attention but does not fully guide them in implementing the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide comments on the differences between the two sets of evaluation methods in Figure 4 and Figure 5. While the comment implies that the authors should address the differences between the methods, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to clarify the differences, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the differences between the two sets of evaluation methods in different OPE methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide comments on the differences between the two sets of evaluation methods in Figure 4 and Figure 5. However, it does not provide any specific reasoning, examples, or references to support why these differences are important or how they might impact the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting that the different metrics used for different OPE methods are quite different in Figure 4 and Figure 5. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods. This feedback is 3 as it points out a potential area for clarification or improvement in the paper. However, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue, such as by providing detailed explanations or additional analysis. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It suggests that the comparison is unfair because it requires two representation models learned for each dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the extra complexity and cost of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the extra complexity and cost involved. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison of the proposed method is unfair because it requires two representation models learned for each dataset, which is not the case for the SOTA. The reviewer provides a logical explanation for why the comparison is unfair, stating that the proposed method\"s advantage is only realized when using prior knowledge. This reasoning is clear and supports the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a strong basis for the claim but lacks some detailed evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It highlights that the comparison is unfair because it requires two representation models learned for each dataset, which is not the case for the SOTA. The comment provides a clear and actionable suggestion for the authors to consider the extra complexity and cost involved in their method. However, it could be more helpful if it offered specific recommendations on how to address this issue or suggested alternative approaches to ensure a fair comparison. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. While the comment implies that the authors should consider including collaborative games in their experiments, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should add collaborative games to their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or specific results. The authors may infer that it relates to the experimental design, but this inference is not explicit. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning or evidence to support why collaborative games are important or how they would enhance the study. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting the absence of collaborative games in the experiments. It suggests that including collaborative games would be interesting and could provide valuable insights into how the evaluated methods behave in different settings. This feedback is clear and actionable, as it directs the authors to consider expanding their experimental design to include collaborative games. However, the comment could be more helpful if it provided specific examples of how collaborative games could be integrated or suggested potential benefits of including them. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. This provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is explicit and concrete, giving the authors a straightforward task to improve the clarity and verifiability of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by noting that the experimental settings are missing, which makes the figures difficult to be convincing. This level of detail is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing. This is a critical point as it affects the verifiability and credibility of the results presented in the figures. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors improve the clarity and robustness of their experimental setup. However, the comment could be more helpful if it suggested how the authors might address this issue, such as by providing a detailed explanation of the missing settings or recommending specific steps to include them. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment does not provide explicit guidance on how the authors should address this ambiguity or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed clarification on the proposed method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the rationale behind the work and the suggestion of pathway protection based on sparsity in activation channels. It highlights an ambiguity regarding how the proposed method avoids impeding the learning of new task knowledge, which is a critical aspect of the work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with the proposed method, but without full grounding, it is challenging for the authors to pinpoint the exact section needing clarification. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It notes that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment lacks specific examples or references to support the claim that the proposed method avoids impeding learning. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale of the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment lacks specific suggestions or guidance on how the authors might address this ambiguity or clarify their approach. While it points out a potential area for improvement, the feedback is 3 as it prompts the authors to consider additional explanations or examples to support their claims. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics and justify their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, specifically mentioning that it seems adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explore alternative statistics is specific, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term appears adhoc and lacks theoretical support, suggesting that other statistics could be used to replace the mean and standard deviation. The reviewer provides a specific suggestion, such as using the median, which is not sensitive to outlier values. However, the comment lacks detailed reasoning or references to support why these statistics are more appropriate or why the current approach is insufficient. The suggestion is 3 as it offers a specific alternative, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, noting that it seems adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for alternative approaches. However, the comment could be more helpful if it included specific examples or references to support the use of the median or other statistics. Overall, the comment offers a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by suggesting the integration of benchmark comparisons against stateoftheart fairness algorithms. This feedback is specific and actionable, as it outlines exactly what needs to be done to improve the paper\"s experimental section. The authors are given a direct path to enhance their draft by providing evidence of the proposed method\"s performance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparisons with existing fairness algorithms. The comment suggests integrating benchmark comparisons against stateoftheart fairness algorithms to enhance the paper\"s experimental section and position the ManyFairHPO framework within the existing FairML research landscape. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper\"s experimental section. The claim is supported by logical reasoning, as it highlights the importance of benchmark comparisons in the field of fairness algorithms. However, the comment could be strengthened by providing specific examples of existing fairness algorithms or references to relevant literature that could be used for comparison. This would make the claim more verifiable. Therefore, the comment is rated as 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s experimental section and provide tangible evidence of the proposed method\"s performance. This feedback is specific and constructive, offering a direct way for the authors to improve the robustness and relevance of their work within the existing FairML research landscape. By addressing this suggestion, the authors can significantly strengthen their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they should also discuss the iteration cost of all related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what aspects of the iteration cost they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and recommends including a discussion of the iteration cost of all related methods, including baseline methods. While it does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the discussion or results sections where computational aspects are typically addressed. The comment is specific in its suggestion to discuss the iteration cost of related methods, providing a clear direction for improvement. However, the lack of explicit mention of a section makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and recommends including a discussion of the iteration cost of all related methods, including baseline methods. This is a logical suggestion that aligns with common practices in the field, as it highlights the importance of computational efficiency in evaluating methods. However, the comment does not provide specific examples or references to support the claim that discussing iteration cost is crucial or how it would benefit the paper. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to discuss the iteration cost (computational budget) of their proposed method. It also recommends including a discussion of the iteration cost of all related methods, including baseline methods. This feedback is valuable as it highlights an important aspect of computational efficiency that should be addressed in the paper. By following this advice, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to related methods for comparison. Overall, the comment is 4 as it guides the authors towards a significant improvement in their draft, but it could be more detailed for maximum benefit."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, making it 5. It instructs the authors to report the average over multiple runs in the experimental section, which is crucial for ensuring the reliability of the results. Additionally, it suggests a discussion on why the decision boundaries look a certain way in Section 3.1, which could provide additional context and insight. Finally, it asks for clarification on the information contained in Fig. 9 middle and right, which is another specific request for improvement. Each of these actions is clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in each section: reporting the average over multiple runs in the experimental section, discussing the decision boundaries in Sec. 3.1, and clarifying the information in Fig. 9 middle and right in Sec. 3.3. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of three separate comments, each addressing different aspects of the paper. The first comment suggests that the results are too close to favor one method, implying that reporting the average over multiple runs would be beneficial. This is a logical suggestion based on the observation of closely grouped results, but it lacks specific examples or references to support the claim. The second comment requests a discussion on the decision boundaries in Sec. 3.1, which is a reasonable suggestion for additional context. The third comment asks for clarification on the information in Fig. 9 middle and right, which is a request for more detailed information. While the comments provide some guidance, they lack detailed justification or references, making them 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental section and sections 3.1 and 3.3. It suggests reporting the average over multiple runs to enhance the reliability of the results, which is a clear and direct recommendation. Additionally, it requests a discussion on why the decision boundaries look a certain way in Section 3.1, which could provide additional context and insight. Finally, it asks for clarification on the information in Fig. 9 middle and right, which is another specific request for improvement. Each of these suggestions is clear and actionable, offering the authors concrete steps to enhance their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggestions for potential solutions. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses this limitation or provides details on how the authors might address it. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in identifying the issue of the curse of dimensionality but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This feedback is 3 as it highlights an important consideration for the authors to address in their work. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might overcome this limitation or explore alternative approaches. To be more helpful, the comment could include potential solutions or strategies for addressing the curse of dimensionality, such as dimensionality reduction techniques or alternative modeling approaches. Therefore, the comment is rated as 3, as it provides a starting point for the authors but does not fully support their efforts to improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative transfer in supervised pretraining based on the prediction of homolumo gap, using TransformerM on QM9. It highlights that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their model. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the supervised pretraining based on the prediction of homolumo gap, using TransformerM on QM9. It highlights that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the contradiction between the model\"s performance and its claimed generalpurpose nature. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential negative transfer in supervised pretraining based on the prediction of homolumo gap, using TransformerM on QM9. It claims that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the extent of the problem and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer in supervised pretraining based on the prediction of homolumo gap, using TransformerM on QM9. It highlights that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. This feedback is 3 as it identifies a specific issue with the model\"s generalpurpose nature and provides a clear example of where the model fails to perform well. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve the model\"s generalpurpose capabilities. Overall, the comment provides a valuable insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking why the metric was found useful in this specific context and what the authors meant by their earlier statement. While the comment implies that the authors should clarify their reasoning or provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this inconsistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 8082\" and \"Figure 4 A&B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. The comment clearly specifies what needs to be addressed, which is an inconsistency in the authors\" statements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the inconsistency or the authors\" rationale for using the metric. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. This feedback is 3 as it prompts the authors to clarify their reasoning or provide an explanation for this inconsistency. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it does not provide actionable guidance or insights that could significantly enhance the paper. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the term \"distributional generalization\" and suggests that it might be too strong to describe the empirical phenomenon presented. It questions whether the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero is realistic, given the limited number of test functions on which the outputs match. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their description. The action is implicit and vague, as the authors are left to infer that they should reconsider the terminology or provide more context. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used to describe the phenomenon of distributional generalization. It points out that the term might be too strong to capture the empirical phenomenon presented, as it implies an ideal state that might not be realistic based on the limited number of test functions. However, the comment does not specify which part of the paper this terminology is used in, making it weakly grounded. The feedback is specific in identifying the issue with the terminology and its potential limitations, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the term \"distributional generalization\" and questions its appropriateness in describing the empirical phenomenon presented. The reviewer points out that the term implies an ideal state of total variation between test and train distributions vanishing to zero, which might not be realistic based on the limited number of test functions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used to describe the phenomenon of distributional generalization. It questions the appropriateness of the term, suggesting that it might be too strong to capture the empirical phenomenon presented, given the limited number of test functions on which the outputs match. This feedback is 3 as it points out a potential area for clarification or improvement in the paper\"s terminology. However, it lacks specific suggestions or guidance on how the authors might address this issue or rephrase the terminology to better align with the empirical evidence. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical. It also mentions that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their theoretical contribution. There is no guidance on how to strengthen the theoretical aspect or what specific elements need to be addressed. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical contribution, specifically mentioning that it is weak and unpractical, and lacks mathematical novelty. However, it does not specify which part of the paper this theoretical contribution is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment provides some level of specificity regarding the issues with the theoretical contribution, it lacks full grounding as it does not explicitly mention a section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical contribution is weak and unpractical, and that the proof lacks mathematical novelty. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical, and lacks mathematical novelty. While it identifies a specific area for improvement, the comment lacks actionable feedback or suggestions on how the authors might strengthen their theoretical contribution. It does not provide any guidance on what aspects of the theoretical framework could be improved or how the authors might address the perceived lack of novelty. As a result, the comment is 2, as it highlights a concern but does not offer concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the experimental evaluation, specifically focusing on the ablation study and the comparison on CIFAR. It highlights that the paper claims a distinction in the \"picking\" step but does not provide an ablation study to support this claim. Additionally, it points out that the comparison on CIFAR is not convincing due to the limited number of approaches compared (only DEN) and the lack of clarity in evaluating DEN. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. While the comments provide specific areas for improvement, they do not explicitly instruct the authors on how to conduct the ablation study or which specific aspects to focus on. The feedback is 3 as it identifies clear areas for enhancement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1,\" \"Ablations 2.1.1,\" \"Experiments on CIFAR,\" and \"2.2.2.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the ablation study, the comparison on CIFAR, and the evaluation of the continual learning approach (DEN). It provides clear guidance on what needs to be addressed, such as conducting an ablation study and using the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several concerns about the experimental evaluation, specifically regarding the ablation study and the comparison on CIFAR. It claims that the paper does not ablate the \"picking\" step, which is a distinction claimed in the paper. Additionally, it questions the convincingness of the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the evaluation of DEN is unclear. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. While the comment provides specific points for improvement, it lacks detailed reasoning or references to support the claim that the comparison is not convincing. This makes the claim 3, as it provides a basis for the critique but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment provides detailed feedback on the experimental evaluation, specifically focusing on the ablation study and the comparison on CIFAR. It highlights that the paper claims a distinction in the \"picking\" step but does not provide an ablation study to support this claim. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the evaluation of DEN is unclear. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. This feedback is 4 as it identifies specific areas for improvement and provides actionable suggestions for enhancing the experimental evaluation. However, it could be more helpful if it offered additional guidance on how to conduct the ablation study or which specific aspects to focus on. Overall, the comment provides clear and actionable feedback, making it 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to make this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L240 and L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification regarding the meaning of \"is sufficient\" and the authors\" intention to explain the sum of the \"optimistic\" hoped for rewards being close to the expected actual rewards. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as 2, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers any further \"explanation\" of how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the scientific insight or provide additional explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model and formalism, questioning whether it provides a scientific insight beyond prior taskoptimized approaches. The comment highlights the lack of explanation regarding the model\"s approximation to nonlinear RNN models and its emergent behavior, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers any further \"explanation\" of how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 offers any additional explanation or scientific insight beyond what is already known. The comment highlights a specific gap in the paper, namely the lack of demonstration that the model is a prototype approximation to nonlinear RNN models with emergent behavior. This feedback is clear and actionable, as it directs the authors to clarify the scientific contribution of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other works have addressed similar gaps. Overall, the comment is 4 as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It explicitly asks how the groundtruths are built and why the network parts responsible for each part can predict all keypoints. However, it does not provide specific guidance or suggestions on how the authors should address these questions or improve their draft. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the nature of the problem and how to resolve it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material, questioning how the network parts responsible for each part can predict all keypoints. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and potentially revise their approach. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered alternative approaches. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to make the texts in legends and axis labels larger, and to ensure that the captions and legend\"s font size is similar to the text size in Figures 2 and 3. This provides clear and concrete guidance on what needs to be done to improve the draft. The action is direct and specific, allowing the authors to easily implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the beginning of page 6, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the text sizes in legends and axis labels, as well as the confusion in the caption and legend\"s font size in Figures 2 and 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the texts in legends and axis labels should be larger and that the captions and legend\"s font size should be similar to the text size in Figures 2 and 3. However, the comment does not provide any reasoning or evidence to support why these changes are necessary or how they would improve the readability of the figures. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the texts in legends and axis labels should be larger, and that the captions and legend\"s font size should be similar to the text size in Figures 2 and 3. This guidance is clear and directly addresses the issue of readability in the figures, which is an important aspect of the paper\"s presentation. By following this advice, the authors can improve the clarity and accessibility of their figures, enhancing the overall quality of the draft. However, the comment could be more helpful if it included additional suggestions on how to achieve this, such as specifying the exact font size or style to use. Despite this, the feedback is 4 as it directs the authors toward a specific improvement that can significantly enhance the manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific comparison to be made in the counterfactual experiments, involving a comparison against Journey TRAK at a particular step of the sampling trajectory. It references a specific figure (Figure 2) from the paper, which provides a clear indication of what needs to be added or included in the analysis. The comment is explicit in its request and provides concrete guidance on how to implement the suggested comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and references a specific comparison against \"Journey TRAK\" at a particular step of the sampling trajectory. It also provides a specific reference to [1, Figure 2], allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the comparison against Journey TRAK and the reference to Figure 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific comparison to be made in the counterfactual experiments, referencing a study by Journey TRAK. It provides a reference to a figure (Figure 2) that shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a comparison against Journey TRAK in the counterfactual experiments. It references a particular step in the sampling trajectory and cites a specific figure (Figure 2) that demonstrates the effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and results. By following this suggestion, the authors can strengthen their paper by providing a more comprehensive comparison, which could lead to a better understanding of the results and their implications. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental results, suggesting that the placement of adaptive convolutions is important but lacks analysis or comments on this aspect. It explicitly points out a specific observation from Table3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific analysis or comments are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct further analysis or provide comments on the placement of adaptive convolutions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation from the experimental results, namely that replacing normal convolutions with adaptive convolutions is not always beneficial, as demonstrated by the performance of ACNNv3 compared to ACNNv2. The comment specifies what needs to be addressed, which is an analysis or comments on the importance of the placement of adaptive convolutions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on the observation that ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This claim is 3 as it provides a specific example from the experimental results to support the assertion. However, the comment lacks detailed reasoning or analysis to fully substantiate the claim, such as explaining why the placement of adaptive convolutions is important or how it affects performance. Therefore, the comment is rated as 3, as it provides some support but requires additional explanation or evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It highlights a specific observation from Table3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This observation suggests that the placement of adaptive convolutions is important and lacks analysis or comments in the paper. The comment is 4 as it provides a clear and actionable suggestion for the authors to conduct further analysis or provide comments on the importance of the placement of adaptive convolutions. However, it could be more helpful if it offered specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the feedback is clear and actionable, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It suggests that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific comparison between the proposed method and a previous work, [10], regarding computation time and search space. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in detailing the issue of information loss and the tradeoff between computation time and search space, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. The claim is 3 as it provides a logical reasoning for the tradeoff between computation time and information loss. However, it lacks specific references or examples to support the comparison with [10] or to substantiate the claim about the richness of the search space. This makes the claim 3, as it provides a basis for the authors to explore but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It points out that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. This observation is insightful and provides a clear comparison that the authors might consider in their work. However, the comment does not offer specific suggestions or guidance on how the authors could address this issue or improve the performance of their method. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the VAD description, suggesting that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with the definition of a VAD. It implies that the authors should reconsider their approach and clarify the definition of VAD. However, the comment does not provide explicit guidance on how to address this issue or what alternative approach to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the VAD description and potentially redefine it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which involves discarding TF bins with a magnitude less than epsilon, questioning whether this constitutes a VAD and suggesting that it should be redefined to look for the presence of speech rather than just energy. The comment provides detailed feedback on the methodology and its alignment with the definition of a VAD, offering clear guidance for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the VAD description, questioning the approach of discarding TF bins with a magnitude less than epsilon. The reviewer suggests that this approach is not consistent with the definition of a VAD, which is typically used to detect the presence of speech and is defined over time, not frequency. The comment provides logical reasoning by explaining why the current approach might not align with the definition of a VAD and suggests a potential redefinition. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the VAD description, pointing out a potential inconsistency in the approach taken by the authors. It clarifies that a VAD is typically used to detect the presence of speech and is defined over time, not frequency, and suggests that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with this definition. The comment offers a clear and actionable suggestion for improvement, encouraging the authors to reconsider their approach and redefine the VAD to align with its intended purpose. This feedback is specific and provides a clear direction for enhancing the draft, making it 4. However, it could be more helpful if it included suggestions on how to redefine the VAD or provided examples of alternative approaches. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what needs to be added to the discussion section. The authors are given a clear direction on how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is fully grounded as it explicitly mentions the discussion section and provides specific details on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. This feedback is based on logical reasoning and specific examples, making it 4. However, it could be strengthened by providing references or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their discussion section. By addressing this suggestion, the authors can provide a more comprehensive and insightful analysis of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify the distinction between the two methods. While the comment identifies specific areas of confusion and requests clarification, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions, questioning the differences between anchorbased regression and RepPoints in RetinaNet, and suggesting that the authors clarify this problem. The comment also references ATSS and provides a rationale for why the authors might need to clarify the distinction between the two methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It references ATSS and suggests that the regression methods do not significantly influence the results. The reviewer questions the motivations behind RepPoints, implying that the authors should clarify the distinction between the two methods. While the comment raises a valid point about the potential equivalence of the methods, it lacks specific examples or references to support the claim that the regression methods do not influence results. This makes the claim 3, as it provides a basis for questioning but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify this problem. The comment provides a logical basis for the concern, referencing ATSS and its findings on the insensitivity of regression methods. This feedback is clear and actionable, as it prompts the authors to clarify the distinctions between the methods and justify the use of RepPoints. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional context. Overall, the comment is 4 as it directs the authors to a specific area for clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their presentation. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance the experimental design. As a result, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not specify which parts of the paper are unclear or lack intuition, nor does it provide specific suggestions for improvement. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not provide enough detail to guide the authors in addressing the issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is difficult to follow due to a lack of clear intuition and insufficient experiments. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the clarity and coherence of their work. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending ways to improve the intuition or structure of the presentation or suggesting additional experiments that could provide more context. While it points out a problem, it does not offer actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment explicitly requests additional metrics, it does not provide specific guidance on how to calculate or present these metrics. The action is clear but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the training of the student and refinement networks simultaneously and questions the fairness of the comparison with the teacher network. It suggests providing KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or the comparison with the teacher network, making it weakly grounded. The comment is specific in its request for KID/FID metrics, but without grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. However, the comment does not provide any specific reasoning or evidence to support why the comparison might be unfair or how the KID/FID metrics would resolve this issue. The request for metrics is a logical suggestion but lacks detailed justification or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment identifies a potential issue with the comparison, it lacks specific guidance on how to calculate or present these metrics, which could be beneficial for the authors. The feedback is 3 as it points out a potential area for improvement but could be more actionable with detailed instructions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they might need to consider scaling the refined vector, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification or context for the authors to address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the scaling of the refined region vector in the paper. It points out that the attention weight is in the range [0, 1] and sums up to 1 for all image regions, suggesting that the refined vector would only scale the most important regions by a factor of two before global pooling. The comment then suggests that having a scaling variable before the attention weight might be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this change. The authors are left with a question but without actionable steps to address it. Therefore, the comment is 3, as it prompts the authors to consider an improvement but does not fully guide them in making it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ALFRED benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of goal misspecification and how it leads to failures on the benchmark, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. While the comment provides a logical explanation of the issue, it lacks specific examples or references to support the claim fully. The reasoning is clear, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable suggestions. The authors are informed of a potential weakness in their work but are not provided with guidance on how to address it or improve their approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. While the comments provide suggestions for analysis and exploration, they do not explicitly instruct the authors on how to conduct these analyses or what specific aspects to focus on. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. However, the comment does not specify which part of the paper these concerns relate to, such as the results section or the discussion. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific suggestions for analysis, the lack of grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This claim is 3 as it provides a suggestion for analysis but lacks specific examples or references to support the claim about the improvement being small. Second, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. This is a logical deduction based on the current state of the field, but it lacks specific evidence or references to fully substantiate the claim. Overall, the comment is 3 due to the suggestion for analysis and the logical reasoning about the difficulty of improvement, but it could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This provides a clear and actionable suggestion for further analysis. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. While this is a valid point, it lacks specific suggestions or examples to help the authors address this concern. Overall, the comment is 4 as it offers actionable feedback on one aspect and raises a thoughtprovoking question on another, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It explicitly mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides a clear and concrete action for the authors to take, as they are directed to focus on specific models and present relevant data. The comment also offers a specific area for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ModelSpecific Insights,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular area for improvement by recommending a deeper investigation into how specific models behave differently when ReGuide is applied. The comment specifies the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide. This suggestion is based on a logical reasoning that adding such specific insights could enhance the paper\"s conclusions. However, the comment lacks detailed references or examples to fully substantiate the claim, making it 3. The authors would need to conduct additional research or analysis to fully address the suggestion, which is why it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that a deeper investigation into how specific models behave differently when using ReGuide could enhance the conclusions. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide, offering a clear direction for the authors to explore. This feedback is actionable and provides a concrete suggestion for the authors to consider, making it 4. However, it could be more helpful if it included additional guidance on how to conduct this investigation or what specific models to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on whether the Fourier modes are real or complex numbers. This is a clear and direct action for the authors to take, as it provides a specific area of ambiguity that needs to be addressed. The comment is concrete, as it specifies exactly what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fourier modes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification on whether the Fourier modes are real or complex numbers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the nature of Fourier modes (real or complex), which is a factual inquiry. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it provides a specific request for clarification regarding the nature of Fourier modes (real or complex). This feedback is valuable because it helps the authors ensure that their presentation of Fourier modes is accurate and consistent with the mathematical framework of their work. By addressing this point, the authors can improve the clarity and rigor of their draft. However, the comment could be more helpful if it included a suggestion on how to present this clarification or why it is important. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. While the comment implies that the authors should provide additional results or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more results or comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that more results or comparisons are needed, but without explicit references to the sections or figures where this comparison is mentioned, the authors may struggle to identify the exact areas needing supplementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the comparison or what specific aspects should be addressed. The comment is 3 as it points out a potential gap in the paper, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus the pretrained language models. It provides a clear and concrete suggestion for the authors to include results using the GCPG model without pretrained initializations. This feedback is explicit and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results\" and \"task formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the lack of ablation studies to clarify the contribution of the task formulation versus pretrained language models. The comment is specific in suggesting that the paper should include results using the GCPG model without pretrained initializations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus pretrained language models. The comment suggests including results using the GCPG model without pretrained initializations. While the suggestion is clear, it lacks specific examples or references to support the claim that ablation studies are necessary. The reasoning is logical, but the comment could be strengthened with more detailed justification or references to similar studies. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of ablation studies. It highlights the importance of understanding the contribution of the task formulation versus the pretrained language models by suggesting that the paper should include results using the GCPG model without pretrained initializations. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. By addressing this issue, the authors can better explain the performance gains and enhance the comprehensiveness of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting a way to clarify the axes or providing examples of how to improve the figure. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding what the axes represent in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty in understanding the axes in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it highlights a potential area of confusion for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the axes or improve the figure. Overall, the comment is 3 as it directs the authors to a specific area needing improvement but lacks depth in terms of actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any explicit guidance on how to achieve this, such as which specific aspects of the method should be tested on ImageNet or how to present the results. The action is implicit and vague, as the authors are left to infer that they should include ImageNet results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion of the method. Without explicit references to specific sections or elements, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding what aspects of the method should be tested on ImageNet or how the results should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific reasoning, examples, or references to support why ImageNet results would be particularly relevant or how they would enhance the method\"s credibility. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific guidance on how to incorporate these results or what aspects of the method should be tested on ImageNet. The feedback is vague and lacks actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and emphasizes the importance of including them to demonstrate the efficiency of the proposed approach. It provides a clear and concrete action for the authors to take, which is to include these comparisons. The comment also explains why these comparisons are necessary, making the action explicit and actionable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Direct runtime comparisons with existing methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, which is the direct runtime comparison with existing methods. The comment highlights the importance of including these comparisons to demonstrate the efficiency of the proposed approach, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which usually requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are essential for demonstrating the efficiency of the proposed approach. However, the comment could be strengthened by providing specific examples or references to similar studies that have included such comparisons. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It explains that the proposed approach is based on implicit differentiation, which typically involves additional computational costs, and thus, these comparisons are necessary to demonstrate the efficiency of the proposed approach. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to strengthen their paper. By including these comparisons, the authors can better justify the utility and practicality of their approach. Therefore, the comment is 5, as it guides the authors in making a significant improvement to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the proposed framework, stating that it is a simple combination of metalearning and federated learning and questioning the lack of technical contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might enhance the technical contribution or what specific aspects of the framework could be improved. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework, stating that it is a simple combination of metalearning and federated learning and questioning the lack of technical contribution. However, it does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the framework are missing or need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the proposed framework, stating that it is a simple combination of metalearning and federated learning and questioning the lack of technical contribution. However, it does not provide any specific suggestions or guidance on how the authors might enhance the technical contribution or improve the framework. Without actionable feedback or detailed insights, the comment lacks depth and does not effectively assist the authors in refining their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. It suggests that the paper could be more insightful or provide possible solutions. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address this concern or what specific aspects they should focus on. The feedback is vague and lacks concrete guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the insufficiency of the contribution, particularly regarding the lack of exploration into leveraging the connection between complementary and model robustness to improve robustness. It highlights that the paper could be more insightful or provide possible solutions. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The authors can infer that it pertains to the discussion or conclusion sections, but this inference is not explicit. The comment is specific in detailing the issue of insufficient exploration and the expected outcomes, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, and it is expected to see more insightful findings or possible solutions. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the contribution is insufficient. The suggestion for more insightful findings or solutions is vague and does not provide actionable guidance. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. This is a critical observation that highlights a gap in the paper\"s analysis. The comment also points out that the conclusion could be easily and intuitively obtained, suggesting that the authors should provide more insightful findings or possible solutions. While the comment raises an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or what additional insights or solutions could be explored. This makes the feedback 3, as it provides a direction for improvement but does not fully empower the authors to make significant changes to their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not provide explicit guidance on how the authors should make this shift or what specific aspects of the representation should be analyzed. The comment implies that the authors should reframe their approach, but it lacks concrete details or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the focus, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this shift is necessary or how it would improve the paper. Without specific examples or logical reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. This feedback is 3 as it identifies a potential area for improvement in the paper\"s focus and methodology. However, it lacks specific guidance on how the authors should reframe their approach or what aspects of the representation should be analyzed. The comment provides a direction for improvement but does not offer detailed suggestions or examples, leaving the authors with a general idea of what to address but without actionable steps. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, which is to make the necessary change to the caption. The comment is explicit and concrete, as it specifies exactly what needs to be done and how to implement the change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, suggesting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding the caption of Figure 7, suggesting that it should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This is a straightforward correction based on the content of the figure, and it does not require any additional justification or evidence. Therefore, the claim is 5, as it is based on a clear and accurate observation. The comment is classified as \"5.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the caption of Figure 7, suggesting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is clear and actionable, providing the authors with a direct and specific correction to make. By addressing this issue, the authors can improve the accuracy and clarity of their figures, enhancing the overall quality of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that discussing case studies and error studies could enhance the paper\"s effectiveness by providing concrete examples of the proposed components. It specifically mentions the Elementlevel Graph Pretraining and its focus on core elements, but it does not provide explicit guidance on how to conduct these studies or what specific aspects to include. The comment implies that the authors should include case studies to support their claims, but it lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to highlight the effectiveness of the proposed components, specifically mentioning the Elementlevel Graph Pretraining. It provides a specific example of a case study, \"Graph pretraining for AMR parsing and generation,\" which helps the authors understand the context and relevance of the suggestion. However, the comment does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The suggestion is specific, as it clearly outlines what kind of studies would be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies could enhance the paper\"s effectiveness by providing concrete examples of the proposed components. It mentions a specific example of case studies, \"Graph pretraining for AMR parsing and generation,\" which could be used to illustrate the effectiveness of the Elementlevel Graph Pretraining. However, the comment does not provide detailed reasoning or evidence to support why case studies and error studies are necessary or how they would improve the paper. The suggestion is 3 as it provides a specific example but lacks comprehensive justification, leaving the authors to infer the importance of the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that discussing case studies and error studies could enhance the paper\"s effectiveness by providing concrete examples of the proposed components. It specifically mentions the Elementlevel Graph Pretraining and its focus on core elements, but it lacks detailed guidance on how to conduct these studies or what specific aspects to include. While the comment identifies a potential area for improvement, it does not provide actionable steps or examples, making it 3. The authors gain some insight into how to strengthen their paper, but the feedback could be more comprehensive and detailed to be fully beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to clarify the motivation. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not specify which part of the paper discusses the DCI framework or the evaluation criteria, making it weakly grounded. The authors can infer that it relates to the discussion of the DCI framework, but the lack of explicit references or specific sections makes it difficult to pinpoint. The comment is specific in detailing the need for clarification on the motivation for considering explicitness(E) and size(S) as extra evaluations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific examples or references to support the claim that the DCI framework already considers these factors. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the traditional DCI framework, suggesting that it may already consider explicitness(E) and size(S) as evaluation criteria. It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their evaluation framework. While it identifies a potential issue, it does not offer actionable steps or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This is a clear and direct action for the authors to take, providing them with a specific task to address. The comment also highlights the issue of not providing the standard deviation after multiple experiments, which is another actionable point. The feedback is concrete and provides clear guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with not providing the standard deviation after multiple experiments and suggests that the improvement brought by SoRA may be due to random fluctuations. The comment further instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided in the paper, which may lead to uncertainty about the improvement brought by SoRA compared to the baseline. The reviewer suggests that the improvement could be due to random fluctuations. However, the comment lacks specific examples or references to support the claim that the improvement is limited or that random fluctuations are the cause. Without additional evidence or detailed reasoning, the claim remains 3, as it provides a logical inference but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper\"s experimental section, noting that the standard deviation after multiple experiments is not provided. This omission could lead to uncertainty about the reliability of the results and the extent of the improvement brought by the SoRA method compared to the baseline. The comment suggests that the improvement may be due to random fluctuations, which is a valid concern. By pointing out this issue and providing a clear suggestion for clarification, the comment offers actionable feedback that can help the authors improve the transparency and robustness of their experimental results. However, the comment could be more helpful if it provided specific guidance on how to calculate and present the standard deviation or suggested alternative ways to address the issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment does not provide specific guidance on how to address these issues or suggest concrete steps for improvement. The authors are left with a general understanding of what needs to be fixed but without clear instructions on how to implement the changes. Therefore, the comment is 3, as it highlights areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some level of specificity in detailing the issues, it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not well organized and identifies specific issues with the layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks detailed reasoning or examples to support these claims, making it difficult for the authors to understand the extent of the issues or how to address them. The lack of specific evidence or references to justify the claims renders the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks actionable guidance on how to address these issues or suggestions for improvement. While it points out areas that need attention, it does not provide detailed advice or examples of how to correct these problems, leaving the authors with a general understanding of what needs to be fixed but without clear steps to take. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider whether the types of interventions included in the paper are practical and safe for querying in the real world. While the comment implies that the authors should evaluate the practicality and safety of their interventions, it does not provide specific guidance on how to conduct this evaluation or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the types of interventions included in the paper, suggesting that they are reasonable computationally but questioning their practicality and safety for querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider the practicality and safety of the interventions, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for querying in the real world. However, the comment does not provide specific examples or evidence to support the claim that the interventions are not practical or safe. Without detailed reasoning or references, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the practicality and safety of the interventions discussed in the paper. It suggests that while the interventions may be computationally reasonable, they should also be evaluated for their practicality and safety in realworld querying scenarios. This feedback is 3 as it points out an important aspect that the authors should consider, but it lacks specific guidance or examples on how to assess the practicality and safety of the interventions. The comment could be more helpful with additional details or suggestions on how to evaluate these aspects, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a clear and explicit action for the authors to take, as it instructs them to define the notation \"cal P\" with a subscript in the same section where it is first used. The comment provides a specific and concrete action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the notation \"cal P\" with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of definition for the notation \"cal P\" with a subscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward statement of a potential issue with the paper\"s notation, which can be addressed by the authors. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"cal P\" with a subscript being used without being defined in the same section. This is a clear and actionable feedback that highlights a potential confusion for readers who might not be familiar with the notation. By pointing out this issue, the comment provides the authors with a specific area to address, which could significantly improve the clarity and readability of their draft. However, the comment could be more helpful if it suggested how the authors might define the notation or provided an example of how to do so. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and issues that require clarification and explanation. It asks for a definition of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \u201cp\u201d is not explicitly defined and has been used extensively throughout the paper, which is problematic. The reviewer suggests moving the definition of \u201cp\u201d to a more appropriate location. While the comments imply actions, such as providing definitions and explanations, they are not explicitly stated. The authors can infer the need for these actions, but the lack of concrete guidance makes the comments 3.", "grounding_specificity_rationale": "The comment raises several specific issues related to the paper, including the definition of \"upper faces\" of the convex hull, the explanation of dual subdivision and projection \u03c0, and the definition of the variable \u201cp\u201d. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing definitions and explanations, but without clear references to specific sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of several questions and observations that require clarification or explanation. It does not contain any subjective opinions, claims, or suggestions that would require verification. The comments are factual and descriptive, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises several specific questions and issues that need clarification in the paper. It asks for a definition of \"upper faces\" of the convex hull and suggests that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \u201cp\u201d is not explicitly defined and has been used extensively throughout the paper, which is problematic. The reviewer provides actionable feedback by suggesting that the definition of \u201cp\u201d should be moved to a more appropriate location. While the comment identifies areas for improvement, it could be more helpful if it offered suggestions on how to improve the explanations or provide examples. Overall, the feedback is 4 as it guides the authors in addressing critical aspects of their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to justify their current approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment questions the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on why the author is not convinced or what specific aspects of the paper support this skepticism. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this skepticism. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not provide any specific reasoning, evidence, or examples to support this skepticism. Without detailed feedback or suggestions for improvement, the authors are left without actionable guidance on how to address this concern or justify their current approach. As a result, the comment is not helpful, as it lacks depth and actionable insights for the authors to improve their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. This feedback is explicit and provides a clear action for the authors to take, which is to conduct separate evaluations of each component. The suggestion is concrete, as it specifies the type of evaluation needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the clarity of the proposed method, specifically questioning which component contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology and results sections where these components are discussed. The authors can infer that it relates to the sections describing the proposed method, but the comment does not provide a direct reference. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. While the comment identifies a potential issue with the clarity of the method\"s contribution, it lacks specific examples or detailed reasoning to substantiate the claim. The suggestion to evaluate separately is a logical step, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. This feedback is clear and actionable, providing a specific direction for the authors to improve the clarity and robustness of their work. By suggesting a method for evaluation, the comment offers a concrete way to address the lack of clarity in the paper, making it 5 for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process, specifically questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they should explore alternative methods for disentangling. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the manual disentangling process, particularly questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not specify which part of the paper discusses the manual disentangling process, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not precise. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or why learning disentangling would be more interesting. The suggestion is based on a subjective opinion rather than a verifiable claim, as it does not provide detailed justification or examples. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue or explore alternative methods. To be more helpful, the comment could include examples of alternative approaches or references to relevant literature. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a perceived lack of connection between the theoretical analysis and the proposed method, suggesting that the proposed method simply adopts the idea of selfattention from the transformer and applies it to graphs. The reviewer questions how this enhances generalization for distant nodes. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the connection between theory and method. The action is implicit and vague, as the authors are left to infer that they need to strengthen the theoretical justification of the method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the PACBayesian bound for GNNs in the transductive setting. It questions the connection between the theoretical analysis and the proposed method, suggesting that the method simply adopts the idea of selfattention from the transformer and applies it to graphs. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The feedback is specific in pointing out the lack of connection between theory and method, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the connection is weak. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. While the comment highlights a gap in the paper\"s argument, it lacks specific suggestions or guidance on how the authors might strengthen the connection or improve the method\"s generalization. The feedback is 3 as it points out a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve the clarity of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to a specific section or discussion, the lack of explicit grounding makes it challenging to determine the exact area of concern. The comment is specific in its focus on the Lipschitz Hessian assumption, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a valid point that could impact the understanding and applicability of the method. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the clarity of their method. Without additional context or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some pieces of the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. It suggests that the authors should provide more clarity by checking the original paper. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the presentation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the presentation of existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"pieces,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces of the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of existing methods, such as equation (12), noting that the presentation is vague and requires checking the original paper for clarity. While it highlights a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might clarify the presentation or improve the understanding of these methods. This limits the usefulness of the feedback, as it does not offer actionable steps for the authors to take to enhance their draft. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or what changes might be necessary. The comment is implicit in its request for clarification, and the authors would need to infer the actions required to improve their draft. As a result, the comment is 3, as it identifies areas for clarification but lacks concrete instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the questions being raised about the rationale behind certain design choices, such as the separate timbre encoder module and the input of SADTW. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the rationale behind certain design choices in Figure 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. While it identifies areas for clarification, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it prompts the authors to consider and potentially clarify their design choices, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Table 4 is incomplete and should include the results for all four datasets. This provides a clear and direct action for the authors to take, which is to ensure that the table is fully populated with the required data. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table is incomplete and should include results for all four datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete, stating that it should include results for all four datasets. This is a factual statement that does not require verification or evidence. It is a clear and direct request for the authors to provide additional data, which is a straightforward and verifiable comment. Therefore, it aligns with a score of 4, as it is 4 but lacks specific examples or references to support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and specific task to address in their draft. By highlighting this omission, the comment helps the authors improve the completeness and accuracy of their results presentation. However, it could be more helpful if it suggested how the inclusion of these results might impact the analysis or interpretation of the data. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern about the writing or presentation being jumbled at times, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the writing or presentation, nor are there suggestions for specific sections or areas that need clarification. Without actionable advice or specific feedback, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"writing\" and \"presentation,\" but it does not specify which parts of the paper are jumbled or unclear. This lack of grounding makes it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its feedback, as it points out a perceived issue with the writing or presentation, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the writing or presentation being jumbled at times, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the writing or presentation being jumbled at times, but it does not provide any specific examples, reasoning, or suggestions for improvement. This lack of detail and actionable feedback makes it difficult for the authors to understand the nature of the issue or how to address it. Without actionable guidance, the comment does not contribute significantly to the authors\" efforts to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the stability definition needs better justification, suggesting that the left side should be both upper and lower bounded. This provides a clear and direct action for the authors to take, which is to revise the definition to address this issue. The comment is specific in its suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"stability definition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current definition, suggesting that it needs better justification and should be made lower bounded. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the stability definition needs better justification, suggesting that the left side can be arbitrarily small under some construction of \u03b4. The reviewer proposes a more reasonable treatment by making it lower bounded. However, the comment lacks specific examples or references to support the claim that the current definition is insufficient. While the suggestion is logical, the absence of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides a reasonable suggestion but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the stability definition, noting that it can be arbitrarily small under certain conditions. It suggests a more reasonable treatment by proposing that the definition should also be lower bounded. This feedback is clear and actionable, providing the authors with a specific area to address and improve in their draft. By offering a constructive suggestion for revision, the comment effectively guides the authors toward enhancing the clarity and robustness of their work. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should investigate the computational complexity and power demand of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about computational complexity and power demand, but without grounding, the authors may struggle to identify the exact section where this information is relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support the claim about computational complexity or power demand. The reasoning is based on the reviewer\"s imagination and speculation, which makes the claim 3. The authors would need to conduct further analysis to address this concern, making the comment 3.", "helpfulness_rationale": "The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device, which is a relevant consideration for practical applications. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a critical aspect of the work, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully guide them in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific error in the authors\" claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. However, the comment does not provide explicit guidance on how the authors should correct this error or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise their claim based on the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of their paper being addressed. It also specifies the issue by pointing out a claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads, which is incorrect according to Wang et al., 2023. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a statement about the attention patterns of certain heads in the base IOI circuit is incorrect, referencing a specific section of a previous work, Wang et al., 2023. This provides a clear and specific reference to support the claim, making it 5. The authors are given a clear basis for revising their claim, as the reference to Wang et al., 2023 provides a logical and unassailable argument. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" claim about the attention patterns of certain heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. This feedback is valuable as it directs the authors to a source that can help them correct their understanding or presentation of the attention mechanisms in their work. However, the comment could be more helpful if it provided additional context or guidance on how to incorporate the findings from Wang et al., 2023 into their paper. Overall, the comment is 4 as it highlights a critical area for improvement and provides a starting point for revision."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, implying that it is a collection of tricks to improve defense evaluation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the work, suggesting that the proposed pipeline is incremental and not novel. However, it does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs improvement. Additionally, the comment lacks specificity in detailing what aspects of the pipeline are considered incremental or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, suggesting it is a collection of tricks to improve defense evaluation. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, suggesting that the proposed pipeline is incremental and not novel, implying it is a collection of tricks to improve defense evaluation. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the critique or address it effectively. Without actionable feedback or suggestions for improvement, the comment does not provide the authors with a clear path to enhance their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible for a single instance to hold all the training data from realworld datasets. However, it does not provide explicit guidance on how the authors should address this issue or whether they should develop a distributed version of the method. The comment lacks concrete suggestions or actions for the authors to take, making it 3. The authors can infer that they might need to explore scalability options, but the lack of specific guidance limits the actionability.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, specifically questioning whether a single instance can hold all the training data from realworld datasets. However, it does not specify which part of the paper discusses the method\"s scalability, making it weakly grounded. The comment is specific in its critique, as it points out a potential limitation of the method and suggests that a distributed version might be necessary. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable, suggesting that a distributed version might be necessary. However, the comment lacks specific reasoning or evidence to support why the method is not scalable or how a distributed version would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential scalability issue with the method, suggesting that a single instance may not be able to hold all the training data from realworld datasets. This is a valid concern that could impact the practical applicability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as exploring distributed versions of the method or alternative approaches to scalability. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the reason why the eta_ri term is noncentral chisquared distribution, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable advice or suggestions for clarification or explanation, leaving the authors without a clear path to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distribution of the eta_ri term, specifically why it is noncentral chisquared. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in questioning the distribution, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the distribution of the eta_ri term, specifically why it is noncentral chisquared. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the distribution of the eta_ri term, specifically why it is noncentral chisquared. While it identifies a potential area of confusion or lack of clarity, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the vagueness of the comment at line 15, suggesting that the authors should refer to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. It also critiques the analogy of reinforcement learning and the agent analogy, suggesting that it is out of place and recommending that the authors focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. While the comment provides clear guidance on what to include and where to find relevant information, it does not explicitly instruct the authors to make these changes themselves. The feedback is concrete and specific, but the action is inferred, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15, L1618) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear feedback on the vagueness of the comment at line 15 and critiques the analogy of reinforcement learning and the agent analogy, suggesting that it is out of place and recommending a focus on generalization capabilities. The comment provides specific references to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/, which further supports the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific references to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. This provides a clear and verifiable basis for the claim, making it 5. The comment also critiques the analogy of reinforcement learning and the agent analogy, suggesting that it is out of place and recommending a focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. This feedback is wellsupported by logical reasoning and specific references, making the claim 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft. It identifies a vague comment at line 15 and suggests referencing the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to provide a more concrete example of RNNs working well for certain natural language reasoning tasks. Additionally, it critiques the analogy of reinforcement learning and the agent analogy, suggesting that it is out of place and recommending a focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. This feedback is clear and actionable, offering the authors a path to improve the clarity and relevance of their draft. However, it could be more helpful if it provided specific suggestions on how to integrate the suggested references or examples into the paper. Overall, the comment is 4, as it provides valuable insights and guidance for enhancing the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures rather than sets. This feedback is explicit and provides a clear action for the authors to take, which is to restructure the presentation of these triples. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, suggesting that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures rather than sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of triples denoted as $(e_1, r, e_2)$ should be structured as tuplelike rather than sets. This is a suggestion for improvement, as it does not contain a claim or an opinion that requires verification. It is a factual statement that provides guidance on how to enhance the clarity of the presentation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of triples in the paper. It suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures rather than sets, which could enhance the clarity and structure of the presentation. This feedback is clear and actionable, offering a concrete way for the authors to improve their draft. However, it could be more helpful if it included an explanation of why this change would be beneficial or if it provided examples of how to implement this suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to include this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a speed analysis and compare it with prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that comparing the inference speed between the proposed network and prior work would be more interesting, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments lack a speed analysis, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the overall evaluation of the proposed network. Without additional context or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the analysis by pointing out the lack of speed analysis in the experiments. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting than just comparing GFLOPs. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the paper\"s contribution and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects of the inference speed analysis would be most informative. Overall, the comment is 4 as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this problem or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to find a way to mitigate the scalability issue without being given concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the comment does not explicitly mention specific sections, it is clear that it relates to the scalability of optimal quantization, which is a critical aspect of the paper. The authors can infer that it pertains to the sections discussing quantization and its implications for scalability. However, the comment lacks specificity in terms of what aspects of the quantization process need improvement or how to address the scalability issue. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It further explains that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the claim is based on the paper\"s own acknowledgment of scalability issues and the authors\" stated goal of speeding up VI, it lacks specific examples or references to support the claim fully. The reasoning is logical and consistent with the paper\"s content, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M), making it a bottleneck for the paper\"s aim of speeding up variational inference (VI) for big data and big model settings. This feedback is valuable as it highlights a significant limitation of the proposed method and suggests that the authors need to address this scalability issue to maintain the method\"s utility. However, the comment could be more helpful if it provided specific suggestions or examples on how to mitigate this bottleneck or improve the scalability of the quantization process. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement but lacks detailed guidance on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to take. It suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. Additionally, it recommends that the paper aim for a more applicationoriented venue if it does not address these issues. The comment is concrete, as it specifies the exact steps the authors need to take to improve their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"contrastive response tuning\" as part of the core methodology, allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, such as comparing the effectiveness against existing methods and addressing the issues mentioned above. Additionally, it suggests that the paper should aim for a more applicationoriented venue if it does not address these issues. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also recommends that the paper aim for a more applicationoriented venue if it does not address these issues. However, the comment does not provide specific examples or references to support the claim that the paper should compare against existing methods or address the issues mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their method, contrastive response tuning, against existing methods such as contrastive decoding. This comparison would help validate the effectiveness of the proposed approach. Additionally, the comment highlights the need to address the issues mentioned above and suggests that the paper should aim for a more applicationoriented venue if it does not address these issues. This feedback is specific and provides a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to address the issues or improve the applicationoriented focus. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed. The reviewer also expects the authors to further elucidate the technical contribution. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or concrete steps to take. The actions are implicit and somewhat vague, leaving the authors to infer the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the algorithm\"s effectiveness, problem, and validation experiments. It points out that the algorithm requires access to the entire training dataset and suggests considering how it operates when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not analyzed. The comment is fully grounded as it explicitly mentions the algorithm\"s effectiveness and problem, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific in detailing what needs to be addressed, such as the need for comprehensive validation experiments and analysis of time complexity and efficiency. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment provides a logical reasoning for the concerns raised, such as the need for comprehensive validation and analysis of efficiency. However, it lacks specific references or examples to fully substantiate the claims, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, the comment points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The reviewer also expects the authors to further elucidate the technical contribution. While the comment provides valuable insights and suggestions for improvement, it could be more helpful if it offered specific guidance or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that every kernel can be described by a feature space parameterized by a neural network, noting that this is not true for infinitedimensional RKHSs like the RBF kernel. It suggests that the authors should clarify this limitation. While the comment identifies a specific issue and implies that the authors should address it, it does not provide explicit guidance on how to clarify this point or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, particularly noting the limitation for infinitedimensional RKHSs like the RBF kernel. The comment suggests that the authors should clarify this limitation, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper, specifically questioning the assertion that every kernel can be described by a feature space parameterized by a neural network. It provides a specific example, the RBF kernel, which is known to have an infinitedimensional RKHS, making it impossible to represent with a finitewidth neural network. This critique is supported by logical reasoning and a reference to common knowledge in the field, making the claim 4. However, the comment could be strengthened by providing additional examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear and detailed critique by pointing out that this claim is not true for infinitedimensional RKHSs, such as the RBF kernel, which requires an infinitewidth neural network to represent it. The comment suggests that the authors should clarify this limitation, which is a valuable piece of feedback. However, while the comment highlights an important point, it does not offer specific guidance on how the authors might address this issue or provide additional context. The feedback is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown. It provides examples of previous works, such as the original denoising score matching objective and \"scoreinterpolation,\" which use this property. The reviewer suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a literature review and how to carry it out. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific examples of previous works, such as the original denoising score matching objective and \"scoreinterpolation.\" This provides clear guidance on which part of the paper is being addressed, allowing the authors to accurately identify the sections or aspects needing revision. The comment is also specific because it highlights the wellknown nature of the key idea and suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown. The reviewer provides examples of previous works, such as the original denoising score matching objective and \"scoreinterpolation,\" which use this property. This provides a clear and specific reference to existing literature, making the claim 4. However, the comment could be strengthened by including more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in previous works. It provides specific examples, such as the original denoising score matching objective and \"scoreinterpolation,\" which use this property. This feedback is valuable as it highlights the need for the authors to conduct a thorough literature review to ensure their work is wellpositioned and differentiated. The comment offers actionable advice by suggesting that the authors should review additional works that utilize this property, which could help them strengthen their contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct this literature review or what aspects to focus on. Overall, the comment is 4 as it provides clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding during inference. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. The reviewer asks if this limitation affects the benefits of the linear attention mechanism. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or what steps they could take to improve their approach. As a result, the authors are left without a clear understanding of what changes or clarifications are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not specify which part of the paper discusses the linear attention mechanism or the autoregressive decoding process, making it weakly grounded. The question is specific in its inquiry about the limitations of the linear attention during inference, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. The reviewer points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or justification, the claim remains 1, making it difficult for the authors to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. It lacks actionable feedback or specific recommendations, leaving the authors without a clear understanding of what changes or clarifications are needed. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer actionable advice or suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment implies that the authors should provide a gradient comparison between KL and PCC to address this concern. While the action is implicit, it is concrete as it specifies the type of comparison needed. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a gradient comparison between KL and PCC. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is 4 as it offers a logical explanation and an example to support its claim, but it could be strengthened by providing more detailed comparisons or references to further substantiate the argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It provides a logical explanation by suggesting that the constraint strength of a loss function is defined by its gradient distribution, and offers an example to illustrate this point. The comment implies that the authors should provide a gradient comparison between KL and PCC to strengthen their argument. This feedback is clear and actionable, as it guides the authors to address a potential weakness in their work by providing additional evidence. However, it could be more helpful if it included specific suggestions on how to conduct the gradient comparison or what aspects of the comparison would be most informative. Overall, the comment is 4, as it effectively directs the authors to improve their draft by addressing a critical assumption."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests the need for additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional discussion and measures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the possibility of GPI with noise reproducing data similarly well and suggests additional measures to demonstrate this. The comment further specifies the need for a discussion on the suitability of the approach for modeling pattern separation tasks, which is relevant to the paper\"s focus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate this. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims or suggestions. The lack of detailed evidence or justification makes it difficult for the authors to fully understand and address the points raised. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a question about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also points out the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment identifies areas for improvement and provides some guidance, it lacks specific suggestions or detailed feedback on how to address these points. The authors are given a direction to consider, but the comment could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors, if they have the resources, should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to perform the comparison or provide guidance on how to execute it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison and understand how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not specify which part of the paper this benchmark is discussed in or how it relates to the proposed approach. The authors can infer that it pertains to the section where the benchmark is mentioned, but the comment lacks explicit grounding. It is specific in suggesting a comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, the comment does not provide any reasoning, evidence, or justification for why this comparison would be beneficial or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This feedback is 3 as it provides a clear direction for potential future work that could enhance the paper. However, it lacks depth and does not offer guidance on how to conduct the comparison or what specific aspects should be considered. The authors are left with a general idea of what could be improved but without detailed instructions on how to implement it. Therefore, the comment is rated as 3, as it provides a suggestion for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what experiments might be necessary. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or conduct additional experiments. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the approach taken to resolve a debate that was previously left open and suggests that the distribution might have changed. The comment further asks whether experiments have been conducted to disentangle changes in distribution from the removal of information, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the approach is flawed or incomplete. This lack of detailed evidence or justification makes the claim 3, as the authors would need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. This feedback is 3 as it identifies a potential issue with the paper\"s methodology and encourages the authors to consider alternative explanations or additional experiments. However, the comment lacks specific suggestions or guidance on how to address these concerns, which limits its usefulness. The authors are left with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the compared methods using the same settings as the proposed method, specifically mentioning the use of AdamW with cosine lr for training. This action is clear and concrete, as it provides a specific step for the authors to take to ensure a fair comparison. The comment also highlights the importance of using the same settings as the compared methods, which is a logical and actionable suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the comparison between the proposed method and other methods, specifically mentioning the use of AdamW with cosine lr for training and the comparison with methods using adam with fixed lr. It suggests reproducing the results of the compared methods using the same settings as the proposed method. This provides full grounding as it explicitly mentions the part of the paper being addressed, which is the comparison and training settings. The comment is also specific because it clearly specifies the issue with the current comparison and suggests a solution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the direct comparison between the proposed method and other methods is unfair because the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests reproducing the results of the compared methods using the same settings as the proposed method to ensure fairness. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a solution to address it. However, it lacks specific references or examples of the compared methods to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests that this difference in training settings could make the comparison unfair. The comment is constructive as it provides a clear and actionable suggestion for the authors to reproduce the results of the compared methods using the same settings as the proposed method. This would ensure a fair comparison and enhance the validity of the study. However, the comment could be more helpful if it provided specific examples of the compared methods or detailed guidance on how to reproduce their results. Overall, the feedback is 4 as it directs the authors to a critical area for improvement and offers a clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct this experiment, analyze the results, or discuss it in their paper. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in its request for information about the performance of the SOTA method combined with the adaptive metric, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric, but it does not contain any claims, opinions, or suggestions that require verification. It is a question seeking clarification or information, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric. While it identifies an area of interest, it does not provide any actionable feedback or suggestions for the authors to improve their draft. It lacks depth and does not offer guidance on how the authors might address this curiosity or integrate it into their work. As a result, the comment is not helpful, as it does not provide the authors with a clear direction for enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the plots are \"terrible\" due to their small size, poor color differentiation, poorly labeled axes, and visually similar labels. It suggests that these issues make the plots difficult to understand and that the experimental results should be presented more clearly. The comment provides a clear and direct action for the authors to take, which is to improve the clarity of the plots. This feedback is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"plots,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the plots, such as their small size, poor color differentiation, poorly labeled axes, and visually similar labels. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, poor color differentiation, poorly labeled axes, and visually similar labels. The reviewer supports this claim by providing specific examples of these issues, such as the difficulty in distinguishing between pink and red colors. This level of detail and specificity makes the claim 4, as it provides clear evidence of the problems with the plots. However, the comment could be strengthened by including references to best practices or examples of welldesigned plots for further justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the plots, such as their small size, poor color differentiation, poorly labeled axes, and visually similar labels. By pointing out these problems, the reviewer provides clear and actionable feedback that can help the authors improve the clarity and effectiveness of their experimental results presentation. The comment is specific and detailed, offering a clear path for the authors to enhance the quality of their figures. However, it could be more helpful if it suggested potential solutions or alternatives for addressing these issues. Overall, the comment is 4, as it provides valuable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance gains, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the different metrics, but it does not specify which metrics are being discussed or which part of the paper this information is presented in. This makes it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out that the performance gains are not very high, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with the difference between the baseline and the best approach being less than 1% for most metrics. However, the comment does not provide any supporting evidence, such as specific metrics or examples, to substantiate this claim. Without detailed information or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a concern about the performance gains, noting that the difference between the baseline and the best approach is less than 1% for most metrics. This feedback is specific and identifies a potential issue with the paper\"s results. However, it does not provide any suggestions or guidance on how the authors might address this concern or improve their performance. Without actionable advice or further elaboration, the comment is 3 as it points out a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network. It asks for a comparison of the network\"s performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform these comparisons to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the performance of the feedback network, specifically regarding the information about incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in its inquiry about the performance with and without these types of information, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network, asking for a comparison of the network\"s performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is crucial or how it might affect the network\"s performance. Without such support, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the performance of the feedback network. It asks for a comparison of the network\"s performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. This feedback is 3 as it prompts the authors to consider the importance of these details in their work. However, it lacks depth and does not provide specific guidance on how to conduct these comparisons or what to look for in the results. To be more helpful, the comment could include suggestions on how to structure the analysis or what metrics to consider. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. It provides a clear action for the authors to take, which is to include standard deviations in Table 1 and conduct more extensive experiments. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. This includes conducting more extensive experiments. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks specific examples or references to support the claim that the inclusion of standard deviations would strengthen the submission. The suggestion to conduct more extensive experiments is vague and does not provide a clear rationale or evidence for why this would improve the paper. Without detailed reasoning or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also provides a clear suggestion for improvement by indicating that the submission would be stronger if the experiments were more extensive, including the inclusion of standard deviations. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct more extensive experiments or suggested specific areas where the additional data could be collected. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that using a better Unary baseline might still result in a performance boost. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to investigate this further. The action is implicit and vague, as the authors are left to infer that they should explore the performance boost with a better baseline. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the performance boost due to additional parameters in LinearTop and NLTop compared to the performance of the Unary model. The comment also references a specific paper ([14]) for context, providing a clear basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper ([14]) for context, suggesting that using a better Unary baseline might still result in a performance boost. However, the comment lacks detailed reasoning or evidence to support the claim that the additional parameters are the sole reason for the performance boost. While the reference to [14] provides some context, the lack of specific analysis or comparison makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper ([14]) for context, suggesting that using a better Unary baseline might still result in a performance boost. This feedback is 3 as it prompts the authors to consider alternative baselines and encourages them to explore the performance boost further. However, the comment lacks detailed guidance or suggestions on how to investigate this further or what specific aspects to focus on. While it provides a direction for improvement, it could be more helpful with additional context or actionable steps. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the paper\"s structure, suggesting a reorganization of sections to enhance clarity. It also highlights the need for more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests improvements to the visualization of Figures 7 and 8. These suggestions are explicit and provide concrete guidance on how the authors can enhance their draft. The authors know exactly what actions to take to improve the paper, making this comment 5.", "grounding_specificity_rationale": "The comment suggests improvements to the paper\"s structure, specifically recommending a reorganization of sections. It also highlights the need for more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, it suggests improvements to the visualization of Figures 7 and 8. While the comment does not explicitly mention specific sections or figures, the authors can infer that it pertains to the introduction, method, and experimental sections, as well as Figures 3, 7, and 8. The feedback is specific in detailing what needs to be improved, such as the structure and the focus on the IEM. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to follow and recommends improvements to the structure and visualization of certain figures. However, it does not provide specific examples or detailed reasoning to support why the structure is confusing or why Figure 3 is considered the main figure. The suggestion to improve the visualization of Figures 7 and 8 is also not substantiated with detailed feedback. Without explicit examples or detailed explanations, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the structure of the paper and the clarity of certain figures. It suggests a reorganization of the sections to enhance readability and provides specific feedback on the need for more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment offers suggestions for improving the visualization of Figures 7 and 8. While the feedback is specific and actionable, it could be more helpful if it provided detailed guidance on how to achieve these improvements. Overall, the comment is 4 as it provides clear directions for enhancing the paper, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. While the comment implies that the authors should expand their discussion to include comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion of related work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This provides clear guidance on what the authors need to address in their discussion of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. However, the comment does not provide specific examples or references to support the claim that a more detailed discussion is necessary. Without additional context or evidence, the authors may find it challenging to understand the extent of the improvement needed. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This feedback is 3 as it identifies a specific area for improvement in the paper, namely the need for a more nuanced and detailed discussion of related work. However, the comment lacks specificity in terms of what aspects of the related work should be discussed or how the differences should be highlighted. To be more helpful, the comment could provide examples or specific suggestions on how to enhance the discussion of related work. Therefore, the comment is rated as 3, as it points out a potential area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that this would be an interesting addition, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the introduction. The authors might infer that it relates to the experimental setup, but this inference is not explicit. The comment is specific in its suggestion to explore other architectures and tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, the comment does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it would enhance the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it provides a direction for potential future work that could enhance the scope and applicability of the study. However, the comment lacks specificity and does not offer guidance on how to conduct these additional experiments or what specific tasks or architectures should be explored. To be more helpful, the comment could include suggestions on which tasks or architectures might be particularly relevant or how to structure the additional experiments. Therefore, the comment is rated as 3, as it points out an area for improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It also raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. While the comment does not provide specific instructions on how to address this issue, it clearly identifies what information is needed and highlights a potential problem. The authors are given a clear action to take, which is to provide the final learning rates and address the concern about the optimal learning rate. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the final used learning rates and the concern about the optimal learning rate being outside the tested interval. This provides clear guidance on what information is required and what potential issue needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a factual request for additional information and does not contain any claims or opinions. The second part raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. This part is a claim that requires justification. However, the comment does not provide specific reasoning or evidence to support this claim, making it difficult for the authors to understand and address the concern. Therefore, the comment is 4, as it contains a claim that is somewhat supported by the request for additional information but lacks detailed justification.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a relevant and actionable suggestion that can help the authors ensure the accuracy and reproducibility of their results. Additionally, the comment raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. This raises an important point that the authors should consider. However, the comment could be more helpful if it provided specific guidance on how to address this concern or suggested alternative methods to test the optimal learning rate. Overall, the comment provides clear and actionable feedback, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so or offer specific guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should have more impact on each other compared to distant nodes. It requests the authors to explain why the absence of locality bias in transformers is not a concern. However, the comment does not specify which part of the paper this concern relates to, making it weakly grounded. The authors might infer that it pertains to the methodology or discussion section, but this is not explicitly stated. The comment is specific in detailing the concern about locality bias and its potential impact, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment highlights a potential issue, it lacks specific evidence, examples, or references to support the claim that transformers without locality bias are not suitable. The reasoning is based on a general observation about information propagation, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment identifies a potential issue and prompts the authors to provide an explanation, it lacks specific suggestions or guidance on how to address this concern. The feedback is 3 as it highlights an area for improvement but could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data are processed. It explicitly suggests that this aspect should be clarified. However, the comment does not provide specific guidance on how to clarify this point or what aspects of the clarification are necessary. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the output of the algorithm depending on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output depending on the order in which the data are processed. It suggests that this aspect should be clarified, which is a valuable observation. However, the comment lacks specific guidance on how to address this issue or what aspects of the clarification are necessary. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to clarify the impact of the mitigation strategies on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and questions whether these strategies significantly impair the model\"s utility. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of the mitigation strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these strategies or how they are implemented, making it weakly grounded. The comment is specific in its concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The suggestion that these strategies might impair the model\"s utility is not substantiated with evidence or references, leaving the authors without a clear path to improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies proposed in the paper, specifically questioning their impact on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is a critical consideration for the authors to address. The comment suggests that these strategies might significantly impair the model\"s utility, which could deter their adoption. While the comment points out an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the potential impact of their mitigation strategies, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of understanding regarding the reason for using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is necessary for their problem. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the crossvalidation method should be explained. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the use of 6fold crossvalidation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper and questions the necessity of this method, given that other papers in the comparison did not use it. However, it does not specify which part of the paper discusses the crossvalidation or where the comparison to other papers is made. This lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in questioning the reason for using 6fold crossvalidation, but it is 1 because it does not provide a clear reference to the relevant sections. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. The reviewer provides a logical reasoning by pointing out the absence of crossvalidation in other papers, which raises a question about the justification for its use in the current study. However, the comment lacks specific references or examples to support the claim that other papers did not use crossvalidation, making it 3. The authors would need to provide additional context or references to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is required for their problem. This feedback is 3 as it points out a gap in the paper\"s justification and encourages the authors to provide a rationale for their choice of crossvalidation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other papers justify their use of crossvalidation. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two issues with the results presented in Table 2: the lack of consistent performance improvement over baselines and the unclear superiority of the proposed methods. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide specific guidance on which experiments to perform or how to conduct them. The action is implicit and somewhat vague, as the authors know they need to address the issues but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the results, such as the lack of consistent performance improvement and the unclear superiority of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods due to the lack of consistent performance improvement and the unclear superiority of the proposed methods. The reviewer provides a logical reasoning by pointing out that the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a strong foundation for the claim but lacks detailed examples or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three. It also points out the lack of a consistent trend in the results, making it unclear which proposed method is better. This feedback is clear and actionable, as it highlights a critical weakness in the paper\"s experimental validation. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims made in the paper. This constructive feedback provides the authors with a clear direction for improving their draft by addressing the identified shortcomings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the presence of combinatorial and heuristic aspects in the proposed framework, particularly in the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information on the impact of these components, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should clarify the impact of the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed framework for ReC, specifically mentioning the NonAmbiguous Query Generation procedure. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights the impact of heuristic components, particularly the sophisticated filtering template used in the procedure. This provides clear guidance on what needs to be clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC, but it also notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components, particularly the NonAmbiguous Query Generation procedure. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s effectiveness in engineering methods for ReC but points out the presence of combinatorial and heuristic aspects, particularly in the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. This feedback is clear and actionable, as it directs the authors to address a specific area of potential concern and provides a clear path for improvement. By addressing this feedback, the authors can enhance the clarity and robustness of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method\"s ability to be trained without camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or explanation. However, the comment does not provide explicit guidance on how the authors should address this issue or what additional information or analysis is needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details or evidence to support their method\"s applicability without camera information, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue by questioning the feasibility of training the proposed method without camera information and asking how the authors know where the ray comes from. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s ability to be trained without using camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or evidence. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the method cannot be trained without camera information. This makes the claim 3, as the authors would need to provide additional information or evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the proposed method\"s ability to be trained without using camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or evidence. This feedback is 3 as it identifies a potential weakness in the methodology and prompts the authors to address this issue. However, it lacks depth and does not provide specific suggestions or guidance on how to resolve the concern. The authors are left with a general understanding of the problem but without detailed steps on how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that a detailed comparison is needed, it does not provide explicit instructions on how to conduct this comparison or which specific aspects should be compared. The action is implicit and somewhat vague, as the authors can infer the need for a detailed comparison but lack concrete guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to include a detailed comparison of time complexity and competitiveness, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is 3 as it identifies a specific area for improvement that could enhance the paper\"s comprehensiveness and relevance. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or which aspects of related work should be compared. To be more helpful, the comment could include examples of relevant works or detailed suggestions on how to structure the comparison. Therefore, the comment is rated as 3, as it points out a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the improvement in performance and computation speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific method, ODA, and its application to solve the MOIP problem. It highlights a gap in the explanation regarding how the presented method improves the performance and computation speed compared to using ODA alone. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely the lack of clarity on the improvement in performance and computation speed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method ODA, used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. The comment suggests that the authors should provide a more detailed explanation of the improvement. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the presented method does not improve performance or computation speed. This makes the claim 3, as the authors would need to infer the exact nature of the improvement that is lacking. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s presentation of the method ODA, which is used to solve the MOIP problem. It points out that while the method has learned to imitate the problemsolving method, it does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. This feedback is 3 as it highlights a gap in the paper\"s explanation, prompting the authors to clarify the improvement in performance and computation speed. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other methods have improved performance. Overall, the comment is 3, as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some figures are not selfexplanatory, specifically mentioning Figure 4 where the line of \"No adapt or Finetune\" is covered by other lines without additional explanation. This feedback implies that the authors should provide more context or explanation to clarify the meaning of these lines. While the comment identifies a specific issue, it does not explicitly instruct the authors to add explanations or clarify the lines. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the line of \"No adapt or Finetune\" is covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where the line of \"No adapt or Finetune\" is covered by other lines without additional explanation. This claim is 3 as it identifies a specific issue with the figure, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how it affects the clarity of the figure. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of certain figures, particularly Figure 4, where the line of \"No adapt or Finetune\" is covered by other lines without additional explanation. This feedback is clear and actionable, as it directs the authors to improve the clarity of their figures by providing additional explanation or context. However, the comment could be more helpful if it suggested specific ways to enhance the clarity, such as adding labels or annotations. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not thoroughly evaluated experimentally on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct additional experiments or evaluations. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental evaluation to address this concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. It notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section or supplementary material, but the lack of explicit mention of specific sections or tables makes it difficult to pinpoint. The comment is specific in detailing what is missing in the experimental evaluation, namely a careful comparison of sampling methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling process used to obtain different initializations x_0 is important for convergence to the optimum, but it is not evaluated carefully on the proposed benchmarks. The comment provides a specific example by mentioning that this aspect is only evaluated in Table 1 of the supplementary material, where it is compared to sampling from a uniform distribution. While the comment highlights a potential area for improvement, it lacks detailed reasoning or specific examples to fully substantiate the claim. The authors are left to infer the importance of this aspect and the need for further evaluation, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by highlighting the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not thoroughly evaluated experimentally on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is 3 as it directs the authors\" attention to a specific area that may require further investigation. However, the comment could be more helpful if it provided suggestions on how to conduct a more comprehensive evaluation or additional experiments to support the claim. Overall, the comment offers a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for only comparing computational cost with [9]. It suggests that the authors should provide further discussion on this aspect, but it does not explicitly instruct them to do so. The comment implies that the authors should clarify their methodology and provide a more detailed discussion, but it lacks specific guidance on how to address these issues. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for only comparing computational cost with [9]. It also questions whether computational cost is a significant contribution to the paper and a relevant issue in practical scenarios. However, the comment does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The authors can infer that the questions relate to the methodology section or the comparison section, but this is not explicitly stated. The comment is specific in detailing the issues with the comparison and the need for further discussion, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for only comparing computational cost with [9]. It questions whether computational cost is a significant contribution to the paper and a relevant issue in practical scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions. Without additional context or justification, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for only comparing computational cost with [9]. It also questions whether computational cost is a significant contribution to the paper and a relevant issue in practical scenarios. While the comment identifies areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider and potentially expand their discussion, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests two actions for the authors to take: conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method, and conducting experiments on the full dataset instead of the lowresource regime. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is 5 because it offers concrete steps for the authors to follow, ensuring they know exactly what changes to make to enhance their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lack of experimental results on more datasets\" and provides specific suggestions for improvement, such as conducting experiments on more datasets and evaluating the method on the full dataset instead of the lowresource regime. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also recommends evaluating the method on the full dataset instead of the lowresource regime. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more datasets are necessary or that the current evaluation is insufficient. The suggestion is 3 as it offers a clear direction for improvement but requires additional justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of experimental results on more datasets. It provides a clear and actionable suggestion for the authors to conduct additional experiments on more datasets to provide a more comprehensive evaluation of their proposed method. Additionally, the comment recommends evaluating the method on the full dataset instead of the lowresource regime, which could further enhance the robustness of the evaluation. This feedback is clear and provides the authors with a concrete direction for improving their draft, making it 4. However, it could be more helpful if it included specific examples of additional datasets or methods for comparison, which would further guide the authors in their experiments. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment identifies areas of concern, it does not provide specific guidance or suggestions on how the authors might clarify or simplify these aspects. The feedback lacks explicit instructions or concrete steps for improvement, leaving the authors uncertain about how to address the issues. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the clarity of the generic argument task and the random argument task, as well as the dataset transformation and experimental setup. However, it does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of clarity and the perceived cumbersome nature of the dataset transformation and experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to substantiate these claims, making it difficult for the authors to understand and address the issues. The absence of supporting evidence or references leaves the claim 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment highlights areas of concern, it lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. The feedback is 3 as it points out areas that need attention, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to compare the PL condition used in their work with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is explicit and provides a clear action for the authors to take, which is to compare their PL condition with the one in the referenced paper. The comment also specifies where the comparison should be made, namely, with the PL conditions proposed in the referenced work. This level of detail and specificity makes the action concrete, allowing the authors to understand exactly what needs to be done to address the comment. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"PL condition\" and references a specific paper, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This provides the authors with a clear indication of which part of their work the comment pertains to, making it fully grounded. The comment is also specific because it asks the authors to compare their PL condition with the one proposed in the referenced paper, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point asks for a comparison between the PL condition used in the paper and the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is clear and specific, as it identifies a particular aspect of the paper that needs further exploration or clarification. However, the comment does not provide any additional context, reasoning, or examples to support why this comparison is necessary or how it might impact the paper. The lack of detailed justification or references makes the claim 3, as the authors would need to independently verify the relevance and importance of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This feedback is specific and actionable, as it prompts the authors to consider the implications of their PL condition in the context of existing literature. By comparing their work with the referenced paper, the authors can gain insights into the novelty and relevance of their approach. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what aspects of the PL condition should be emphasized. Overall, the comment is 4 as it directs the authors to an important area for further exploration and comparison, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a significant gap in the paper\"s analysis, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, giving the authors a specific action to take: to include an analysis of the impact of additional parameters and computational effort. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly mentions the need for this analysis to provide a fair comparison with the baseline, which is [31, 33, *]. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically the discussion on computational effort and parameter impact. The comment is also specific, as it clearly specifies what needs to be addressed in terms of analysis and comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that the authors should provide this analysis for a fair comparison with the baseline. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains vague and 1, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It provides a clear and actionable suggestion for the authors to include this analysis for a fair comparison with the baseline. By highlighting this omission, the comment offers a concrete direction for improvement, making it 5. The feedback is specific and provides a clear path for the authors to enhance their draft, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions whether this trend holds across different model architectures and lacks theoretical evidence. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or theoretical evidence. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, specifically questioning the trend across different model architectures and the absence of theoretical evidence. However, it does not specify which part of the paper this analysis is found in, making it weakly grounded. The comment is specific in its critique of the analysis, clearly identifying what is lacking in terms of theoretical evidence and the need for further exploration across different model architectures. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, questioning whether this trend holds across different model architectures and lacking theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It questions whether this trend holds across different model architectures and lacks theoretical evidence. This feedback is 3 as it points out a potential weakness in the analysis, prompting the authors to consider whether their findings are robust and generalizable. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered guidance on how to strengthen the analysis. Overall, the comment provides a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their analysis. The questions posed are more of an inquiry than a direct action, leaving the authors without clear direction on what steps to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the potential information leakage in AutoAugment\"s policy and questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the implications and potential issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. The comment provides a logical inquiry that challenges the authors\" assumptions and suggests a potential area for further investigation. However, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their analysis. While it prompts the authors to consider important aspects of their work, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multimodal data. While the comment implies that this could be an interesting direction to explore, it does not explicitly instruct the authors to include this aspect in their work. The suggestion is vague and lacks concrete guidance on how to implement this idea, making it 3. The authors can infer that they might want to explore this direction, but the comment does not provide specific steps or examples on how to do so. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests exploring the use of tabular data as a modality, which is another popular form of multimodal data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors might infer that it relates to the discussion of multimodal data, but this inference is not explicit. The comment is specific in suggesting an interesting direction for exploration but lacks grounding, as it does not clearly identify the part of the paper where this suggestion should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that tabular data is another popular form of multimodal data and proposes exploring how the model works for tabular data. However, it does not provide any specific reasoning, examples, or references to support why this is an interesting direction or how it could be relevant to the paper. The claim lacks depth and does not offer a clear rationale for why this exploration would be beneficial. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multimodal data. While the comment identifies an interesting direction for exploration, it does not provide specific guidance or suggestions on how to incorporate this idea into the paper. The feedback lacks actionable steps or detailed advice, making it 3. The authors might find the suggestion intriguing, but without more detailed guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to take: \"add more analysis about the multilingual alignment of entity representations\" and suggests that \"it would be better to have visualizations or case studies for different types of languages such as language family.\" Additionally, it raises a specific question about the alignment of entities from lowresourced languages with highresourced ones. The comment is concrete, as it specifies what additional analysis and visualizations are needed, and it provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the analysis of entity representations, specifically the alignment of entity representations across different languages. It suggests adding more analysis on multilingual alignment and provides specific suggestions for visualizations or case studies to illustrate this alignment for different language families. Additionally, it raises a question about the alignment of entities from lowresourced languages with highresourced ones. This feedback is fully grounded as it explicitly mentions the \"languageagnostic characters of entity representations\" and the specific areas needing improvement. It is also specific because it provides clear guidance on what additional analysis and visualizations are needed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper has weak analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific suggestions for visualizations or case studies to illustrate this alignment for different language families. The comment also raises a question about the alignment of entities from lowresourced languages with highresourced ones. While the comment provides a clear direction for improvement, it lacks specific references or detailed examples to fully substantiate the claim. The suggestion for visualizations or case studies is a logical extension of the critique, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of weakness in the paper, namely the analysis of the alignment of entity representations across different languages, particularly in the context of multilingual alignment. It provides a clear and actionable suggestion for the authors to enhance their analysis by adding more detailed examination of this aspect. The comment also suggests the inclusion of visualizations or case studies to illustrate the alignment for different language families, which can help in better understanding and presentation. Additionally, it raises a question about the alignment of entities from lowresourced languages with highresourced ones, which could be an important consideration for the authors. Overall, the comment is 4 as it provides clear guidance on how to improve the analysis and presentation of the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While the action is explicit, it lacks concrete guidance on what specific details should be included or how they should be presented. The authors are aware of the need for more information on attention, but the comment does not provide detailed instructions on how to implement this suggestion. Therefore, the comment is 3, as it identifies a need for additional information but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in its suggestion to include more details on attention, but without grounding, the authors may struggle to identify the exact sections where this information should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While this feedback acknowledges the need for additional information, it lacks specificity and does not provide guidance on what specific details should be included or how they might enhance the paper. The suggestion is vague and does not offer actionable steps for the authors to take, making it 2. The authors are left with a general idea of what might be improved but without concrete direction on how to address it. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies two issues with the references list: duplicates and missing publication venues or years. This provides clear and concrete actions for the authors to take, such as removing duplicates and ensuring that all publications are correctly listed with their respective venues and years. The comment is specific in its guidance, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of duplicates in the references list and the missing publication venues and years of many papers. However, it does not specify which references are duplicates or which papers lack publication venues or years, making it weakly grounded. The comment is specific in identifying the issue of duplicates and missing information, but without explicit references or sections, the authors may find it challenging to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, the comment does not provide any specific examples or reasoning to support these claims, making it difficult for the authors to understand the extent of the issue or how to address it. Without detailed evidence or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: duplicates and missing publication venues or years. This feedback is clear and actionable, providing the authors with a straightforward list of tasks to address. By correcting these issues, the authors can improve the accuracy and completeness of their reference list, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it offered suggestions on how to avoid such issues in the future or provided examples of how to format references correctly. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it specifically points out the lack of clarity regarding the error bound. It also suggests that the authors need to analyze and compare their theoretical results to other comparable methods. This feedback provides a clear and direct action for the authors to take, which is to clarify the theoretical analysis and compare it with other methods. The comment is explicit and concrete, offering a clear path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, particularly the lack of clarity regarding the error bound and the need for comparison with other methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear what the error bound means. It provides a clear and actionable suggestion for the authors to analyze and compare their theoretical results with other comparable methods. This feedback is valuable as it directs the authors to a specific area of improvement, offering a clear path for enhancing the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it provided additional guidance on how to analyze and compare the results or suggested specific methods for doing so. Overall, the comment is 4, as it effectively highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudocode of the proposed method is missing. The first part of the comment suggests that the authors should provide an explanation for the observed performance difference, but it does not specify how or what information should be included in this explanation. The second part of the comment is explicit in stating that the pseudocode is missing, but it does not provide guidance on how to include it or what specific details should be included. Therefore, the comment is 4, as it provides a clear direction for the first issue but lacks concrete guidance for the second issue.", "grounding_specificity_rationale": "The comment addresses two specific issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. However, it does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the performance comparison and the missing pseudocode, providing clear guidance on what the authors should include or explain. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises two issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. The first part of the comment questions the performance difference, but it does not provide any specific reasoning or evidence to support this claim. The second part of the comment is more verifiable, as it references external works (S\u00f8ren Asmussen and Peter W Glynn, and P. Florence, C. Lynch, A. Zeng, O. A. Ramirez, A. Wahid, L. Downs, A. Wong, J. Lee, I. Mordatch, and J. Tompson) that discuss implicit behavioral cloning. However, the comment lacks detailed analysis or specific examples to fully substantiate the claim about the performance difference. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed reasoning or examples.", "helpfulness_rationale": "The review comment raises two important points. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a critical aspect of the paper\"s methodology and results. This question prompts the authors to provide a detailed explanation or analysis of this observation, which could enhance the paper\"s understanding and contribution. Second, the comment points out the absence of pseudocode for the proposed method, which is crucial for reproducibility and clarity. This feedback is actionable and provides specific guidance on what the authors need to include to improve the draft. Overall, the comment is 4 as it identifies key areas for clarification and improvement, but it could be more comprehensive by offering suggestions on how to address these issues. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of lowresource language pairs in finetuning a multilingual model and suggests using the R3F method to maintain generalization ability. It also mentions a specific improvement of 0.8 in lowresource language translations, but questions its practical significance. The comment provides a reference to a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could be used to support the argument. However, the comment does not explicitly instruct the authors to include this reference or discuss the implications of the R3F method in their work. While the suggestion is clear, the lack of explicit guidance on how to integrate the reference or apply the R3F method makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs in finetuning a multilingual model and mentions the R3F method as a potential solution. It also questions the practical significance of the claimed improvement of 0.8 in lowresource language translations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the practical significance of the improvement and suggesting a reference for further discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs in finetuning a multilingual model is not practical, as the improvement of 0.8 is insignificant. It also suggests using the R3F method to maintain generalization ability. The comment provides a reference to a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could support the argument. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the practical significance of the improvement. While the reference provides a basis for further exploration, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs in finetuning a multilingual model, questioning the practical significance of the claimed improvement of 0.8. It suggests using the R3F method to maintain generalization ability and provides a reference to a relevant paper for further discussion. This feedback is 3 as it highlights a specific area for improvement and offers a potential solution, but it could be more helpful if it included more detailed guidance on how to apply the R3F method or discuss the implications of the reference. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. While the comment implies that the authors should provide results for other types of noise, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their results to include other types of noise. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper mentions that their model can work well for a variety of image noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on images corrupted with Gaussian noise, despite the claim of working well for various noise types. This provides clear guidance on what aspect of the paper needs further clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. This is a logical question that seeks clarification on the authors\" rationale. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why this is a concern. As a result, the comment is considered 1, as it lacks the necessary justification or evidence to support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why only results on images corrupted with Gaussian noise are shown, given the claim that the model can work well for various image noise types. This feedback prompts the authors to consider expanding their experimental setup to include other types of noise, which could enhance the robustness and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as which types of noise to include or how to conduct the additional experiments. While it identifies a potential weakness, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. While the comment implies that this visualization would be beneficial, it does not explicitly instruct the authors to perform this task or provide specific guidance on how to create the visualization. The action is implicit and somewhat vague, as the authors need to infer that they should include a visualization and how to create it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The authors can infer that it pertains to the motivation or discussion of the research, but this inference is not explicit. The comment is specific in its suggestion to visualize the effect, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not provide any specific evidence, reasoning, or examples to support why this visualization would be beneficial or how it would enhance the paper. The claim lacks detailed justification or references to existing literature, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. This is a constructive suggestion that could enhance the paper by providing a clearer understanding of the research motivation. However, the comment lacks specific guidance on how to create the visualization or what aspects should be included. While it identifies a potential improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. While it implies that the authors should consider moving this content to the supplementary materials, it does not explicitly instruct them to do so or provide a rationale for why this would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should move the content to the supplementary materials. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"objective (3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests moving the empirical version of the objective to the supplementary materials, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. However, it does not provide any reasoning, examples, or references to support why this is the case. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. While this provides a potential area for improvement, it lacks specific guidance or reasoning on why this would be beneficial. The comment does not offer detailed feedback or suggestions on how to present this information or why it should be moved to the supplementary materials. As a result, the authors may find it challenging to fully understand and act upon this feedback. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a convoluted description of results and suggests that the authors need to simplify their language. It also provides specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication. The comment includes explicit references to external works, which provides concrete guidance on how to address the issue. This level of detail and specificity makes the feedback 5, as the authors know exactly what changes to make and where to find additional information. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the convoluted description of results, specifically mentioning the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This provides some grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or figure this description is found in. The comment is specific in suggesting that the authors simplify their language and provides references to related work for further exploration. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the convoluted description of results, suggesting that it could be simplified. It provides specific examples and references to related work, such as [1] and [2], which offer a basis for comparison and further exploration. The comment also questions the differences in figures and suggests that the authors check for useful communication. While the references provide some support, the claim could be strengthened by more detailed reasoning or examples of how the convoluted description affects the clarity of the results. Therefore, the comment is 4, as it provides a logical basis for the claim but lacks full detail.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted description of results, providing a clear example of where the language could be simplified. It suggests referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication, which offers actionable guidance for improving the clarity and coherence of the results section. The comment also provides specific references to external works, which can help the authors contextualize their findings and enhance their draft. However, the comment could be more helpful if it offered additional suggestions or examples on how to simplify the language or structure the results more effectively. Overall, the feedback is 4 as it provides clear direction for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the approximation error should be more clearly defined by providing a mathematical characterization. While the comment implies that the authors should clarify the definition of the approximation error, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to provide a mathematical characterization, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the definition of the approximation error, specifically mentioning the gap between objective values. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that a mathematical characterization should be provided to clarify the definition, which is a clear and actionable suggestion. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the definition of the approximation error is ambiguous and proposes providing a mathematical characterization to clarify it. However, the comment does not provide specific examples or references to support the claim that the definition is ambiguous. The suggestion to provide a mathematical characterization is a logical step to improve clarity, but without further justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the definition of the approximation error, noting that it is unclear unless the values are seen in the table. It suggests providing a mathematical characterization to clarify the definition. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the clarity of the paper. However, it could be more helpful if it provided examples of how a mathematical characterization could be applied or if it discussed the potential impact of this improvement on the paper\"s overall understanding. Despite this, the comment is 4 as it guides the authors toward a specific enhancement that could significantly improve the clarity and rigor of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the claim in lines 180182, suggesting that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This feedback implies that the authors should reevaluate or clarify their claim regarding the minimization of the expected convex surrogate. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or revise their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, which is that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This claim is 3 as it provides a logical reasoning based on the claim\"s content, suggesting that the authors need to clarify their claim. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further investigate or provide additional context to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim in lines 180182, noting that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This feedback is clear and actionable, as it points out a potential misunderstanding or misinterpretation in the paper. By highlighting this issue, the authors are prompted to reevaluate their claim and potentially revise it to clarify the relationship between uncertainty sampling and the expected convex surrogate. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative explanations. Overall, the comment is 4 as it directs the authors\" attention to a critical area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The feedback lacks concrete suggestions or steps for improvement, leaving the authors uncertain about how to enhance their model. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the simplicity of the evolution model. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average because the reassignment probability is 1/n, which allows for very slow dynamics. It also notes that the evolution model is simplistic as it only changes edges associated with the 1 node changing cluster on average. While the comment provides a logical explanation for the slow dynamics and the simplicity of the model, it lacks specific references or examples to fully substantiate the claim. The reasoning is clear but could be strengthened with additional evidence or references. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. This feedback is clear and actionable, providing the authors with concrete areas to address and improve upon. By highlighting these weaknesses, the comment offers valuable guidance for enhancing the model\"s dynamics and complexity. However, it could be more helpful if it suggested potential solutions or ways to address these issues. Overall, the comment is 4, as it effectively directs the authors\" attention to critical areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add missing details about the division of the dataset into training and test sets, including the numbers involved and the method used for division (e.g., random or other considerations). This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what information needs to be added to improve their draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"division to train and test sets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, such as the numbers involved and the method used for division. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft lacks detail, namely the division of the dataset into training and test sets. It points out that the numbers and the method used for division are missing, which is crucial information for understanding the experimental setup. By suggesting that these details should be added, the comment provides clear and actionable feedback that can help the authors improve the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have handled similar details. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions that the longtext input could restrict the scalability of the framework. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or formats for text descriptions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the current approach and the potential limitations, but without explicit references to sections, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the implications of these issues, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the current approach, specifically the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also points out that this could restrict the scalability of the framework. While the comment highlights an important area for improvement, it lacks specific suggestions or actionable steps for the authors to address this issue. The feedback is 3 as it points out a potential limitation but does not provide detailed guidance on how to overcome it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It suggests using tables to present the key improvements more intuitively and in detail. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3\" and \"table,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the performance improvement of the proposed methods is not significant and suggests using tables to present the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It also suggests using tables to present the key improvements more intuitively and in detail. However, the comment lacks specific examples or detailed reasoning to support the claim about the significance of the performance improvement. The suggestion to use tables is a logical recommendation but does not provide evidence or examples to substantiate the need for this change. Therefore, the claim is 3, as it provides a basis for the suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the improvement is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It also suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a specific area for improvement and offers a practical suggestion for enhancing the clarity and impact of the results. However, the comment could be more helpful if it provided additional guidance on how to effectively use tables to present the improvements or examples of how this could be done. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the positioning of the work with respect to related works. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental setup to include deeper networks and provide more details about the optimization strategy. The suggestion about layer redundancy is specific but does not offer detailed guidance on how to incorporate this into the paper. Therefore, the comment is 3, as it provides some direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses several specific issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, referencing a specific paper on layer redundancy. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises several concerns about the experimental validation, including the consideration of only shallow networks and the lack of description of the optimization strategy. It also points out a minor issue regarding the positioning of the work with respect to related works. The comment provides a specific reference to a related work on layer redundancy, which is the opposite of diversity, in the context of network pruning. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the experimental validation being unconvincing. While the reference to the related work provides some support, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several specific issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also points out a minor issue regarding the positioning of the work with respect to related works, referencing a specific paper on layer redundancy. While the comment provides clear and actionable feedback on areas that need improvement, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to enhance the experimental validation. Overall, the comment is 4 as it directs the authors to specific areas that require attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to prove new theoretical results. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not specify which part of the paper this claim pertains to, such as the methodology, results, or discussion sections. The authors may have to infer that it relates to the theoretical contributions or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of new theoretical results, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or references to existing literature, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s theoretical contributions, noting that the use of a novel type of loss in a specific setting does not result in any new theoretical results. This observation is relevant and could prompt the authors to reconsider the novelty of their work or provide a more detailed explanation of how their approach contributes to the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the theoretical aspects of their work. While it identifies a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment implies that the authors should investigate and provide evidence for their hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to support or refute the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. However, the comment does not specify which part of the paper this hypothesis relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area needing attention. While the comment is specific in terms of the hypothesis, it lacks grounding, as it does not point to a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point presents a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, suggesting that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion to provide evidence is a request for further analysis, which is not inherently verifiable. Therefore, the comment is 3, as it provides a basis for the claim but requires additional details to be fully substantiated.", "helpfulness_rationale": "The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment identifies a potential area for exploration and suggests a hypothesis, it lacks specific guidance on how the authors might gather or present this evidence. The feedback is 3 as it prompts the authors to consider a new perspective on their dataset, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, given that it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to other tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1 of bAbI. This provides some grounding as it allows the authors to identify the part of the paper being addressed, which is the testing methodology or results. However, the comment does not specify what needs to be addressed or improved in terms of testing on other tasks. It lacks specificity regarding the details of the testing or the potential issues that might arise from only testing on a single supporting fact dataset. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. However, it does not provide any evidence, reasoning, or references to support the claim that only Task 1 was tested or that testing on other tasks is necessary. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer any insights into why testing on other tasks might be important or what benefits it could bring. As a result, the comment is 3, as it prompts the authors to consider a potential limitation but does not fully support them in addressing it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the authors improve it by providing more illustrations and examples. While the action is explicit, the comment does not specify which parts of the section are particularly confusing or how the illustrations and examples should be incorporated. This lack of detail makes the action somewhat vague, as the authors know they need to improve the section but may not know exactly how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the section is difficult to follow and recommending the inclusion of more illustrations and examples. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is difficult to follow and recommends improvements by providing more illustrations and examples. However, the comment does not provide any specific examples or reasoning to support why the section is unclear or how the suggested improvements would enhance understanding. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending the inclusion of more illustrations and examples to enhance understanding. This feedback is actionable and provides a concrete direction for the authors to improve the clarity of their work. However, the comment could be more helpful if it offered specific examples of what types of illustrations or examples would be beneficial. Overall, the comment is 4 as it guides the authors toward a clear area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the technical contribution is limited because there is no significant extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need to be improved. As a result, the authors are left without any actionable steps to follow, making this comment 1.", "grounding_specificity_rationale": "The comment claims that the technical contribution is limited because there is no significant extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. The authors may have an idea of where this critique applies, but the comment lacks explicit grounding, making it difficult to pinpoint the exact area needing attention. Additionally, the comment does not provide specific details on what aspects of the technical contribution are lacking or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited because there is no significant extension based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution, specifically noting that there is no significant extension based on a typical model for the crossdomain recommendation setting. This feedback is 3 as it points out an area where the paper could be improved. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance their technical contribution. Without actionable advice or detailed feedback, the authors may find it challenging to address the critique effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. While the action is explicit, it does not provide specific guidance on how to implement these additions or what specific metrics or results should be included. The authors are aware of the need to include these baselines but may need more detailed instructions on how to execute this suggestion. Therefore, the comment is 4, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include fullysupervised baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any reasoning, evidence, or examples to support why this addition would be useful or how it would contribute to the understanding of the gap. Without such justification, the claim is not verifiable, as it lacks the necessary support to help the authors understand the significance of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. This is a constructive suggestion that could provide valuable insights into the performance of models under different supervision conditions. However, the comment lacks specificity regarding which models or specific metrics should be included in the baselines, leaving the authors with a general idea but no detailed guidance on how to implement this suggestion. While it points out an area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it identifies a potential enhancement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be timeconsuming, especially for problems with many objectives. The reviewer suggests that this could make LaMOO impractical for such problems. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze and possibly optimize the time complexity of the algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the time complexity of the proposed algorithm, particularly the calculation of the hypervolume in each step of LaMOO, and raises a concern about its practicality for problems with many objectives. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. The reviewer questions whether this could make LaMOO impractical for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the calculation of the hypervolume is timeconsuming or impractical. The reasoning is based on general observations about the complexity of the calculation, but without detailed evidence or analysis, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically focusing on the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be timeconsuming, especially for problems with many objectives, and questions whether LaMOO would become impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm that the authors should address. However, the comment could be more helpful if it provided suggestions on how to optimize the algorithm or mitigate the time complexity issue. Overall, the comment is 4 as it identifies a significant area for improvement but lacks detailed guidance on how to address it. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the dataset used in the experiments is small and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific guidance on how to address this concern. The authors are left with a general suggestion but without concrete steps or examples on how to implement it. Therefore, the comment is 3, as it identifies a potential improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses the issue of the small dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting a potential improvement, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the use of small datasets in the experiments and suggests that it would be more convincing to see results on medium or large datasets, such as ImageNet. However, the comment does not provide specific reasoning or evidence to support why this is a significant issue or how it affects the overall quality of the paper. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the use of small datasets in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. This feedback is 3 as it identifies a potential area for improvement in terms of dataset size, which could enhance the credibility of the results. However, the comment is vague and lacks specific guidance on how to address this issue or what improvements would be necessary. The authors are left with a general suggestion but without detailed instructions on how to implement it. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues and suggestions for improvement. It highlights the need for a more detailed discussion on the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. The reviewer suggests being honest and direct in the paper, which is a clear and explicit action. Additionally, the comment critiques the title as being too generic and vague, suggesting that the authors should be more precise. The reviewer also questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods, which are widely adopted. While the comment provides specific suggestions for improvement, it does not offer concrete guidance on how to address these issues or what specific changes to make. The authors are aware of the need for improvement but may need additional direction to fully implement the suggestions. Therefore, the comment is 4, as it provides clear guidance on what needs to be addressed but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of evolutionary methods, specifically mentioning the need for a more detailed discussion on leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and vague, suggesting that the authors should be more precise. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the title and the need for a more detailed discussion, but without explicit references to sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions for improvement. It claims that the limitations of evolutionary methods are not fully addressed, suggesting that there are deeper aspects to consider, such as leveraging state, reactiveness, and learning during an episode. The reviewer also critiques the title as being too generic and vague, suggesting that the authors should be more precise. Additionally, the comment questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods, which are widely adopted. While the comment provides some reasoning and references to support the claims, it lacks detailed examples or specific references to external works, making it 3. The authors would need to further explore the suggestions to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the limitations of evolutionary methods and the need for a more detailed discussion on leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and vague, suggesting that the authors should be more precise. Additionally, the comment questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods, which are widely adopted. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to improve their paper, but the feedback could be more actionable with detailed advice or examples. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer that they need to provide more details or explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can infer that these questions relate to the methodology or results sections, the comment lacks full grounding. It is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the paper, such as the synthesis of the focal stack and the handling of edges with depth discontinuities. These questions are not claims but rather requests for information or explanation. Therefore, they do not fit the criteria for a claim, and the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises important questions about the methodology and implementation details of the focal stack synthesis process. It specifically inquires about the forward model used to synthesize defocused images from a defocus map and an image, as well as how the edges with depth discontinuities are handled. These are critical aspects that could significantly impact the accuracy and effectiveness of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. While the comment implies that such justification is necessary, it does not explicitly instruct the authors to include this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include empirical evidence to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, which is that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this contribution is discussed in, making it weakly grounded. The comment suggests that empirical justification is needed for this claim, but it does not provide specific details on what kind of empirical evidence would be necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces, which is a departure from existing algorithms. However, the comment lacks specific examples or references to existing algorithms that the proposed algorithm differs from. This makes it difficult for the authors to understand the basis of the claim and how to address it. The absence of detailed evidence or references leaves the claim 3, as the authors would need to conduct additional research to fully understand and respond to the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential contribution of the paper, specifically that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces, which is a departure from existing algorithms. However, the comment suggests that the authors should provide empirical justification for this claim. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the empirical analysis or what kind of evidence would be necessary to support the claim. This makes the feedback 3, as it points out a potential weakness but does not offer detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and identical to BRPNAS. The comment further states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies specific issues with the approach, it does not provide explicit guidance on how the authors should address these concerns or improve their work. The feedback lacks actionable steps or suggestions for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment addresses specific components of the approach, such as the weak predictors used (MLP, Regression Tree, and Random Forest) and the sampling strategy (epsilongreedy and similar to BRPNAS). It also references Table 2 in Appendix C to show the similarity in results between the proposed WeakNAS and BRPNAS. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific in detailing what is not novel and how the results compare to existing work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and identical to BRPNAS. The comment provides references to specific works ([2, 3, 7]) and cites BRPNAS [5] to support its claim. This level of detail and evidence makes the claim 4, as it provides a clear basis for the assertion. However, the comment could be strengthened by including more specific examples or detailed comparisons to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the novelty of the approach, noting that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before for NAS performance prediction. It also points out that the sampling strategy is similar to epsilongreedy and identical to BRPNAS, suggesting that the results of the proposed WeakNAS are almost the same as BRPNAS. The comment provides references to specific works ([2, 3, 7] and BRPNAS [5]) to support its claims. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their approach. While it highlights areas for improvement, it does not offer concrete steps or recommendations for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. It explicitly recommends that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a specific action to take: to include a detailed comparison with RMED in their paper. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed S1DBED algorithm, suggesting that it is too similar to RMED (Komiyama et al. 2015). It recommends that the paper needs to give a sufficient discussion on the comparison with RMED. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the discussion or results sections where the proposed algorithm is presented. The comment is specific in its suggestion to provide a detailed comparison, but it lacks full grounding as it does not directly reference a section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. The reviewer supports this claim by referencing a specific work (RMED) and implying that the comparison with this work is necessary to demonstrate the novelty of the proposed algorithm. However, the comment lacks specific details or examples of the similarities between the two algorithms, which would strengthen the claim. The mention of RMED provides some context, but the lack of detailed comparison or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to demonstrate the novelty of the proposed algorithm. This feedback is clear and actionable, as it directs the authors to address the lack of novelty by providing a detailed comparison. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what aspects should be emphasized. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or what aspects of the discussion are lacking. This lack of detail makes it difficult for the authors to understand exactly what needs to be addressed or how to improve their draft. The comment is vague and does not provide concrete guidance, leaving the authors without a clear action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or sections of the paper are being referred to, making the comment weakly grounded. However, it is specific in pointing out the absence of a comprehensive discussion of previous work, which is a clear area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not give a comprehensive discussion of previous work on the topic. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand which previous works are missing or how to address the issue. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, noting that the authors do not provide a comprehensive discussion of previous work on the topic. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their contribution. However, the comment lacks specificity and does not provide guidance on which previous works should be discussed or how to expand the discussion. While it points out a critical area for improvement, it does not offer actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment implies that more details and a flow chart could be added to clarify the process, it does not explicitly instruct the authors to include these elements. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details and a flow chart to enhance clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, such as the OT sample selection process and the iterative nature of the EP module during training. It also mentions the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. However, it does not explicitly mention which section of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing more details and a flow chart to clarify the process. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. The comment suggests that adding more details and a flow chart would help readers understand the process better. However, it does not provide specific evidence, examples, or references to support the claim that these aspects are unclear or need clarification. The lack of detailed reasoning or references makes the claim 3, as the authors would need to infer the need for additional information based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. It suggests that adding more details and a flow chart would help readers understand the process better. This feedback is 4 as it identifies specific areas where the paper could be improved for clarity and comprehension. However, it could be more helpful if it provided suggestions on how to address these issues or offered examples of how to incorporate the requested details. Overall, the comment provides clear guidance on what needs to be improved, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the discussion of KG handling continuous tasks and the lack of experiments with continuous tasks. It also questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The comment implies that the authors should include these experiments to provide a more comprehensive evaluation of their methods. However, it does not explicitly instruct the authors to include these experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should include these experiments and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of experiments with continuous tasks despite discussing KG\"s handling of continuous tasks, and the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The authors can identify the relevant sections of the paper, as the comment explicitly mentions \"Section 7 in the appendix,\" providing full grounding. The comment is also specific because it clearly outlines what needs to be addressed: the inclusion of experiments with continuous tasks and the comparison of empirical performance to ConBO. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: first, that the authors discuss KG\"s handling of continuous tasks but do not conduct experiments with continuous tasks, and second, that the entropy methods for conditional optimization derived in Section 7 of the appendix are not included in the experiments. The reviewer suggests that the empirical performance of these methods should be compared to ConBO. While the comment highlights a discrepancy, it does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would improve the paper. The lack of detailed justification or references makes the claims 3, as the authors would need to infer the significance of these points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss how KG handles continuous tasks, there are no experiments conducted to validate this claim. This is a critical oversight that should be addressed to provide empirical evidence for the discussion. Second, the comment questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. It suggests that the empirical performance of these methods should be compared to ConBO, another method mentioned in the paper. This feedback is clear and actionable, as it directs the authors to include experiments that would enhance the paper\"s empirical validation and comparison. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4, as it identifies meaningful areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. Additionally, the comment mentions a minor point about the low jailbreaking percentage for certain LLMs, which is also a specific suggestion for improvement. Therefore, the comment is 5, as it provides both explicit and concrete actions for the authors to take.", "grounding_specificity_rationale": "The comment suggests including a comparison of the authors\" approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. It also mentions a minor point about the low jailbreaking percentage for certain LLMs. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or results section where the authors present their approach and its transferability. The authors can infer that it relates to the sections where the results are discussed, but the comment lacks explicit grounding. The suggestion to include a comparison is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. It also mentions a minor point about the low jailbreaking percentage for certain LLMs. The claim about the low jailbreaking percentage is 3 as it provides a specific observation, but it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion to include a comparison is logical and reasonable, but it could be strengthened with more detailed examples or references to support the need for such a comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two pieces of feedback. First, it suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is a clear and actionable suggestion that could enhance the paper\"s comprehensiveness and impact. Second, it mentions a minor point about the low jailbreaking percentage for certain LLMs, which could be relevant for the authors to address if it affects the overall results or conclusions. While the comment identifies specific areas for improvement, it could be more helpful if it provided additional context or suggestions on how to address these issues. Overall, the comment is 4 as it offers clear guidance on what the authors could include to strengthen their work, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it implies that the authors should provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between these concepts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the introduction of the importance of unsupervised feature selection from a diffusion perspective. It also raises a question about the difference between similarity and exit times, which is a relevant point for the authors to clarify. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the introduction or discussion sections, but this is not explicit. The comment is specific in questioning the difference between similarity and exit times, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. It does not contain any subjective opinions, claims, or suggestions that require verification. Instead, it is a request for clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it provides some insight but does not offer detailed or constructive feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not provide explicit guidance or suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore the capabilities of the framework in different contexts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate this inquiry. The comment lacks specific examples or references to external works that might address this concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. This is a relevant and insightful inquiry that prompts the authors to consider the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore these areas. While it identifies an important aspect for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It first asks for clarification on how the precision, recall, and F1score were calculated for the 4class classification of breast density. This is a direct request for additional information. Additionally, it suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection. The comment further recommends providing AUC results for comparisons, which is another explicit action. These actions are clear and concrete, giving the authors a specific path to follow for improving their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision, recall, and F1score for the 4class classification of breast density, and it also refers to the comparison of model performance with AUC, sensitivity, and specificity for breast cancer detection. This provides clear guidance on which parts of the paper need attention. The comment is specific because it details the need for additional information on the calculation methods and suggests a more informative way to report results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for clarification on the calculation of precision, recall, and F1score for the 4class classification of breast density, and a suggestion to report AUC with sensitivity and specificity for breast cancer detection. The first part is a request for additional information, which does not require verification. The second part suggests a more informative way to report results, which is a suggestion rather than a claim. Therefore, the comment is primarily factual and consists of requests for clarification, making it \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the methodology and reporting of results. It questions the calculation of precision, recall, and F1score for the 4class classification of breast density, suggesting that the authors clarify their methodology. Additionally, it recommends reporting AUC with sensitivity and specificity for breast cancer detection, which is a common practice in the field. This feedback is clear and provides the authors with a concrete way to improve their draft by offering more detailed and informative results. However, the comment could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is 4 as it guides the authors in enhancing the clarity and comprehensiveness of their results section."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the dataset creation is optional and mentions that the Kialo dataset is wellstudied and cleaner than the dataset created in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the creation of the dataset, specifically mentioning the Kialo dataset as an alternative that is wellstudied and cleaner than the dataset created in the paper. This provides some grounding as it allows the authors to understand the context of the comment, but it does not specify which part of the paper this feedback pertains to, such as a particular section or table. The comment is specific in suggesting that the created dataset can be additional data to learn from, but it lacks explicit references to the paper\"s content. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the creation of the dataset is optional and mentions the Kialo dataset as a wellstudied alternative. However, it does not provide any specific reasoning or evidence to support the claim that the Kialo dataset is cleaner or more suitable than the dataset created in the paper. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the creation of the dataset is optional and mentions the Kialo dataset as a wellstudied alternative that provides the exact information needed. It highlights that the Kialo dataset is cleaner than the dataset created in the paper, suggesting that the authors might consider using the Kialo dataset instead. However, the comment does not provide specific guidance or suggestions on how the authors could use the Kialo dataset or whether it should be included in the paper. While it identifies a potential alternative, it lacks actionable advice or detailed feedback, making it 3. The authors gain some insight into the dataset creation process but are left without clear direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also critiques the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the critique of the crosslayer modification and the limited improvement observed, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment lacks specific examples or references to support the claim that the crosslayer modification does not bring much insight or that the improvements are negligible. The reasoning is based on general observations and lacks detailed evidence or analysis, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel and questioning the significance of the crosslayer modification. It also points out that the ablation study results, specifically the limited improvement observed in the selfcross attention, suggest that the main improvements come from using a na\u00efve transformer rather than the proposed modification. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it identifies areas for concern, it does not provide actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, the comment is 3, as it highlights potential weaknesses but does not fully support the authors in addressing them."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. The comment explicitly requests the authors to address these weaknesses, providing a clear and direct action for improvement. It also includes specific suggestions on what needs to be added or changed, making the feedback 5. The authors are given a clear path to follow in order to enhance their draft, ensuring that they know exactly what steps to take to improve it.", "grounding_specificity_rationale": "The comment addresses the number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as the number of tasks and the presentation of results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include several tasks and present sequential results in terms of tasks learned rather than epochs. However, the comment does not provide specific examples or references to support the claim that the number of tasks is insufficient or that sequential results are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the limited number of tasks in the experiments. It suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing this comment, the authors can enhance the comprehensiveness and robustness of their experimental results. However, the comment could be more helpful if it included additional suggestions or examples of how to present the sequential results. Overall, the feedback is 4 as it guides the authors towards a significant improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and provides a specific direction for the authors to improve their experiments. The action is explicit and concrete, as it outlines exactly what additional experiments need to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments\" and \"sentence similarity tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what additional experiments are needed to enhance the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, without mentioning other tasks involving sentence pairs. The reviewer suggests that the authors should conduct experiments on more types of sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This claim is 3 as it provides a logical reasoning for the need to expand the experimental scope, but it lacks specific examples or references to support the claim fully. The authors would need to conduct additional research or provide more detailed justification to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope of the paper, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness and relevance of their experimental results. By addressing this suggestion, the authors can improve the robustness and applicability of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, which is an explicit action. However, it does not specify why this is important or provide guidance on how to include it. The comment also mentions minor issues with the abstract and Figure 2, but these are not actionable suggestions. Therefore, the comment is 3 as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment about the prompt being included in the appendix or supplement is somewhat specific as it suggests a particular section where the prompt should be placed. However, it does not specify which part of the paper this prompt is currently located in, making it weakly grounded. The comment is specific in its suggestion to include the prompt in the appendix or supplement, but without explicit references to sections, it is challenging for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, but it does not provide any reasoning or evidence to support why this is necessary or beneficial. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the rationale behind the suggestion. Without additional context or explanation, the authors may find it challenging to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 4 as it provides a clear and actionable suggestion regarding the inclusion of the prompt in the appendix or supplement. This feedback is specific and directly addresses a potential issue with the paper\"s organization, guiding the authors on how to improve the accessibility and organization of their work. However, the comment could be more helpful if it explained why the prompt should be included in the appendix or supplement, or if it provided additional guidance on how to present it effectively. Despite this, the comment is clear and actionable, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity does not appear in earlier layers. While the comment raises a valid concern about the rationale behind the analysis, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the motivation for their analysis or provide additional context. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in questioning the rationale behind the analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. This feedback is 3 as it prompts the authors to clarify their rationale for this specific choice, which could be important for understanding the methodology and results. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the analysis. To be more helpful, the comment could include specific questions or suggestions for further exploration or justification. Therefore, the comment is rated as 3, as it identifies a potential area for clarification but does not fully guide the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or action for the authors to take, such as recommending a specific method or approach to determine the parameter S. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about setting the parameter S, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper this comment pertains to, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of setting the parameter S, leaving the authors without clear direction. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any specific reasoning, examples, or references to support why this is a problem or how it affects the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue related to setting the parameter S, which is a problem that needs to be addressed. However, it does not provide any suggestions or guidance on how the authors might approach this problem or what steps they could take to improve their draft. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively support the authors in enhancing their work. Therefore, it is rated as 2, as it highlights a potential area of concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider including a human evaluation, it does not explicitly instruct them to do so or provide guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include a human evaluation and understand how to incorporate it into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this evaluation should be included in or how it should be conducted. The authors can infer that it relates to the evaluation section, but the comment lacks specificity in terms of what needs to be addressed or how to implement the suggestion. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, the comment does not provide specific examples or references to support the claim that automatic metrics are misleading. While the suggestion is logical, it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it identifies a potential limitation in the current evaluation approach and provides a suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the evaluation should be focused on. To be more helpful, the comment could include examples of how human evaluation could be implemented or what criteria should be considered. Overall, the feedback offers a direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or rephrase the claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" noting that the choice of employing specific constraints can be considered a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction\"s statement about shape constraints not requiring tuning a free parameter is technically true but suggests that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. This claim is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these constraints are indeed hyperparameters. The comment could be strengthened by providing more detailed examples or references to substantiate the claim, making it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and potentially revise it to accurately reflect the nature of the constraints. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to rephrase the claim. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that requires clarification."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, noting that the theoretical proof appears straightforward due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It suggests that the convergence proof lacks substantial novelty and rigor. However, the comment does not provide specific guidance on how the authors might address this issue or improve the proof. The action is implicit and vague, as the authors are left to infer that they need to enhance the proof\"s novelty and rigor but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Theoretical proof for convergence\" and references \"Assumption 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the convergence proof, noting that the proof appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The comment further explains that the convergence proof lacks substantial novelty and rigor, providing a clear rationale for the critique. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, based on the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a logical reasoning by referencing Assumption 4.1 and Modification 1 in Appendix C, which suggests that the convergence proof lacks novelty and rigor. This is supported by the reviewer\"s explanation of how the covariance matrix is derived and how it relates to the i.i.d. assumption. However, the comment could be strengthened by providing specific examples or references to similar works that might highlight the lack of novelty. Overall, the claim is 4 due to the logical reasoning and references provided, but it could be further strengthened with additional examples or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a clear explanation of how this leads to a lack of novelty and rigor in the proof. By pointing out this weakness, the comment offers a valuable insight that could help the authors improve the draft. However, the comment could be more helpful if it suggested ways to address this issue or provided guidance on how to enhance the proof\"s novelty and rigor. Overall, the comment is 4 as it highlights a critical area for improvement but lacks detailed suggestions for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the experimental setup borrowed from [2] is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, ensuring that they address this issue in their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup is not fully realistic. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it provides a direct suggestion for the authors to clarify this point in their draft. By addressing this issue, the authors can enhance the transparency and credibility of their experimental methodology. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested ways to mitigate the limitations of the semireal setup. Overall, the comment is 4 as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and model coverage to include other biases and stateoftheart generative models. However, the comment lacks concrete details on how to implement these changes, such as suggesting specific datasets or models to include. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on other important biases and stateoftheart generative models like GPT. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the comment pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as other biases and stateoftheart models, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these omissions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to expand the dataset or model coverage or provided examples of other biases and datasets that could be included. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a contradiction in the paper\"s statements regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly requests clarification on this apparent contradiction. However, the comment does not provide specific guidance on how the authors should address this issue or what additional information or analysis is needed to resolve the contradiction. While the action is clear, the lack of detailed instructions on how to implement the clarification makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the statements about the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly mentions these two statements, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies the contradiction and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a logical inconsistency by noting that the paper simultaneously claims both a performance loss for the multienv model and its outperformance due to knowledge sharing. This is a clear claim that requires clarification. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the specific statements being referred to, which adds to the complexity of addressing the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a logical inconsistency in the paper\"s claims regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. By pointing out this contradiction, the comment provides a clear and actionable suggestion for the authors to clarify their statements. This feedback is valuable as it helps the authors address a potential confusion in their paper, ensuring that their claims are consistent and wellsupported. However, the comment could be more helpful if it offered specific guidance on how to resolve the contradiction or suggested ways to clarify the statements. Overall, the comment is 4 as it directs the authors to an important area for clarification, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing them. While the comment implies that the authors should include more information about the metrics, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide more details or citations, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of metrics in the paper, suggesting that it is limited and recommending either an explanation of the metrics or a citation to them. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its suggestion to provide more information about the metrics, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation or citing the metrics. However, the comment does not provide specific examples or references to support the claim that the metrics are not adequately explained. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that either an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the metrics used. However, the comment could be more helpful if it offered additional guidance on how to explain the metrics or suggested specific references for the authors to consider. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. However, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the figure more understandable. The authors are left to infer that they need to clarify the workflow, improve the captions, and possibly rework the representation of communication modes, but the comment lacks concrete steps or examples. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issues with the figure, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and the representation of communication modes. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the workflow, captions, and representation of communication modes are unclear. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity of their figure, which is crucial for effectively communicating their workflow and findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending specific changes to the layout or labeling. Overall, the comment is 4 as it highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify or address this issue, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. This makes it difficult for the authors to pinpoint the exact area needing clarification. Additionally, the comment lacks specificity in detailing what aspect of the \"learned [MASK] embedding\" is unclear or how it is used in the SSL pretraining stage. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to clarify the issue or suggest why this is unclear. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any additional context or suggestions for clarification. The comment lacks actionable feedback or guidance on how the authors might address this issue or improve the clarity of their explanation. As a result, the comment is not helpful, as it does not offer the authors a clear path to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they should consider to make their results more original. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, it does not specify which part of the paper these results are reported in or which specific results are being discussed. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the issue of derivative results, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the reported results, suggesting that they may be partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. This feedback is 3 as it points out a potential area for improvement, specifically the need to differentiate the results or provide additional value beyond what is already known. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the originality of their work. To be more helpful, the comment could provide examples of how the authors might differentiate their results or suggest ways to make the extension more meaningful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the empirical analysis is based on static datasets, which may not fully align with the paper\"s objective. The reviewer implies that the paper should provide a more compelling motivation for the problem, but does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed motivation for the problem. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem of designing fast label aggregation algorithms in a streaming setting, specifically noting that the empirical analysis is based on static datasets. However, it does not specify which part of the paper lacks motivation or where the static datasets are used. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem of designing fast label aggregation algorithms in a streaming setting, as it does not discuss the applications where such algorithms are needed. The reviewer also notes that the empirical analysis is based on static datasets, which may not align with the paper\"s objective. However, the comment does not provide specific examples or references to support the claim that the problem is not wellmotivated or that the datasets are static. This makes the claim 3, as it lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s motivation and relevance. It points out that the paper\"s objective of designing fast label aggregation algorithms for a streaming setting is not adequately supported by a discussion of the applications where such algorithms are needed. Additionally, the comment notes that the empirical analysis is based on static datasets, which may not align with the paper\"s objective. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s motivation and methodology. By addressing this issue, the authors can improve the relevance and impact of their work. However, the comment could be more helpful if it provided suggestions on how to better motivate the problem or discuss the applications. Overall, the comment is 4, as it effectively guides the authors towards enhancing the paper\"s clarity and relevance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, suggesting that it is underspecified. It implies that the work focuses on injecting a CoTbased approach to smallscale Language Models, and if that is not the case, it points out that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. The comment also includes a clarification question, \"See Question A,\" which further guides the authors on what needs to be addressed. However, the comment does not explicitly instruct the authors to add specific CoT baselines or clarify the scope of the study. While the action is implicit, it is concrete and provides clear guidance on what needs to be done to improve the draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the scope of the study is underspecified and suggesting that additional relevant CoT baselines for incontext learning of Large Language Models are missing. The comment further clarifies this by referencing \"See Question A,\" which provides additional guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified, suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. The reviewer implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or examples makes the claim 3, as it requires the authors to infer the nature of the missing baselines and their relevance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. The comment also includes a clarification question, \"See Question A,\" which provides further guidance on what needs to be addressed. While the comment highlights a critical area for improvement, it could be more helpful if it suggested specific CoT baselines or provided examples of what should be included. Overall, the comment is 4 as it directs the authors to clarify the scope of their study and provides a starting point for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the figure\"s readability, such as suggesting changes in font size, color contrast, or layout. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the figure is \"very hard to read anything on the figure,\" which is a clear and specific description of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty of reading Figure 3, which is a claim that can be verified by the authors themselves. However, the comment does not provide any reasoning, examples, or references to support why the figure is hard to read or how it could be improved. This lack of supporting evidence makes the claim 3, as the authors would need to independently assess the figure\"s readability and determine how to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it does not provide any suggestions or guidance on how the authors might improve the figure\"s readability or what specific elements are causing the difficulty. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment implies that the authors should clarify or elaborate on this connection, it does not provide explicit guidance or suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the mention of tensor decomposition being harder in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what additional information should be included. The comment lacks depth and actionable feedback, making it 3. The authors are given a direction to explore but without detailed instructions on how to proceed, limiting the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences need rewriting to improve clarity. This provides clear and concrete actions for the authors to take, such as seeking English language review and revising sentences for clarity. The feedback is explicit and actionable, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the training of the GAT model, specifically mentioning that it is trained with the whole model. This provides some grounding as it refers to a specific aspect of the paper, but it does not specify which part of the paper this training is discussed in, making it weakly grounded. The comment is specific in suggesting that the model needs to be reviewed by an English native speaker and that some sentences need rewriting for clarity. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the GAT model is trained with the whole model, which is a claim that requires verification. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues: the training of the GAT model with the whole model, which may require further explanation or review, and the need for rewriting some sentences to improve clarity. While the comment points out areas that need attention, it lacks detailed guidance or suggestions on how to address these issues. The authors are given a starting point but would need to further explore and implement the feedback themselves. Therefore, the comment is 3, as it provides some direction but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to replace the expression `n^2/(2*s^2)` with an arbitrary parameter `lambda` and to clarify the justification for using a SGD learning rate of ~0.1. These actions are clear and concrete, as they specify exactly what needs to be done to improve the draft. The authors know exactly how to address these issues, making the comment 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the replacement of an expression with an arbitrary parameter `lambda` and the use of a SGD learning rate of ~0.1. It provides explicit references to lines 119121 and line 164, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be addressed, such as justifying the use of the SGD learning rate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two claims: the first claim suggests replacing an expression with an arbitrary parameter, and the second claim questions the justification for using a specific SGD learning rate. The first claim is 3 as it provides a suggestion for improvement but lacks specific reasoning or examples to support the need for this change. The second claim is more verifiable, as it questions the justification for a specific learning rate, but it could be strengthened with additional context or references to support the claim that the default value of Adam is different from the one used. Overall, the comment is 4, as it provides some reasoning but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improvement. It first recommends replacing the expression `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a clear and direct suggestion for enhancing the clarity and flexibility of the mathematical notation. Additionally, it questions the justification for using a SGD learning rate of ~0.1, noting that it is unclear why this value was chosen. This feedback is valuable as it prompts the authors to justify their choices and potentially refine their methodology. However, the comment could be more helpful if it provided additional guidance or examples on how to justify the learning rate choice. Overall, the comment is 4, as it identifies specific areas for improvement and offers clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. It also highlights the importance of error analysis in guiding subsequent improvements and expansions of the research. This feedback is explicit and concrete, giving the authors a clear direction on what to include in their paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section where this analysis should be incorporated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. This feedback is logical and provides a clear rationale for why error analysis is important, making it 4. However, it lacks specific examples or references to support the claim, which could strengthen the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offers guidance on how to provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their paper by addressing a critical aspect of model evaluation. However, the comment could be more helpful if it included specific examples or references to similar studies that have effectively used error analysis. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should analyze the domain gap and discuss the gap between datasets. It also recommends adding discussions about the adaption issue and the value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a clear direction for improvement, it does not specify which parts of the paper should be revised or how to implement these suggestions. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discusses the gap between datasets, suggesting that some datasets may be closer, making the adaptation issue less significant. It also recommends that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discusses the gap between datasets, recommending that some datasets may be closer, making the adaptation issue less significant. It also suggests that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. While the comment provides a logical reasoning for the suggestions, it lacks specific examples or references to support the claim about the datasets\" closeness or the potential value of finetuning on synthetic data. This makes the claim 3, as the authors would need to explore these suggestions further to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides valuable feedback by suggesting that the authors analyze the domain gap and discuss the gap between datasets. It highlights the importance of considering the closeness of datasets, which can affect the adaptation issue. Additionally, the comment suggests that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. This feedback is clear and actionable, offering specific areas for improvement and enhancement. However, it could be more helpful if it provided additional guidance on how to analyze the domain gap or discuss the datasets. Overall, the comment is 4 as it directs the authors to important aspects of their work that need further exploration and improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" claim that their work is NLPspecific, suggesting that it lacks specificity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach are not NLPspecific. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim that their work is NLPspecific, suggesting that it lacks specificity. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the claim but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" claim that their work is NLPspecific by questioning the lack of NLPspecificity in their approach. However, the comment does not provide specific examples or evidence to support this claim, making it difficult for the authors to understand or address the issue. The lack of detailed reasoning or references leaves the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It questions the lack of NLPspecificity in the approach, suggesting that the authors should clarify or substantiate their claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of their approach are not NLPspecific. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of the critique but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific work, [1], which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear and explicit action for the authors to take, as they are directed to include a comparison with an NCEbased method. The comment also offers a specific reference to guide the authors in their selection. Therefore, the comment is 5, as it provides a direct and concrete action for the authors to implement.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference for the authors to follow, making the comment fully grounded. The suggestion is also specific, as it directs the authors to include a comparison with an NCEbased method, which is a concrete action. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including at least one NCEbased method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the inclusion of an NCEbased method would enhance the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This feedback is clear and actionable, as it provides a specific recommendation for the authors to include a comparison with an NCEbased method. The reference to [1] offers a concrete example of how the authors could enhance their work by incorporating a relevant comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate this comparison effectively or what specific aspects of the NCEbased method should be emphasized. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear direction for enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two specific improvements to the experiment section: conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. These suggestions are explicit and provide clear guidance on what actions the authors should take to enhance their draft. The comment is concrete, as it specifies the types of tests and comparisons that would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with the most recent LLM. However, it does not specify which part of the experiment section this feedback pertains to, making it weakly grounded. The comment is specific in its suggestions for improvement, providing clear guidance on what actions to take. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. While the comment provides a logical suggestion for enhancing the experimental analysis, it lacks specific examples or references to support the claim that these additions would be beneficial. The reasoning is based on general knowledge about the importance of statistical significance and the relevance of recent LLMs, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiment section, suggesting that conducting a significance test on human evaluation results would enhance the analysis. Additionally, it recommends comparing the proposed method with the most recent LLMs, which is a relevant and constructive suggestion for expanding the scope of the comparison. However, the comment could be more helpful if it provided specific guidance on how to conduct the significance test or which LLMs to compare with. Overall, the feedback is 4 as it offers clear directions for enhancing the experimental section, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the authors\" claim that there is no research on joint error for UDA, suggesting that this problem has been studied in previous works, such as \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019. The reviewer explicitly instructs the authors to discuss this work and illustrate the relationship between it and the proposed method, as well as why their method is better. This feedback provides a clear and specific action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the authors\" claim about the lack of research on joint error for UDA and suggests discussing this previous work to clarify the relationship between it and the proposed method. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, referencing a specific work from ICML 2019. This claim is supported by a direct reference to a previous work that addresses the same issue, providing a clear and specific example. The reviewer also suggests that the authors discuss this work and illustrate the relationship between it and their proposed method, which adds depth to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to further substantiate the claim. Overall, the comment is 4 due to the clear reference to a previous work and the suggestion for further discussion, but it could be more robust with additional supporting details.", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" claim about the lack of research on joint error for UDA, pointing out that this problem has been studied in previous works, such as \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019. The reviewer provides a specific reference to illustrate the point, suggesting that the authors discuss this work and clarify the relationship between it and their proposed method. This feedback is 5 as it not only corrects a factual error but also offers a constructive suggestion for improving the paper by highlighting relevant prior work and encouraging a more comprehensive discussion. The comment empowers the authors to enhance their draft by addressing a potential oversight and providing a basis for further development. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a new, largescale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of dataset size on their results and potentially adjust their comparison accordingly. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a new, largescale dataset (209M) compared to existing methods that use smaller datasets. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison due to the scale of the datasets, which is a clear and actionable point for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods is unfair due to the use of a new, largescale dataset (209M) compared to existing methods that use smaller datasets. The reviewer provides a specific example, mentioning GEM, which uses only 20M unlabeled data. This provides some logical reasoning and a specific example to support the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or references to further substantiate the claim about the impact of dataset size on accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a new, largescale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. This feedback is 3 as it identifies a potential issue with the comparison and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it offered suggestions on how to address this concern, such as proposing alternative methods for comparison or ways to account for dataset size differences. Overall, the comment provides some actionable insight but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the need for a new curriculum learning method for text graphs, suggesting that existing methods could be applied. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the existing methods should be considered. The comment implies that the authors should explore why existing methods are not applicable, but it lacks concrete suggestions or steps for the authors to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the need for a new curriculum learning method for text graphs and questions why existing methods cannot be applied. The comment provides a clear direction for the authors to consider, namely, to discuss the research gap and why existing methods are not applicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified, as existing methods could be applied. However, the comment does not provide specific examples or references to existing methods that could be applied or why they are not suitable for text graphs. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion of curriculum learning methods, specifically questioning the need for a new method for text graphs. It points out that existing methods could be applied, suggesting that the authors should discuss the research gap and why existing methods are not applicable. This feedback is 3 as it highlights an area for improvement and provides a direction for the authors to consider. However, it lacks specific suggestions or examples on how to address the issue, which would make the comment more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This action is explicit and provides a clear direction for the authors to follow. It also offers concrete guidance on how to implement this change, making the comment 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to use pretrained language models and compare transfer parts, but without grounding, it is challenging for the authors to implement the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This claim is based on the observation that pretrained language models can overcome domainshift problems in the NLP field. However, the comment lacks specific references or examples to support the claim that these models are the most effective choice. While the suggestion is logical, it would be strengthened with additional evidence or references to make it 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s methodology. It suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This feedback is specific and offers a concrete way to enhance the paper\"s approach, making it 5 for the authors to improve their draft. By following this suggestion, the authors can strengthen their methodology and potentially enhance the results and conclusions of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or is simply due to more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to conduct a more effective ablation study. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more thorough ablation study to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or is merely due to more parameters, and notes that the current ablation study does not provide definitive answers. However, the comment does not specify which part of the paper discusses the proposed method or the ablation study, making it weakly grounded. The authors can infer that it relates to the method section or the ablation study, but this is not explicit. The comment is specific in detailing the issue with the current ablation study, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or is merely due to more parameters, and notes that the current ablation study does not provide definitive answers. However, the comment lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. The authors are left to infer that the study is not comprehensive enough, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically the complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, and notes that the current ablation study does not provide definitive answers to these questions. This feedback is valuable as it highlights a significant area for improvement in the paper, prompting the authors to conduct a more thorough analysis of their method\"s components and their contributions to performance. However, the comment could be more helpful if it provided specific suggestions on how to conduct a more effective ablation study or what additional analyses could be performed to address these concerns. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request provides a clear and direct action for the authors to take, as it specifies what aspect of the model they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the discussion of the sensitivity of any fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should focus on in their revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to discuss the sensitivity of fixed tuning parameters in their model, both in terms of strengths and weaknesses. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of any fixed tuning parameters in their model, both in terms of strengths and weaknesses. This feedback provides a clear direction for the authors to enhance their analysis and understanding of their model. However, the comment lacks depth and does not offer specific suggestions or examples of how to address this issue, which could make it more actionable. Therefore, the comment is 3, as it points out an area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. However, it does not provide explicit instructions on how to conduct these experiments or what specific policy gradient approaches to consider. The request for \"experiment results\" is somewhat vague, as it does not specify which experiments are being referred to or what additional information is needed. The comment lacks concrete details on how to implement the suggested exploration, making it 3. The authors can infer that they need to conduct additional experiments, but the lack of specific guidance on what to include in these experiments limits the actionability.", "grounding_specificity_rationale": "The comment suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional information about the experimental setup, which could help the authors address the suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies. However, it does not provide any reasoning, evidence, or references to support why this exploration is necessary or how it would impact the framework. The request for \"experiment results\" is vague and lacks specific guidance on what aspects of the experiments should be detailed. Without additional context or justification, the claim is difficult for the authors to understand and address, making it 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. This suggestion could potentially expand the scope of the study and provide additional insights into the framework\"s performance. However, the comment lacks specificity regarding which policy gradient approaches to consider or how the exploration should be structured. Additionally, it does not provide guidance on how to conduct these experiments or what specific results to expect. While the suggestion is intriguing, it does not offer detailed or actionable feedback, making it 3. The authors can gain some insight into potential areas for improvement but would need to further develop the suggestion themselves. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. While the comment implies that the authors should expand their evaluation to include additional datasets and tasks, it does not provide explicit instructions or guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and specify which datasets and tasks to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this evaluation is based on, nor does it provide details on which datasets or tasks should be considered. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and tasks. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, specifically noting that the analysis is conducted only on one dataset and one task. It suggests that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on how to select additional datasets or tasks or how to structure the analysis to accommodate multiple datasets. Overall, the comment is 4 as it guides the authors in improving their draft by expanding the evaluation scope."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing could be improved in some places, specifically mentioning two examples. The first example is the definition of \"relevant\" auxiliary model weights in definition 2.1, which the reviewer finds difficult to interpret. This feedback provides a clear and explicit action for the authors to take, which is to clarify the definition of \"relevant\" auxiliary model weights. The second example is not specified, but the first example gives a concrete action for the authors to address. Therefore, the comment is 5, as it provides a direct and concrete action for the authors to improve their writing.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the difficulty in interpreting the definition of \"relevant\" auxiliary model weights. The second example is not mentioned, but the first example provides a clear indication of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the writing is difficult to understand. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the writing, specifically mentioning the difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their work. However, the comment could be more helpful if it provided suggestions on how to improve the definition or offered examples of clearer phrasing. Overall, the comment is 4 as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA [1] as an alternative. While the comment identifies a potential issue and suggests a solution, it does not provide explicit instructions on how to address the concern or integrate ULiRA into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider using ULiRA and understand how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA [1] as an alternative. However, the comment does not specify which part of the paper discusses MIA testing or unlearning effectiveness, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not robust for privacy guarantees and suggests using ULiRA [1] as an alternative. However, the comment does not provide specific evidence, examples, or references to support the claim that MIA testing is not robust. The suggestion to use ULiRA is not accompanied by an explanation of why it is a better alternative or how it addresses the issue. Without detailed justification or references, the claim remains 1, making it difficult for the authors to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the effectiveness of MIA testing itself is not robust for privacy guarantees, which is a critical concern for the paper\"s claims. Additionally, the comment suggests using ULiRA [1] as an alternative, offering a specific recommendation for improvement. While the comment highlights a significant weakness in the methodology, it does not provide detailed guidance on how to integrate ULiRA or address the issue of MIA testing robustness. The feedback is 4 as it directs the authors to consider an alternative approach but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit guidance on how the authors should incorporate these suggestions or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these connections and present them in a different context. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact sections that need to be addressed. The comment is specific in its suggestion to explore connections with kernel regression and smoothing, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" This feedback is 3 as it points out a potential connection that the authors might explore, which could expand the scope of their work. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these suggestions or what specific aspects of the paper should be revisited in light of this connection. As a result, the feedback is 3, as it offers a direction for further exploration but does not fully address the authors\" needs for improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\"s superiority to competitors. The comment implies that a quantitive comparison on the final outputs could be more convincing. While the action is implicit, it is clear that the authors need to address this issue by providing a comparison of final outputs. The suggestion is concrete, as it specifies what needs to be done to improve the evaluation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitive evaluation results only reflect middle outputs and suggests that a comparison on final outputs would be more convincing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\"s superiority to competitors. The reviewer implies that a comparison on the final outputs would be more convincing, but the comment lacks specific examples or references to support this claim. While the suggestion is logical, it requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It points out that Figure 4 illustrates the comparison of final results with a single data sample, suggesting that the current evaluations are not convincing enough to confirm ModelAngelo\"s superiority to competitors. The comment implies that a comparison on the final outputs would be more convincing. While the feedback highlights an important area for improvement, it lacks specific suggestions or guidance on how to conduct this comparison or what aspects should be emphasized. The authors are left with a clear direction but without detailed instructions on how to implement it, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including qualitative explanations, minimal description of procedures in simulations or experiments, confusing figures, and the lack of statistical inferences with error bars or pvalues. It suggests adding more details to the paper or supplementary information to clarify the procedures and results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what additional details should be included. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the explanations being qualitative and the procedures being described minimally, as well as the confusion regarding the term \"sample count\" in the figure. The comment further suggests adding more details to the paper or supplementary information to clarify the procedures and results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanations are qualitative and that the procedures in simulations or experiments are described minimally or not at all. It also notes that some figures are confusing, such as the unclear term \"sample count\" in Figure 2. The reviewer suggests adding more details to the paper or supplementary information to clarify the procedures and results. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include error bars and pvalues for statistical inferences is a logical extension but is not explicitly supported by the comment. Therefore, the claim is 3, as it provides some guidance but requires additional explanation or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the qualitative nature of explanations, the minimal description of procedures in simulations or experiments, and confusing figures. It provides specific examples, such as the unclear term \"sample count\" in Figure 2, which helps the authors pinpoint where additional details are needed. The comment also suggests adding more details to the paper or supplementary information to clarify the procedures and results. Additionally, it emphasizes the importance of including error bars and pvalues for statistical inferences. This feedback is clear and actionable, offering the authors a roadmap for enhancing the clarity and rigor of their work. However, it could be more helpful if it provided specific suggestions on how to improve the explanations or what additional details should be included. Overall, the comment is 4, as it provides valuable insights and actionable steps for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that the authors should include references to support their claims. However, the comment does not provide explicit instructions on which references to include or how to integrate them into the paper. While the action is implicit, it is concrete because the authors know what needs to be done to address the feedback. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to add supportive references for claims that may be inspired from existing studies. The comment provides a specific example, mentioning the factors discussed in the lines, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that the authors should include references to support their claims. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the suggestion, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that some claims may be inspired from existing studies and recommending the inclusion of supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that the authors should include references to support their claims. This feedback is clear and actionable, as it guides the authors to strengthen their claims by referencing relevant studies. However, the comment could be more helpful if it provided specific examples of existing studies or detailed guidance on how to integrate these references into the paper. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their draft. The suggestion is concrete, as it specifies what needs to be added to the paper to enhance its comprehensiveness and utility for the community. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. While it does not specify which part of the paper this suggestion pertains to, it implies that it should be addressed in the methodology or results sections where these settings are typically discussed. The comment is specific in its suggestion to include these settings, which would help the community by providing a comprehensive review of the algorithm\"s advancements. However, the lack of explicit mention of a specific section makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback is based on the idea that providing these settings would help the community by offering a comprehensive review of the algorithm\"s advancements. However, the comment lacks specific examples or references to prior work that would support the need for this information. While the suggestion is logical, it requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback is clear and actionable, as it provides a specific way for the authors to enhance the comprehensiveness and utility of their work. By including these settings, the paper would better align with prior work and provide a more detailed review of the algorithm\"s advancements. This suggestion is valuable as it offers a concrete step for the authors to take to improve their draft, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an unclear aspect regarding the generalizability of the biases discussed in the paper. It mentions specific examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1), but questions the extent to which these situations are generalizable. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or clarify the generalizability of the biases. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence regarding the generalizability of these biases. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the unclear generalizability of the biases discussed in these sections. The comment provides a clear direction for the authors to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the biases discussed in the paper, specifically mentioning examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1). However, the comment does not provide specific examples or detailed reasoning to support the claim that these situations are not generalizable. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the generalizability of the biases discussed in the paper. It highlights that while the paper presents examples of biases in target statistics and prediction shift of gradient values, it does not provide clarity on the extent to which these situations are generalizable. This feedback is 3 as it points out a potential gap in the paper\"s analysis, prompting the authors to consider whether their findings are applicable beyond the specific examples provided. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provided additional context to clarify the generalizability of the biases. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide specific guidance on which datasets would be most useful or how they should be incorporated into the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks concrete details on what datasets to include or how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not specify which datasets are currently being used or which additional datasets would be most relevant. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs improvement. While the comment implies that the datasets section or methodology should be addressed, it does not provide clear guidance on what specific datasets should be added or how they would enhance the study. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide any specific examples or reasoning to support why additional datasets are necessary or how they would enhance the study. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets would be most relevant or how they could enhance the study. The feedback is 3 as it points out a potential limitation but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. While the comment implies that the authors should explore these unique tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding these unique tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment does not specify which part of the paper discusses the tasks or the dataset, making it weakly grounded. The authors can infer that it relates to the tasks or dataset sections, but this inference is not explicit. The comment is specific in suggesting unique tasks that could be explored, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment lacks detailed reasoning or evidence to support why these tasks are unique or how they would enhance the diversity of the dataset. The suggestion is based on a general observation rather than a comprehensive analysis or reference to existing literature. Therefore, the claim is 3, as it provides a specific example but lacks detailed justification or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the tasks presented in the paper, suggesting that they are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. This feedback is 3 as it offers a clear direction for the authors to explore more diverse tasks that could enhance the dataset\"s utility. However, the comment could be more helpful if it provided additional suggestions or examples of unique tasks that could be explored. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows the previous work, Luciddreamer. While it implies that the authors should clarify or correct this impression, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details or evidence to support the novelty of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the section on 3D Gaussians generation is novel or follows previous work, Luciddreamer. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows previous work, specifically Luciddreamer. The comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the section on 3D Gaussians generation, specifically in relation to the previous work, Luciddreamer. It prompts the authors to clarify whether there are any additional novel efforts or contributions in this part of the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The feedback is 3 as it directs the authors to consider the novelty of their work, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It also inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment raises important questions, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer the need for clarification or further exploration. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.3, binary classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues regarding the relevance of the framework to nonconvex losses and nonnorm type defenses, as well as the impact of the nonvanishing duality gap and maximization over nonnorm type constraints. Additionally, it questions the potential intuitions on the risk upperbound and the possibility of using the true mean to design a better defense. This level of detail provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or whether it still provides intuitions on the risk upperbound. The comment also questions the use of the true mean to design a better defense. While the questions are logical and could prompt the authors to consider these aspects, they do not provide specific evidence, examples, or references to support the claim that the algorithm is irrelevant or to suggest how it might still provide insights. The lack of detailed justification or references makes the claim 3, as it requires the authors to infer the implications of the questions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it questions whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment identifies areas for clarification and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is an explicit suggestion that provides a clear direction for the authors to explore. However, the comment does not specify how to implement this action or what specific aspects of the sparsification process to focus on. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014sparsifying the trained models and comparing their accuracy to the proposed model. This provides clear guidance on what needs to be done to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. However, the comment does not provide any reasoning, evidence, or references to support why this action might be beneficial or necessary. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This feedback is 3 as it provides a specific direction for the authors to explore, potentially leading to improvements in the model\"s performance or understanding. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of sparsification to focus on. To be more helpful, the comment could include additional context, such as the potential benefits of sparsification or how it might impact the model\"s performance. Therefore, the comment is rated as 3, as it provides a starting point for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, and the fixed radius with different scales. While the comment identifies these areas as needing more detail, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples for each of these aspects. However, the lack of specific guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lacks in detail about the techniques\" and provides specific examples of areas where more detail is needed, such as the sparsification process, generating landmarks on the edge, deciding the number of landmarks used, and the type of image features. This level of detail allows the authors to accurately identify the parts of the paper that require additional explanation. The comment is also specific in detailing what needs to be addressed, providing a clear path for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of areas where more detail is needed, such as the sparsification process, generating landmarks, and achieving shape invariance. However, the comment does not provide specific references, examples, or detailed reasoning to support these claims. While the examples are clear, the lack of detailed justification or evidence makes the claim 3. The authors would need to infer the extent of the issues based on the examples provided, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks detailed explanations about the techniques used, making it difficult for readers to reproduce the results. It specifically points out the sparsification process, which is crucial for extracting landmark features, and questions the generation of landmarks on the edge, the number of landmarks used, the type of image features, and the fixed radius with different scales. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed information to enhance the reproducibility and clarity of their work. However, the comment could be more helpful if it suggested ways to address these issues or provided examples of how to improve the explanations. Overall, the comment is 4 as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized, but it does not provide any specific guidance on how to reorganize it or what changes should be made. The action is implicit, as the authors can infer that they need to reorganize the section, but it lacks concrete details on how to do so. This makes the comment 3, as the authors know they need to address the issue but are left without clear instructions on how to proceed.", "grounding_specificity_rationale": "The comment suggests reorganizing the Appendix H section, but it does not specify which part of the paper this section is located in or what specific issues make it difficult to follow. Without this information, the authors cannot confidently determine which part of the paper the comment addresses, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the section are difficult to follow or how they might be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the Appendix H section should be reorganized because it is difficult to follow, but it does not provide any specific reasoning, examples, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance on what aspects of the section are unclear or how they might be improved. Without detailed feedback or examples, the authors are left without actionable steps to enhance the clarity and organization of the section. This makes the comment 3, as it identifies a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the paper\"s reproducibility, noting that while the pseudocode is provided in the supplementary material, it does not feel like the paper is written to be reproduced. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback implies that the authors should include these missing details to enhance the reproducibility of their work. However, the comment does not explicitly instruct the authors to add these details, leaving the action somewhat implicit. The authors are left to infer that they need to provide additional implementation details, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of reproducibility, specifically mentioning the lack of details about the RNN implementation, such as the number of units. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional details to enhance reproducibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, despite the presence of pseudocode in the supplementary material. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This claim is 3 as it points out a specific issue with the paper\"s reproducibility, but it lacks detailed examples or references to support the claim fully. The authors would need to infer the exact details that are missing, making the comment 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s reproducibility, noting that while pseudocode is provided in the supplementary material, the paper does not feel written to be reproduced. The reviewer highlights the need for additional details, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback is clear and actionable, as it points out a specific area where the authors can enhance the reproducibility of their work. By addressing this issue, the authors can significantly improve the utility and impact of their research. However, the comment could be more helpful if it provided suggestions on how to include these details or examples of how to structure the information for better reproducibility. Overall, the comment is 4, as it effectively guides the authors towards improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials. This feedback provides a clear and explicit action for the authors to take, which is to include error bars and more random trials in the figure. The suggestion is concrete, as it specifies what needs to be added to improve the figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of error bars and more random trials to strengthen the figure. This provides clear guidance on how to improve the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger if it included error bars and more random trials. This is a subjective claim as it is an opinion about the potential improvement of the figure. However, it does not provide any specific reasoning or evidence to support why these additions would strengthen the figure. Without further explanation or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving Figure 1 by recommending the inclusion of error bars and more random trials. This feedback is clear and directly addresses the potential enhancement of the figure, offering a concrete way for the authors to strengthen their data presentation. By following this advice, the authors can improve the clarity and robustness of their results, making the comment 5. However, it could be more helpful if it included additional guidance on how to implement these changes or why they are important. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section. It also mentions a specific issue with Figure 1, where it is unclear which points correspond to different learning rates in the left graph and different steps in the right graph. While the comment explicitly states these actions, it does not provide detailed guidance on how to address these issues or what specific information should be included in the introduction. The authors are aware of the need for clarification but may need additional guidance on how to implement these suggestions effectively. Therefore, the comment is 4, as it provides clear actions but lacks detailed instructions for execution.", "grounding_specificity_rationale": "The comment suggests that the authors provide a brief introduction to energy models in the related work section and mentions a specific issue with Figure 1 regarding the correspondence of points to different learning rates and steps. This provides some grounding as it references a specific section and figure, but it does not explicitly mention the exact part of the paper being addressed, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the introduction of energy models and the clarification of Figure 1. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and mentions a specific issue with Figure 1 regarding the correspondence of points to different learning rates and steps. The comment does not contain a claim or an opinion that requires verification. It is a request for clarification or additional information, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section, which is a constructive suggestion for improving the context of the paper. Additionally, it points out a specific issue with Figure 1, where it is unclear which points correspond to different learning rates and steps. This feedback is clear and actionable, as it directs the authors to address a specific gap in their paper and provides a clear path for improvement. However, the comment could be more helpful if it offered suggestions on how to clarify the figure or what specific information should be included in the introduction. Overall, the comment is 4, as it provides valuable guidance for enhancing the clarity and comprehensiveness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores could introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they might need to consider alternative approaches or metrics to mitigate these biases. However, the lack of concrete suggestions or specific actions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED for determining chunk significance, specifically mentioning the potential issue of introducing biases when basing eviction decisions solely on utility scores. However, it does not specify which part of the paper discusses this approach or where the potential biases might be discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in identifying the potential issue with the utilitybased approach and its implications, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the utilitybased approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential issue, it lacks specific examples or references to support the claim of introducing biases. The reasoning is based on a logical deduction, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It points out that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. This feedback is 3 as it highlights a specific area where the authors might need to consider alternative approaches or metrics to mitigate these biases. However, the comment lacks depth and does not provide detailed suggestions or examples on how to address this issue, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the first paragraph of the Introduction, stating that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a specific issue with the introduction, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should revise the introduction to better align with the paper\"s focus on drift detection. However, the comment lacks concrete details on how to restructure the introduction, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, which is that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a potential issue with the introduction, it lacks specific examples or references to support the claim that the introduction is not valuable. The reasoning is based on the reviewer\"s perception of the paper\"s focus, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. This feedback is clear and actionable, as it directs the authors to revise the introduction to better align with the paper\"s focus on drift detection. However, the comment could be more helpful if it provided suggestions on how to integrate the DNN introduction with the drift focus or offered examples of how to make the introduction more relevant. Overall, the comment is 4 as it highlights a significant issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how different parts of the framework contribute to the final result and suggests that the authors should provide either quantitative experiments or detailed explanations. While the comment identifies a specific area for improvement, it does not explicitly instruct the authors to conduct these experiments or provide detailed explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative experiments or detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of how different parts of the framework contribute to the final result, specifically mentioning the lack of quantitative experiments and detailed explanations in the result section. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, such as quantitative experiments and detailed explanations, which helps the authors understand the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of different parts of the framework and provides a suggestion for improvement. However, it does not provide specific examples or references to support the claim that the framework lacks detailed explanations or quantitative experiments. The mention of \"See questions\" implies that the authors should address these issues through additional questions, but without further elaboration, the claim remains 3. The authors would need to infer the specific areas needing improvement, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s clarity regarding the performance of different parts of the framework and their contribution to the final result. It points out the lack of quantitative experiments and detailed explanations, which is crucial for understanding the framework\"s effectiveness and potential improvements. The comment also suggests that the authors should provide either quantitative experiments or detailed explanations, offering a clear direction for enhancing the paper\"s clarity and comprehensiveness. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or present detailed explanations. Overall, the feedback is 4 as it highlights a critical area for improvement and provides actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to clarify this point. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the model\"s capabilities, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable feedback or suggestions for how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors present a simplified version of theorem 2 for the general audience, similar to theorem 1. While the comment implies that the current presentation of definition 2 and theorem 2 is difficult to understand, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should simplify theorem 2. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2 and theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding these sections for the general audience. The comment provides a clear direction for improvement by suggesting a simplified version of theorem 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of theorem 2 is difficult for the general audience, similar to theorem 1. However, it does not provide any specific reasoning, examples, or references to support why this is the case. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of theorem 2, suggesting that it might be difficult for the general audience to understand, similar to theorem 1. This feedback is 3 as it points out a potential area for improvement in terms of accessibility and clarity. However, the comment lacks specific suggestions or guidance on how to simplify theorem 2 or make it more accessible. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution than the current 224*224. While the comment implies that the authors should consider conducting experiments with different image resolutions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore different resolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the performance of experiments with larger image resolutions, specifically mentioning the current resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as a particular experiment or section. The authors can infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting a potential area for exploration but lacks grounding, as it does not pinpoint a specific section or experiment. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution than the current 224*224. However, the comment does not provide any evidence, reasoning, or references to support why this would be interesting or how it could impact the results. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for further exploration by suggesting that the authors consider conducting experiments with larger image resolutions than the current 224*224. This feedback provides a potential area for improvement or expansion of the study, encouraging the authors to investigate the impact of image resolution on the performance of their experiments. However, the comment does not offer specific guidance on how to conduct these experiments or what aspects to focus on, which limits its helpfulness. While it prompts the authors to consider an important aspect of their work, it could be more beneficial with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking what the \"keypoint mask averaged feature vector\" is and whether it is obtained by multiplying each feature map elementwise by H_psi. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this aspect in their draft. However, the comment is 3 because it directs the authors to a specific area that needs clarification, but it lacks concrete details on how to implement this clarification. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the nature of the \"keypoint mask averaged feature vector\" and asks whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific aspect of the paper, namely the calculation of the \"keypoint mask averaged feature vector.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the calculation of the \"keypoint mask averaged feature vector\" in the KeyQN section. It asks whether this vector is obtained by multiplying each feature map elementwise by H_psi. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, the comment could be more helpful if it provided additional context or suggested how this clarification might impact the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area that needs clarification, which is beneficial for improving the draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests making improvements to Figure 2 by distinguishing between different curves. It provides explicit guidance, recommending the use of styles like dashed lines or adding color to enhance the clarity of the figure. This feedback is clear and concrete, giving the authors a specific action to take to improve the figure. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in distinguishing between different curves. The reviewer suggests using styles like dashed lines or adding color to improve the figure\"s clarity. This provides clear guidance on how to address the issue, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 2 is difficult to distinguish between different curves and recommends using styles like dashed lines or adding color to improve clarity. This is a subjective observation, as it is based on the reviewer\"s perception of the figure\"s clarity. However, the comment does not provide specific examples or detailed reasoning to support why the figure is difficult to distinguish or how the suggested changes would improve it. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between different curves. It provides actionable suggestions by recommending the use of styles like dashed lines or adding color to enhance the clarity of the figure. This feedback is clear and provides a concrete way for the authors to improve the figure, making it 4. However, it could be more helpful if it included specific examples of how these changes would improve the figure or if it suggested additional ways to enhance clarity. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should tone down their claims in the introduction and not label the task as language learning, as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and provides a direct action for the authors to take, making it 5. The reviewer offers a specific suggestion for how to improve the introduction, which is concrete and actionable. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claims made in the introduction, suggesting that the task is more accurately described as a feedbackdriven QA rather than language learning. The comment provides a clear and actionable suggestion for the authors to tone down their claims and reframe the task description. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not accurate, as they are far from what has been achieved by the tasks and models. The reviewer suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog, rather than language learning. However, the comment lacks specific examples or references to support the claim that the task is not language learning or that it is more accurately described as a feedbackdriven QA. Without detailed reasoning or evidence, the claim remains 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are not aligned with the actual tasks and models discussed. It specifically points out the discrepancy between labeling the task as language learning and evaluating it on question answering. The reviewer provides a clear and actionable suggestion to tone down the claims and reframe the task description, which is a valuable piece of feedback for the authors to consider. This feedback is specific and actionable, offering a clear direction for improvement, making it 4. However, it could be more helpful if it provided additional context or examples to support the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or analysis to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the central contribution of modeling weight evolution using ODEs, particularly the problem of neural ODEs exhibiting inaccuracy while recomputing activations. It references a previous paper that first reported this issue, indicating that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need for more evidence or analysis to support the claim, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide specific references to the previous paper or detailed reasoning to substantiate the claim. This makes the claim 3, as the authors would need to investigate further to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the central contribution of the paper, which is the modeling of weight evolution using ODEs. It questions the issue of neural ODEs exhibiting inaccuracy while recomputing activations, suggesting that a previous paper first reported this issue. The reviewer expresses doubt about the problem and notes that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. This feedback is 3 as it highlights a potential weakness in the paper\"s contribution and suggests that the authors need to provide more evidence or analysis to support their claim. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue, such as recommending additional references or methods to substantiate the claim. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not explicitly instruct the authors to include this information or provide guidance on where or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should make this mention but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on why this information is important or how it could be incorporated into the paper. The feedback is 3 as it points out a potential area for improvement, but it does not offer actionable advice or examples, leaving the authors with limited guidance on how to address the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the paper\"s approach to proving lower bounds for round complexity, suggesting that the results follow easily from the reduction to collaborative ranking. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the approach to proving lower bounds for round complexity in the context of batched ranking problems. It mentions the exploitation of an easy reduction from collaborative ranking, which provides some grounding as it relates to a specific part of the paper. However, the comment does not specify which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the exploitation of the easy reduction, but without explicit references or detailed guidance, the authors may still struggle to pinpoint the exact part of the paper needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a major part of the work involved in proving results for batched ranking problems, and that the paper exploits an easy reduction from collaborative ranking, leading to easy corollary results. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach to proving lower bounds for round complexity in the context of batched ranking problems. It points out that the paper exploits an easy reduction from collaborative ranking, which may lead to the lower bound results being an easy corollary of these collaborative ranking results. This feedback highlights a potential weakness in the paper\"s methodology and suggests that the authors should consider whether their approach adequately addresses the complexity of the problem. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to fully utilize the potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment implies that the authors should consider using more sophisticated prompting techniques, it does not provide specific guidance on how to implement this suggestion or what constitutes a \"carefully curated\" prompt. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their prompting technique. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of a basic prompting technique in the study and suggests that using carefully curated prompts could lead to better results in generating systematic reviews. However, it does not specify which part of the paper discusses the prompting technique or where the authors might find guidance on improving it. This lack of explicit reference to a specific section or method makes it difficult for the authors to pinpoint the exact area needing improvement. The comment is specific in its suggestion to use carefully curated prompts, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of large language models (LLMs). However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with other studies or detailed explanations of how the current technique limits the potential of LLMs. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the study\"s use of a basic prompting technique, suggesting that more sophisticated prompting could enhance the results. It provides a specific suggestion by recommending the use of carefully curated prompts to improve systematic reviews. However, the comment lacks detailed guidance on how to implement this suggestion or what constitutes \"carefully curated\" prompts. While it offers a clear direction for improvement, the feedback could be more helpful with additional examples or detailed advice. Therefore, the comment is 3, as it provides a valuable insight but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger datasets, noting that compute might be an issue. It also mentions that maintaining probabilities could become problematic at large batch sizes but acknowledges that this aspect is not critical. The comment provides a clear suggestion for further experimentation and acknowledges the authors\" efforts in addressing concerns. However, it lacks specific guidance on how to conduct these experiments or what results to expect, making the action somewhat vague. The authors know that additional experiments are suggested but may not have a clear idea of how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger datasets, noting that compute might be an issue. It also mentions that maintaining probabilities could become problematic at large batch sizes but acknowledges that this aspect is not critical. The comment is fully grounded as it explicitly mentions \"larger data sets\" and \"probabilities,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what additional experiments could be beneficial and acknowledges the authors\" efforts in addressing concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests additional experiments on larger datasets, noting that compute might be an issue. It also mentions that maintaining probabilities could become problematic at large batch sizes but acknowledges that this aspect is not critical. The comment provides a logical reasoning for the suggestion, as larger datasets could provide more comprehensive results, but it lacks specific examples or references to support the claim. The authors are left with a general understanding of the suggestion but without detailed guidance on how to implement it or what results to expect. Therefore, the comment is 3, as it provides some reasoning but lacks comprehensive support.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, noting that compute might be an issue. It acknowledges the authors\" efforts in addressing concerns but also points out a potential challenge with maintaining probabilities at large batch sizes. While the comment identifies an area for improvement, it lacks specific guidance on how to conduct these experiments or what results to expect. The authors are left with a general understanding of the suggestion but without detailed instructions on how to implement it. Therefore, the comment is 3, as it provides a direction for further exploration but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the performance of the models in Table 4, noting that the performance on REC and RES is behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT. However, the comment does not explicitly instruct the authors to make any changes or improvements to their models or results. The action is implicit, as the authors can infer that they need to address the performance gap, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT. The comment provides specific examples of the performance achieved by these models, which helps the authors understand the scope of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES is behind more recent models, providing specific examples of other models that achieve better results. This claim is supported by references to GLaMM and UNINEXT, which provide concrete examples of the performance gap. The inclusion of specific references and examples makes the claim 4, as it offers a clear basis for the authors to understand and address the issue. However, the comment could be strengthened by providing more detailed comparisons or analysis of the performance differences, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that the results on REC and RES are behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT, which helps the authors understand the scope of the problem. However, the comment does not offer actionable suggestions or guidance on how to improve the performance of the models or address the identified gap. While it highlights a critical area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the phrase \"evidence\" in the comment might be too strong and proposes a more moderate statement like \"Fig.\" This feedback provides a specific suggestion for revising the language used in the comment, which is explicit and concrete. The authors know exactly what action to take to improve the clarity of their comment, making this feedback 5.", "grounding_specificity_rationale": "The comment addresses a specific part of the paper, specifically mentioning \"Fig. 5,\" which allows the authors to accurately identify the section being discussed. This provides full grounding. The comment also suggests a revision to the language used, indicating that the authors should use \"Fig.\" instead of \"evidence.\" This provides a clear and specific direction for improvement, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the phrase \"evidence\" in the comment might be too strong and proposes a more moderate statement like \"Fig.\" This feedback is based on a subjective interpretation of the comment\"s strength, which is not supported by any specific reasoning, examples, or references. The reviewer\"s suggestion is a matter of opinion and lacks detailed justification, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for revising the language used in the comment, suggesting that the phrase \"evidence\" might be too strong and proposing a more moderate statement like \"Fig.\" This feedback is clear and actionable, offering a concrete way for the authors to improve the clarity and precision of their language. By following this suggestion, the authors can enhance the effectiveness of their communication and ensure that their feedback is more impactful. However, the comment could be more helpful if it explained why the change is necessary or provided additional context for the revision. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. While the comment identifies a potential issue with the novelty, it does not provide explicit guidance or suggestions on how the authors might address this limitation or enhance the novelty of their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the video storyboarding approach, specifically mentioning the reliance on framewise SDSA and the similarity to ConsiStory. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or the introduction. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in identifying the limited novelty and the similarity to ConsiStory, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, as it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. The reviewer provides a specific comparison to ConsiStory, which helps to ground the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. The lack of specific references or detailed analysis makes the claim 3, as it provides a basis for the critique but requires further elaboration for full clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. While the comment points out a potential issue with the originality of the work, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their approach. Without actionable feedback or detailed advice, the comment provides only a vague insight into the paper\"s shortcomings, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weakness of the method might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not specify which part of the paper this observation pertains to, such as a specific section or experiment. The authors can infer that it relates to the method\"s performance or evaluation, but without explicit grounding, it is challenging to pinpoint the exact area. The comment is specific in its suggestion to compare the approach with previous work, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment lacks specific examples or references to support the claim that the method\"s weakness is more pronounced in these scenarios. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method, suggesting that its performance might be more challenging in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification in such datasets, which could provide valuable insights. However, the comment lacks specific guidance on how to address this issue or how to conduct the proposed comparison. While it points out an area for improvement, the feedback could be more actionable and comprehensive. Therefore, it is 3, as it provides a direction for the authors to consider but lacks detailed guidance on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to include this explanation or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should add more explanation but are not given concrete steps on how to implement this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its suggestion to provide more explanation of the bounds, but without grounding, the authors may struggle to identify the exact sections that need this additional explanation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional explanation is necessary or how it would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the bounds need clarification or how this additional explanation could enhance the paper. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or suggestions for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment implies that the authors should consider revising their explanation, it does not explicitly instruct them to do so or provide guidance on how to simplify the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should streamline the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels with OpenAI\"s Triton, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is in, making it weakly grounded. The comment is specific in its suggestion to simplify the explanation, but without explicit references to the paper, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the implementation of kernels with OpenAI\"s Triton is wellknown and does not require a fullpage explanation. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment identifies a potential area for simplification, it does not provide specific guidance or suggestions on how to streamline the explanation or what aspects of the implementation are particularly noteworthy. The feedback lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it points out a potential area for simplification but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. The comment provides specific examples of tasks (Walkerrun and manipulation scenarios) and highlights the need for clarity in the paper. However, it does not explicitly instruct the authors to make these clarifications or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) and suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or figures. While the authors can infer that it relates to the experimental setup or results, this inference is not as clear as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) to illustrate the point. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim about the zeroshot nature of the experiments or the limitations of transferability. While the examples provide some context, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) to illustrate the point and suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. This feedback is clear and actionable, as it guides the authors to make necessary clarifications in their paper to avoid misleading readers. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context for the authors to consider. Overall, the comment is 4, as it provides valuable insights and actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to test the method on larger backbones. The action is implicit and somewhat vague, as the authors need to infer that they should explore the method\"s performance on larger models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not specify which part of the paper discusses the experimental results or the proposed methods, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issue with the relative gains and suggesting a potential area for further exploration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed methods are not very strong, particularly on a small backbone ResNet50, where only a 1% gain is achieved. The reviewer suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to the smaller receptive field of ResNet50. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method would perform better on larger backbones. The suggestion is based on a plausible assumption but lacks concrete evidence or references to substantiate it. Therefore, the claim is 3, as it provides a logical basis but requires further elaboration or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL, which could be an area for further exploration. While the comment highlights a concern and provides a potential direction for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or conduct the necessary experiments. The feedback is 3 as it points out a potential limitation but does not offer detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of neural networks contributes less and suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies an issue with the analysis, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analysis of neural networks, specifically mentioning \"Section 3.2, 3.3,\" which provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies the issue by pointing out that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of neural networks, specifically noting that the analysis contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it points out a specific area where the paper could be improved. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance their analysis. Without additional context or detailed advice, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation. It also mentions that some datasets are large, which could limit the applicability of certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not explicitly instruct the authors to take any specific action, such as adding more datasets or explaining the limitations of the current dataset selection. While the feedback provides valuable insights, it lacks explicit guidance on how the authors should address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses the adequacy of the datasets used for evaluation, specifically mentioning the number of datasets for each task. It highlights concerns about the potential insufficiency of the datasets, particularly if some are too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or figures, making it weakly grounded. The feedback is specific in detailing the concern about dataset size and the need for more rigorous evaluation, but without explicit grounding, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This response provides additional context and justification for the authors\" dataset selection, which supports the claim. However, the original comment lacks specific examples or references to substantiate the claim about the insufficiency of the datasets. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This feedback is 3 as it identifies a potential limitation in the dataset selection and provides some context through the authors\" response. However, it could be more helpful if it offered suggestions on how to address the issue or if it provided specific examples of how the datasets could be improved. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while there is good performance on ImageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This suggests that the authors should include results with these larger models to provide a more comprehensive evaluation. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include results with larger models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of ResNet models on the ImageNet classification task, specifically mentioning ResNet50/34/18. However, it does not specify which part of the paper this information is presented in, making it weakly grounded. The comment is specific in pointing out the absence of results with larger models like ResNet101/152, which is a clear issue that needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is good performance on ImageNet classification with ResNet50/34/18, but no results are provided for larger models like ResNet101/152. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while there is good performance on the ImageNet classification task with ResNet50/34/18, there are no results for larger models like ResNet101/152. This observation is important as it highlights a potential limitation in the scope of the evaluation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of results for larger models or explaining why these results are not included. While it points out a weakness, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a confusing aspect in the paper regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting a rephrasing or clarification. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, referencing a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment also specifies the issue with the terms \"relatively inexpensive\" and \"expensive to evaluate,\" which are confusing in the abstract and introduction, respectively. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing in the abstract and introduction, respectively. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate,\" which are used inconsistently in the abstract and introduction. This feedback is specific and highlights a clear inconsistency that could impact the clarity of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing alternative phrasing or reorganization. While it points out a potential problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and whether it supports this claim through the experiments. It also asks if the proposed method requires subtaskspecific rewards, which would be similar to providing dense rewards. Additionally, it inquires about the ability of other methods (Qmix) to solve sparsereward tasks when given the sum of lowlevel rewards as the global reward. While the comment raises valid questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples, references, or detailed explanations, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it prompts the authors to consider additional aspects of their method, but it could be more actionable with more detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. While the comment does not explicitly instruct the authors to make a change, it does highlight a potential issue that needs to be addressed for a fair comparison. The authors can infer that they should clarify this aspect in their paper, but the action is not explicitly stated. The comment is 3 because it provides a clear direction for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. This question is specific and addresses a particular aspect of the paper, namely the training process and dataset usage. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not as clear as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. This question is logical and seeks clarification on a specific aspect of the methodology, which is relevant to the evaluation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for this clarification. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a critical question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. This is an important consideration for ensuring a fair comparison in the paper. By pointing out this issue, the comment provides the authors with a clear direction for improvement, specifically to clarify the training process and dataset usage. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to clarify this aspect. Overall, the comment is 4 as it identifies a significant area for improvement but lacks detailed guidance on implementation. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific guidance or suggestions on how to address these issues. The authors are left without clear instructions on what changes to make or how to improve their draft. The lack of actionable details makes it difficult for the authors to know how to proceed, leaving the comment 1.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes\" in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding the nature of the confusing mistakes or what aspects of the discussion and comparison are missing. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence or justification renders the claim 1, as it does not provide the authors with a clear path to improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies two main issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific examples or detailed guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights areas for improvement, it lacks depth and specificity, making it 2. The authors are left with a general understanding of what needs to be improved but without clear steps to take. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the unclear motivation for using an adversarial network in the model and the unfair comparison of experimental results due to the proposed model\"s larger size. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The lack of actionable suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the motivation for using an adversarial network in the model and the unfairness of the experimental results comparison due to the proposed model\"s larger size. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the motivation and the unfair comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises two concerns: the motivation for using an adversarial network in the model and the unfairness of the experimental results comparison due to the proposed model\"s larger size. The first claim about the motivation is 3 as it questions the necessity of the adversarial network, but it lacks specific examples or references to support this claim. The second claim about the unfair comparison is more verifiable, as it points out the size difference between the proposed model and others, which could affect the results. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network in the model and the unfairness of the experimental results comparison due to the proposed model\"s larger size. It highlights that the comparison is biased because the proposed model is equipped with newlyadded CAT and GAN, which makes it larger than other models. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation. While it points out important areas for improvement, the feedback is 3 as it provides a starting point for the authors to consider but does not offer detailed steps or examples for addressing these concerns. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and mentions specific examples of previous works that have performed well on this challenge. The comment also recommends comparing the paper\"s results to those of other approaches where corresponding publications are available. This feedback is clear and provides specific guidance on how the authors can improve their comparison and evaluation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as comparing the results on the official COOC leader board and the blind test set, and suggesting that the paper should at least compare to previous works where corresponding publications are available. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and suggests that the paper should at least compare to previous works where corresponding publications are available. The comment provides a specific reference to the COOC leader board and mentions previous works that have performed well on this challenge. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to investigate further to fully understand the basis of the claim and how it should be applied. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s evaluation. It identifies a gap in the comparison of the captioning experiment, specifically recommending that the results should be compared on the official COOC leader board, which includes the blind test set. The comment also references specific previous works that have performed well on this challenge, providing a benchmark for the authors to consider. Additionally, it suggests that the paper should at least compare to other approaches where corresponding publications are available, offering a comprehensive approach to evaluation. This feedback is detailed and constructive, offering the authors a clear path to enhance the robustness and relevance of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises questions about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the reliability of the results or what steps to take to investigate the discrepancy between MSE and MAE. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, particularly the concern about the reliability of the results due to the discrepancy between MSE and MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, such as specific examples, references to similar studies, or detailed reasoning about why this discrepancy is problematic. Without additional context or justification, the claim remains 1, as it lacks the necessary details to help the authors understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a problem but lacks actionable insights or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their methodology or suggest alternative approaches. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology section. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered novel or how the proposed meta algorithm differs from existing methods. Without this information, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. While it identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights a concern but does not provide actionable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what kind of adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a particular section, figure, or table. The authors may have to infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the need for an adversarial loss to address the issue, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is no adversarial loss to guarantee the perturbed data being similar to the authentic data. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. This is a critical point that could significantly impact the effectiveness of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what kind of adversarial loss could be used. While it highlights a potential weakness, it lacks actionable feedback, making it 2. The authors are left with a clear understanding of the problem but without a clear path to improvement. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. While the comment identifies a potential area of confusion, it does not explicitly instruct the authors to make this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms, but they are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the meaning of \"good,\" \"bad,\" or \"wrong\" explanations before using these concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"wrong\" used in the paper, suggesting that it lacks clarity. However, it does not provide any specific examples or reasoning to support why this term is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. This feedback is valuable as it points out a potential area of confusion for the reader and provides a clear direction for improvement. By addressing this issue, the authors can enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to clarify these terms or provided examples of what constitutes a \"good\" or \"wrong\" explanation. Overall, the comment is 4 as it identifies a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the samplebysample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, such as recommending specific methods for tuning or suggesting ways to mitigate the variability in hyperparameters. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the samplebysample optimization. However, it does not specify which part of the paper discusses these hyperparameters or how they are tuned, making it weakly grounded. The comment is specific in identifying the issue of hyperparameter tuning and the potential variability in optimal hyperparameters, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the need to tune multiple hyperparameters and questions the variability in optimal hyperparameters due to the samplebysample optimization. However, the comment lacks specific examples or detailed reasoning to support the claim about the variability in optimal hyperparameters. While it highlights a potential issue, it does not provide sufficient evidence or context to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some insight but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment identifies a critical issue related to the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the samplebysample optimization. This feedback is valuable as it points out a potential weakness in the methodology that could affect the robustness and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative methods for tuning or strategies to mitigate the variability in hyperparameters. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the limited number of methods used for performance comparison and the lack of consistency in the proposed method\"s performance. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. However, the comment does not explicitly instruct the authors to take any specific actions, such as suggesting which methods to include for comparison or how to analyze the inferior results. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance comparison and the consistency of the proposed method\"s performance compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than other methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s performance evaluation, noting that the comparison is limited to a few methods and that the proposed method is not consistently better than other methods. It highlights a potential inconsistency with the motivation of the study, suggesting that the authors should provide analysis for the inferior results. This feedback is clear and actionable, as it directs the authors to address a critical weakness in their work by expanding the performance comparison and offering explanations for the results. However, the comment could be more helpful if it provided specific suggestions on how to improve the analysis or which methods to include for a more comprehensive comparison. Overall, the comment is 4, as it effectively guides the authors towards enhancing the quality and rigor of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It suggests that this comparison is necessary to prove the superiority of the schema searched by the author\"s method (ELF) over the schema in Mid Vision Feedback (MVF). While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct this comparison or what specific metrics or experiments should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know how to execute them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically pointing out the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely a comparison with the image classification result of Mid Vision Feedback (MVF). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by stating that the absence of this comparison does not prove the superiority of the schema searched by the author\"s method (ELF) over the schema in Mid Vision Feedback (MVF). However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact comparison that should be made, which adds to the vagueness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a specific area where the authors can enhance their paper by providing a more comprehensive comparison. By suggesting the inclusion of this comparison, the comment offers a clear direction for improvement, making it 4. However, it could be more helpful if it provided additional guidance on how to conduct this comparison or what specific metrics should be used. Overall, the comment is valuable in guiding the authors towards a more robust evaluation of their method\"s contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While it identifies an area that needs attention, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or examples of what specific types of activities should be discussed or how they relate to occupant comfort and energy efficiency. As a result, the authors are left with a general understanding of what needs to be addressed but without clear instructions on how to implement the changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for more discussion on the types of activities and their importance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact areas that need improvement. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area that needs further exploration or discussion. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which types of activities should be discussed or how they relate to occupant comfort and energy efficiency. To be more helpful, the comment could provide examples or references to support the importance of these activities. Therefore, the comment is rated as 3, as it highlights a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the notation \"D\" should be used differently to avoid confusion between its representation as dimensionality of points and dilation factor. This feedback is clear and provides a direct action for the authors to take, which is to change the notation. The suggestion is concrete and actionable, as it specifies what needs to be done to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using different notation for \"D\" to avoid confusion between its representation as dimensionality of points and dilation factor. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to use different notation, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the notation \"D\" should be used differently to avoid confusion between its representation as dimensionality of points and dilation factor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity of the paper. Without such details, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the notation \"D\" is used to represent both dimensionality of points and dilation factor. This feedback is clear and actionable, as it suggests using different notation to avoid ambiguity. By providing a specific suggestion for improvement, the comment helps the authors enhance the clarity and readability of their draft. However, it could be more helpful if it included examples of how the notation could be changed or if it provided additional guidance on the specific sections where this issue is most prominent. Despite this, the comment is 4 as it directs the authors toward a clear and effective way to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of state, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions\" in the context of the paper. It suggests that more elaboration is needed to clarify this aspect. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to elaborate or what specific details should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the concept of state, questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" The comment provides a clear direction for the authors to elaborate on this aspect, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of state, specifically regarding the equivalence of \"elements\" to \"states\" or \"actions.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of state in the paper, particularly in relation to the elements and their equivalence to states or actions. It provides a clear and actionable suggestion for the authors to elaborate on this aspect, which could help clarify the paper\"s understanding of the state concept. However, the comment could be more helpful if it offered additional guidance or examples on how to elaborate on this concept. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section where this comparison should be made. The comment is specific in its suggestion to use a Jaccard index for comparison, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any reasoning, evidence, or references to support why this comparison would be interesting or beneficial. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This suggestion could provide additional insights into the effectiveness of the proposed scheme. However, the comment does not offer specific guidance on how to conduct this comparison or what aspects should be considered, leaving the authors with a general idea but without detailed instructions. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue in Section 5.3, where the use of a standard RGCN as a discriminator leads to generator collapse, while the proposed module does not. The reviewer suggests that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. However, the comment does not provide explicit instructions on how the authors should address this issue or what specific aspects of the proposed module prevent collapse. The action is implicit and somewhat vague, as the authors need to infer that they should explain the mechanism of the proposed method in more detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of a generator equipped with a standard RGCN as a discriminator collapsing after several iterations, while the proposed module does not. The comment further specifies that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN as a discriminator tends to collapse, while the proposed module does not. The reviewer suggests that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. However, the comment lacks specific evidence, examples, or references to support the claim that the proposed module prevents collapse. Without detailed reasoning or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is 3, as it provides a general observation but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 5.3, where the use of a standard RGCN as a discriminator leads to generator collapse, while the proposed module does not. The reviewer suggests that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. However, the comment lacks detailed guidance on how the authors should address this issue or what specific aspects of the proposed module prevent collapse. While it highlights an important area for improvement, the feedback could be more actionable by providing specific suggestions or examples. Therefore, the comment is 3, as it points out a significant issue but does not fully guide the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It raises a question about whether the current work is merely an extension or introduces novel contributions. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and vague, as the authors are left to infer that they need to demonstrate originality or differentiate their work from the previous study. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which part of the paper these similarities are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in questioning the originality of the work, but it lacks grounding as it does not point to specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the article\"s reasoning and writing logic bear similarities to a previous study, raising questions about the originality of the work. However, the comment does not provide specific examples or detailed comparisons to substantiate this claim. Without concrete evidence or references to the previous study, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. This feedback is 3 as it highlights an important aspect of originality that the authors should consider. However, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. To be more helpful, the comment could provide examples of where the similarities are most apparent or offer suggestions on how to demonstrate originality. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of these comparisons or what specific aspects need to be clarified. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper the comment addresses, making it weakly grounded. The comment is specific in identifying the need for clarity in the theoretical comparisons, but without grounding, it is difficult for the authors to pinpoint where to make improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the theoretical comparisons to adaptive learning of GPRGNN. However, it lacks detail and does not provide any suggestions or guidance on how the authors might clarify or enhance these comparisons. Without actionable feedback or specific examples, the authors are left without a clear understanding of what needs to be addressed or how to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer actionable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what alternative measures they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the evaluation or discussion of object hallucination, but this inference is not explicit. The comment is specific in its critique of the measurement approach, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. This feedback highlights a potential limitation in the evaluation methodology, prompting the authors to consider alternative measures or metrics for assessing object hallucination. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be more effective. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what needs to be improved, but the action is not directly stated, making it 3. The authors can infer the need for additional experiments, but the comment lacks explicit guidance on how to implement this suggestion. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the discussion section, specifically mentioning the \"verylongterm forecasting task\" and suggesting improvements by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. This provides some grounding as it refers to a specific part of the paper, but it does not specify which sections or figures are being discussed. The comment is specific in suggesting improvements to the discussion, such as conducting additional experiments and using the correct forecast horizon. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, the comment does not provide specific examples or references to support the claim about the task\"s practical significance or the need for additional experiments. The suggestion to use the \"correct\" forecast horizon is not elaborated upon, leaving the authors without clear guidance on what constitutes the \"correct\" forecast horizon or how it should be determined. Therefore, the claim is 3, as it provides a general direction but lacks detailed justification and examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical significance of the verylongterm forecasting task and suggests that the discussion could be improved by conducting additional experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is 3 as it points out a specific area for improvement in the paper\"s discussion section. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what constitutes the \"correct\" forecast horizon. While it offers a direction for enhancement, it does not fully empower the authors to make significant improvements to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also questions the impact of having only spatial or temporal/summary queries. This provides a clear and direct action for the authors to take, specifying what additional experiments and explanations are needed to address the key differences between the work and VideoChatGPT and other related works. The feedback is explicit and concrete, allowing the authors to understand exactly what needs to be added to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This provides clear guidance on what additional information is required to address the key differences between the work and VideoChatGPT and other related works. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. The reviewer questions the impact of having only spatial or temporal/summary queries. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim that these components are crucial or missing. The reasoning is based on the reviewer\"s understanding of the field, but without detailed evidence or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This feedback is clear and actionable, as it directs the authors to include additional experiments and explanations that would enhance the understanding of the key differences between the work and related studies like VideoChatGPT. By addressing this suggestion, the authors can provide a more comprehensive analysis and justification for their approach. However, the comment could be more helpful if it included specific examples or references to support the importance of these components. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detail on the innovation of the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify what aspects of the innovation should be detailed or how the authors should present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the innovation, but they are not given clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to identify the exact section being referred to. The comment suggests that the innovation should be detailed, but it does not provide specific guidance on what aspects of the innovation need to be elaborated upon. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovation should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed FRM, noting that it is a simple combination of channel and spatial attention mechanisms. It suggests that the innovation should be detailed, implying that the authors should provide more context or explanation to justify the novelty of their approach. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the innovation should be elaborated upon or how to present this information. While it highlights an area for improvement, it does not offer actionable advice or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider mentioning the social impact of increased automation or the risks associated with the dual use of their method, given that the authors state there are no negative social impacts. While the comment implies that the authors should address this aspect, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as it does not provide specific guidance on how to address the social impact. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number (379) where the authors state that they foresee no negative social impacts of their work. This provides clear guidance on where the authors should address this issue. The comment is also specific because it suggests that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim that their work has no negative social impacts and suggests that they should consider the potential risks from increased automation or the dual use of their method. However, the comment does not provide specific examples or references to support the claim that the work could have negative social impacts. The reasoning is based on the reviewer\"s personal belief, which lacks detailed justification or evidence. Therefore, the claim is 3, as it provides a logical basis for questioning the authors\" claim but lacks sufficient detail to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential oversight in the paper\"s discussion of societal impact, specifically questioning the authors\" assertion that their work has no negative social impacts. It suggests that the authors should consider the social impact of increased automation and the risks associated with the dual use of their method. This feedback is clear and actionable, as it prompts the authors to address a critical aspect of their work that may have been overlooked. However, the comment could be more helpful if it provided specific examples or references to support the potential risks. Overall, the comment is 4 as it guides the authors towards a more comprehensive analysis of their work\"s societal implications."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific action to improve the redundancy between Section 3 and Section 4 by rearranging the content. It provides a concrete suggestion to move the first paragraph of Section 4 to Section 3 and the remainder of Section 4 before Section 3. This explicit guidance gives the authors a clear idea of how to address the redundancy issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a rearrangement of content to reduce redundancy, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a rearrangement of content to reduce redundancy between Section 3 and Section 4. It provides a specific suggestion by recommending the movement of certain content from one section to another. However, the comment lacks detailed reasoning or evidence to support why this rearrangement would be beneficial or how it would improve the flow of the paper. The suggestion is based on a subjective judgment of redundancy, which could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides a logical suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a redundancy issue between Section 3 and Section 4 and provides a specific suggestion for rearranging the content to address this redundancy. By suggesting the movement of certain content from one section to another, the comment offers a clear and actionable way for the authors to improve the organization and flow of their paper. This feedback is valuable as it helps the authors enhance the clarity and coherence of their manuscript, making the comment 4. However, it could be more helpful if it included additional guidance on how the rearrangement might impact the overall structure or if it provided examples of how the content could be reorganized. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of connection between the improved variance control of prediction y^ and the smoothness of the loss landscape with zeroshot learning effectiveness. It suggests that the authors need to provide more details to clarify this connection. However, the comment does not explicitly instruct the authors on how to achieve this clarification or what specific details should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context or examples to strengthen the connection. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in detailing the issue of poor clarity and the need for more details to clarify the connection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" suggesting poor clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s clarity, noting that there is a lack of connection between the improved variance control of prediction y^ and the smoothness of the loss landscape with zeroshot learning effectiveness. It highlights the need for more details to clarify this connection, which is a valuable insight for the authors to consider. However, the comment does not provide specific suggestions or examples on how to improve the clarity or connection, leaving the authors with a general direction but without detailed guidance. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to perform these analyses or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for these analyses and how to carry them out. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the results section or discussion, but this inference is not explicit. The comment is specific in detailing what additional analyses or experiments are needed, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support why these analyses are necessary or how they would contribute to the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of the suggestion and how to implement it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is valuable as it points out a potential area for deeper investigation that could enhance the novelty and understanding of the paper\"s contributions. However, the comment lacks specific guidance on how to conduct these analyses or what aspects to focus on, which limits its usefulness. While it identifies a direction for improvement, the authors would need to further develop this feedback to fully address it. Therefore, the comment is 3, as it provides a clear direction for enhancement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for a citation where the kmax problem was discussed elsewhere in the paper. This is a clear and direct request for the authors to provide additional references or information, making the action explicit and concrete. The authors know exactly what information is needed to address the comment, ensuring full actionability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kmax problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a citation for where the kmax problem was discussed elsewhere in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for a citation, which is a factual statement rather than a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide a citation where the kmax problem was discussed elsewhere in the paper. This is a specific and direct request that helps the authors identify and address any potential gaps in their reference list or discussion. By following this feedback, the authors can ensure that their work is wellsupported and referenced, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it provided additional context or suggestions on how to find or include relevant citations. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a specific gap in their reference list."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. It explicitly asks for clarification on these aspects, providing a clear and direct action for the authors to take. The comment specifies what needs to be addressed, namely the estimation process and the reliability of the model, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what the authors need to include or clarify in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of information regarding the estimation of the function for the optimal sequence length and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by questioning the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide additional details or justification for their model\"s reliability. By addressing this issue, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it suggested specific ways to estimate the function or provide examples of how to assess reliability. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, noting that strong assumptions are made about the availability of camera parameters and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the applicability. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue of limited applicability due to assumptions, but it lacks grounding as it does not pinpoint the exact section of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide specific examples or references to support these assumptions or explain why they are limiting. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the applicability of the methods discussed in the paper, noting that strong assumptions are made about the availability of camera parameters and object segmentation. This feedback is valuable as it highlights an area that could impact the realworld utility of the proposed methods. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. While it points out a critical issue, it does not provide actionable steps or examples for the authors to consider. Therefore, the comment is 3, as it offers insight into a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to modify the statement \"thousands\" in the text to \"on the subword level.\" This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and how to implement the correction. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the phrase \"thousands\" is not accurate and recommending the addition of \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a correction to the text, specifically recommending the change from \"thousands\" to \"on the subword level.\" This is a factual statement that does not contain subjective opinions or claims, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the accuracy of a statement in the text. By recommending the change from \"thousands\" to \"on the subword level,\" the reviewer offers a clear and direct way for the authors to enhance the precision and clarity of their writing. This feedback is valuable as it helps the authors correct a potential misunderstanding or misinterpretation of their work. However, the comment could be more helpful if it explained why this change is necessary or provided additional context. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft, but it could be more comprehensive with additional explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is explicit and concrete, as it directly instructs the authors to provide the missing hyperparameters. The second issue is also explicit, as it requests clarification on the y value at x=0 and suggests further analysis using interpolations. However, the comment does not provide specific guidance on how to clarify the y value or what further analysis should involve. While the actions are clear, the lack of detailed instructions on execution makes the comment 4.", "grounding_specificity_rationale": "The comment addresses two specific issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. It provides explicit references to \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be clarified or improved, such as providing the missing hyperparameters and explaining the y value at x=0. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is a factual observation that requires clarification, while the second is a request for further analysis. The comment does not contain subjective opinions or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. It provides clear and actionable feedback by explicitly instructing the authors to provide the missing hyperparameters and clarifying the y value at x=0. Additionally, it suggests further analysis using interpolations, which could enhance the paper\"s depth and understanding. This feedback is detailed and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is 5, as it provides actionable guidance that can significantly enhance the paper\"s quality and clarity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions should be in the main sections rather than the appendix. While the comment explicitly states these actions, it does not provide specific guidance on how to restructure the paper or what changes to make. The authors are aware of the issues but lack detailed instructions on how to address them. Therefore, the comment is 4, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment addresses the issue of forward referencing in the paper, specifically mentioning Figure 1 and the need for clearer explanation of contributions in the Introduction. It also notes that supporting material for the main contributions is in the appendix, which is not in the main sections. This provides some grounding as it mentions specific sections and figures, but it does not explicitly name them, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the clarity of contributions and the placement of supporting material. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It also suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions should be in the main sections rather than the appendix. The comment provides specific examples, such as Figure 1 and the deeprag algorithm, which helps the authors understand the issue. However, it lacks detailed reasoning or references to support the claim fully. While the examples provide some context, the comment could be strengthened with more detailed explanations or references to substantiate the claim. Therefore, the comment is 3, as it provides some support but could be more robust with additional evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions should be in the main sections rather than the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and organization of the paper. By addressing these points, the authors can enhance the coherence and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to restructure the paper or provide examples of how to clarify the contributions. Overall, the comment is 4, as it directs the authors to improve the clarity and organization of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It specifically asks for an error bound in terms of epsilon, which is a clear and explicit request for additional information. The authors are given a direct action to provide this information, making the comment 5. The feedback is concrete and provides a specific direction for improvement, ensuring that the authors know exactly what needs to be addressed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the rounding of core tensors is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it questions the theoretical effect of rounding on the approximation error and asks for an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It asks for an error bound in terms of epsilon, which is a logical inquiry seeking clarification on the approximation error. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for an error bound or to explain why it is important. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It asks for an error bound in terms of epsilon, which is a relevant and detailed inquiry that could help clarify the approximation error in the full tensor. This feedback is clear and actionable, providing the authors with a specific area to address and improve upon. However, it could be more helpful if it included suggestions on how to calculate or estimate the error bound or if it pointed out the potential implications of this information for the paper. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs further exploration and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the presentation of test settings in the visual dialog domain. It highlights that while there are two test settings, only one is shown in Table 1, specifically the discriminative setting. The reviewer questions why the generative setting is not included and asks for the results on this setting. This feedback is explicit and concrete, as it directly instructs the authors to provide results for the generative setting, which is a clear action that can be taken to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the presentation of test settings in visual dialog, specifically questioning why only the discriminative setting is shown in Table 1 and asking for results on the generative setting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the completeness of the results presented in Table 1, specifically regarding the discriminative setting in visual dialog. It highlights that the discriminative setting is not applicable to realworld applications and asks for results on the generative setting. While the comment raises a valid concern about the relevance of the discriminative setting, it lacks specific examples or references to support the claim that the generative setting is more applicable. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only shows the results for the discriminative setting in visual dialog, while there are two test settings in total. The reviewer points out that the discriminative setting is not applicable to realworld applications and asks for results on the generative setting. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive presentation of their results. By addressing this issue, the authors can improve the completeness and relevance of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide specific guidance on how to achieve this, such as suggesting additional examples, case studies, or detailed explanations. The comment also mentions a \"little thing,\" but it does not specify what this is. Without explicit or concrete actions, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what should be done to achieve this, such as providing examples or detailed explanations. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. This is a valid point, as it highlights an area where the paper could be strengthened. However, the comment lacks specificity and does not provide any guidance on how to achieve this, such as suggesting additional examples, case studies, or detailed explanations. While it identifies a potential weakness, it does not offer actionable advice, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to test the approach in other language families. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section, table, or figure this comment pertains to, making it weakly grounded. The comment is specific in that it highlights a potential limitation of the approach, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to similar work, the authors are left without guidance on how to address this concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, specifically questioning its effectiveness for other language families. This is a valid concern that could impact the broader applicability of the work. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or explore the effectiveness of their approach in different language families. Without specific recommendations or steps for improvement, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (privacy protection) of the proposed framework. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting specific methods or techniques to analyze security or privacy. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific area of concern regarding the security (privacy protection) of the proposed framework, but it does not specify which part of the paper this issue is addressed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the lack of analysis of security, but it lacks grounding as it does not pinpoint the exact section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not analyze the security (privacy protection) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the proposed framework, specifically the lack of examination of security (privacy protection). This feedback is clear and actionable, as it highlights an area that the authors need to address to ensure the completeness and robustness of their work. However, the comment could be more helpful if it provided suggestions on how to analyze security or references to existing methods for privacy protection. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the form of p near line 135, indicating that it is assumed to be a Gaussian distribution but not explicitly stated. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of the form of p, and it assumes it is a Gaussian distribution but is not explicitly stated. This provides clear guidance on what the authors need to include or clarify in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, assuming it is a Gaussian distribution but not explicitly stated. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out the need to describe the form of p near line 135. It assumes that p is a Gaussian distribution but notes that this is not explicitly stated. This feedback is specific and helps the authors understand where additional information is required to clarify their methodology. However, it could be more helpful if it provided a suggestion on how to describe the form of p or why this is important for the readers to understand. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the named works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about providing this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the named works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not specify which specific works are being referred to or what aspects of the differences need to be described. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment is weakly grounded because it does not provide explicit references to sections or specific works, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works are being referred to or what aspects need more detailed descriptions. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to substantiate the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, suggesting that more detailed descriptions of the differences between named works are needed. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and specificity. The authors are given a direction to improve their draft, but the comment could be more helpful if it provided examples of how to enhance the descriptions or suggested specific works to focus on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by examining PPP maps. While the comment implies that the authors should provide this explanation, it does not specify how to do so or what aspects of the explanation are needed. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but may not know exactly how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of reliable PPP metrics for understanding PPP effects in different tasks, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the introduction or discussion sections, but this inference is not explicit. The comment is specific in questioning the lack of explicit explanation of what type of understanding one can gain by examining PPP maps. However, without full grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of explicit explanation regarding the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should provide a more detailed explanation of what type of understanding one can gain by examining PPP maps. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is based on the logical assumption that understanding PPP effects is crucial and should be explained, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, this explanation is not explicitly provided in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by examining PPP maps. This feedback is clear and actionable, as it directs the authors to clarify a significant aspect of their work that may be unclear to readers. By addressing this gap, the authors can enhance the comprehensibility and impact of their paper. Therefore, the comment is rated as 4, as it provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include for comparison. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional comparisons with stateoftheart methods. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with stateoftheart methods for spanrelated tasks, specifically mentioning SpanBERT. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for comparison with other methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation by pointing out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors might conduct these comparisons or what methods they should consider. The feedback is 3 as it points out a critical weakness, but it lacks depth and actionable advice, leaving the authors with a general direction to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic of the forward prediction model. Additionally, it points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and provides specific actions for the authors to take, such as revising the figure and improving the connection between the text and the figure. The comment is explicit and concrete, offering a direct path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figure does not effectively represent the schematic of the forward prediction model and that it is difficult to connect the text, figure, and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, and specifically mentions that Figure 2(b) does not effectively represent the schematic of the forward prediction model. The reviewer suggests that the figure should be redrawn to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim that the figure is not effective or how it could be improved. The suggestion to redraw the figure provides a direction for improvement but does not offer a comprehensive explanation or justification for the need for revision. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, noting that the details are not well explained and that Figure 2(b) does not effectively represent the schematic of the model. It also points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and actionable, as it provides specific suggestions for improvement, such as revising the figure and improving the connection between the text and the figure. By addressing these issues, the authors can enhance the clarity and effectiveness of their draft. However, the comment could be more helpful if it offered additional guidance or examples on how to improve the representation of the forwardprediction model. Overall, the comment is 4, as it directs the authors to a specific area for improvement and provides a clear path forward."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their baseline. The action is implicit and vague, as the authors are left to infer that they need to provide a stronger baseline or address the issue of rewardless actions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This feedback is fully grounded as it explicitly mentions \"RBI\" and \"rewardless actions,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the training process and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment lacks specific examples or detailed reasoning to support the claim that rewardless actions are being ignored. Without additional evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides a logical basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a specific concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This observation suggests that this oversight could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer questions whether this is the case and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. While the comment identifies a potential issue, it lacks detailed guidance or suggestions on how the authors might address this concern or improve their baseline. The feedback is 3 as it points out a potential weakness but does not offer comprehensive advice on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the multiscale statement, suggesting that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multiscale statement or rephrase it to accurately reflect the operation of the RNNs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the multiscale statement, specifically pointing out that the slow and fast RNNs operate on the logical time scale rather than the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment is fully grounded as it explicitly mentions the multiscale statement, making it easy for the authors to pinpoint the relevant section. It is also specific because it details the issue with the multiscale statement and provides a clear explanation of the logical time scale. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNNs operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the multiscale statement, pointing out that it is misleading because the slow and fast RNNs operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. This feedback is 3 as it identifies a specific area of confusion in the paper and provides a clear explanation of the issue. However, it could be more helpful if it suggested ways for the authors to clarify this point or rephrase the multiscale statement to accurately reflect the operation of the RNNs. Overall, the comment offers valuable insights but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the baseline methods are weak and not presenting stateoftheart results, and suggests that there is no discussion of limitations. It also raises questions about the difference between the work and reinforcement learning. The comment implies that the authors should address these issues by discussing the limitations and providing a comparison with reinforcement learning. While the action is implicit, it is concrete as it specifies the areas that need attention and suggests a direction for improvement in the conclusion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the baseline methods, suggesting they are weak and not presenting stateoftheart results, and lacks discussion of limitations. It also raises questions about the difference between the work and reinforcement learning, implying that the authors should discuss these similarities and differences in the conclusion. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for a discussion of limitations and the difference between the work and reinforcement learning, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not presenting stateoftheart results, and that there is no discussion of limitations. It also questions the difference between the work and reinforcement learning, suggesting that the conclusion should address these issues. However, the comment lacks specific examples or references to support the claim about the baseline methods being weak or the lack of discussion of limitations. The suggestion to discuss the difference between the work and reinforcement learning is a logical extension of the critique but remains somewhat vague without further elaboration. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not presenting stateoftheart results, suggesting that there is no discussion of limitations. Additionally, it raises questions about the difference between the work and reinforcement learning, implying that the authors should address these issues in the conclusion. The comment provides a clear direction for the authors to enhance their draft by discussing limitations and comparing their work with reinforcement learning. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should clarify the distinction between the decision maker\"s interest in the true objective function and the noise, which is typically assumed to be noise. The comment provides a clear action for the authors to take, which is to make this distinction more explicit in the formulation. This guidance is concrete and provides a direct path for the authors to improve their draft by addressing the specific issue of clarity. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formulation, which is the distinction between the decision maker\"s interest in the true objective function and the noise, which is assumed to be noise. The comment suggests that this distinction should be clarified upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the typical use of expected performance under observation noise for evaluation is misleading because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. The reviewer suggests that the formulation in the paper should clarify this distinction. While the comment provides a logical argument, it lacks specific examples or references to support the claim that the typical use is misleading. This makes the claim 3, as the authors would need to explore the reasoning further to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formulation of the paper, noting that the decision maker\"s interest is in the true objective function, not the noise, which is typically assumed to be noise. The comment suggests that this distinction should be clarified upfront to avoid potential confusion. This feedback is clear and actionable, as it provides a specific area for improvement that can enhance the clarity and accuracy of the paper. By addressing this issue, the authors can better align their work with the intended focus of the decisionmaking process. Therefore, the comment is rated as 5, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two separate issues. First, it suggests exploring the use of VGAE with a vamp prior to more accurately match the doubly stochastic construction in the work. This action is explicit and provides a clear direction for improvement, as it offers a specific method to enhance the model. Second, it suggests a minor point regarding Figure 3, recommending that the generative model be kept fixed while optimizing only the inference part of the model. This suggestion is also explicit and provides a clear action for the authors to take. Both actions are concrete and directly guide the authors on how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"VGAE with a vamp prior,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as exploring the use of VGAE with a vamp prior to match the doubly stochastic construction and comparing representations with SIGVAE or VGAE. This provides detailed feedback on how to improve the draft, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests exploring the use of VGAE with a vamp prior to more accurately match the doubly stochastic construction in the work. This is a logical suggestion that could help clarify whether the benefits of the model are due to a better generative model or better inference. However, the comment does not provide specific examples or references to support the claim that this would be beneficial, making it 3. The suggestion is clear but lacks detailed justification, leaving the authors to infer the potential benefits themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two actionable suggestions. First, it suggests exploring the use of VGAE with a vamp prior to more accurately match the doubly stochastic construction in the work. This action is explicit and provides a clear direction for improvement, allowing the authors to better understand the origins of the benefits observed in their model. Second, it raises a minor point regarding Figure 3, suggesting that keeping the generative model fixed while optimizing only the inference part of the model would be beneficial for comparison. This feedback is specific and provides a clear way to enhance the clarity and comparability of the results. Overall, the comment is 4 as it offers actionable suggestions for improvement, but it could be more comprehensive by providing additional guidance or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their contribution. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to enhance the novelty or contribution of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, which allows the authors to identify the part of the paper being discussed. It also critiques the novelty and contribution of the method, suggesting that the main contribution is a new network design inspired by prior work for the sound source localization task. This provides some specificity in terms of what needs to be addressed, but it does not specify how the authors might enhance the novelty or contribution of their work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. However, the comment lacks specific examples or references to prior work that might be relevant, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. While the comment identifies a potential issue with the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might enhance the novelty or contribution of their work. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to address this concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. However, the comment does not explicitly instruct the authors to include such a discussion or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the importance of learning longrange dependencies and suggests a discussion about this, particularly regarding the encoding of locality in the graph structure. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. However, the comment lacks specific examples or references to support the claim that learning longrange dependencies is not fully required or that the truth lies somewhere in between. Without detailed reasoning or evidence, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. This feedback is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to address. However, it could be more helpful if it offered specific suggestions or examples of how to incorporate this discussion. Overall, the comment is actionable and provides valuable insights for the authors to consider, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3 and Theorem 4. It suggests that the results have a weakness, possibly due to the theoretical results being too dependent on the diameter $M$. However, the comment does not provide specific guidance on how to address these issues or improve the draft. The authors are left with a general understanding of what needs to be clarified or revised but are not given concrete steps to take. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the definition of $e_l$ and the exponential dependence on the diameter $M$ of the domain of data, providing clear guidance on what needs to be addressed. The comment is specific in detailing the weaknesses and suggesting that the results may exhibit a weakness in the proposed approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3 and Theorem 4. It claims that the results have a weakness due to the exponential dependence on $M$, which affects the constant factor of the required feature size. The comment provides some reasoning by mentioning that the performance is more quickly getting worse than standard random features, suggesting a potential weakness in the proposed approaches. However, the comment lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3 and Theorem 4. It points out that the results have a weakness due to the exponential dependence on $M$, which affects the constant factor of the required feature size. The comment also mentions that the performance is more quickly getting worse than standard random features, suggesting a potential issue with the proposed approaches. However, the comment lacks detailed guidance on how to address these issues or improve the draft. While it highlights important areas for consideration, the feedback could be more actionable and comprehensive to be rated as 5. Therefore, it aligns with a score of 4, indicating that the comment is 4 but could be more detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the potential issue of oversmoothing in addition to oversquashing and vanishing/exploding gradients, which are known issues with deep graph networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or where in their paper it should be discussed. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the poor longrange modeling ability of DGNs and attributes it to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the potential causes of the poor performance, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not provide specific references, examples, or detailed reasoning to support these claims. The mention of oversmoothing is made in the context of very deep graph networks, but without further elaboration, the authors may find it challenging to understand the relevance and impact of this claim. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It provides a reference to a relevant paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning,\" which could help the authors understand the context and implications of these issues. However, the comment lacks specific guidance on how the authors might address these challenges or where in their paper these issues should be discussed. While it highlights an important area for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is 3, as it points out a potential weakness but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. While the comment implies that the authors should provide evidence or results to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional results or demonstrations to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the demonstration or results related to the model collapsing less than other methods, and it references a specific point in the text where gradients become 0 and collapse. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the demonstration or results related to the model collapsing less than other methods. It references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. However, the comment does not provide any evidence, reasoning, or references to support the claim or question. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods, referencing a specific point in the text where gradients become 0 and collapse. While the comment identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors might address this issue or what additional information should be included. The feedback is 3 as it prompts the authors to consider demonstrating or explaining their model\"s performance, but it does not offer detailed suggestions or actionable steps. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment notes that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the problem. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the problem formulation is unclear, the comment lacks full grounding as it does not provide specific guidance on what aspects need clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the problem and how to address it. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or detailed examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential weakness but lacks actionable advice, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and direct action for the authors to take, which is to include these experiments to enhance the paper\"s applicability and generalizability. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or methodology. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in suggesting what experiments to conduct, it lacks grounding as it does not reference a specific section of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical suggestion for improving the paper\"s applicability and generalizability. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It provides a clear and actionable suggestion by recommending that the authors conduct trials with models like OPT, BLOOM, or other alternatives. This feedback is valuable as it guides the authors on how to enhance the applicability and generalizability of their method. However, the comment could be more helpful if it included specific guidance on how to design and execute these experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or whether they should consider expanding the scope of their method to other types of generative models. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper discusses this limitation or provides examples of generative models that can be finetuned. This makes it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method or models are problematic. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, stating that it only works for generative models that can be finetuned as an in/outpainting model. This observation is relevant and could prompt the authors to consider the applicability of their method to a broader range of generative models. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their method. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not provide specific guidance or suggestions on how the authors might strengthen these connections or improve the clarity of their presentation. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not specify which sections or parts of the paper are being discussed, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in its critique of the connections but lacks grounding, as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not provide specific examples or detailed reasoning to support this claim. The comment mentions a potential misunderstanding of the paper\"s content but does not offer a clear explanation or evidence to substantiate the claim. As a result, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It provides a specific example of the author\"s initial expectations, which were not met, and notes that the process could be computationally demanding. However, the comment lacks actionable suggestions or guidance on how the authors might strengthen the connections or improve the clarity of their presentation. While it identifies a potential issue, it does not offer concrete steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include results for linear scalarization + Concorde for a better comparison, given that the obtained Pareto front is not highly nonconvex. This is an explicit action that the authors can take to improve their draft. The comment also provides a specific suggestion on which baseline to include, making the action concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific comparison between learningbased and heuristicbased solvers. It also references the single objective TSP and the Pareto front, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it suggests including results for linear scalarization + Concorde for a better comparison, given the nature of the Pareto front. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers outperform heuristicbased solvers in the experimental results, but the SOTA heuristicsolver (e.g., Concorde) usually has the best performance for single objective TSP. The reviewer suggests including results for linear scalarization + Concorde for a better comparison. This claim is 3 as it provides a logical reasoning based on the experimental results and the nature of the Pareto front. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines in the experimental results. It points out that while learningbased solvers perform better overall, the SOTA heuristicsolver (Concorde) is typically superior for single objective TSP. The comment suggests including results for linear scalarization + Concorde to provide a more comprehensive comparison, especially since the Pareto front is not highly nonconvex. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the paper\"s analysis and conclusions. However, it could be more helpful if it provided additional context or guidance on how to integrate these results into the paper. Overall, the comment is 4, as it directs the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using generalized Voronoi graphs or semantic maps, and methods that employ longterm storage through pose graphs in SLAM. While the comment implies that the authors should compare their method with these existing approaches, it does not provide explicit instructions on how to conduct this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using generalized Voronoi graphs or semantic maps, and methods that employ longterm storage through pose graphs in SLAM. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what the authors should discuss, namely, the comparison with existing methods and the relevance of these methods to the proposed method. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the general ideas of the proposed method are already present in other methods for exploration, such as reasoning topologically and longterm storage through pose graphs in SLAM. It provides examples of existing methods, such as those using generalized Voronoi graphs or semantic maps, and references to the graphbased SLAM appendix section. This provides some support for the claim, but it could be strengthened by more detailed examples or references to specific works. Therefore, the comment is 3, as it offers a basis for the claim but lacks comprehensive evidence or detailed references.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, noting that some of its general ideas are already present in other methods for exploration. It provides specific examples, such as reasoning topologically and longterm storage through pose graphs in SLAM, which are discussed in the graphbased SLAM appendix section. The comment suggests that the paper should discuss the proposed method in relation to these existing methods, which is a constructive suggestion for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to compare the proposed method with these existing approaches or what aspects of the comparison would be most insightful. Overall, the comment is 4 as it directs the authors to a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some details from the appendix back into the main text and moving some background information from Section 2 to the appendix. This provides explicit actions for the authors to take, such as identifying which details should be moved back and which background information should be moved to the appendix. The suggestion is concrete, as it outlines specific steps for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of moving experimental details and tasks to the appendix, which makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. This provides a clear and specific suggestion for the authors to consider, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim fully. The authors might find it challenging to understand the exact details that need to be moved back or why the background information should be moved to the appendix. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s organization, noting that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret. It provides a clear suggestion to move some of these details back into the main text and to move some background information from Section 2 to the appendix. This feedback is actionable and provides a concrete way for the authors to improve the clarity and accessibility of their work. However, the comment could be more helpful if it specified which details should be moved back or why certain background information should be moved to the appendix. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide glosses in Figure 2, which is a clear and explicit action. It does not require the authors to infer the action, as it is directly stated. The suggestion is also concrete, as it specifies what needs to be added to the figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the provision of glosses in the figure. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide glosses in Figure 2, which is a request for clarification or improvement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment suggests that the authors provide glosses in Figure 2, which is a clear and actionable suggestion. It identifies a specific area where the paper could be improved, offering a direct way for the authors to enhance the clarity and accessibility of their work. However, the comment does not provide additional context or reasoning about why glosses are necessary or how they might benefit the readers. While it provides a clear direction for improvement, it lacks depth and could be more helpful with additional explanation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This implies that the authors should include a reference to the stateoftheart work, \"Memb,\" to provide context and support for their claim. However, the comment does not explicitly instruct the authors to include a reference or specify which reference to use. The action is implicit and somewhat vague, as the authors need to infer that they should add a reference but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This implies that the authors should include a reference to support this claim. However, the comment does not specify which part of the paper this issue is related to, such as a section or a particular discussion. The authors can infer that it pertains to the stateoftheart section or a related discussion, but this inference is not explicit. Therefore, the comment is weakly grounded as it does not provide a clear reference to the specific part of the paper being addressed, and it is specific in pointing out the need for a reference. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that \"Memb is apparently the previous stateoftheart,\" but it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or references, the authors are left without guidance on how to address the issue or improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This feedback highlights a gap in the paper\"s documentation, suggesting that the authors should include a reference to support their claim about Memb being the stateoftheart. However, the comment does not provide specific guidance on which reference to include or how to integrate it into the paper. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a gap but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a suggestion for improvement or a point that needs clarification. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references or detailed context, the authors may find it challenging to determine the exact area being addressed. Additionally, the comment lacks specificity regarding the issue or improvement needed, as it does not provide any reasoning or suggestions for why finer grouping might be beneficial. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification or an opinion rather than a claim. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. While it identifies a potential area for improvement or clarification, it does not provide any specific reasoning or suggestions on why finer grouping might be beneficial or how it could be implemented. The comment lacks depth and actionable guidance, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it provides some insight but does not offer comprehensive feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples. This feedback is explicit, as it directly instructs the authors to conduct a study on the impact of the ratio of unseen classes. The comment also provides a concrete example of what aspect to investigate, making it 5. The authors know exactly what action to take and how to implement it, aligning with a score of 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes, specifically how the performance varies with different ratios of unseen classes unlabeled examples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental design or results, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting a particular aspect to investigate, which is clear. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on performance, specifically how it varies with different ratios of unlabeled examples. However, the comment does not provide any evidence, reasoning, or references to support why this is a critical aspect to investigate. Without such support, the claim lacks verifiability, as it does not help the authors understand the significance of this suggestion or how it could impact their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on their model\"s performance. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples. This feedback is clear and actionable, as it directs the authors to a specific area for further investigation that could enhance the depth and relevance of their study. However, the comment could be more helpful if it included suggestions on how to conduct this study or what specific metrics to consider. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should justify their choice of architectures or explore alternative combinations. As a result, the authors are left without a clear understanding of what steps to take to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, it does not specify which part of the paper discusses these architectures or where the improvements are mentioned. The authors can infer that it relates to the methodology section, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in questioning the choice of architectures and their impact on improvements, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this combination might be beneficial or why it could be a reason for the improvements. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While it identifies a potential area for improvement or clarification, it lacks specific guidance or suggestions on how the authors might address this issue or justify their choice of architectures. The comment provides a starting point for the authors to consider, but it does not offer detailed feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in line 135, where the author mentions that the network initially has a few active vertices due to sparsity. While the comment identifies a specific area of the paper that requires clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the definition of \"active vertices,\" but it is not concrete because it lacks specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the definition of \"active vertices,\" providing a clear direction for the authors to address the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in line 135, which is a specific and actionable inquiry. It prompts the authors to clarify their terminology, ensuring that readers understand the context and meaning of \"active vertices\" in their network. This feedback is valuable as it helps the authors improve the clarity and precision of their writing, making the paper more accessible to readers. However, the comment could be more helpful if it provided a suggestion on how to define \"active vertices\" or offered an example to illustrate the concept. Overall, the comment is 4 as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s limitations, specifically mentioning that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects of the theory or assumptions should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the paper, specifically mentioning that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the limitations section or the appendix, but this is not explicit. The comment is specific in detailing the issues and suggestions for improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theory presented in the paper is not applicable to the used model and that unspecified structural assumptions are only given in the appendix, making it hard to find. The reviewer also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific areas for improvement, it lacks detailed reasoning or evidence to fully substantiate the claims. The suggestion to elaborate on potential negative societal impacts is a logical extension of the critique but is not explicitly supported by examples or references. Therefore, the comment is 3, as it provides some reasoning but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s limitations, specifically noting that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts of graph neural networks. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention but does not provide detailed actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the meaning. As a result, the authors are left without a clear understanding of what action to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...,\" providing a clear indication of what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" without providing any claim or suggestion for improvement. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue. The feedback lacks depth and actionable advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. It implies that the method lacks originality or innovation, as it does not introduce new concepts or techniques. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to respond or enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the proposed method, suggesting it is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the method\"s originality, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. The reviewer implies that this approach lacks originality or innovation, as it does not introduce new concepts or techniques. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the model architecture, noting that only the projection head (CNN layers) is affected but not the classification head (FCN layer). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their model. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the model architecture, noting that only the projection head (CNN layers) is affected but not the classification head (FCN layer). However, it does not specify which part of the paper discusses this architecture or where the issue is addressed. The authors may have an idea of where this issue might be discussed, but the comment lacks explicit references to specific sections or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the model architecture, but without full grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) is affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the model architecture, noting that only the projection head (CNN layers) is affected but not the classification head (FCN layer). This observation is relevant and could potentially impact the performance or effectiveness of the model. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their model. Without actionable feedback or additional context, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning. It suggests that the discussion is necessary and could help distinguish the paper from related work. However, the comment does not provide explicit guidance on which parts of the framework are crucial or how the discussion should be structured to achieve this distinction. The action is implicit and somewhat vague, as the authors need to infer that they should focus on clarifying the critical components and enhancing the discussion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning. It suggests that the discussion is necessary and could help distinguish the paper from related work, but it does not specify which part of the paper this discussion should be in or how it should be structured. The authors can infer that it pertains to the discussion section, but the comment lacks specificity in terms of what needs to be addressed or how to improve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning, suggesting that the discussion is necessary but lacks clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is necessary or how it could be improved. Without specific references or detailed explanations, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning, suggesting that the discussion is necessary but lacks clarity. It implies that the discussion could help distinguish the paper from related work. However, the comment does not provide specific guidance or suggestions on how to improve the discussion or clarify the critical components. While it identifies an area for improvement, the feedback lacks actionable details, making it 3. The authors are given a direction to consider but are left to infer the specific steps needed to address the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analogy between HOI analysis and Harmonic analysis is weak, as there are only two \"basis\" (human and object) in the problem contexts. It also notes that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. While the comment identifies specific issues with the analogy and the connection to Fourier analysis, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. However, it does not specify which part of the paper this analogy is discussed in, making it weakly grounded. The comment is specific in identifying the issues with the analogy and the connection to Fourier analysis, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The absence of detailed evidence or references leaves the claim 3, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. This feedback is 3 as it points out a specific area where the paper\"s claims may be questionable. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their analysis. Without additional context or specific recommendations, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. It implies that the proposed methodology might have limited implications due to this limitation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors could address this issue or explore alternative implications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning that it might only show meaningful performance gains on bitserial accelerators. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in identifying the potential limitations and suggesting that the proposed methodology might have limited implications due to the common use of bitparallel fixedpoint numbers in existing ML accelerators. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This claim is 3 as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This observation is relevant and provides a critical perspective on the applicability of the proposed methodology. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or explore alternative implications. While it highlights an important consideration, it does not offer specific steps or insights that could help the authors improve their draft. Therefore, the comment is 3, as it points out a potential issue but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalization of the focusing distance in the images shown in Figure 8, specifically questioning why only 1m and 5m are shown when other distances may exist in the training data. While the comment implies that the authors should consider including other focusing distances to test generalization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the range of focusing distances tested. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalization of the focusing distance in the images shown in Figure 8, specifically asking about focusing distances other than those in the training data. This provides clear guidance on what aspect of the figure needs further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalization of the focusing distance in the images shown in Figure 8. It points out that the figure only shows 1m and 5m, which are present in the training data, and asks whether the model generalizes well to other focusing distances. While the comment is a question seeking clarification, it does not contain a claim or an opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the generalization of the focusing distance in the images shown in Figure 8. It points out that the figure only shows 1m and 5m, which are present in the training data, and asks whether the model generalizes well to other focusing distances. This feedback is 3 as it prompts the authors to consider the generalization capabilities of their model beyond the training data. However, it lacks specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in implementing those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should revisit their definitions and clarify their understanding of \"style,\" it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. However, the comment does not specify which part of the paper this feedback pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of style and movement dynamic, but this inference is not explicit. The comment is specific in detailing what needs to be addressed regarding the definitions of content and style, as well as the understanding of \"style\" in the context of the model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. However, the comment does not provide specific examples or detailed reasoning to support the claim that the authors\" understanding of \"style\" is unclear or incorrect. The reference to Gabbay & Hosehn (2018) is a step towards justification, but it lacks detailed explanation or specific examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a general direction for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. This feedback is 3 as it identifies a potential area for improvement in the authors\" understanding and definitions of key concepts. However, it lacks specific guidance on how the authors might redefine or clarify these terms, leaving the authors with a general direction but without detailed actionable steps. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. The comment explains that the proposed approach does not improve the phenomenon of information distortion, as evidenced by the variance difference in the figures. It also references existing work in the NLP domain to highlight the issue of precision loss in transformer quantization. While the comment provides specific examples and references, it does not explicitly instruct the authors on how to address these issues or improve their analysis. The feedback is detailed and informative, but the lack of explicit guidance makes it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Line 45,\" \"Fig1(b),\" and \"Fig5(b),\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the analysis of vit quantification, including the information distortion and the loss of precision in the quantization of MHSA. The comment provides clear examples and references to existing work in the NLP domain, making it specific and actionable. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point presents a claim about the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. The comment provides specific examples, such as the variance difference in the figures, to support the claim. It also references existing work in the NLP domain to highlight the issue of precision loss in transformer quantization, which is not unique to the ViT model. This provides a logical and detailed justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. It points out that the proposed approach does not improve the phenomenon of information distortion, as evidenced by the variance difference in the figures. Additionally, it references existing work in the NLP domain to highlight the issue of precision loss in transformer quantization, which is not unique to the ViT model. This feedback is clear and actionable, offering specific examples and references to help the authors improve their analysis and address the identified weaknesses. However, the comment could be more helpful if it provided suggestions on how to address these issues or further improve the analysis. Overall, the comment is 4, as it provides valuable insights and guidance for enhancing the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness in the work, which is the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It also points out that the proposed Xtransformation is similar to STN but applied locally, and that PointNet uses a variant of STN. The comment suggests that the technical novelty is limited and that there should be empirical or conceptual comparisons to STN. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or analyses should be conducted. The action is implicit and somewhat vague, as the authors can infer the need for comparisons and novelty enhancements but lack detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the technical novelty of the work, specifically regarding the use of spatial transformer networks (STN) and the proposed Xtransformation. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture. However, the comment does not specify which part of the paper discusses STN or the proposed Xtransformation, making it weakly grounded. The comment is specific in detailing the issues with the technical novelty and the need for comparisons, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty with respect to spatial transformer networks (STN) and does not provide comparisons to existing works that use STN. It also notes that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture. The comment provides a logical reasoning by comparing the proposed Xtransformation to STN and existing works, which supports the claim. However, it could be strengthened by providing specific references or examples of the existing works mentioned, which would make the claim 5. Therefore, the comment is 4, as it provides a clear rationale but lacks full support with specific references.", "helpfulness_rationale": "The review comment identifies a main weakness in the work, specifically regarding the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty of the work is limited. The comment also highlights the need for empirical or conceptual comparisons to STN, which is important for evaluating the work\"s contribution. While the comment provides clear and actionable feedback on areas for improvement, it could be more helpful if it offered specific suggestions or examples of how to enhance the technical novelty or comparisons. Overall, the comment is 4 as it directs the authors to address critical aspects of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that one of the r_i might be taken from Equation 11. It also recommends explaining the network model in Section 4.2 using equations to improve clarity. The comment provides a clear and explicit action for the authors to take, which is to clarify the origin of the reward and explain the network model with equations. This guidance is concrete, as it specifies what needs to be addressed and how to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation 12, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the origin of the reward at each trial and suggesting that one of the r_i might be taken from Equation 11. Additionally, it provides a specific recommendation to explain the network model in Section 4.2 using equations to improve clarity. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equation 12 is confusing and questions the origin of the reward at each trial. It suggests that one of the r_i might be taken from Equation 11 and recommends explaining the network model in Section 4.2 with equations to improve clarity. The comment provides references to relevant literature, such as [1], [2], and [3], which could help the authors understand the context and potential improvements. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about Equation 12 being confusing. While the references provide some support, the lack of detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that one of the r_i might be taken from Equation 11. It provides a clear and actionable suggestion to improve clarity by explaining the network model in Section 4.2 with equations. The comment also includes references to relevant literature, which can guide the authors in addressing the issue and enhancing the clarity of their work. This feedback is detailed and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests correcting a labeling error in the supplementary material (Row 821, \"Fig.7\" should be \"Fig.12\") and recommends attaching proof links to each theorem and corollary in the main paper for easier reader navigation. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion. While the comment does not specify how to address these concerns, the actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue with the labeling error and provides a clear suggestion for improvement. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion, which are specific to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a mix of factual statements and suggestions. The factual statements about the labeling error and the recommendation to attach proof links are clear and verifiable. However, the claim about the paper\"s novelty, theoretical guarantees, and empirical results is subjective and requires more detailed justification or examples to be 5. The authors may find it challenging to address these claims without additional context or evidence. Therefore, the comment is 4, as it provides some support but lacks comprehensive justification for the subjective claims.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two main points: a labeling error in the supplementary material and the need to attach proof links to theorems and corollaries in the main paper. This feedback is clear and directly addresses the authors\" need to correct an error and improve the reader\"s understanding of the paper. Additionally, the comment raises concerns about motivation, methodology soundness, and experiment persuasion, which are important aspects for the authors to consider in enhancing the paper\"s quality. While the comment does not delve into detailed suggestions for addressing these concerns, it provides a strong foundation for the authors to improve their draft. Therefore, the comment is 4, as it offers clear guidance on specific issues and areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions that seek clarification on specific aspects of the paper. The first question asks about the missing determiner in the definition, while the second question inquires about the selection of 50 classes and whether they are explicitly tagged as action verbs by Levin. The third question asks about the concept of \"action frames\" and how they are chosen. These questions provide explicit actions for the authors to take, such as clarifying the missing determiner and explaining the selection of action verbs and frames. However, the comment lacks concrete guidance on how to address these issues, such as suggesting specific changes or references to support the clarification. While the actions are clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the definitions and selection of action verbs and frames, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"above\" and the selection of action verbs and frames. These questions are not claims but rather requests for clarification, making them normal statements. Therefore, they do not require verification and should be labeled as \"No\".", "helpfulness_rationale": "The review comment consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"above\" and the selection of action verbs and frames. While the questions provide valuable insights into areas that need further explanation, they do not offer actionable feedback or suggestions on how to improve the clarity or accuracy of these definitions. The comment highlights gaps in the paper\"s presentation but lacks detailed guidance or constructive suggestions for improvement. Therefore, it is 3, as it identifies areas for clarification but does not fully support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is explicit and direct, instructing the authors to correct a spelling error in the text. The action is clear and concrete, as it specifies exactly what needs to be changed (\"Empiically\" should be \"Empirically\"). This provides the authors with a straightforward task to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the text, \"Empiically\" should be \"Empirically.\" This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a spelling error in the text, \"Empiically\" should be \"Empirically.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor typographical error in the text, specifically correcting \"Empiically\" to \"Empirically.\" While this is a small and straightforward issue, it highlights the importance of attention to detail in academic writing. However, the comment does not provide any additional context or suggestions for improvement, such as how this error might impact the clarity or professionalism of the paper. As a result, the comment is 3, as it points out a specific error but lacks depth and actionable guidance for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework (Line 167174, Sec. 4) does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of feature selection need enhancement. The action is implicit and somewhat vague, as the authors can infer that they need to consider representation learning, but they may not know how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. Additionally, it mentions a discussion about representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The comment suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. However, the comment lacks specific examples or detailed reasoning to support the claim that the feature selection could be improved. The mention of representation learning in the appendix provides some context but does not substantiate the claim. Therefore, the comment is 3, as it provides a general suggestion but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the feature selection process. However, the comment could be more helpful if it offered more detailed guidance or examples on how to incorporate representation learning into the feature selection. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify or provide more information on the design of rewards, but it does not offer concrete steps or examples of what should be included. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area where details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft is lacking detail, specifically mentioning the lack of understanding of how to design rewards. This feedback is 3 as it points out a gap in the paper that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how to improve this aspect. The authors are left with a general understanding of what needs to be clarified but without actionable steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about generalizing a model to different numbers of entities, referencing Figure 3 from INs. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific steps to take. The comment implies that the authors need to clarify or modify their model to accommodate varying entity counts, but it lacks concrete details or actionable advice on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the model can be generalized to different numbers of entities, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the model to different numbers of entities, referencing Figure 3 from INs. However, it does not provide specific examples or detailed reasoning to support why this is a concern or how it affects the model\"s applicability. The mention of INs provides some context, but without further elaboration, the claim remains 3. The authors would need to infer the exact issue and how it impacts the model, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s generalizability to different numbers of entities, referencing Figure 3 from INs. This feedback is 3 as it points out a potential limitation in the current model\"s design. However, it lacks detailed guidance on how the authors might address this issue or suggestions for improving the model\"s generalizability. While it highlights an important area for consideration, the comment could be more helpful with additional context or actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions that the experimental design is good. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment highlights a potential weakness, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The action is implicit and vague, as the authors are left to infer that they should consider code release or other means to enhance the novelty of their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the incremental nature of the work compared to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions the good experimental design and raises a concern about the lack of code release, which could impact the reproducibility of the results. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in its critique of the novelty and reproducibility aspects, it lacks grounding as it does not reference specific sections of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, lacking significant novelty but requiring substantial engineering and execution effort. It also mentions the good experimental design. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment provides some reasoning and context, it lacks specific examples or references to support the claim about the novelty and engineering effort. The mention of personal execution (replicable) beating the idea (novelty) adds a subjective element, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also highlights the good experimental design. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. It implies that the authors should include a discussion on the computational efficiency of Prithvi WxC as a limitation for MLbased emulators of climate model parametrizations. While the comment explicitly states the action needed, it does not provide specific guidance on how to discuss the runtime or what aspects of the runtime should be emphasized. The action is concrete, but the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment suggests discussing the runtime of Prithvi WxC, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the importance of discussing the runtime as a limitation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be placed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. While the comment implies that the runtime is a relevant aspect, it does not provide specific reasoning or evidence to support why this is a critical consideration. The claim is 3 as it highlights a potential issue but lacks detailed justification or examples to fully substantiate the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the computational efficiency of Prithvi WxC. However, the comment lacks depth and does not provide specific guidance on how to discuss the runtime or what aspects of the runtime should be emphasized. To be more helpful, the comment could include suggestions on how to present this information or why it is important for the intended applications. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights the lack of novelty in the idea and points out that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the lack of novelty or improve the originality of their work. Without specific suggestions or directions, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the idea and points out that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of novelty and the simplicity of the new metric and method, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the limitations of the novelty of the idea, stating that both the new metric and method are relatively straightforward. However, it does not provide any constructive feedback or suggestions on how the authors might enhance the originality or improve the presentation of their work. Without actionable advice or specific guidance, the comment lacks depth and fails to offer the authors meaningful insights for improvement. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contribution. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the framing are problematic or how they contribute to the paper\"s clarity. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it difficult to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed feedback on how the framing could be improved or what aspects of the method are being oversold. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to address the issue. This lack of detail and specificity makes the comment 2, as it provides a general observation but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding. It also recommends using a notation table to clarify the use of symbols. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the generative process and the use of symbols and a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or subsection. This makes it difficult for the authors to identify the exact area needing improvement, leaving them with a weak grounding. The comment is specific in suggesting ways to improve the model description, such as presenting the generative process in separate steps and using a notation table. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to clarify the use of symbols. While the comment provides a suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors may find it challenging to understand the exact issues without additional context or examples. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully justify the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that presenting the generative process in separate steps would enhance understanding. It also recommends using a notation table to clarify the use of symbols, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided examples of how the generative process could be broken down or detailed further. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of ensuring that the paraphrases generated for the training data are significantly different from the original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, such as suggesting methods to ensure significant differences or how to measure this difference. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of generating paraphrases for the training data, specifically mentioning the need for these paraphrases to be significantly different from the original sentences. This provides some grounding as it relates to the data generation process, but it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the importance of the paraphrases and their impact on the model\"s reliance on the quality of the data. However, it lacks explicit references to sections or figures, which could help the authors pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases used in the training data, noting that the difference between paraphrases and original sentences is crucial for the model\"s performance. The comment explains that if the difference is not significant, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of paraphrase quality on model performance. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the data generation process, specifically the need for significant differences between paraphrases and original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should consider ensuring significant differences between paraphrases and original sentences to improve the quality of the training data. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this, such as techniques for generating diverse paraphrases. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a mix of explicit and implicit actions. It explicitly acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation. However, it also suggests that the paper is wellorganized and easy to follow, which is a positive observation. The comment implicitly suggests that Figure 2 is cluttered and recommends using another color or a bigger font to improve the visibility of the human identified rationales. While the action to improve Figure 2 is clear, the comment lacks specific guidance on how to implement these suggestions. The authors know they need to address the clutter in Figure 2, but the feedback is somewhat vague on the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is cluttered and suggesting a potential solution by recommending the use of another color or a bigger font to improve the visibility of the human identified rationales. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation. This is a logical observation that aligns with common knowledge in the field. The comment also provides a specific suggestion for improving Figure 2, recommending the use of another color or a bigger font to enhance visibility. While the suggestion is clear, it lacks detailed reasoning or examples to fully substantiate the claim about the difficulty of identifying rationales for complex tasks. Therefore, the comment is 4, as it provides a logical basis for the claim but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation, which is a relevant observation. This recognition can help the authors understand the limitations of their work and potentially guide future research directions. However, the comment also highlights a specific issue with Figure 2, noting that it is cluttered and suggesting a solution by recommending the use of another color or a bigger font to improve the visibility of the human identified rationales. This feedback is actionable and provides a clear suggestion for improvement. Overall, the comment is 4 as it identifies a potential area for enhancement and offers a specific recommendation, but it could be more comprehensive by providing additional guidance or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework to nonLLMbased models like HiTeA and InternVideo. While the comment implies that the authors should expand their analysis to include these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper discusses the FlippedQA framework or how it is currently applied to LLMbased models. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to expand the analysis to nonLLMbased models, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. The reviewer provides a logical reasoning by stating that the framework is a general approach for various generative VideoQA models, but the authors have only applied it to LLMbased models. This implies that the framework\"s applicability and effectiveness should be tested on other models as well. However, the comment lacks specific examples or references to support the claim that HiTeA and InternVideo are suitable models for this framework. While the suggestion is reasonable, it could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s scope, suggesting that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. This feedback is valuable as it points out an area for expansion and improvement, encouraging the authors to broaden their analysis and potentially enhance the applicability of their framework. However, the comment could be more helpful if it provided specific suggestions on how to conduct this verification or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for enhancing the paper\"s scope and impact, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, but it does not provide specific guidance on how to achieve this improvement. The authors are left without any explicit or implicit actions to take, such as suggestions for clearer explanations, rephrasing, or additional examples. Without concrete details or examples, the authors are unable to determine how to address the issue, making this comment 1.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, but it does not specify which sections or parts of the paper are particularly challenging to understand. This lack of grounding makes it difficult for the authors to identify the specific areas that need improvement. The comment is specific in its feedback, as it highlights the effort required to understand the main idea and theoretical analysis, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing could be improved, but it does not provide any specific examples or reasoning to support this claim. The comment lacks detailed feedback or evidence to substantiate the need for improvement, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the authors may struggle to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing could be improved, indicating that the reviewer found it challenging to understand the main idea and theoretical analysis of the paper. However, the comment lacks specific details or suggestions on how to enhance the writing, such as clarifying complex concepts, reorganizing the structure, or providing additional examples. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not provide sufficient direction for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. The reviewer is willing to improve their score if the authors can address these concerns. While the comment implies an action, it does not provide explicit guidance on how to address the lack of novelty or theoretical contribution. The authors are left to infer that they need to provide more detailed explanations or evidence of novelty. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks concrete guidance on how to achieve it.", "grounding_specificity_rationale": "The comment addresses the theoretical novelty of the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. However, the comment does not specify which part of the paper discusses these methods or where the novelty is claimed, making it weakly grounded. The comment is specific in identifying the lack of theoretical novelty and suggesting a potential area for improvement, but it lacks grounding in terms of specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks significant theoretical novelty, primarily because it builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer provides references to specific works by Clopper and Pearson, as well as Golub and Van Loan, which support the claim. This provides a clear and detailed basis for the claim, making it 5. The authors can use these references to understand the context and address the concern by demonstrating how their work extends or improves upon these existing methods. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination, lacking significant theoretical novelty. The reviewer is willing to improve their score if the authors can address this concern. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a critical area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to consider. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. Without specific grounding, the authors cannot confidently determine where to address this concern. The comment is specific in its inquiry about the concatenation of text elements, but the lack of grounding makes it weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text elements in the text input. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by the four text elements of an object. While it identifies a potential area for clarification, it does not provide any context, reasoning, or suggestions on why this might be an issue or how it could be addressed. Without additional guidance or explanation, the authors are left without actionable feedback on how to improve their draft. Therefore, the comment is 2, as it lacks depth and specificity, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, which implies that the authors should clarify why the presented topic is important or relevant. However, the comment does not specify what aspects of the motivation should be improved or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the importance of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to address the motivation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the motivation. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly identifies a specific sentence in the abstract as cumbersome and suggests that it can be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made. The authors are left with a clear understanding of what needs to be improved but are not given concrete steps on how to implement the suggested changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 1217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, which is its cumbersome nature and suggests that it can be made clearer. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning, examples, or references to support why the sentence is cumbersome or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the abstract, noting that the sentence in lines 1217 is cumbersome and suggesting that it can be made clearer. While the comment points out a potential problem, it does not provide any guidance on how to achieve clarity or what specific changes should be made. This lack of actionable advice limits the usefulness of the feedback, making it 3. The authors are aware of the issue but are left without clear instructions on how to improve the abstract. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the fairness of the comparisons made between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zeroshot singleimage 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the comparison of the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, particularly in relation to the fairness of comparisons to zeroshot singleimage 3D reconstruction models. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it difficult for them to pinpoint the exact part of the paper being addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D are unfair, particularly when compared to zeroshot singleimage 3D reconstruction models. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment critiques the fairness of the comparisons made between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zeroshot singleimage 3D reconstruction models. While it identifies a potential issue with the experimental setup, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparisons. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy. The comment concludes by recommending that the authors address these issues and continue their work for future submission. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, including the performance comparison with Decouple [Kang et al.] and the tradeoff between head and tail categories. It provides a specific example of how the proposed approach does not outperform or is worse than Decouple, and it suggests that the tradeoff has not been fully investigated for the baselines. The comment also highlights a potential issue with the baselines, suggesting that changing hyperparameters could improve tail accuracy. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the areas that need improvement, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also suggests that the tradeoff between head and tail categories has not been fully investigated for the baselines, and that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy. The comment provides a clear and actionable suggestion for the authors to address these issues, which could significantly enhance the paper\"s contribution. However, it could be more helpful if it offered specific guidance on how to investigate the tradeoff or how to implement the suggested changes. Overall, the comment is 4 as it directs the authors to areas that need improvement and provides a clear direction for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the action is explicit, it is somewhat vague because it does not specify which aspects of the C2D method should be tested or how the experiments should be designed. The authors are aware of the need for additional experiments but may need to infer the details of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments on a particular dataset, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is 3 as it identifies a specific area where the authors could enhance the robustness and applicability of their findings. However, the comment lacks detailed guidance on how to design these experiments or what specific results should be expected. To be more helpful, the comment could include suggestions on how to structure the experiments or what metrics to use to evaluate the C2D method. Overall, the feedback provides a direction for improvement but could be more comprehensive."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include more scenarios, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the reliance on 4 OCR QA datasets and the potential unreliability of the evaluation as indicated in Fig 4(5). It suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides some grounding as it references specific figures and suggests a potential improvement. However, it does not explicitly mention which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include more scenarios and the need for ablation studies, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. The claim is 3 as it points out the reliance on a limited number of datasets and suggests a potential improvement by including more scenarios. However, the comment lacks specific examples or references to the LLaVA benchmark, which would strengthen the justification. Additionally, the mention of Fig 4(5) provides some context but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, noting that it relies heavily on 4 OCR QA datasets and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This feedback is 3 as it points out a potential weakness in the current evaluation and provides a clear suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to incorporate these additional scenarios or what aspects of the evaluation should be expanded. Overall, the comment provides a direction for improvement but lacks depth and detail, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, noting that they are unintuitive and difficult to solve. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment does not specify which part of the paper these tasks are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the tasks are problematic or how they could be simplified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment lacks specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. The comment also asks for proof that more simpler visual reasoning tasks would not be more effective. However, the feedback lacks specific suggestions or guidance on how the authors might address these issues or improve their approach. While it identifies a potential area for improvement, the comment does not provide actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide concrete steps to enhance the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the evaluation of weak supervision and provides examples of unrealistic elements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This provides a clear and detailed justification for the claim, making it 5. The authors can easily understand the basis of the critique and the need for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, suggesting that the evaluation could be enhanced by considering the realism of the evaluated tweets. It provides detailed examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This feedback is clear and actionable, offering the authors a concrete direction for improving the evaluation of weak supervision. However, the comment could be more helpful if it suggested specific ways to assess the realism of the tweets or provided examples of more realistic prompts. Overall, the comment is 4 as it provides valuable insights and actionable suggestions for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or examples of what specific visualizations or comparisons are needed, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for more visualization, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement, namely the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending specific types of visualizations or comparisons that could be included. Without actionable advice, the comment is vague and does not offer the authors a clear path to improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. Additionally, the comment points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimensionfree iteration complexity. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns or improve their results. The feedback is 3 as it identifies areas for potential improvement but lacks detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the importance of the results, referencing a previous work [15] and noting the loss of dimensionfree iteration complexity in Theorem 3. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. However, the comment also points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimensionfree iteration complexity. While the comment provides a logical reasoning based on previous work, it lacks specific references or detailed examples to fully substantiate the claim. This makes the claim 3, as it provides a basis for the concern but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. However, the comment also points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimensionfree iteration complexity. While the comment identifies specific areas for improvement, it lacks detailed guidance on how the authors might address these concerns or enhance the significance of their results. The feedback is 3 as it highlights potential weaknesses but could be more comprehensive with actionable suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the keypoint detection results should be included in the experiments section. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and concrete, giving the authors a clear path forward in improving their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the keypoint detection results should be included in the experiments section. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs revision. Additionally, the comment lacks specificity regarding what aspects of the keypoint detection results should be included or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the keypoint detection results should be included in the experiments section. This is a clear and actionable suggestion that provides the authors with a specific area to address in their draft. By including these results, the authors can enhance the completeness and transparency of their experimental section, allowing readers to better understand and evaluate their findings. However, the comment could be more helpful if it provided additional guidance on how to present these results or what specific aspects of the keypoint detection should be emphasized. Overall, the comment is 4 as it directs the authors to an important aspect of their draft that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors might infer that it relates to the discussion of the proposed model\"s performance or its comparison with other models, but this inference is not explicit. The comment is specific in its suggestion to compare with a particular existing work, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This claim is 3 as it provides a specific reference to an existing work that could be used for comparison. However, the comment lacks detailed reasoning or explanation on why this comparison would be beneficial or how it would enhance the proposed model\"s performance. The authors would need to infer the potential benefits of such a comparison, making the claim 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that the authors could make to enhance the evaluation of their proposed model. By comparing their model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16), the authors could provide a more comprehensive understanding of their model\"s performance and its advantages. This feedback is clear and actionable, offering a concrete suggestion for improvement. However, it could be more helpful if it included additional context or reasoning on why this comparison is important or how it could impact the paper\"s conclusions. Overall, the comment is 4 as it provides a clear direction for enhancing the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the methodology used in the grid search for learning rate, specifically whether it is conducted on the validation set. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the grid search for learning rate is conducted on the validation set. While it identifies a potential issue with the methodology, it does not provide any further context, analysis, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance on how the authors might address this concern. As a result, it is 2, as it provides a starting point for the authors but does not fully support their efforts to improve the draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is necessary to make changes. As a result, the authors are left without a clear understanding of what steps to take in response to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a large number of discourse relations in the treebank and suggests that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. This feedback is 3 as it prompts the authors to consider whether their approach aligns with established linguistic conventions or if there are potential issues with the classification of discourse relations. However, the comment lacks detailed guidance or suggestions on how to address this concern, such as whether the authors should reevaluate their classification criteria or provide additional context. While it identifies an area for improvement, the feedback could be more actionable with more specific advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalizability of the results to different groups, specifically marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity, and its implications for generalizability. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the generalizability of their results to diverse groups. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generalizability of the results to different groups, particularly marginalized groups, and suggests considering racial and economic diversity in the sample. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the results to different groups, specifically marginalized groups, and suggests considering racial and economic diversity in the sample. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external works that might address the issue of generalizability, making it difficult for the authors to understand the basis of the concern. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the suggestion.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the results to different groups, particularly marginalized groups. It prompts the authors to consider the diversity of their sample, including racial and economic diversity, and its implications for the applicability of their findings. This feedback is valuable as it encourages the authors to broaden their perspective and address potential biases or limitations in their study. However, the comment could be more helpful if it provided specific suggestions or examples of how to assess or address these issues. Overall, the comment is 3 as it identifies an important area for consideration but lacks depth in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the current state of output quality, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, suggesting that the paper\"s results are not up to par. The reviewer also mentions the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment does not provide specific guidance or suggestions on how the authors might improve the output quality or address these issues. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, suggesting that the paper\"s results are not up to par. The reviewer also mentions the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment does not specify which part of the paper should be improved or how the authors might address these issues. While it provides some context, it lacks explicit references to specific sections or elements of the paper, making it weakly grounded. The feedback is specific in identifying areas for improvement but lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output quality of the paper is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive quality. The reviewer also notes the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment lacks specific examples or references to the recent GAN works, making it difficult for the authors to fully understand and address the critique. While the claim is based on a comparison with recent advancements, the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, setting a higher standard for the field. The reviewer also points out the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment lacks specific suggestions or actionable feedback on how the authors might improve the output quality or address these issues. While it highlights important areas for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to extend the curve. The action is implicit and somewhat vague, as the authors need to infer the need for further analysis and experimentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the results, particularly the use of soft labels in relation to CRM and Cross entropy. It mentions the iNaturalist19 dataset and suggests that a higher beta value might be more effective, implying that the authors should extend the curve further. However, the comment does not explicitly mention which part of the paper this discussion pertains to, such as specific figures or sections. While the authors can infer that it relates to the results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue with the use of soft labels and suggesting an extension of the curve, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. However, the comment lacks specific evidence or detailed reasoning to support the claim that the hyperparameters are subpar or why extending the curve would be beneficial. The suggestion to extend the curve is not fully justified, as it does not provide a clear rationale or examples of how this would improve the results. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their results. While it identifies a potential area for improvement, it does not provide actionable steps or detailed feedback, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is 3, as it highlights an area of concern but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should provide more evaluation in this direction, specifically on classifying unseen words. The reviewer suggests adding translations to Figure 6 to help nonChinese speakers understand the results. While the comment implies that more evaluation is needed, it does not explicitly instruct the authors to add translations to Figure 6. The action is somewhat implicit and vague, as the authors need to infer that they should enhance the evaluation and provide translations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the addition of translations to help nonChinese speakers understand the results. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that more evaluation is needed in this direction, specifically on classifying unseen words. The reviewer suggests adding translations to Figure 6 to aid nonChinese speakers. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more evaluation is necessary. The suggestion is 3, as it points out a potential area for enhancement but does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the simple/traditional experiment for unseen characters is presented as an afterthought. It implies that more evaluation is needed in this direction, specifically on classifying unseen words. The reviewer provides a specific suggestion to enhance the evaluation by adding translations to Figure 6, which could aid nonChinese speakers in understanding the results. This feedback is clear and actionable, offering the authors a concrete way to improve their draft. However, it could be more helpful if it included additional suggestions or examples of how to enhance the evaluation. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the number of images in the VioT dataset, suggesting that it may be insufficient to validate the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting additional data collection or analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the number of images provided is small, which may affect the validity of the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may affect the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a potential issue with the VioT dataset, noting that it consists of only 20 images in each of the four categories. This observation is relevant as it questions the sufficiency of the dataset for validating the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern, such as recommending additional data collection or analysis. While it highlights an important aspect to consider, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, it is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an ablation study on the number of layers and performance, which is a concrete and explicit action for the authors to consider. The response from the authors indicates that they have revised their score in light of the feedback, further emphasizing the actionability of the initial suggestion. This feedback provides clear guidance on what the authors should include in their draft to enhance its depth and comprehensiveness. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests an ablation study on the number of layers and performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors can infer that it pertains to the experimental results or methodology, but the lack of explicit grounding makes it challenging to pinpoint the exact section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests an ablation study on the number of layers and performance, which is a specific suggestion for improvement. However, the comment does not provide any reasoning or evidence to support why this study would be interesting or beneficial. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an ablation study on the number of layers and performance, which is a specific and actionable suggestion for the authors to consider. This feedback provides a clear direction for enhancing the depth and comprehensiveness of the paper, offering a valuable insight into areas that could be explored further. However, the comment could be more helpful if it included additional context or reasoning about why this study might be interesting or relevant to the field. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and that figure captions should include additional explanations and legends, such as explaining the colors in Figure 2. However, the comment does not provide specific guidance on how to improve the mathematical explanations or what additional information should be included in the figure captions. While the authors can infer that they need to enhance the clarity of their derivations and figure captions, the lack of detailed instructions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the difficulty in following the paper and suggests the need for more intuitive explanations on mathematical derivations. It also points out the lack of explanations in figure captions, specifically mentioning Figure 2 and the need to explain the colors used. However, the comment does not specify which sections of the paper are particularly challenging to follow or which figures are missing explanations, making it weakly grounded. The comment is specific in its suggestions for improvement, such as providing more intuitive explanations and additional explanations in figure captions. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests that more intuitive explanations on mathematical derivations are needed. It also points out the lack of explanations in figure captions, specifically mentioning Figure 2. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that the paper is difficult to follow and suggesting the need for more intuitive explanations on mathematical derivations. It also points out the lack of explanations in figure captions, such as the need to explain the colors in Figure 2. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to enhance the clarity of the derivations or figure captions. The authors are left with a general understanding of what needs to be improved but without detailed steps on how to achieve it. Therefore, the comment is 3, as it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices and emphasizes the importance of addressing this issue. It suggests that the authors should consider this aspect and potentially revisit the rating if the issue is resolved. While the comment highlights a critical area for improvement, it does not provide explicit guidance on how to address the sensitivity or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the sensitivity of their results and potentially adjust their rating if the issue is resolved. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the sensitivity of the empirical results to hyperparameter choices, which is a critical aspect of the study. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the importance of addressing this issue, as it could potentially affect the validity of the results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a valid concern in any study. However, the comment does not provide specific examples or detailed reasoning to support why this issue is particularly critical or how it could affect the study\"s validity. The mention of \"conceivably\" suggests that the reviewer is speculating on the potential impact, which makes the claim 3. The authors would need to provide more detailed evidence or examples to fully address this concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, which is a common issue in machine learning studies. It highlights the potential impact of incorrect hyperparameter choices on the validity of the results, emphasizing the importance of addressing this aspect. The comment is specific in its suggestion that the authors should consider the sensitivity of their results and potentially revisit their rating if the issue is resolved. This feedback is actionable and provides a clear direction for the authors to improve their study, making it 4. However, it could be more helpful if it offered specific guidance on how to assess and address the sensitivity of the results. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to clarify the novelty and contribution of their proposed method, as it appears to be similar to existing attack methods on a surrogate model. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to emphasize the originality of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and contribution of the proposed method, suggesting that it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in its critique, as it highlights the need for the authors to clarify the novelty of their approach. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that it is similar to using the transferability of adversarial examples directly. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it appears to be similar to existing attack methods on a surrogate model. It suggests that the authors need to clarify the novelty and contribution of their approach. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate comments. The first comment explicitly states that the text in Table 1 is too small and hard to read, providing a clear and direct action for the authors to take. The second comment mentions a missing gradient symbol in Algorithm 1, which is also an explicit action. Additionally, the comment provides references to external works, which can guide the authors in expanding their literature review or understanding of related work. Both comments are concrete and provide specific actions for the authors to take, making them 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the small text in Table 1 and the missing gradient symbol in Algorithm 1, providing clear guidance on what needs to be addressed. Additionally, the comment includes references to external works, which further supports the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment is a factual observation about the readability of text in Table 1, which is a normal statement and does not require verification. The second comment mentions a missing gradient symbol in Algorithm 1, which is also a factual observation. Therefore, the overall comment is a mix of factual statements and observations, making it \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the small text in Table 1, which makes it difficult to read, and the missing gradient symbol in Algorithm 1. These are clear and actionable points that provide the authors with specific areas to address, such as improving the legibility of the table or ensuring all necessary symbols are included in the algorithm. Additionally, the comment includes references to external works, which can guide the authors in expanding their literature review or understanding of related work. However, the comment could be more helpful if it provided suggestions on how to improve the readability of the table or how to incorporate the gradient symbol into the algorithm. Overall, the feedback is 4 as it directs the authors to specific areas for improvement and provides some context through references, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to discuss computational aspects more thoroughly, possibly including methods to make the algorithm more practical for highdimensional data. However, the comment lacks concrete suggestions or examples of how to achieve this, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects, specifically mentioning the appendix and the experiments performed on smallscale datasets. However, it does not explicitly mention which part of the paper discusses computational aspects, making it weakly grounded. The comment is specific in pointing out the need for more detailed discussion on computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly regarding the practicality of their methods for highdimensional data. The reviewer provides specific examples, such as the requirement to solve several LPs in high dimensions with parameters that are not easily calculable, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these issues impact the practicality of the methods. Overall, the claim is 4 due to the specific examples and reasoning provided, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s discussion of computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors need to address the computational feasibility of their methods. However, the comment could be more helpful if it provided specific suggestions or examples of how to make the methods more practical for highdimensional data. Overall, the comment is 4 as it directs the authors\" attention to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It also suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison, as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this alternative baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the ResNet in the experiments shares parameters between residual blocks and suggests an alternative baseline by comparing to a deeper ResNet with parameter sharing. This comparison is relevant to the discussion of ODE nets with a fixed timestep Euler integrator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison, as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment does not provide explicit evidence or references to support the claim that parameter sharing would make the ResNet equivalent to an ODE net, it does offer a logical suggestion for further exploration. The authors might find this suggestion valuable in expanding their analysis, but the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the parameter sharing in the ResNet used in the experiments, suggesting that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison. This comparison would be relevant as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might implement this comparison or what insights it could provide. The feedback is 3 as it points out a potential avenue for improvement but lacks detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the motivation are unclear or need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point challenges the claim that the crossencoder architecture \"ignores crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. It provides a counterpoint by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support the claim that the architecture is not as finegrained as implied. This makes the claim 3, as it provides a logical argument but requires further evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores, which is a significant point of clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their motivation or clarify their claims. While it identifies a potential area for improvement, it does not offer actionable feedback or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an odd design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors can infer that they might need to reconsider this design choice, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the design choice of trimming questions after the first 10, noting that it seems odd given the nature of the question model. The comment provides a clear rationale for this concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. The reviewer provides a logical reasoning by pointing out the inconsistency between the model\"s nature and the chosen design. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to infer the exact reasoning behind the claim, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the design choice of trimming questions after the first 10, given that the question model is a bag of words and does not involve expensive encoding of longer sequences. This observation is clear and provides a logical basis for questioning the design decision. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their design. While it highlights a potential area for improvement, the feedback could be more helpful if it included actionable advice or examples of alternative approaches. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work uses an antiquated GNN model and method, which impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or methods, nor are there suggestions for alternative approaches or references to more recent work. As a result, the authors are left without any actionable steps to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the use of an \"antiquated GNN model and method\" and the antiquated nature of the baseline algorithms/methods. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in pointing out the antiquated nature of the methods, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work uses an antiquated GNN model and method, which impacts the performance of the framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to more recent work, the authors are left without guidance on how to address the issue. As a result, the claim is 1, as it lacks the necessary justification or evidence to support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which is likely to impact the performance of the framework. It also points out that the baseline algorithms/methods are antiquated, which could be a concern for the authors. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations, the authors are left without a clear path to improve their work. Therefore, the comment is 2, as it highlights a potential problem but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should provide more detailed explanations or clarify the method\"s workings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, questioning the clarity of the explanation and suggesting that additional adhoc postanalysis might be necessary to extract shared motifs. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. The comment provides a logical reasoning by pointing out the lack of clarity in the figure and suggesting a potential need for additional analysis. However, it lacks specific examples or references to support the claim fully. While the reasoning is sound, the comment could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in Figure 1, questioning the clarity of the explanation provided. It points out that the explanation seems to require additional adhoc postanalysis to extract shared motifs for a set of instances. This feedback is clear and actionable, as it directs the authors to clarify the explanation in Figure 1 and potentially provide more detailed analysis. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided examples of how the analysis could be simplified. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the lack of true feature importance. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The comment provides a clear direction for improvement by suggesting that the authors should consider the impact of the perturbation value and the implications of Prop 3.2. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to strengthen the experiment. The action is implicit but concrete, as the authors know what needs to be done to improve the experiment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment\" and \"Prop 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the reliance on pseudo feature importance and the difficulty in judging the experiment\"s trustworthiness due to the small difference between the tested method and the pseudo feature importance. The comment provides clear guidance on how to strengthen the experiment, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment\"s reliance on pseudo feature importance due to the lack of true feature importance makes it difficult to judge the experiment\"s trustworthiness. The claim is supported by logical reasoning, as it points out the potential impact of the perturbation value and the reference to Prop 3.2. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. The lack of specific references or detailed explanations makes the claim 3, as it provides a basis for the authors to explore but does not fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment, noting that the reliance on pseudo feature importance due to the lack of true feature importance makes it difficult to judge the experiment\"s trustworthiness. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The comment provides clear and actionable feedback, guiding the authors on how to improve the experiment by considering the impact of the perturbation value and the implications of Prop 3.2. This feedback is detailed and constructive, offering the authors a clear path to enhance the robustness and credibility of their experimental results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific properties of function Z are relevant. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the potential nonconvexity issue and its relation to the convergence of SGD. The comment specifies that the function Z should have certain good properties to mitigate this issue, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate the assertion that the function Z has good properties that could mitigate nonconvexity. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the nonconvexity of the function Z, suggesting that it may not be a concern for the SGD to converge. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific properties of function Z are relevant. Without actionable advice or detailed feedback, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, as it provides a starting point for consideration but lacks depth and actionable insights."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the paper, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific instructions or suggestions makes it difficult for the authors to know exactly what changes to make. The feedback is vague and does not offer concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. It provides explicit references to specific lines and sections, such as \"Line 99, section 3.1\" and \"Line 165, section 3.4,\" which allows the authors to accurately identify the parts of the paper that need attention. Additionally, the comment highlights the need for citations and references, which is a clear and specific issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several observations and requests for clarification. It highlights the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. While these observations are important for the authors to address, the comment does not provide specific examples or detailed reasoning to support the claims. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. These are important points that the authors need to address to improve the clarity and rigor of their work. However, the comment does not provide detailed guidance or suggestions on how to resolve these issues, such as which models to compare or how to clarify confusing sections. While it highlights areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide explicit guidance on how to conduct such an analysis or what specific aspects should be addressed. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details or actionable steps, making it vague and 3. The authors can infer that they need to enhance their analysis, but the lack of specific guidance makes it challenging to implement the suggested improvement. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not specify which part of the paper this analysis should be applied to, making it weakly grounded. The comment is specific in its suggestion that a more extensive analysis would enhance the paper, but without grounding, the authors cannot confidently determine which sections need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for a more extensive analysis, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it acknowledges that this is a short paper, implying that the authors may not have the space to include such an analysis. While the comment identifies a potential area for improvement, it lacks specific guidance or actionable steps on how the authors might enhance their analysis within the constraints of a short paper. The feedback is 3 as it points out a potential weakness but does not provide detailed suggestions for improvement, leaving the authors with limited direction on how to address this issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical issue with the experimental settings, noting that result reproducibility is essential and that the authors do not provide the code. This feedback implies that the authors need to clarify the experimental settings and ensure that the code is made available for reproducibility. However, the comment does not explicitly instruct the authors to provide the code or clarify the experimental settings, leaving the action somewhat implicit. The authors can infer that they need to address these issues, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of experimental settings and result reproducibility, specifically mentioning that the authors do not provide the code. This provides some grounding as it highlights a specific area of concern related to the experimental setup. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned, making it weakly grounded. The comment is specific in identifying the need for code provision to ensure reproducibility, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that result reproducibility is critical using the provided information. However, the comment lacks specific examples or detailed reasoning to support why the experimental settings are not mentioned properly or how this affects reproducibility. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, specifically noting that result reproducibility is essential and that the authors do not provide the code. This feedback is valuable as it highlights a significant gap in the paper\"s reproducibility, which is crucial for the credibility and impact of the research. However, the comment could be more helpful if it provided specific suggestions on how to improve the experimental settings or how to ensure reproducibility. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance for the authors to address the issue effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the online learning formulation, including the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. While the comment identifies specific areas that need clarification, it does not provide explicit actions for the authors to take. The questions are clear and specific, but the authors are left to infer the actions required to address these issues. Therefore, the comment is 3, as it provides valuable insights but lacks explicit guidance on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the issue is discussed, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly outlines the issues with the online learning formulation, such as the lack of proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. The comment provides detailed questions that guide the authors on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the online learning formulation, specifically questioning the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. It raises specific questions that guide the authors in addressing these issues, such as why online learning cannot be used and how to compare retraining cost with incremental updates. This feedback is clear and actionable, providing the authors with a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to conduct these comparisons or included examples of similar studies. Overall, the comment is 4 as it highlights important areas for improvement and offers a starting point for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should include a deeper connection to metalearning and cite relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. While the comment implies that the authors should take these actions, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. However, the comment does not specify which part of the paper should include these connections or how they should be integrated. The authors can infer that it pertains to the discussion or literature review sections, but the lack of explicit grounding makes it difficult to pinpoint the exact sections. The comment is specific in suggesting what needs to be addressed but lacks full grounding, as it does not explicitly mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. The comment provides a logical reasoning by suggesting that these connections would enhance the paper\"s depth and relevance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to explore the suggested connections themselves to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that there is a deeper connection to metalearning, which has several approaches. It recommends citing relevant works that do not directly target continual learning but are still relevant, and it suggests linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s depth and relevance. By following this advice, the authors can significantly improve their draft by establishing a stronger connection to existing literature. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback. It suggests that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. While the comment implies an action\u2014exploring different types of feedback\u2014it does not provide explicit instructions on how to implement this suggestion. The authors are left to infer that they should consider generating diverse feedback, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it identifies a potential issue but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a potential solution to address the lack of diversity in the feedback, which is a clear and actionable suggestion. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback. However, the comment does not provide specific examples or references to support the claim that the diversity is lacking. The suggestion to manually review or generate different feedback is a logical response to the concern, but without additional evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the lack of lexical and syntactic diversity in the teacher feedback, particularly if it is autogenerated. It suggests that the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a potential solution. However, it could be more helpful if it included more detailed guidance on how to generate diverse feedback or examples of what types of feedback could be considered. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. It also includes a question, which is an explicit request for clarification. However, the comment does not provide specific guidance on how to summarize the results or what aspects should be emphasized. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. However, it does not specify which part of the main text should be revised or how the additional experiments should be summarized. The authors can infer that the main text needs to be revised to include this information, but the comment lacks specificity in identifying the exact sections or details to address. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a request for clarification regarding the presence of additional experiments in the supplement and a question about summarizing their results. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the main text, suggesting that it should clarify the presence of additional experiments in the supplement and ideally summarize their results. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to summarize the results or what aspects of the additional experiments should be highlighted. Overall, the comment is 4 as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that important references are missing, specifically mentioning GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encodedecoder architecture. It encourages the authors to include a comprehensive comparison with these works. The comment provides specific references for the authors to consider, making the action explicit and concrete. The authors know exactly what needs to be done to improve their draft, which is to include these references and conduct a comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GFF\" and \"EfficientFCN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, which is the inclusion of these references for a comprehensive comparison. The comment is specific in detailing the need for a comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF and EfficientFCN, which aim to implement fast semantic segmentation methods in an encodedecoder architecture. The reviewer provides specific references for the authors to consider, which supports the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the current work. The inclusion of references provides some level of verification, but the lack of detailed reasoning or context makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue by pointing out that important references are missing from the paper. It specifically mentions GFF and EfficientFCN, which are relevant to the field of fast semantic segmentation methods in encodedecoder architectures. The reviewer encourages the authors to include a comprehensive comparison with these works, providing specific references for them to consider. This feedback is actionable and provides clear guidance on how the authors can improve their draft by incorporating relevant references and comparisons. However, the comment could be more helpful if it offered additional suggestions or examples of how to integrate these references into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the claim that the experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. It specifically questions the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claim. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in these tables supports the effectiveness of the proposed prompts. The comment provides a clear and detailed critique of the experimental results, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 supports the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this critique. Without additional context or justification, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the claim that the experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. It specifically questions the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7. However, the comment lacks actionable feedback or suggestions on how the authors might address this critique or improve their claim. Without specific guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but does not provide actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This is a clear and direct action for the authors to take, as it provides specific references to compare with. The comment also specifies that these works involve training adapters on top of a welltrained multilingual pretrained model, which gives the authors a clear idea of what to look for in these comparisons. Therefore, the comment is 5, as it provides explicit and concrete guidance on how to improve the draft by including relevant comparisons.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" However, it does not specify which part of the paper this recommendation pertains to, such as a section or a particular experiment. This makes it difficult for the authors to identify the exact area where this comparison should be included. The comment is specific in its suggestion to compare with these works, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance of the work with two specific references: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" However, the comment does not provide any reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the significance of these comparisons. Therefore, the claim is considered 2, as it provides a suggestion but lacks sufficient explanation or evidence to fully support the recommendation.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation is 5 as it directs the authors to relevant literature that could enhance the comprehensiveness and impact of their study. By including these comparisons, the authors can better position their work within the existing literature and demonstrate its novelty and contribution. The comment is specific and provides a concrete path for improvement, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis of the Cycle FC align feature is insufficient and could be improved by considering different designs, such as experiments or analysis with different sampling intervals and sample sizes. While the comment implies that the authors should expand their analysis to include these variations, it does not provide explicit instructions on how to conduct these experiments or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the Cycle FC align feature, suggesting that the analysis is insufficient and could be expanded by considering different designs, such as experiments with different sampling intervals and sample sizes. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting ways to improve the analysis, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the Cycle FC align feature is insufficient and could be improved by considering different designs, such as experiments with different sampling intervals and sample sizes. However, the comment does not provide specific examples or references to support the claim that the analysis is insufficient or how it could be improved. The suggestion is vague and lacks detailed reasoning or evidence, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the analysis of the Cycle FC align feature, suggesting that the analysis could be expanded by considering different designs, such as experiments with different sampling intervals and sample sizes. This feedback is 3 as it points out a specific aspect of the analysis that could be enhanced, but it lacks detailed guidance on how to implement these improvements. The authors are given a direction to consider, but the comment could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the absence of standard deviations in the paper makes it difficult to assess the reliability of the results. It suggests that the authors should include standard deviations to provide a clearer understanding of the performance of the best method and other RF configurations. While the comment implies that the authors should add standard deviations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include standard deviations, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which makes it difficult to assess the reliability of the results. It suggests that including standard deviations would provide a clearer understanding of the performance of the best method and other RF configurations. However, the comment does not specify which sections or figures should include these standard deviations, making it weakly grounded. The authors can infer that it pertains to the results section or figures, but this is not explicitly mentioned. The comment is specific in its suggestion to include standard deviations, but the lack of grounding makes it challenging for the authors to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper makes it difficult to assess the reliability of the results. However, the comment does not provide any specific examples or references to support this claim, nor does it offer a logical explanation or reasoning for why standard deviations are necessary. Without additional context or evidence, the authors may find it challenging to understand the significance of this claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the absence of standard deviations in the results section. This omission makes it difficult for readers to assess the reliability and robustness of the findings, as it does not provide a measure of variability or confidence in the results. The comment suggests that including standard deviations would enhance the clarity and credibility of the results, offering a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific guidance on how to calculate and present standard deviations or examples of how this information could be integrated into the paper. Overall, the comment is 4 as it highlights a significant gap in the paper and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests that the authors consider extending their approach to more general settings. While the comment implies that the authors should explore broader applicability, it does not provide explicit guidance on how to achieve this extension or what specific aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the extent of the extension required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. However, the comment does not specify which part of the paper discusses the current setting or how it could be extended. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in terms of the limitations it identifies, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the current setting is specific and requires certain conditions, such as knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. The reviewer suggests extending the approach to more general settings. However, the comment does not provide specific examples or references to support the claim that the current setting is too specific or how it could be extended. This lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the extent of the limitations and potential extensions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. This feedback is 3 as it points out a potential area for improvement by highlighting the current constraints of the setting. However, the comment could be more helpful if it provided specific suggestions or examples of how the approach could be extended to more general settings. Overall, the comment offers a direction for improvement but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is explicit in its request for clarification regarding the feature extractor used for the dimensionality of each region, which is specified as 512. This is a clear and direct action for the authors to take, as it prompts them to provide the specific feature extractor used in their work. The comment is concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the feature extractor used for the dimensionality of each region, which is specified as 512. This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement seeking clarification about the feature extractor used for a specific dimensionality. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is clear and actionable, seeking clarification on the feature extractor used for the dimensionality of each region, which is specified as 512. This is a specific and important detail that the authors should address to ensure transparency and reproducibility in their work. By providing this feedback, the reviewer helps the authors improve the clarity and completeness of their draft. However, the comment could be more helpful if it suggested a specific feature extractor or provided examples of similar works for reference. Overall, the comment is 4 as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add these details but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in or what specific details are missing. This makes it difficult for the authors to identify the exact sections that need revision. The comment is 1 because it does not reference specific parts of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not provide any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While this is a valid suggestion, it lacks specificity and does not offer actionable guidance on how to include these details or where they should be placed in the paper. Without further elaboration or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks the authors to explain how they chose the value p < 0.4 in Algorithm 1. This is a direct request for clarification, providing the authors with a clear and explicit action to take. The comment does not require any inference or interpretation, making it 5. The authors know exactly what information they need to provide to address the comment, ensuring a straightforward path to improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on how the value p < 0.4 was chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a direct request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not provide any feedback or suggestions on how to improve the paper or address potential weaknesses. The comment is specific in its inquiry but lacks actionable guidance or context that could help the authors enhance their draft. Therefore, it is rated as 2, as it identifies a gap in the paper but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify why there are negative numbers in Figure 1 and to provide explanations or analysis for Figures 2 and 3. This feedback is clear and direct, giving the authors a specific action to take: to include explanations or analysis for the figures. The comment also specifies what needs to be addressed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" \"Figure 1,\" \"Figure 2,\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing explanations or analysis for the figures and clarifying the presence of negative numbers in Figure 1. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify why there are negative numbers in Figure 1 and provide explanations or analysis for Figures 2 and 3. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these clarifications are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by providing explanations or analysis for Figures 1, 2, and 3. It highlights a potential issue with negative numbers in Figure 1 and requests clarification on their significance. Additionally, it suggests that the authors should provide analysis for Figures 2 and 3, which is a constructive suggestion for enhancing the clarity and depth of the paper. However, the comment could be more helpful if it offered specific guidance on how to address these issues or provided examples of how to improve the figures. Overall, the feedback is 4 as it directs the authors to important areas for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its suggestion to provide a clearer explanation, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation for applying CMD in federated learning, suggesting that it could benefit from a more explicit demonstration or explanation. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance on how to address this issue. The authors are left with a general understanding of what needs clarification but are not given actionable steps to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It also suggests references for further reading. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to conduct the analysis or compare methods. The authors are aware of what needs to be done but may require additional information to fully implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"data augmentation method\" and \"paraphrasing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as the lack of analysis and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment further provides references for the authors to consider, making it specific in its guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the effectiveness of each data augmentation method is insufficient and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to support the claim, such as [1] and [2], which are relevant to the topic of language models and their effectiveness. This provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by elaborating on how these references specifically relate to the analysis of data augmentation methods or by providing more detailed reasoning on why these comparisons are necessary. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of detailed analysis of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would provide clarity on the unique advantages of the proposed method. Additionally, the comment provides references to relevant literature, which can guide the authors in expanding their analysis and understanding of the topic. This feedback is clear and actionable, offering specific suggestions for improvement that can enhance the depth and rigor of the paper. However, it could be more helpful if it included more detailed guidance on how to conduct the analysis or compare methods. Overall, the comment is 4, as it provides valuable insights and actionable steps for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an ablation study is necessary to understand the net effect of each component in the proposed model. It provides specific examples of what could be included in the ablation study, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This guidance is explicit and concrete, as it clearly outlines the actions the authors should take to address the issue. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the need for an ablation study to understand the net effect of each component in the proposed model, specifically mentioning \"learning with MMD.\" However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an ablation study to evaluate the effect of each component, but without full grounding, it is challenging for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study is necessary to understand the net effect of each component in the proposed model, specifically mentioning \"learning with MMD.\" However, the comment does not provide specific examples or detailed reasoning to support why an ablation study is crucial or how it would benefit the understanding of the model. The suggestion is vague and lacks detailed justification, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the lack of an ablation study to understand the net effect of each component in the proposed model. It provides a clear suggestion by suggesting specific ablation studies, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and provides the authors with a concrete path to enhance their draft by offering detailed guidance on how to address the identified weakness. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear direction for enhancing their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what implications it might have for the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario in their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the experimental results or discussion of negative samples. While the comment is specific in its question, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how to address this question or what implications it might have for the paper. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it identifies a potential area for exploration but does not offer actionable insights or suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the scalability of RLCD compared to RLAIF, as the advantage of RLCD diminishes when moving from 7B to 30B language models. It suggests that the authors should explore whether RLCD or RLCDRescore can scale to even larger language models. However, the comment does not provide specific guidance on how to address this issue or what aspects of scalability should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore scalability in more detail. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison between RLCD and RLAIF, specifically mentioning Tab. 2, which indicates full grounding as the authors can accurately identify the part of the paper being discussed. The comment also specifies the issue by noting that the advantage of RLCD over RLAIF diminishes as the language model size increases, and it questions whether RLCD can scale to even larger models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the language model size increases, specifically from 7B to 30B, as shown in Table 2. However, the comment does not provide any supporting evidence, such as specific data or analysis, to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this observation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of RLCD compared to RLAIF, noting that the advantage of RLCD diminishes as the language model size increases from 7B to 30B, as shown in Table 2. It raises a question about whether RLCD or RLCDRescore can scale to even larger language models, which are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential limitation of the proposed method and suggests an area for further investigation. However, it lacks specific guidance or suggestions on how the authors might address this issue or explore scalability in more detail. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, particularly when applied to largescale datasets like ImageNet. It questions the practical contribution of the paper if the method cannot be effectively scaled. The reviewer suggests that there should be a solution to address this scalability issue, but does not provide specific guidance on how to implement such a solution. While the comment highlights a potential limitation, it lacks explicit and concrete actions for the authors to take, making it 3. The authors know that they need to address the scalability issue, but the comment does not provide detailed steps on how to do so. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the scalability issue of the proposed NC measure, specifically mentioning the use of the whole training and test datasets as input. This provides some grounding as the authors can infer that it relates to the methodology or experimental setup. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. It is specific in questioning the scalability of the method and suggesting a solution to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to largescale datasets like ImageNet. The reviewer suggests that there should be a solution to address this scalability issue, implying that the practical contribution of the paper may be reduced without such a solution. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about scalability. This makes it difficult for the authors to fully understand and address the issue, leaving the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the scalability of the proposed NC measure, particularly when applied to largescale datasets like ImageNet. It questions the practical contribution of the paper if the method cannot be effectively scaled. The comment suggests that there should be a solution to address this scalability issue, which is a constructive and actionable feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the scalability issue. Overall, the comment is 4 as it identifies a critical area for improvement and offers a direction for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. This feedback is clear and direct, providing the authors with a specific action to take: conducting a quantitative analysis to support their claims. The comment also offers concrete suggestions on what aspects to measure, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the paper\"s claim of efficiency improvements. It provides a clear and specific issue by highlighting the need for measurements like GPU hours, memory usage, or training time to substantiate these claims. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. The comment provides a clear rationale for why such measurements are important, as they would provide stronger evidence of the efficiency improvements. However, the comment could be strengthened by including specific examples or references to similar studies that have conducted such analyses. Overall, the claim is 4 as it offers a logical reasoning and a suggestion for improvement, but it could be more robust with additional supporting evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing quantitative analysis of computational gains. It highlights the lack of measurements or comparisons, such as GPU hours, memory usage, or training time, which would substantiate the efficiency improvements claimed by the paper. By suggesting a quantitative analysis, the comment offers a clear and actionable feedback that can help the authors strengthen their claims and provide a more robust evaluation of their work. This feedback is detailed and constructive, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, implying that the method is less efficient for these scenes. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the time factor in their comparisons. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison of methods, specifically mentioning COLMAP and scenebyscene finetuning. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the time taken for these processes should be considered when comparing methods, indicating what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, suggesting that the method is less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, specifically noting that the time taken for COLMAP and scenebyscene finetuning should be considered when evaluating efficiency. This feedback is 3 as it points out a critical aspect that the authors might have overlooked, which could impact the interpretation of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative methods or approaches to account for the time factor. Therefore, the comment is 3, as it highlights an important consideration but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), including the lack of discussion or analysis, the need for experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. The reviewer also questions the scalability of FMN with larger input and output channels. While the comment identifies specific areas for improvement, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer the need for additional experimentation and analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and concerns about the FMN, including the lack of discussion, experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. The comment also questions the scalability of FMN with larger input and output channels, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the lack of discussion and analysis on the \"filter manifold network\" (FMN), suggesting that the authors should experiment with other architectures for FMN and explore the scalability of adaptive convolutions with the number of filter parameters. The reviewer also questions the scalability of FMN with larger input and output channels. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that FMN is not being adequately discussed or analyzed. The suggestion to experiment with other architectures and explore scalability is logical but requires further elaboration to be 5. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion and analysis on the \"filter manifold network\" (FMN), which is a crucial part of the technique. It raises several questions, such as whether the authors have experimented with other architectures for FMN and how the adaptive convolutions scale with the number of filter parameters. The comment also questions the scalability of FMN with larger input and output channels, which is common in many CNN architectures. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider additional aspects of their work, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be improved."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain, suggesting that comparisons to UNets are necessary. The reviewer implies that the authors should include comparisons to UNets to clarify the performance boost. While the comment explicitly states that comparisons to UNets are necessary, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is implicit but concrete, as the authors know what needs to be done to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fractional transform\" and \"UNet part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a logical reasoning by comparing the UNet operation to pointwise multiplication as done in FNOs and references relevant literature. However, it lacks specific examples or detailed comparisons, which could strengthen the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment raises a valid concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a logical reasoning by comparing the UNet operation to pointwise multiplication as done in FNOs and references relevant literature. This feedback is clear and actionable, as it guides the authors to include comparisons to UNets to better understand the model\"s performance. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies a potential weakness and offers a clear direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the computational complexity of the proposed PSA method compared to baselines. It specifically mentions that the PSA requires the calculation of all flipped previous layer outputs into the current layer, which contributes to increased computation. The comment suggests that a comparison of computation complexity should be included in the experiment section. While the action is explicit, it does not provide detailed guidance on how to conduct this comparison or which specific metrics or methods should be used. The authors are aware of the issue and know that they need to address it, but the comment lacks concrete steps on how to implement the suggested comparison. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It explicitly mentions \"algorithm 1,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment also specifies the issue by pointing out the calculation of flipped previous layer outputs into the current layer, which contributes to increased computation. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of flipped previous layer outputs into the current layer in Algorithm 1. This claim is 3 as it provides a specific observation about the computational complexity of the PSA method. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to conduct a more detailed analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computational complexity, specifically mentioning the calculation of flipped previous layer outputs into the current layer in Algorithm 1. The comment suggests that a comparison of computation complexity should be included in the experiment section, which is a clear and actionable suggestion. This feedback is valuable as it guides the authors on how to improve their draft by addressing the computational efficiency of their method. However, the comment could be more helpful if it provided specific recommendations on how to conduct the comparison or which metrics to use. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should investigate the individual contributions of noise and the exponential moving average to the proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\"s performance. The comment provides a clear and explicit action for the authors to take, which is to conduct specific experiments to assess the contributions of each factor. This guidance is concrete, as it outlines a specific direction for the authors to follow to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\"s performance. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a method for further analysis, but without explicit grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It implies that the authors should investigate the individual contributions of each factor to the model\"s performance. However, the comment does not provide specific evidence, examples, or references to support the claim that these factors are beneficial or how they contribute to the model. Without detailed reasoning or references, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It provides a clear and actionable suggestion for further analysis, which could enhance the understanding of the model\"s performance. However, the comment could be more helpful if it included specific guidance on how to conduct these experiments or what metrics to use for evaluation. Overall, the feedback is 4 as it directs the authors towards a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides a list of specific issues and suggestions for improvement. It explicitly mentions that the fonts in figures 1 and 2 should be larger, and it provides examples of elements that are too small. Additionally, it suggests clarifying the \"CTRL\" long form explanation and improving the font size in figure 2. These suggestions are clear and provide concrete guidance on how the authors can enhance their draft. The comment also highlights the lack of details in the comparison with other stateoftheart Transformer designs, suggesting that a table would better emphasize the data. This feedback is actionable because it gives the authors specific steps to take to improve their draft, making it a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 1,\" \"fig 2,\" and specific elements like \"V_mem,\" \"Th_i,\" and \"U_i^t,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as increasing font sizes and clarifying the \"CTRL\" long form explanation. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of observations and suggestions for improvement, such as recommending larger fonts and clarifying the \"CTRL\" long form explanation. However, it does not contain any claims or opinions that require verification. The comments are descriptive and provide specific feedback on the draft, but they do not make subjective judgments or assertions that would need to be substantiated. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft, focusing on both the visual elements of the figures and the textual content. It highlights issues with font sizes, suggesting that certain elements, such as \"V_mem,\" \"Th_i,\" and \"U_i^t,\" are too small and recommending that the \"CTRL\" long form explanation be clarified. Additionally, it points out that the font in figure 2 is too small. Furthermore, the comment identifies a lack of details in the comparison with other stateoftheart Transformer designs, suggesting that a table would better emphasize the data for readers to justify the improved accuracy. This feedback is clear and provides the authors with specific steps to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent might not behave well during the learning process. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent might not behave well during the learning process. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent might not behave well during the learning process. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on speculation rather than concrete evidence, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent might not behave well during the learning process. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their results. The feedback is 3 as it points out an area for consideration but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to rewrite a sentence that is unclear, specifically \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct instruction, providing the authors with a specific action to take. The comment also specifies the page and line number, making it easier for the authors to locate and address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"P. 5, p. 3, l.\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by requesting a rewrite of a sentence that is unclear, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a sentence that is unclear. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence in the paper, specifically \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This feedback is clear and actionable, as it directly points out a confusing sentence that needs to be rewritten for better understanding. By specifying the page and line number, the authors are given a clear indication of where to make the necessary changes. This level of detail and specificity makes the comment 5, as it provides a direct path for the authors to improve the clarity of their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether they consider documents as entire sentences in the context of the DocRED dataset. It also inquires about how the authors handle concepts with multiple entity mentions referring to the same entity. These questions provide clear and direct actions for the authors to take, such as adding this information to the manuscript. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors consider documents as entire sentences and how they handle concepts with multiple entity mentions referring to the same entity. This provides clear guidance on what information is missing from the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on specific aspects of the paper, such as whether documents are considered as entire sentences and how concepts with multiple entity mentions are handled. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the handling of documents in the context of the DocRED dataset, particularly regarding whether they are considered as entire sentences and how concepts with multiple entity mentions are addressed. This feedback is clear and actionable, as it prompts the authors to clarify these aspects in their manuscript. By addressing this question, the authors can provide more detailed information that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included suggestions on how to handle these issues or examples of how other studies have addressed similar concerns. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated. It also questions the need for adding another stream for lowresolution, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their contribution. The action is implicit and vague, as the authors are left to infer that they need to justify the significance of their work or consider alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated. It questions the need for adding another stream for lowresolution, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or method, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity in detailing what aspects of the contribution are marginal or how the addition of another stream might be significant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal because the methods used are welldesigned and demonstrated, and adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific reasoning or evidence to support these claims, such as detailed comparisons with existing work or examples of how the methods are welldesigned. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated, and adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential issue with the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the significance of their work. The feedback is vague and does not provide actionable steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It highlights that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks for clarification on any other motivations for PBSD. While the comment implies that the authors should provide additional context or motivation for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It references the ablation study and the paper\"s motivation, which is primarily supervised contrastive learning. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the motivations for PBSD, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It points out that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks for clarification on any other motivations for PBSD. While the comment identifies a potential issue with the paper\"s focus, it lacks specific examples or references to support the claim that the main contribution is unclear. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It points out that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer asks for clarification on any other motivations for PBSD, suggesting that the authors should provide additional context or motivation for this component. This feedback is 3 as it identifies a potential area of confusion and encourages the authors to clarify their main contribution. However, it could be more helpful if it provided specific suggestions or examples of how to address this issue, such as discussing the broader implications of PBSD or its relation to other components in the paper. Overall, the comment provides a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It specifically asks how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, and it provides a specific example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, specifically asking if the tester immediately yields an (\u03b5, \u03b4)identity tester. It also questions how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that the tester does not yield an (\u03b5, \u03b4)identity tester. The reasoning is based on a logical inquiry into the functionality of the tester, but without additional evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It highlights a potential issue regarding how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. By addressing this question, the authors can improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to handle such cases. Overall, the comment is 4, as it identifies a potential weakness and offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not include any explicit or implicit actions for the authors to take. The comment mentions that the reviewer did not read additional experiments in the Appendix due to time constraints, but this does not provide any guidance or suggestions for improvement. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not specify which parts of the paper are being addressed or what specific issues are being discussed. The mention of \"additional experiments described in the Appendix\" provides some context, but it does not allow the authors to pinpoint the exact sections or elements being discussed. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not contain any claims, opinions, or suggestions that require verification. It is a statement of appreciation and does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not offer any specific feedback or suggestions for improvement, nor does it highlight any particular areas that need attention or clarification. The comment lacks actionable guidance or insights that could help the authors enhance their draft. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. While the comment highlights a potential issue with the description, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or correct the description of the active learning method. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples for labeling. This provides clear guidance on what aspect of the description needs clarification or correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. The comment does not contain any subjective claims or opinions, making it a factual statement. It does not require verification as it is a question seeking clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. This feedback is 3 as it prompts the authors to clarify their method, which could be important for the readers\" understanding. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or improve their description. To be more helpful, the comment could include examples of traditional active learning methods or suggest ways to clarify the description. Therefore, the comment is 3, as it identifies a potential area for clarification but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should clarify this distribution or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the detailed distribution of the proposed dataset, indicating that it is unclear. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the dataset description or analysis, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed dataset, noting that the detailed distribution is unclear. However, it does not provide any suggestions or guidance on how the authors might clarify this distribution or improve the dataset\"s description. Without actionable feedback or specific recommendations, the comment lacks depth and does not offer the authors a clear path to enhance their draft. As a result, the comment is 2, as it highlights a problem but does not provide actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method\"s reliance on annotated labels for learning semantic tokens limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement this suggestion or provide specific guidance on how to transition to a selfsupervised approach. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for annotated labels in the proposed method, suggesting that a selfsupervised pretraining approach without annotations could be more appealing. However, it does not specify which part of the paper discusses the use of annotated labels or the proposed method. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks explicit grounding. It is specific in suggesting a potential improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method\"s reliance on annotated labels limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which is its reliance on annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is clear and actionable, as it points out a potential area for improvement and provides a specific direction for the authors to consider. By suggesting a selfsupervised approach, the comment offers a concrete way to enhance the applicability and versatility of the method. However, it could be more helpful if it included specific examples or guidance on how to implement a selfsupervised approach. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should expand their experiments to include these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. The authors can infer that it relates to the scalability of LFF, but the comment lacks explicit grounding. The suggestion is specific in terms of what the authors should demonstrate, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why the authors should expand their experiments to include more challenging tasks. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s demonstration of the scalability of the proposed method, LFF. It suggests that the authors should expand their experiments to include more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids, to fully demonstrate the method\"s capabilities. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their work. By addressing this suggestion, the authors can significantly improve the impact and relevance of their research. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the abstract should include a more detailed statement about the expressivity of the model, referencing a specific citation. Additionally, it recommends including learning curves for all experiments, at least in an appendix. These suggestions are clear and provide specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract\" part of the paper, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed, suggesting that the abstract should include a more detailed statement about the expressivity of the model and the inclusion of learning curves for all experiments. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific change to the abstract, recommending that it should include a more detailed statement about the expressivity of the model, referencing a specific citation. It also suggests including learning curves for all experiments, at least in an appendix. While the comment provides a clear suggestion for improvement, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion is based on a logical assumption that including more detailed information would enhance the abstract, but it does not provide specific examples or references to support this claim. Therefore, the comment is 3, as it offers a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting a more detailed statement about the expressivity of the model, referencing a specific citation. It also recommends including learning curves for all experiments, at least in an appendix, which is a valuable suggestion for enhancing the transparency and completeness of the paper. This feedback is clear and actionable, offering the authors a straightforward way to improve their draft. However, it could be more helpful if it provided additional context or examples to further support the suggestions. Overall, the comment is 4, as it guides the authors in making significant improvements to their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the motivation of the paper, specifically regarding the application of the proposed method. It suggests that the authors clarify the need for domain adaptation and provide examples of actual tasks where the methodology could be useful. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the application of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the motivation of the paper, specifically regarding the application of the proposed method. It questions the relevance of the results, which involve mapping one RGB image to another with a different style, and suggests that the authors clarify the need for domain adaptation and demonstrate the methodology\"s utility on actual tasks. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its request for clarification and examples of actual tasks, providing clear guidance on what the authors need to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the motivation of the paper, questioning the relevance of the results and suggesting that the authors clarify the need for domain adaptation and demonstrate the methodology\"s utility on actual tasks. The comment provides a logical reasoning by pointing out the lack of clear application and suggesting a more practical demonstration. However, it lacks specific examples or references to support the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the motivation of the paper, specifically regarding the relevance and application of the proposed method. It points out that the paper\"s results involve mapping one RGB image to another with a different style, and it questions the need for domain adaptation and the utility of the methodology. The reviewer suggests that the authors provide examples of actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset, which would better demonstrate the methodology\"s usefulness. This feedback is clear and actionable, as it directs the authors to clarify the motivation and application of their work, which is essential for improving the paper\"s clarity and impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any explicit or implicit actions for the authors to take regarding these references. There is no guidance on how the authors should incorporate these references into their paper or what specific aspects of their work should be compared or discussed with these references. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific references, such as MISA, M2FNet, and MMDFN, which are relevant to the field of multimodal sentiment analysis. However, it does not specify which part of the paper these references are relevant to, making it difficult for the authors to identify the exact section that needs attention. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline that considers crosssensory interaction, but it is out of fashion since it was proposed in 2019. While the comment provides some context, it lacks specificity in terms of what aspects of the paper need improvement or clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered out of fashion. However, the comment does not provide any specific evidence or reasoning to support this claim. It lacks detailed references or examples to substantiate the assertion that MULT is outdated or out of fashion. Without additional context or justification, the claim remains 1, as it does not provide the authors with a clear understanding of why MULT is considered outdated or out of fashion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a list of references to other works in the field of multimodal sentiment analysis, including MISA, M2FNet, and MMDFN. However, it does not offer any specific feedback or suggestions on how the authors might use these references to improve their paper. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline that considers crosssensory interaction, but it is out of fashion since it was proposed in 2019. While this observation may be relevant, it does not provide actionable guidance or suggestions for the authors to enhance their work. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a major issue with the comparison against other models in the experiments, specifically noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It explicitly instructs the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. The comment provides a clear and concrete action for the authors to take, which is to include the ranks for all models and compare them with the same number of parameters. This guidance is explicit and provides a specific direction for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the value of the used ranks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, noting that the ranks are omitted, which makes it impossible to conduct a fair comparison. The comment further provides a concrete suggestion for improvement by instructing the authors to compare tensor completion results for all models with the same number of model parameters. This detailed guidance ensures the authors know exactly what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all models. This makes it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models while ensuring they have the same number of model parameters. This is a logical and reasonable suggestion, as it provides a clear and specific way to address the issue of fairness in the comparison. However, the comment could be strengthened by providing examples or references to similar studies that have successfully compared models with different ranks. Overall, the claim is 4 due to the logical reasoning and the suggestion for improvement, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the comparison against other models in the experiments. It points out that the omission of the value of the used ranks for all models makes it impossible to conduct a fair comparison. The comment provides a clear and actionable suggestion for improvement, instructing the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. This guidance is specific and provides a concrete way for the authors to enhance the clarity and fairness of their comparison. However, the comment could be more helpful if it included additional details or examples of how to compute the number of model parameters or if it suggested specific models to include in the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA is a bit better than FP according to the results in Table 1.\" This feedback is explicit and provides a clear action for the authors to take, which is to include \"ATA\" in the comparison. The suggestion is concrete, as it specifies what needs to be added to the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that the proposed method should be compared to \"ATA\" in addition to \"+LFP.\" This provides clear guidance on what needs to be addressed in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA is a bit better than FP according to the results in Table 1.\" This claim is based on the observation that \"ATA\" is better than \"FP\" in terms of results, as indicated in Table 1. The reviewer provides a logical reasoning by referencing specific results from Table 1, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is 4, as it provides a clear rationale but lacks some depth in its explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, suggesting that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in the leave one out setting. This feedback is clear and actionable, as it provides a direct suggestion for improving the comparison by including a more relevant baseline. By addressing this point, the authors can enhance the comprehensiveness and validity of their results. However, the comment could be more helpful if it explained why including \"ATA\" is important or how it would strengthen the comparison. Overall, the comment is 4 as it guides the authors towards a specific improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the normalization module, suggesting that it appears different in the two versions but seems to be the same based on the text. It also recommends standardizing pictograms and addressing a minor issue with Fig. 4 regarding symbol overlap in the 0/50 latency range. Additionally, it mentions a minor problem with the text on page 4 after the equation. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to resolve these problems. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures,\" \"Fig. 4,\" and \"page 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the normalization module, the need for standardization of pictograms, and the confusion in Fig. 4 regarding symbol overlap. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the normalization module and the pictograms in Fig. 4, suggesting that they are confusing. It also mentions a minor problem with the text on page 4 after the equation. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The mention of \"Fig. 4\" provides some context, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including concerns about the normalization module and the pictograms in Fig. 4. It suggests that the normalization module appears different in the two versions but seems the same based on the text, and recommends standardizing pictograms to improve clarity. Additionally, it points out a minor problem with Fig. 4 regarding symbol overlap in the 0/50 latency range. The comment also mentions a minor issue with the text on page 4 after the equation. While the feedback is 3 in identifying areas for improvement, it could be more comprehensive by providing specific suggestions or examples on how to address these issues. Overall, the comment provides valuable insights but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide explicit guidance on how the authors should address this issue or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"observation\" and the \"theoretical part\" of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the lack of detail on how the proposed algorithm removes subdivision splines and whether it incurs extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific examples or references to support the claim that the algorithm lacks detail or incurs extra computation cost. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional details are needed. The feedback is 3 as it highlights an area that requires further clarification, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that W1 and W2 are not defined in the paper, suggesting that they might denote the Encoder and the Decoder network. It also mentions that W and V are not defined in Eq. 3, which is similar to the issue with W1 and W2. However, the comment does not provide explicit instructions on how the authors should define these terms or where they should be defined. The actions are implicit and somewhat vague, as the authors need to infer that they should define these terms in the appropriate sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides explicit references to page 3, line A4, and Eq. 3, allowing the authors to accurately identify the parts of the paper being addressed. This level of detail ensures full grounding. Additionally, the comment specifies what needs to be addressed, namely the need to define these terms, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that W1 and W2 are not defined in the paper, suggesting they might denote the Encoder and the Decoder network. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides clear and actionable feedback by suggesting that these terms might denote the Encoder and the Decoder network, which could help the authors clarify their notation. However, the comment could be more helpful if it offered suggestions on how to define these terms or where they should be defined in the paper. Overall, the comment is 4 as it directs the authors to address a critical issue in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not provide specific guidance on how to make this comparison fairer or what alternative baselines should be used. The action is implicit and somewhat vague, as the authors need to infer that they should improve the comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the fairness of the comparison with some baselines, specifically mentioning that they lack prior knowledge of users or language embedding computation. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the fairness of the comparison, suggesting a better approach should be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed justification or references to substantiate the assertion that the comparison is unfair. As a result, the claim is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and some baselines. It points out that these baselines lack prior knowledge of users or language embedding computation, suggesting that a better comparison should be considered. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how to address this issue or what alternative baselines might be more appropriate. The feedback is 3 as it points out a potential weakness in the paper, but it could be more actionable with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the paper. It asks why the outputside layers do not benefit from a certain aspect, questions the clarity of Figure 4, and seeks clarification on the Pixelshuffle operation. Additionally, it points out the lack of discussion on limitations and potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the benefits of the outputside layers, improve the clarity of Figure 4, explain the Pixelshuffle operation, and discuss the limitations and societal impacts of their work. The feedback is 3 as it provides a direction for improvement but lacks concrete steps or examples. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses several specific issues, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of the Pixelshuffle operation, and the absence of discussion on limitations and potential negative societal impacts. It provides detailed feedback on each of these points, making the comment fully grounded as it explicitly mentions the sections or elements being addressed. The comment is also specific because it clearly outlines what needs to be addressed in each case. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of the Pixelshuffle operation, and the absence of discussion on limitations and potential negative societal impacts. While the comment identifies these issues, it does not provide specific evidence, examples, or references to support the claims. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several specific concerns and questions about the paper, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of the Pixelshuffle operation, and the absence of discussion on limitations and potential negative societal impacts. These points are relevant and provide actionable feedback for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to areas that need further clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore the impact of this process on performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the process and its potential impact on performance, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance and asks for clarification. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to enhance their draft. The feedback is 3 as it prompts the authors to consider the impact of their current approach, but it does not provide detailed or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on new patients and old patients separately, given that the patients are firsttime visitors without historical reports. This is an explicit action that provides clear guidance on how the authors can improve their work. The suggestion is concrete, as it specifies the type of evaluation needed and the distinction between new and old patients. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate the approach on new and old patients, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. However, the comment does not provide any reasoning, evidence, or references to support why this evaluation is necessary or how it would improve the approach. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. This feedback is 3 as it identifies a potential limitation in the current evaluation and provides a clear direction for improvement. However, it lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered when evaluating new versus old patients. To be more helpful, the comment could include suggestions on how to differentiate between new and old patients or what metrics should be used to assess the approach. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether this dataset is used in all experiments or just some, and if so, whether this provides an unfair advantage to the proposed method. While the comment highlights a potential issue, it does not explicitly instruct the authors to clarify this point or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the experimental methodology, specifically questioning the use of the 300WLP dataset in the experiments. It points out that the paper claims to use the same procedure as the baselines, but most baselines do not use this dataset. The comment is fully grounded as it explicitly mentions the 300WLP dataset and the experimental methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the dataset and questions whether it provides an unfair advantage to the proposed method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether this dataset is used in all experiments or just some, and if so, whether this provides an unfair advantage to the proposed method. The comment is based on a logical reasoning that the use of a dataset not commonly used by baselines could affect the fairness of the comparison. However, the comment lacks specific examples or references to support the claim that the use of 300WLP provides an unfair advantage. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether this dataset is used in all experiments or just some, and if so, whether this provides an unfair advantage to the proposed method. This feedback is valuable as it highlights a potential issue that could affect the validity of the experimental results. By pointing out this ambiguity, the comment encourages the authors to clarify their methodology, ensuring a more transparent and fair evaluation of their work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the use of additional datasets or methods to validate the results. Overall, the comment is 4 as it identifies a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that some aspects of the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these concerns or what specific improvements might be necessary. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques or where they are applied, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in terms of what needs to be addressed or improved, leaving the authors without clear guidance on how to respond. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some aspects of the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any detailed feedback or suggestions on how the authors might address this issue. Without actionable guidance or examples, the authors are left without a clear understanding of what aspects need to be revised or improved. Therefore, the comment is 2, as it provides a general observation but does not offer meaningful feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides an understanding of the integral in Equation (1) as a bag observation model or spatial aggregation process. It highlights a potential issue with the authors\" assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to modify their assumptions. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation (1), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the authors\" assumption about the observations being obtained by averaging over the corresponding support $v$. The comment points out that the data might be aggregated by another procedure, such as simple summation or population weighted average, and provides examples of how disease incident data are often available. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to a bag observation model or spatial aggregation process, referencing specific works. It then questions the authors\" assumption about the observations being obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides examples of how disease incident data are often available in count or rate per the number of residents. While the comment offers a logical explanation and references external works, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a detailed explanation of the integral in Equation (1), relating it to bag observation models or spatial aggregation processes. It highlights a potential issue with the authors\" assumption about the observations being obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. The comment also points out that disease incident data are often available in count or rate per the number of residents. This feedback is valuable as it offers a clear understanding of the integral and suggests a potential area for improvement in the authors\" assumptions. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or suggested alternative approaches. Overall, the comment is 4, as it provides insightful feedback that can guide the authors in refining their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis of this training dynamics would strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, but without explicit references to sections or figures, the authors may struggle to pinpoint where this analysis should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis would strengthen the paper. However, the comment does not provide specific reasoning or evidence to support why this analysis is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of indepth analysis in the paper, specifically questioning why inverse scaling occurs over compute. It suggests that providing an analysis of this training dynamics would significantly strengthen the paper. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. The feedback is 3 as it points out a critical gap in the paper\"s analysis but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multihead attention. It also asks for clarification on the split arrow in Figure 2 and whether the same vectors are used for keys and values. While the comment does not explicitly instruct the authors to provide these definitions, it clearly indicates what information is missing and how it could be improved. The authors can infer that they need to clarify these details to enhance the readers\" understanding. However, the comment lacks specific guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition in architectural details, particularly regarding multihead attention. The comment also asks for clarification on the split arrow in Figure 2, specifying what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multihead attention. It also asks for clarification on the split arrow in Figure 2. While the comment identifies areas where the paper could be improved, it does not provide specific reasoning or evidence to support the need for these clarifications. The request for a formal definition of multihead attention and the split arrow in Figure 2 is clear, but without additional context or examples, the authors may find it challenging to fully understand and address the issues. Therefore, the comment is 3, as it provides a basis for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of mathematical definition in the architectural details, particularly regarding multihead attention. It provides a clear and actionable suggestion by asking for clarification on the split arrow in Figure 2 and whether the same vectors are used for keys and values. This feedback is valuable as it guides the authors to enhance the clarity and understanding of their work for readers. However, the comment could be more helpful if it offered additional suggestions or examples on how to improve the mathematical definition. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider a more complex setting where the policy is not fixed, which would allow them to compare with a reinforcement learning algorithm baseline. While the comment implies that the authors should explore a more challenging scenario, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to expand the scope of their work, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring a more complex setting where the policy is not fixed, which would allow the authors to compare with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider a more challenging scenario, but without explicit references to sections or parts of the paper, the authors may struggle to identify the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. However, the comment does not provide specific examples or references to support the claim that tasks could become more complicated. The suggestion to compare with a reinforcement learning algorithm baseline is a logical extension of the proposed setting, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. This suggestion could be valuable for the authors as it opens up a new direction for exploration and comparison with reinforcement learning algorithms. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the current work could be expanded to achieve this. While it provides a direction for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analyses. The action is implicit and vague, as the authors are left to infer that they need to conduct more comprehensive analyses or provide a clearer explanation of their method\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the issue with the comprehensiveness of the analyses and the question regarding the performance improvement claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are not comprehensive enough. The authors are left to infer that more detailed analyses are needed, but the comment does not provide explicit guidance or evidence to substantiate this claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s experimental analysis, noting that the majority of the experiments focus on presenting results rather than comprehensively analyzing the method itself and the experimental outcomes. It highlights a potential limitation in the paper\"s claims, questioning the extent to which the performance improvement brought by the pretraining method can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. This feedback is 3 as it points out a critical area for improvement in the paper\"s analysis and raises a valid concern about the authors\" claims. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or enhance their analysis. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might expand the scope of their work or what specific areas they should explore to enhance applicability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this critique pertains to, such as a particular section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s focus on explaining multitask models limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on explaining multitask models, suggesting that this focus may limit the applicability of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the literature review ignores several papers that seem relevant, specifically mentioning VRMARINA for online problems from [1] and DASHAMVR from [2]. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to include these papers in their literature review. The suggestion is implicit and lacks concrete details, making it 3. The authors can infer that they need to consider including these papers, but the comment does not provide a clear path for implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the literature review ignores several papers that seem relevant, specifically mentioning VRMARINA for online problems from [1] and DASHAMVR from [2]. This provides clear guidance on what needs to be addressed in the literature review. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA for online problems from [1] and DASHAMVR from [2]. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide specific examples or detailed reasoning to support why these papers should be included or how they improve upon QSGD. The mention of [1] and [2] provides some context, but the lack of detailed justification or evidence makes the claim 3. The authors would need to conduct further research or analysis to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the literature review, specifically mentioning that several papers relevant to the topic are ignored. It highlights two papers, VRMARINA for online problems and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment suggests that these papers should be included in the literature review. However, the feedback lacks specific guidance on how the authors should incorporate these papers or what additional context should be provided. While it points out an important omission, the comment could be more helpful with detailed suggestions or examples. Therefore, it is rated as 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the presentation of the paper is difficult for the reviewer to follow, but it does not provide any specific guidance or suggestions on how the authors might improve the presentation. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the presentation need improvement. As a result, the authors are left without any actionable steps to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is difficult to follow, but it does not specify which part of the paper is problematic or provide any details on what aspects of the presentation are unclear. This lack of specificity makes it challenging for the authors to identify the exact areas that need improvement. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point states that the presentation of the paper is difficult to follow, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed information or context, the authors may find it challenging to understand the basis of the reviewer\"s difficulty in following the presentation. As a result, the claim is 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses difficulty in following the presentation of the paper, but it does not provide any specific examples or suggestions for improvement. This lack of detail makes it challenging for the authors to understand where the presentation is unclear or how to address the issue. Without actionable feedback or guidance, the comment does not contribute significantly to the authors\" efforts to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions asking for additional insights into the modest performance gains on the Clothing1M dataset and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While the questions provide a clear direction for the authors to explore, they do not explicitly instruct them to make specific changes or additions to their draft. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional insights or comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment consists of two questions, one asking for additional insights into modest performance gains on the Clothing1M dataset and the other inquiring about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The questions are specific in terms of what information is being sought, but without grounding, the authors cannot determine where to address these issues. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance comparisons. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment consists of two questions that seek additional insights and performance comparisons. The first question asks for more information about the modest performance gains on the Clothing1M dataset, while the second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions provide the authors with valuable feedback on areas where they can enhance their understanding and presentation of their results. However, the comment does not offer specific guidance or suggestions on how to address these questions or improve the draft. While it prompts the authors to consider additional aspects of their work, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a more detailed presentation of the compared models, specifically KVAE, and requests an explanation of the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information and explain the computation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely, a more detailed presentation of the compared models and an explanation of the computation requirements of the three methods. The comment provides clear guidance on what additional information is needed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the reviewer is not familiar with the compared models DMM and DVBF in detail but understands their differences with KVAE. The reviewer suggests a more detailed presentation of these models. The comment also provides a specific observation about the KVAE, noting that it is simpler due to its linear state space transition but requires computation of timedependent LGSSM parameters. However, the comment does not provide specific examples or references to support the claim about the computation requirements of the three methods compared in Table 1. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the presentation of the compared models, specifically KVAE, could be more detailed. It highlights a specific aspect of KVAE, noting that it is simpler due to its linear state space transition but requires computation of timedependent LGSSM parameters. The reviewer also requests an explanation of the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it provides specific areas for the authors to address to enhance the clarity and completeness of their presentation. However, the comment could be more helpful if it included suggestions on how to present this information or examples of how other models are discussed. Overall, the comment is 4, as it guides the authors towards improving their draft by providing specific areas for clarification and detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. While the comment implies that these experiments are necessary to provide a more comprehensive benchmark, it does not explicitly instruct the authors to perform these additional experiments or provide guidance on how to integrate them into the study. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack specific instructions on how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. However, it does not specify which part of the paper discusses the current experiments on T5, PaLM, and GPT series LLMs, making it weakly grounded. The comment is specific in suggesting additional experiments to include, but without explicit references to the current experiments, the authors may find it challenging to pinpoint the exact sections that need further exploration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. However, the comment does not provide any reasoning, examples, or references to support why these specific LLMs are more appropriate or why they should be included. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the current experimental setup, specifically suggesting that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. This feedback is 3 as it points out a gap in the study that could enhance the comprehensiveness of the results. However, the comment lacks specific guidance on how to integrate these additional experiments or what specific aspects of the study would benefit from them. To be more helpful, the comment could provide more detailed suggestions or examples of how these additional experiments could be conducted and what insights they might yield. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper does not describe the hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the lack of description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the hyperparameters and evaluation, providing clear guidance on how to improve the paper. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not describe the hyperparameters used by each defense nor how they are derived. It suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This claim is 3 as it points out a specific gap in the paper\"s methodology, but it lacks detailed examples or references to support the suggestion of a maximally charitable evaluation. The authors would need to infer how to address this issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not describe the hyperparameters used by each defense nor how they are derived. This is a critical aspect of the methodology that could impact the evaluation and interpretation of the results. The comment also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by including this information. However, the comment could be more helpful if it offered additional guidance on how to optimize hyperparameters or what specific aspects of the evaluation should be considered. Overall, the comment is 4 as it highlights a significant omission and offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment does not explicitly instruct the authors to include these takeaways or provide detailed guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include more practical implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and suggests that they lack immediate practical implications, which is understandable given the novelty of the work. It also mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main takeaway point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the main takeaway point, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that more takeaway points for practitioners would be beneficial, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks specific examples or references to support the claim that this observation is novel or unique to the paper. The reasoning is somewhat vague, as it does not provide detailed evidence or context to fully substantiate the claim. Therefore, the comment is categorized as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks depth and does not provide specific guidance on how to present these takeaways or what additional points might be valuable for practitioners. While it identifies a potential area for improvement, the feedback is 3 as it provides a starting point for the authors to consider, but it could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information they provide beyond T/I/O. While the comment raises a valid point about the need for clarification, it does not explicitly instruct the authors to provide this information or suggest specific details to include. The action is implicit and somewhat vague, as the authors can infer that they need to explain the purpose and additional information of the separators, but the comment does not provide concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of introducing separators and asks for clarification on the additional information they provide beyond T/I/O. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or what specific issues might arise. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the purpose and additional information provided by the introduction of separators in section 4. It prompts the authors to clarify why these separators are necessary and what specific information they convey beyond the traditional T/I/O (transmission, input/output) framework. This feedback is 3 as it encourages the authors to provide more detailed explanations, which could enhance the clarity and depth of their paper. However, the comment could be more helpful if it suggested specific areas for clarification or provided examples of how the information could be better presented. Overall, the comment offers a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate different pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling and suggests considering other pooling strategies. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of mean pooling and suggests considering other pooling strategies. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a request for clarification or further explanation, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how they might be implemented. The comment lacks depth and actionable advice, leaving the authors with a general idea of what to consider but without concrete steps to take. Therefore, it is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is an explicit suggestion that provides a clear action for the authors to take, as it specifies what additional information should be included in the comparison. The comment is concrete, as it gives a specific metric to consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost, such as the number of GPU days, in addition to the number of queries. This provides clear guidance on what needs to be added to improve the comparison in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is a logical suggestion that aligns with common practices in evaluating computational efficiency. However, the comment does not provide specific examples or references to support the claim that this additional comparison is necessary. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of results in Table 3. It suggests comparing the real search cost, such as the number of GPU days, in addition to the number of queries. This feedback is actionable and provides a clear direction for enhancing the comprehensiveness of the comparison. By addressing this suggestion, the authors can better illustrate the computational efficiency of their method, which is an important aspect of evaluating machine learning algorithms. However, the comment could be more helpful if it explained why this additional comparison is important or how it could impact the interpretation of the results. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This request provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"training details\" and specifically asks about the pretraining of the VQGAN and its training on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what part of the paper needs clarification. The comment is specific because it identifies the exact details that are missing, allowing the authors to address the issue directly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on specific training details, specifically whether the VQGAN is pretrained or trained on a particular dataset. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on a specific dataset. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or emphasized its importance. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should include references to relevant works, such as Li, 2017, and discuss how the current work differs from other chatbox research, like He, 2015. While the comment implies that these references and comparisons would be beneficial, it does not explicitly instruct the authors to include these references or discuss the differences. The action is implicit and somewhat vague, as the authors can infer the need for these additions but may not know how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should include references to relevant works, such as Li, 2017, and discuss how the current work differs from other chatbox research, like He, 2015. However, it does not specify which part of the paper these references should be included in or how the discussion should be structured. The authors can infer that the references should be added to the literature review or discussion sections, but the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the work should include references to relevant works, such as Li, 2017, and discuss how the current work differs from other chatbox research, like He, 2015. However, the comment does not provide specific reasoning or evidence to support why these references are important or how they would enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the suggested additions or comparisons. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the work should include references to relevant works, such as Li, 2017, and discuss how the current work differs from other chatbox research, like He, 2015. This feedback is 3 as it provides specific references that could enhance the paper\"s context and relevance. However, the comment lacks detailed guidance on how to integrate these references or what aspects of the work should be emphasized in the discussion. While it points out areas for improvement, it does not offer actionable steps or suggestions for the authors to follow, limiting its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the generality of their methods. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). This feedback is 3 as it highlights a potential limitation of the methods, which could guide the authors in revising or expanding their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the generality of their methods. Therefore, the comment is rated as 3, as it provides a starting point for improvement but does not fully support the authors in making significant enhancements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative approach of running vanilla Adam on the final network with 40 random initial points, where one restart could reach the global minimum. However, the comment does not explicitly instruct the authors to adopt this alternative approach or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider this alternative and potentially test it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative approach of running vanilla Adam on the final network with 40 random initial points, where one restart could reach the global minimum. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the experimental design are questionable or how the suggested alternative could be implemented. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the approach, questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative approach of running vanilla Adam on the final network with 40 random initial points, where one restart could reach the global minimum. However, the comment lacks specific reasoning or evidence to support why this alternative approach is more effective or why the current approach is flawed. The suggestion is based on a logical argument but lacks detailed justification or references to substantiate the claim. Therefore, the comment is considered 2, as it provides some reasoning but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative approach of running vanilla Adam on the final network with 40 random initial points, where one restart could reach the global minimum. While the comment identifies a potential weakness in the experimental design, it lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors should investigate or establish this relationship, nor are there suggestions for additional experiments or analyses that could be conducted. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the study, specifically mentioning that the relationship between the top selected patches and the disease is not yet established. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the missing relationship, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, specifically pointing out that the relationship between the top selected patches and the disease is not yet established. This feedback is clear and actionable, as it highlights a critical area that needs further investigation or clarification. However, the comment could be more helpful if it provided suggestions on how the authors might explore or establish this relationship, such as through additional experiments or analyses. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide explicit guidance on how the authors should address this issue or improve the performance of FedSP. The comment lacks concrete suggestions or actions for the authors to take, making it difficult for them to know how to respond. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of FedSP in Tables 1 and 2, suggesting that it is not the best on some datasets. However, it does not specify which datasets are being referred to or provide details on what aspects of the performance are lacking. The authors can infer that the comment pertains to the performance of FedSP in the tables, but the lack of specificity makes it difficult to pinpoint the exact issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2, suggesting that the theme of the paper might be mainly about FedSP. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or improve the performance of FedSP. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify what Omega is and to be more explicit about the link function and the theorem in [32] that provides the regret guarantee. These requests are direct and specific, providing clear guidance on what needs to be addressed. The authors know exactly what information to include and how to improve their draft to address these points. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying what Omega is, being more explicit about the link function, and specifying the theorem in [32] for the regret guarantee. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions asking for clarification on specific aspects of the paper, such as the definition of Omega, the link function used, and the theorem referenced for the regret guarantee. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the authors need to provide more clarity and detail in their draft. By asking for clarification on what Omega is and being more explicit about the link function and the theorem in [32], the comment provides clear guidance on how the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to make the information more explicit. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their models. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the absence of a Markovian state in the learning process, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the models being learned directly from pixels without a Markovian state. This is a critical observation that could impact the validity and effectiveness of the models. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without additional context or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed feedback or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a question about a specific practice mentioned in Example 2. The reviewer is surprised by the mention of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF). They suggest that the authors clarify this by providing references to relevant works. While the comment identifies a specific area of confusion and requests clarification, it does not explicitly instruct the authors to provide references or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide references to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in the example, namely the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF. The reviewer questions the commonality of this approach and suggests that the authors provide references to clarify this point. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about a specific practice mentioned in Example 2, questioning the commonality of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF). The reviewer suggests that the authors provide references to clarify this point. While the comment identifies a potential area of confusion, it lacks specific references or examples to support the claim that this practice is uncommon. The suggestion to provide references is a logical response to the question, but the initial claim is not 5 due to the lack of supporting evidence. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a specific question about a particular practice mentioned in Example 2. The reviewer is surprised by the mention of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF) and suggests that the authors clarify this by providing references to relevant works. This feedback is clear and actionable, as it directs the authors to address a potential misunderstanding or lack of awareness in the field. By suggesting references, the comment provides a concrete way for the authors to enhance the clarity and credibility of their work. However, it could be more helpful if it offered additional context or examples to support the suggestion. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two actions: changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections while briefly mentioning the metrics in the captions of the tables. These suggestions are explicit and provide clear guidance on how the authors can improve their draft. The first action is concrete, as it specifies what needs to be changed, and the second action is also concrete, as it outlines how the metrics should be integrated into the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, which implies that the authors should consider renaming the section and possibly revising the content. However, it does not specify which sections or parts of the paper are being addressed, making it weakly grounded. The comment is specific in suggesting changes to the terminology and structure of the paper, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, suggesting that the metrics are wellknown and standard practice. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the metrics are indeed wellknown and standard. The authors would benefit from more detailed justification or examples to fully understand and apply the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting a change in terminology and the removal of sections, which could improve the clarity and organization of the paper. It also offers a specific suggestion to briefly mention the metrics in the captions of the tables, aligning with common practices. This feedback is clear and provides concrete steps for the authors to enhance their draft, making it 4. However, it could be more helpful if it included additional context or examples to fully support the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any explicit guidance or suggestions on how to explore the dataset further or what aspects should be emphasized. The action is implicit and vague, as the authors are left to infer that they should expand their discussion or analysis of the dataset but without specific direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper where the dataset is mentioned. Without explicit references or detailed guidance, the authors may find it challenging to determine exactly where to focus their efforts. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific guidance or examples on how the authors might expand their discussion or analysis of the dataset. Without actionable advice or detailed suggestions, the comment lacks depth and does not offer the authors a clear path to improve their draft. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or steps to enhance their work. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It provides a specific example of the issue, mentioning the squished axes and the difficulty in characterizing the improvement as remarkable. This feedback is clear and direct, giving the authors a specific action to take in revising their draft. The comment is 5 because it provides a concrete and explicit direction for improvement, ensuring the authors know exactly what changes to make.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"[218],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of the term \"remarkable\" and the difficulty in characterizing the accuracy improvement as such, given the squished axes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"remarkable\" should be replaced with more objective terms due to the difficulty in characterizing the accuracy improvement as such, given the squished axes. The reviewer provides a specific example of the issue, which is the squished axes, and suggests using more objective terms. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing additional examples or references to support the use of more objective terms. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors use more objective terms instead of describing the accuracy improvement as \"remarkable.\" It highlights a potential issue with the use of subjective language, which could mislead readers. By pointing out the squished axes and the difficulty in characterizing the improvement as remarkable, the comment offers a clear direction for improvement. This feedback is valuable as it helps the authors refine their language to be more precise and objective, enhancing the clarity and credibility of their work. However, the comment could be more helpful if it provided examples of more objective terms or suggested alternatives. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could potentially address these issues. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what could be done to improve the results, but the action is not directly stated, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and references the UCF101 dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the synthesized results, noting inconsistencies in motion, color, and object disappearance over time. The suggestion to use videos with a longer duration by running the LSTM over many time steps is specific and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synthesized results for UCF101 exhibit inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration could potentially address these issues by running the LSTM over many time steps. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim of inconsistencies. The suggestion is 3 as it offers a potential solution but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for the UCF101 dataset, noting inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could potentially address these issues. This feedback is clear and actionable, providing the authors with a concrete direction for improvement. However, the comment could be more helpful if it included specific examples or detailed reasoning about how the suggested approach would resolve the issues. Overall, the comment is 4 as it offers a valuable suggestion for enhancing the results, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that realizing efficiency gains on GPU is a common challenge in pruning work, but it does not provide any specific guidance or suggestions for addressing this issue. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges a common challenge in pruning work, specifically regarding the difficulty of realizing efficiency gains on GPU. However, it does not specify which part of the paper this issue is relevant to, nor does it provide any guidance on how the authors might address this challenge. Without explicit references to sections or specific parts of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges a common challenge in pruning work, specifically regarding the difficulty of realizing efficiency gains on GPU. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. While it identifies a relevant issue, it lacks actionable feedback or suggestions for addressing this challenge. The comment does not provide any guidance on how the authors might overcome this limitation or improve their work in this area. As a result, it is not helpful to the authors in terms of improving their draft, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not entirely fair due to the complexity of the problem addressed by [5]. While the comment identifies a potential issue with the evaluation, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for improvement, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with [5] is not completely fair due to the complexity of the problem addressed by [5]. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the evaluation and the potential unfairness of the comparison, but it lacks grounding as it does not reference a specific section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the evaluation being conducted only on synthetic data and the comparison with [5] being unfair because [5] is designed for a more complex problem. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate why the evaluation is not convincing or why the comparison is unfair. Without additional context or justification, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not entirely fair due to the complexity of the problem addressed by [5]. This feedback highlights an important aspect that the authors should consider when evaluating their method, which is crucial for ensuring the robustness and generalizability of their results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. Overall, the comment is 3 as it points out a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment implies that conducting this experiment could strengthen the paper, but it does not explicitly instruct the authors to perform the experiment. The action is implicit and somewhat vague, as the authors need to infer that they should consider conducting the experiment to enhance the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in questioning the impact of the number of bits in logits on robustness, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external works that could validate the suggestion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment provides a potential area for further exploration that could strengthen the paper, but it lacks specific guidance or suggestions on how to conduct the experiment or what results to expect. While it identifies a potential avenue for improvement, the feedback is 3 as it prompts the authors to consider additional experiments but does not offer detailed advice on how to implement them. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the method might affect insurance costs. The comment lacks both explicit and implicit actions, leaving the authors without any direction on how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about insurance costs, but without grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the impact of the method on insurance costs for men and women. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the method might affect insurance costs. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it provides a starting point for the authors but does not offer comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which gives the authors a clear direction on how to address the issue. This level of specificity and directness makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the difference between meta solvers and centralized RL, specifically mentioning that the meta solvers seem to be centralized controllers. It suggests that the authors clarify this distinction and provides a reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which helps ground the comment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could help the authors understand the distinction. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference is a step in the right direction, the lack of detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this distinction by referencing a specific work, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016.\" This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing a potential misunderstanding in the literature. However, the comment could be more helpful if it included additional context or suggestions on how to present this clarification effectively. Overall, the comment is 4 as it guides the authors in improving their understanding and presentation of the topic, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their categorization. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the discrepancy between arXiv and ACL Anthology publication dates, particularly mentioning the BERT paper as an example. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper categorizes papers based on their publication years, but many papers are available on arXiv much earlier than the ACL Anthology. The comment provides a specific example, mentioning the BERT paper as an instance where this discrepancy exists. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as statistics or comparisons between the two sources. This makes the claim 3, as it provides a specific example but requires additional context or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. It provides a specific example, mentioning the BERT paper as an instance where this discrepancy exists. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their categorization. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are given a starting point for reflection but are left without clear steps to take to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. While the action is explicit, it is somewhat vague because it does not specify which part of the paper this definition is found in or how the examples should be structured. The authors know they need to provide examples, but the comment lacks detailed guidance on how to do so effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. However, the comment does not provide specific examples or detailed reasoning to support why the notation is unclear or how examples could improve understanding. The lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used to define M_T, specifically noting that it is unclear whether M_T is defined over the probabilities of atomic events. The reviewer suggests that providing examples could help clarify this concept. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to present these examples or what aspects of the notation are unclear. This feedback is 3 as it points out a potential area of confusion but does not offer comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a valid concern but does not provide explicit guidance on how the authors should address this issue. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u to demonstrate the difference. While the second part is 3, the first part lacks explicit guidance, making the overall comment barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the use of rejection sampling with an arbitrary parameter beta instead of importance sampling, and the differentiation between QRS and RS in Algorithm 1. The first part of the comment is fully grounded as it explicitly mentions the use of rejection sampling and the parameter beta, allowing the authors to accurately identify the part of the paper being addressed. The second part is also fully grounded, as it refers to Algorithm 1 and the specific elements QRS and RS. The comment is specific in detailing what needs to be addressed in each part, providing clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a logical question but lacks specific reasoning or evidence to support the claim that importance sampling would be more appropriate. The second part of the comment points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, suggesting that the authors should clarify this. However, it does not provide specific examples or references to support the claim. Therefore, the comment is 4, as it raises valid points but lacks detailed justification or evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises two points. First, it questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta, suggesting that the latter choice is arbitrary. This raises a valid concern about the appropriateness of the method used. Second, it points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, asking the authors to clarify this if they can provide a specific value of u for which the two methods behave differently. While the comment identifies areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it highlights potential weaknesses but does not fully support the authors in making the necessary improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the performance. The comment lacks actionable details, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not specify which part of the paper discusses these enhancements or where further refinement is needed. This lack of grounding makes it difficult for the authors to identify the exact sections that require attention. The comment is specific in suggesting a need for further refinement, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that the enhancements are modest or to suggest where further refinement is needed. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. While it identifies a potential area for improvement, the comment lacks specificity and actionable guidance. It does not provide any suggestions on how the authors might address this issue or what steps they could take to enhance the performance further. As a result, the feedback is vague and does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide references for specific passages in Section 3.2, lines 230234 and 234235, which discuss the sequencetosequence machine translation model and its components. Additionally, it asks for clarification on \"MLP\" in Figure 2, as it is not described in the paper. These requests are clear and direct, providing the authors with explicit actions to take. The feedback is concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing references for specific passages and clarifying the term \"MLP\" in Figure 2. This level of detail ensures that the authors can effectively address the feedback. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: one requesting references for specific passages in the paper and the other asking for clarification on \"MLP\" in Figure 2. The first part is 3 as it suggests providing references for existing knowledge, but it lacks specific examples or references to support the need for these references. The second part is 1 because it does not provide any reasoning or context for why \"MLP\" should be clarified or why it is not described in the paper. Therefore, the overall verifiability of the comment is 2, as it provides some support for the first part but lacks sufficient justification for the second part.", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the paper lacks references and clarity. It explicitly requests references for two passages in Section 3.2, which discuss the sequencetosequence machine translation model and its components, and for \"MLP\" in Figure 2. This feedback is clear and actionable, providing the authors with specific steps to improve the paper by adding references and clarifying terminology. However, the comment could be more helpful if it offered suggestions on which references to include or how to clarify \"MLP.\" Overall, the comment is 4 as it guides the authors in enhancing the paper\"s clarity and completeness."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to provide more convincing evidence or address the issues mentioned. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not specify which part of the paper these experiments are located in, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in questioning the effectiveness of the proposed method and suggesting potential issues, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The absence of detailed evidence or references leaves the claim 3, as it requires the authors to infer the nature of the problems and how to improve the experimental results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above, implying that the authors need to address these issues. However, the comment lacks specific guidance or suggestions on how to improve the experimental results or address the concerns raised. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is 3, as it highlights an area for concern but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference between detecting \"just\" the long one. While the comment raises a valid point about the purpose of detecting both entities, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the purpose of detecting both entities or provide a rationale for including both in the example. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks about the difference to \"just\" knowing the long one. This provides clear guidance on what aspect of the example needs further explanation or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with a general question that does not offer a clear path for improvement. Therefore, it is rated as 2, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks empirical validation, specifically mentioning the absence of experiments to validate the bounds. It provides a clear and direct action for the authors to take, suggesting that they should include experiments to validate the bounds. This feedback is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment points out the absence of empirical validation, specifically mentioning the lack of experiments to validate the bounds. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for empirical validation, but without grounding, it is challenging for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, specifically mentioning the absence of experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of empirical validation, specifically mentioning the lack of experiments to validate the bounds. This feedback is clear and actionable, as it directs the authors to include experiments to substantiate their claims. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what aspects of the bounds should be validated. Overall, the comment is 4 as it highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" in line 285, specifically asking if \"chunk\" is still considered sequential information. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the meaning of \"nonsequential information\" and \"chunks\" in their draft. However, the comment lacks concrete details on how to resolve the confusion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"nonsequential information such as chunks,\" questioning whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific phrase in the text, \"nonsequential information such as chunks.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the phrase \"nonsequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this phrase, which could potentially improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address the confusion. Overall, the comment is 4 as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly questions the discrepancy between Equation 9 and Figure 1, suggesting that the output patches might not be cropped parts of the input image but just masked versions with most pixels black. It also points out that Figure 1 might be misleading and suggests that zooming on the region of interest using bilinear sampling could provide better results. This feedback is clear and provides a direct action for the authors to address the discrepancy and improve the clarity of their figures. The suggestion is concrete, as it specifies the issue and offers a potential solution. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the discrepancy between the equation and the figure, specifying that the output patches might not be cropped parts of the input image but just masked versions. The comment further suggests that zooming on the region of interest using bilinear sampling could provide better results, offering a concrete suggestion for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific question about the discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions with most pixels black. The reviewer suggests that Figure 1 might be misleading and proposes an alternative method (zooming on the region of interest using bilinear sampling) that could provide better results. While the comment is based on a specific observation and suggests a potential improvement, it lacks detailed reasoning or references to support the claim that Figure 1 is misleading. The suggestion for an alternative method is a logical inference, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions with most pixels black. This observation is clear and actionable, as it prompts the authors to clarify the nature of the output patches and the potential misleading nature of Figure 1. The comment also suggests an alternative method (zooming on the region of interest using bilinear sampling) that could provide better results, offering a concrete suggestion for improvement. This feedback is valuable as it helps the authors address a potential confusion in their presentation and provides a direction for enhancing the clarity and effectiveness of their figures. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply highlights a potential issue without suggesting how the authors should address it. As a result, the authors are left without guidance on how to improve their draft in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption of a separate node with 0 neighbors and explaining why the upper bound would be 0, which is not true. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim or explain why it is a concern. Without additional context or justification, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about Theorem 1, pointing out a potential issue with the assumption of a separate node with 0 neighbors. It highlights that the upper bound in this case would be 0, which is not true, and asks for an explanation. This feedback is clear and actionable, as it directs the authors to clarify or correct the theorem, providing a specific area for improvement. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context. Overall, the comment is 4 as it identifies a critical point for the authors to consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the novelty of their work. As a result, the authors are left without a clear understanding of what steps to take to enhance the technical novelty of their paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what aspects of the paper are similar to the previous works, such as the coattention mechanism or architecture. Without clear grounding and specific guidance, the authors may struggle to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). However, the comment does not provide specific examples or detailed reasoning to support the claim that the idea, coattention mechanism, or architecture are similar to those in the previous works. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). It highlights that the idea, coattention mechanism, and architecture of the paper are quite similar to those in the previous works. This feedback is 3 as it points out a potential area for improvement, but it lacks specific suggestions or guidance on how the authors might differentiate their work or enhance its novelty. The comment could be more helpful if it provided actionable advice or examples of how to address the issue of limited novelty. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a statement on page 5 regarding the training time reduction compared to parameter reduction. It suggests that the discussion on this topic has not been revisited in the Discussion section, and if it is not relevant, it should be deleted. However, the comment does not provide explicit instructions on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they should review the Discussion section and potentially remove it if it is not relevant. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5\" and \"Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early downsampling layers. The comment further suggests that this discussion may not be relevant and should be deleted. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques a statement on page 5 regarding the training time reduction compared to parameter reduction. It suggests that the discussion on this topic has not been revisited in the Discussion section and proposes deleting the Discussion section if it is not relevant. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the discussion is not relevant or why it should be deleted. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques a statement on page 5 regarding the training time reduction compared to parameter reduction. It suggests that the discussion on this topic has not been revisited in the Discussion section and proposes deleting the Discussion section if it is not relevant. While the comment identifies a potential issue with the discussion, it lacks specificity and does not provide detailed guidance on why the discussion is not relevant or how it could be improved. The suggestion to delete the Discussion section is 3, but it does not offer actionable feedback or alternative suggestions for addressing the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem addressed in the paper is specific to binding affinity prediction or applies to other downstream tasks. While the comment implies that the authors should clarify this distinction, it does not provide explicit guidance on how to address this issue or what specific aspects need to be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should provide a detailed explanation of the problem\"s scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors may have to infer that it relates to the methodology or results sections where the problem is discussed. While the comment is specific in its inquiry about the scope of the problem, it lacks grounding as it does not explicitly mention a section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. While this question prompts the authors to clarify the scope of their work, it does not provide specific guidance or suggestions on how to address this issue. The comment lacks actionable feedback or detailed advice, leaving the authors with a general direction but no concrete steps to take. Therefore, the comment is 3, as it identifies an area for clarification but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a gap in the analysis of GPTgenerated rumors, suggesting that there should be an analysis of why these rumors are closer to natural rumors and why they are as difficult to detect as natural rumors. While the comment implies that the authors should conduct further analysis or propose solutions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or solutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the analysis of why GPTgenerated rumors are closer to natural rumors and why they are as difficult to detect as natural rumors. The comment provides a clear direction for the authors to improve their analysis, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting GPTgenerated rumors compared to natural rumors. It suggests that since Artificial Rumor is written by humans, it should be about the same difficulty as Natural Rumor, but the experimental results show otherwise. The comment questions the logic behind the experimental results and implies that there might be a gap in the analysis. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to conduct further analysis or provide additional context to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the analysis of GPTgenerated rumors, specifically questioning why these rumors are as difficult to detect as natural rumors. It points out that since Artificial Rumor is written by humans, it should be about the same difficulty as Natural Rumor, but the experimental results suggest otherwise. This feedback is clear and actionable, as it prompts the authors to conduct further analysis or propose solutions to address this issue. By highlighting this gap, the comment provides valuable insights for improving the paper\"s depth and comprehensiveness. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. While it identifies a potential issue with the technical contribution, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details or actionable steps for the authors to take, such as recommending specific changes or improvements to the content. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This feedback is 3 as it points out a potential area for improvement in the paper\"s technical contribution. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and improve upon this aspect of their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 6, noting that the font size is a bit small. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting a specific font size to use or recommending ways to improve the readability of the figure. Without any guidance or instructions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being small. It does not express an opinion, judgment, or suggestion that requires verification. It is a descriptive statement that does not claim anything beyond what is observed. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6, noting that the font size is too small. While this feedback highlights a potential problem with the figure\"s readability, it lacks actionable guidance or suggestions on how the authors might address this issue, such as recommending a specific font size or suggesting ways to improve the figure\"s clarity. Without additional context or advice, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it points out a problem but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. It implies that using various probability mass functions would add depth to the experimental setting. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different probability mass functions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the probability mass function in MixBoost, specifically mentioning that it is set to a quasiuniform distribution with only one parameter. It suggests that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is not wellsuited or that using various probability mass functions would be beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the probability mass function, which is currently set to a quasiuniform distribution, could be more effectively utilized. The reviewer points out that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental design. However, the comment could be more helpful if it included examples or references to support the claim that various probability mass functions would be beneficial. Overall, the comment is 4 as it guides the authors towards a potential improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or whether they should consider abstention rates when comparing accuracies. The comment lacks actionable advice or suggestions, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in questioning the fairness of the comparison, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or whether they should consider abstention rates when comparing accuracies. The comment lacks actionable advice or specific recommendations, leaving the authors without a clear path forward to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss connections with a specific reference, [a], which is relevant to their topic. It provides a clear action by suggesting that the authors should address the connections between their work and the supervised learning in QBF solving, as [a] does. The comment also provides a specific example of a relevant work, [a], which helps the authors understand what is expected. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, such as [a], which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is discussing connections with [a] and its relevance to supervised learning in QBF solving. This provides clear guidance on what the authors should focus on. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references provided are relevant to the topic and suggests discussing connections with a specific reference, [a]. However, the comment does not provide detailed reasoning or examples to support why these connections are important or how they relate to the authors\" work. The mention of [a] provides some context, but without further elaboration, the claim remains 3. The authors would need to infer the significance of the connections, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It suggests discussing connections with a particular reference, [a], which uses supervised learning in QBF solving. This is a constructive suggestion as it provides a clear direction for the authors to enhance their paper by incorporating relevant literature. However, the comment could be more helpful if it offered additional guidance on how to integrate this reference or what specific aspects of the connection should be emphasized. Overall, the comment is 4 as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and that explaining this point may be beneficial. While the comment implies that the authors should consider exploring alternative relationships, it does not provide explicit guidance on how to do so or what specific relationships to explore. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and that explaining this point may be beneficial. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explore alternative relationships is specific, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and that explaining this point may be beneficial. The comment references a specific paper, \"Learning the Pareto Front with Hypernetworks,\" which provides a potential context for the discussion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to explore the referenced paper or provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and that explaining this point may be beneficial. The comment references a specific paper, \"Learning the Pareto Front with Hypernetworks,\" which provides a potential context for the discussion. While the comment identifies a potential area for improvement, it lacks detailed guidance on how to explore alternative relationships or what specific relationships to consider. The suggestion to explain this point is a step in the right direction, but it could be more helpful with additional context or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison in terms of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to focus on. Without any actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in asking about the comparison of computation cost or running time, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question asking for clarification about the comparison in terms of computation cost or running time. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison they should focus on. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the goal of the paper in the introduction and provides a specific example of a problem where the paper\"s results are irrelevant due to being already embarrassingly parallel. It also suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make these changes or specify how to address the issues. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper in the introduction\" and provides specific examples of problems where the paper\"s results are irrelevant, such as samplingbased Bayesian methods and ERMbased distributed algorithms like Hogwild. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need for a clearer explanation of the paper\"s goal and a focus on problems where the loss function does not decompose as the sum of sample losses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s goal is not clear and suggests that the examples chosen do not convince the reader of the need for interprocess communication. The reviewer provides a specific example from the second paragraph, where samplingbased Bayesian methods are mentioned, and argues that the paper\"s results are already parallelizable, making them irrelevant. The reviewer also suggests focusing on problems where the loss function does not decompose as the sum of sample losses. While the comment provides a logical argument and specific examples, it lacks detailed references or further elaboration to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper\"s introduction regarding its goal and provides a specific example of a problem where the paper\"s results are irrelevant due to being already parallelizable. It suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. This feedback is clear and actionable, offering the authors a specific direction for improvement by highlighting areas where the paper\"s focus could be more relevant and impactful. However, the comment could be more helpful if it provided additional guidance on how to address these issues or suggested specific examples of such problems. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for enhancing the paper\"s clarity and relevance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or evidence regarding privacy preservation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the privacypreserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. However, it does not specify which part of the paper this discussion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questions about privacy and the application of federated learning, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. However, it does not provide any specific evidence, examples, or references to support these claims. The comment lacks detailed reasoning or references to substantiate the assertion that privacy preservation is a concern in traffic signal control, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the privacypreserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. This feedback is 3 as it prompts the authors to consider the privacy implications of their approach and provides a critical perspective on the application of federated learning in traffic signal control. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these concerns or improve the privacypreserving aspects of the approach. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct a fair comparison by comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s pretraining module design. This feedback is clear and provides a concrete action for the authors to take, making it 5. The comment specifies the exact comparison needed, ensuring the authors know exactly what to do to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of fairness in the comparison between CPEF and PMEF, suggesting that CPEF should be compared with another pretrained model like ExpertBert to demonstrate the advantage of its pretraining module design. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison in Figure 3 is unfair because PMEF lacks a pretraining module, while CPEF does. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to ensure fairness. This claim is supported by logical reasoning, as it points out a potential bias in the comparison and provides a clear suggestion for improvement. However, the comment could be strengthened by providing specific examples or references to similar studies that have used pretrained models for comparison. Therefore, the comment is 4, as it provides a strong basis for the claim but could be further enhanced with additional evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the fairness of the comparison presented in Figure 3, specifically regarding the comparison between CPEF and PMEF. It points out that PMEF lacks a pretraining module, which could affect the results and makes the comparison unfair. The reviewer suggests a more fair comparison by recommending the inclusion of another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s innovative pretraining module design. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improvement. By addressing this issue, the authors can enhance the validity and comprehensiveness of their results. Therefore, the comment is rated as 5, as it effectively guides the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions that the hyperlinks for footnotes 3 and 4 do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and correct the hyperlinks. The comment is explicit and concrete, giving the authors a straightforward task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is specific because it clearly identifies the issue with the hyperlinks not working, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the nonfunctioning of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a straightforward statement of a technical issue, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable feedback that directly impacts the usability and accessibility of the paper. By pointing out this technical issue, the authors are given a straightforward task to address, which is to verify and correct the hyperlinks. This feedback is helpful as it provides a concrete step for improvement, ensuring that the paper is more userfriendly and accessible. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It specifically mentions the need for a better formalization of the architecture in section 2 and points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to revise the discussion or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer the need for clarification but lack detailed guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, indicating that it is currently unclear. It specifies that a better formalization of the architecture in section 2 would be beneficial, and it points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. This provides some level of grounding as it mentions specific sections and elements of the paper, but it does not explicitly name them, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the architecture and the figure, which helps the authors understand the issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific example by mentioning section 2 and the need for a better formalization of the architecture. The comment also points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. While the comment provides some reasoning and examples, it lacks detailed justification or references to support the claim fully. The authors are left with a suggestion to improve clarity but without explicit guidance on how to achieve this. Therefore, the comment is 3, as it provides some support but requires more detailed explanation or references to be fully actionable.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific suggestion to improve clarity by offering a better formalization of the architecture in section 2. Additionally, it points out a potential issue with the figure, suggesting that it might be misleading, as it implies that Label Embeddings are the output of the encoder rather than external parameters. This feedback is clear and actionable, as it directs the authors to improve the clarity of their discussion and provides specific areas for revision. However, the comment could be more helpful if it offered additional guidance on how to achieve these improvements or suggested alternative approaches. Overall, the comment is 4, as it provides valuable insights and actionable steps for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to start the section with a description of the neural network, which is currently difficult to understand. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be done to improve the clarity of the section, ensuring that the authors know exactly how to address the issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the description of the neural network is hard to understand and suggests starting the section with the final paragraph for clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand, but it does not provide any specific examples, reasoning, or evidence to support this claim. The comment suggests starting the section with the final paragraph for clarity, but without further explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 1 due to the lack of supporting evidence or justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the neural network, noting that it is difficult to understand. It provides a clear suggestion to start the section with a clearer explanation, which could significantly improve the clarity and accessibility of the content. This feedback is actionable and provides a direct way for the authors to enhance the draft, making it 4. However, it could be more helpful if it offered additional guidance on how to clarify the description or what specific aspects need improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of training the model with attentionbased encdec training instead of CTC loss. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not specify which part of the paper discusses the model\"s training or limitations, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this change might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance or reasoning on why this change might be beneficial. It does not offer suggestions on how to implement this change or what benefits it might bring to the model. As a result, the feedback is 3, as it points out a potential area for exploration but does not fully guide the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the necessity of having a column header as a separate type. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or simplify the division of tables. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"line 247252,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of having a column header as a separate type in the tables, providing a clear direction for the authors to consider revising their approach. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the necessity of having a column header as a separate type. However, it does not provide any supporting evidence, reasoning, or examples to justify this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the division of tables into three types in Section 3, questioning the necessity of having a column header as a separate type. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation of their tables. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be revised. Therefore, it is rated as 2, as it provides some insight but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction on how to improve their work. The comment is explicit in its suggestion and provides concrete guidance on what additional attack methods to explore, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of attack methods in the paper, specifically mentioning that the methods are naive and suggesting the consideration of other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction on what additional attack methods to explore. However, the comment does not explicitly mention which part of the paper discusses the attack methods, making it weakly grounded. Despite this, the comment is specific in its suggestion and provides clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which offers a clear and logical basis for the claim. The mention of specific papers provides a strong foundation for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of why the suggested methods are more appropriate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the attack methods used are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction on how to improve their work. This feedback is actionable and provides a concrete suggestion for enhancing the robustness and depth of the paper\"s analysis. However, the comment could be more helpful if it offered additional guidance on how to integrate these new attack methods or what specific aspects of the existing methods could be improved. Overall, the comment is 4 as it directs the authors towards a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and \"image generation capabilities,\" but it does not specify which part of the paper discusses these topics. This lack of grounding makes it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting that the mitigation methods affect image quality, but without clear references or examples, it remains weakly grounded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific suggestions or guidance on how the authors might address this problem or improve the image quality. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or mitigate the risk of unfairness. The action is implicit and vague, as the authors are left to infer that they need to consider these issues and possibly adjust their methodology or analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the fairness of comparisons, making it weakly grounded. The issue is clearly specified, as it addresses the potential risk of unfairness in the comparisons. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to support the claim of unfairness, making it difficult for the authors to fully understand and address the issue. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. This feedback is important as it points out a critical aspect that the authors should consider when evaluating their results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of unfairness. While it identifies a potential problem, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what aspects of the paper could be revised in response. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, which is a clear issue for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or context to explain why this might be surprising or how it relates to the paper\"s content. Without any justification or references, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as depicted in Figure 1. However, it does not provide any context, explanation, or suggestions for why this might be surprising or how it relates to the paper\"s content. Without additional information or guidance, the authors are left without a clear understanding of what aspects of the paper need improvement or clarification. As a result, the comment is not helpful, as it lacks actionable feedback or insights that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that using the minimal kmeans objective over multiple seeds might be more reasonable than the average of kmeans objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. While the suggestion is clear, the lack of explicit action or detailed instructions makes it 3. The authors can infer that they should consider using the minimal kmeans objective, but they may need to consult the references for more detailed guidance on how to apply this suggestion.", "grounding_specificity_rationale": "The comment suggests a minor change regarding the use of the average of kmeans objectives with multiple seeds as a baseline, proposing that the minimal kmeans objective over multiple seeds might be more reasonable. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific, as it provides a rationale and references for the change. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a minor change in the use of the average of kmeans objectives with multiple seeds as a baseline, proposing that the minimal kmeans objective over multiple seeds might be more reasonable. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. These references provide a logical basis for the suggestion, making the claim 4. However, the comment could be strengthened by including specific examples or further elaboration on why the minimal kmeans objective is more reasonable. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a minor suggestion for improvement regarding the use of the average of kmeans objectives with multiple seeds as a baseline. It suggests that the minimal kmeans objective over multiple seeds might be more reasonable, referencing specific works for support. This feedback is specific and actionable, as it offers a rationale for a potential change in methodology. However, the comment could be more helpful if it included detailed guidance on how to implement this suggestion or discussed the implications of this change. Overall, the comment is 4 as it directs the authors\" attention to a potential improvement in their methodology, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends that the paper clarify the differences between the task and Argument Mining/Discussion Summarization. While the comment implies that the authors should address this clarification, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the differences, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends further clarification of the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area needing clarification. While the comment is specific in its suggestion to clarify the differences, it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends further clarification of the differences against Argument Mining/Discussion Summarization. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential misalignment between the task described in the paper and the field of Summarization, suggesting that it might be more closely related to Argument Mining. It provides a clear and actionable suggestion for the authors to clarify the differences between their task and those in the field of Argument Mining/Discussion Summarization. This feedback is valuable as it guides the authors in refining their understanding and presentation of their work, potentially leading to a more accurate and comprehensive description of their contribution. However, the comment could be more helpful if it offered specific examples or references to help the authors better understand the distinctions. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues regarding the uncertainty calibration process and the regularization term H. It suggests that the authors clarify the relationship between temperature calibration and uncertainty calibration, as well as the role of H in reducing entropy and its potential conflict with the paper\"s motivation for calibration. The comment explicitly requests clarification on these points, providing a clear action for the authors to take. Additionally, it highlights a specific contradiction in the paper\"s motivation and calibration process, offering a concrete suggestion for improvement. This feedback is explicit and provides detailed guidance on how the authors can address the issues, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) where the confusion arises regarding the relationship between temperature calibration and uncertainty calibration. It also references lines 133136, which discuss the paper\"s motivation regarding calibration. This provides clear guidance on where the authors need to address the issue, making the comment fully grounded. The comment is also specific as it highlights the confusion regarding the training regularization term (H) and its relationship with temperature calibration, as well as the contradiction in the paper\"s motivation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It questions the apparent contradiction in the paper\"s claims and suggests that the authors clarify this point. The comment provides a logical reasoning by pointing out the inconsistency between the claim that temperature calibration is independent of uncertainty calibration and the subsequent discussion in the paper. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a confusing aspect of the paper regarding the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It points out a contradiction in the paper\"s motivation and calibration process, suggesting that the authors clarify this point. The comment provides specific questions and observations, such as the need for clarification on the relationship between temperature calibration and uncertainty calibration, and the potential conflict with the paper\"s motivation. This feedback is clear and actionable, offering the authors a path to improve their draft by addressing these issues. However, it could be more helpful if it provided additional suggestions or examples to further guide the authors. Overall, the comment is 4, as it effectively directs the authors\" attention to areas that need clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss the relationship, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the reference and discuss the context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not specify which part of the paper should include this reference or discuss the context, making it weakly grounded. The authors can infer that it relates to the introduction or related work section, but this is not explicitly mentioned. The comment is specific in suggesting the need for context and the importance of including the reference, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is closely related to the idea of unrolling, as proposed in \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" However, the comment does not provide specific examples or detailed reasoning to support why this reference is important or how it relates to the paper\"s context. The claim is 3 as it highlights a potential gap in the paper\"s references, but it lacks the depth and specificity needed for a 5 comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical reference, \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context and situate the paper within the appropriate academic context. This feedback is valuable as it highlights a potential oversight in the paper\"s literature review and encourages the authors to enhance the clarity and depth of their discussion. However, the comment could be more helpful if it provided specific suggestions on how to integrate the reference or discuss the differences between the proposed work and \"Lista.\" Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain the linear program in Theorem 3 intuitively, specifically asking for clarification on the objective and constraints. This feedback is clear and direct, providing a specific action for the authors to take. The comment also highlights the importance of this explanation by noting that it is a main theorem, which further emphasizes the need for clarification. Therefore, the comment is 5, as it gives the authors a clear and concrete direction on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for an intuitive explanation of the linear program, including the objective and constraints. This provides clear guidance on what the authors should focus on improving. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained intuitively, specifically asking for clarification on the objective and constraints. This is a request for clarification rather than a claim or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely, the need for an intuitive explanation of the linear program in Theorem 3. It highlights the importance of this theorem by noting that it is a main result, which suggests that the authors should provide more context or explanation to help the reader understand the objective and constraints of the linear program. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their work. However, the comment could be more helpful if it provided suggestions on how to achieve this clarification or examples of how other papers have effectively explained similar concepts. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. This is a factual statement that does not require any supporting evidence or justification. It is a straightforward observation that the authors can verify by checking the algorithm section of their paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable feedback that highlights a gap in the paper\"s presentation, which is important for the authors to address. By pointing out this omission, the comment provides a direct suggestion for improvement, allowing the authors to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance on how to define the FLOT cost matrix or suggested potential consequences of this omission. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about Algorithm 2, specifically questioning whether it is possible to update one node based on results from multiple connected nodes. It also notes that \"avg\" is computed but not used, and asks for clarification on the variables \"j\" and i\"\". The authors\" response addresses some concerns but does not fully address the initial questions. The comment provides explicit actions for the authors to clarify their algorithm and explain the variables, but it lacks concrete details on how to implement these actions. The authors are given a direction but not fully guided on how to execute it, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the algorithm, such as the unclear update process for nodes and the use of \"avg,\" as well as questions about the variables \"j\" and i\".\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the update process for nodes based on results from multiple connected nodes. It also questions the use of \"avg\" and the meaning of \"j\" and i\".\" While the comment identifies areas of confusion, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors\" response addresses some concerns but does not provide additional context or evidence to fully verify the claims. Therefore, the comment is 3, as it provides some support but requires more detailed explanation or references to be fully substantiated.", "helpfulness_rationale": "The review comment raises several concerns about Algorithm 2, specifically questioning the update process for nodes based on results from multiple connected nodes. It also notes that \"avg\" is computed but not used and asks for clarification on the variables \"j\" and \"i\"\". While the comment identifies areas of confusion and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The response from the authors indicates that some concerns have been addressed, but the initial feedback remains incomplete. Therefore, the comment is 3, as it provides some insight into areas that need clarification but does not fully guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the definition of the sparsity of the residual term and suggests that the authors provide evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment does not explicitly instruct the authors to provide specific evidence or comparisons, the actions are clear and can be inferred from the comment. The authors know what needs to be addressed, but the comment lacks concrete details on how to execute these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the definition of the sparsity of the residual term and suggests providing evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the definition of sparsity or the assumptions of the proposed method. The comment is specific in detailing what needs to be addressed, such as providing evidence and demonstrating advantages. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the definition of the sparsity of the residual term and suggests providing evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim. The suggestion to provide evidence and demonstrate advantages is logical but not fully substantiated with detailed reasoning or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment raises a specific concern about the clarity of the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support this assumption across various noisy cases. Additionally, the comment implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment identifies a potential area for improvement, it lacks detailed guidance on how to address these issues or specific examples of what evidence or comparisons would be beneficial. The feedback is 3 as it points out a specific area of confusion and suggests a direction for improvement, but it could be more comprehensive with additional guidance or examples."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the term \"connectivity\" as misleading because it does not reflect the structural connections between the brain and body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what alternative terminology might be more appropriate. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the term \"connectivity\" as misleading, stating that it does not reflect the structural connections between the brain and body. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the term \"connectivity\" as misleading because it does not reflect the structural connections between the brain and body. While it identifies a potential issue with the terminology, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how to address the issue or what alternative terminology might be more appropriate. As a result, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, but it does not provide specific guidance on what details are missing or how to address them. The action is implicit, as the authors need to infer that they should review the \"Clarity, Quality, Novelty And Reproducibility\" section for guidance, but it lacks concrete details on how to improve the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which sections or parts of the paper are missing details, making it weakly grounded. The comment is specific in identifying the areas that need improvement, such as related work, experiments, and writing, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to infer the nature of the missing details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not polished and lacks details in related work, experiments, and writing. It suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, which could be helpful if the authors follow up on this suggestion. However, the comment lacks specific guidance or actionable steps on how to address these issues, such as what details are missing or how to improve the writing. While it points out a critical area for improvement, the feedback is incomplete and does not provide detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the importance of using an orthogonal matrix weight in Step 3, as it is the vital part that only orthogonal matrix weight can perform. However, the comment does not provide specific guidance on how to conduct this study or what aspects should be investigated. The action is implicit and somewhat vague, as the authors are left to infer the need for further research but without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific steps in the paper, namely Steps 2 and 3, which are related to the use of orthogonal matrix weights. It suggests that the authors should study the importance of using an orthogonal matrix weight in Step 3, as it is the vital part that only orthogonal matrix weight can perform. However, the comment does not specify which part of the paper these steps are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of using orthogonal matrix weights in Step 3. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of an orthogonal matrix weight in Step 3 is crucial for the effectiveness of the method, as it is the vital part that only orthogonal matrix weight can perform. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the importance of using an orthogonal matrix weight. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should study the importance of using an orthogonal matrix weight in Step 3, as it is the vital part that only orthogonal matrix weight can perform. This feedback is clear and actionable, as it provides a clear direction for the authors to enhance their work by exploring the significance of orthogonal matrix weights. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order of around 45. While the comment implies that the authors should consider overfitting as a potential cause, it does not explicitly instruct the authors to investigate this or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore overfitting as a possible explanation for the accuracy drop. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason behind the accuracy drop after a certain order, specifically asking if it is due to overfitting. This provides clear guidance on what aspect of the figure needs further explanation or analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5, specifically asking why it starts to drop after a certain order of around 45. This question prompts the authors to consider potential causes, such as overfitting, which could help them better understand and potentially improve the results presented in the figure. However, the comment does not provide specific guidance or suggestions on how to address this issue or what steps to take to investigate overfitting. While it identifies an area for further exploration, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViTtiny or small. Additionally, the reviewer asks if there is a foreseeable challenge to experiment on language tasks. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or address the questions. The actions are implicit and somewhat vague, as the authors need to infer the need for these changes and the questions need to be answered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViTtiny or small. It also raises a question about the possibility of experimenting on language tasks. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed regarding the models and datasets, as well as the potential for language task experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViTtiny or small. The reviewer also questions the possibility of experimenting on language tasks. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion to include more challenging datasets is a logical one, but without detailed justification or examples, it remains somewhat vague. Therefore, the comment is categorized as 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViTtiny or small. Additionally, the reviewer raises a question about the possibility of experimenting on language tasks. While the comment provides specific suggestions for improvement, it does not offer detailed guidance on how to implement these changes or address the questions. The feedback is 3 as it highlights areas for enhancement but lacks depth and actionable advice, leaving the authors with a general sense of what needs to be improved without clear steps on how to achieve it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is an explicit action for the authors to take, as it clearly indicates a specific area that requires attention. The comment also raises a minor question about the central argument against pretraining, which further guides the authors on what to consider. While the comment does not provide detailed instructions on how to conduct these studies or address the argument, the actions are clear and concrete. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a specific suggestion that provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, which is the inclusion of a specific baseline. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a logical claim that can be supported by the reviewer\"s understanding of the field or by providing examples of similar studies that have included such baselines. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim. The lack of explicit examples or detailed justification makes the claim 3, as it provides a direction for the authors to consider but does not offer comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of certain natural ablation studies, such as the need to include a baseline where scratchGAN is pretrained. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further exploration. The comment also raises a minor question about the central argument against pretraining, which could prompt the authors to consider additional perspectives or evidence. While the comment does not provide detailed guidance on how to conduct these studies or address the argument, it offers a clear direction for improvement. Therefore, the comment is 4, as it provides valuable insights and actionable feedback for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete guidance on how the authors should address the issue of comparing episodes with different lengths. It suggests that the authors should state how they handle these comparisons and mentions the specific issue of padding shorter sequences and the lack of a normalization factor. The comment also provides a clear explanation of why these decisions should be understood by readers without needing to check the code. This level of detail and specificity makes the action clear and actionable, allowing the authors to directly address the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the handling of comparisons between episodes with different lengths, suggesting that the authors should state how they handle this and providing a specific example of padding shorter sequences and the lack of a normalization factor. The comment also explains why these decisions should be understood by readers without needing to check the code. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths and provides specific examples of issues with the current approach. It references the provided code and explains the lack of a normalization factor, which could affect the comparison of trajectories. The reviewer also suggests that these decisions should be understood by readers without needing to check the code. While the comment provides some reasoning and examples, it could be strengthened by including specific references or further explanation to fully substantiate the claim. Therefore, the comment is 4, as it offers a logical explanation but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the handling of comparisons between episodes with different lengths in the paper. It points out that the authors pad shorter sequences by replicating the last state and lack a normalization factor of 1/T, which could favor longer trajectories. This feedback is clear and actionable, as it provides a specific suggestion for improvement by recommending that the authors state how they handle these comparisons. The comment also highlights the importance of understanding these decisions without needing to check the code, which is a valuable insight for the authors. However, the comment could be more helpful if it offered additional guidance on how to address these issues or suggested alternative approaches. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the clarity and understanding of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors did not consider the Vision Transformer, an important SOTA model in image classification, in their experiments. It also raises a question about whether the technique is still effective for larger datasets like ImageNet and whether the pruning strategy would differ in selfattention layers. While the comment identifies a potential gap in the experimental setup and raises a question about the applicability of the technique, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should consider including the Vision Transformer in their experiments and explore its potential impact on larger datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of the Vision Transformer in the experiments and questions its applicability to larger datasets like ImageNet. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in questioning the inclusion of the Vision Transformer and its potential impact on the pruning strategy in selfattention layers. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not consider the Vision Transformer, an important SOTA model in image classification, in their experiments. It also questions whether the technique is still effective for larger datasets like ImageNet and whether the pruning strategy would differ in selfattention layers. While the comment raises valid concerns about the completeness of the experimental setup and the applicability of the technique, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors may need to conduct additional research or provide evidence to address these concerns. Therefore, the comment is 3, as it provides a basis for further investigation but requires more detailed support.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental setup by noting the absence of the Vision Transformer, an important SOTA model in image classification. It raises a valid concern about the applicability of the technique to larger datasets like ImageNet and questions whether the pruning strategy would differ in selfattention layers. This feedback is clear and actionable, as it prompts the authors to consider including the Vision Transformer in their experiments and exploring its potential impact on larger datasets. However, the comment could be more helpful if it provided specific suggestions on how to incorporate the Vision Transformer or what aspects of the pruning strategy might differ in selfattention layers. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of comparison against baselines in the paper, specifically mentioning the absence of baselines in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architectureagnostic similarity comparison or codesearch tasks. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include baseline comparisons to enhance the comprehensiveness of their study, but the comment lacks concrete details on which baselines to consider or how to implement them. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of baseline comparisons and provides context by mentioning that many papers have developed architectureagnostic similarity comparison or codesearch tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, which is a widely understood binary analysis application. The reviewer provides context by mentioning that many papers have developed architectureagnostic similarity comparison or codesearch tasks, which are similar to the task described in the paper. This provides some logical reasoning and common knowledge to support the claim, making it 3. However, the comment could be strengthened by providing specific examples of relevant papers or detailed reasoning about why baseline comparisons are necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architectureagnostic similarity comparison or codesearch tasks, which are similar to the task described in the paper. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it provided specific suggestions on which baselines to consider or how to incorporate them into the study. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention in SI 6.5 that the preprocessing is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This provides a clear and direct action for the authors to take, specifying exactly what needs to be included in the supplementary information. The comment is explicit and concrete, allowing the authors to know exactly how to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to mention that the preprocessing is identical to that in Mnih et al. [7] but the evaluation is slightly different due to the absence of human starts. This provides clear guidance on what the authors should include in their supplementary information. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is slightly different from Mnih et al. [7] because no human starts are used. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples that would help the authors understand the basis of the claim or how it impacts the evaluation. Without additional context or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient evidence or explanation to fully support it.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include in their supplementary information. It highlights a discrepancy between the preprocessing method mentioned in Mnih et al. [7] and the evaluation process in the current work, noting that no human starts are used in the evaluation. This feedback is clear and direct, offering a concrete way for the authors to enhance the transparency and completeness of their work. By addressing this point, the authors can better align their evaluation with the established methods in the field, potentially strengthening the credibility and reproducibility of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors in improving their draft by highlighting a specific area for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with figures 1 to 3, including small text, unclear explanations of inputs and outputs, and captions that are not selfcontained. It suggests that the authors should make these figures more readable and understandable. However, the comment does not provide specific guidance on how to address these issues, such as recommending font sizes, rephrasing explanations, or improving the layout of the figures. While the action is implied, the lack of concrete details makes it vague, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with these figures, such as the small text, unclear explanations of inputs and outputs, and captions that are not selfcontained. The comment further specifies the need to link these figures to certain parts of the main text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that figures 1 to 3 are difficult to parse due to small text, unclear explanations of inputs and outputs, and captions that are not selfcontained. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific issues with figures 1 to 3, noting that the texts are too small, the inputs and outputs are not clearly explained, and the captions are not selfcontained. It also points out that it is difficult to link these figures to certain parts of the main text. This feedback is clear and actionable, as it provides the authors with specific areas to address to improve the clarity and readability of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the figures, such as recommending font sizes or providing clearer explanations. Overall, the comment is 4 as it directs the authors to improve their figures, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. It explicitly states that the paper does not report any metrics for efficiency, which is a clear and direct action for the authors to take. However, the comment does not provide specific guidance on which metrics to report or how to measure efficiency, leaving some ambiguity in terms of how to implement the suggested action. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. It explicitly mentions \"efficiency,\" which provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the paper, namely, the reporting of metrics for efficiency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metrics that demonstrate the efficiency of the proposed method compared to previous work. This is a factual statement that does not require verification, as it is based on the absence of specific information in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. This is a clear and actionable feedback that highlights an important area for improvement. By pointing out this omission, the comment provides the authors with a clear direction to enhance their draft by including relevant metrics. However, the comment could be more helpful if it suggested specific metrics or methods for measuring efficiency, which would further guide the authors in addressing this issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses that the contribution is not enough and highlights the importance of addressing overfitting with limited data using differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their contribution. There is no guidance on how to enhance the contribution or what specific aspects need further development. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the contribution being insufficient and highlights the importance of addressing overfitting with limited data using differentiable augmentation. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are insufficient or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is not enough, suggesting that the paper does not address the overfitting problem of training GANs with limited data effectively. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the contribution being insufficient, specifically regarding the paper\"s focus on addressing overfitting with limited data using differentiable augmentation. While it identifies a potential weakness, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests the authors to provide more details about the statespace, whether it is finite or continuous, and to specify the space in which theta lies. The reviewer also suggests that the actions should be precise, implying that the authors should clarify these aspects. This feedback is clear and direct, giving the authors a specific action to take in order to improve their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more details about the statespace, whether it is finite or continuous, and the space in which theta lies. The comment also suggests that the authors should be precise in their answers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for more details, which is a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors need to provide more details, namely, the statespace and the space in which theta lies. However, the comment lacks depth and does not offer suggestions on how to improve the clarity or precision of the information. While it points out a gap in the paper, it does not provide actionable guidance or examples of how to address this issue. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method or what specific aspects need to be addressed. Without actionable advice or suggestions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the method on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper discusses the method or the results that are being evaluated. The authors may have an idea of where this discussion is located, but the comment lacks explicit references, making it weakly grounded. The comment is specific in pointing out a potential issue with the method\"s performance, but without grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the method\"s performance. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the need for normalization to make the results from Theorem 1 applicable. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the proof. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the contradiction or provide a more robust proof. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the reliance on a special case where a contradiction arises as matrix norms approach infinity, and the need for normalization to make the results from Theorem 1 applicable. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged by the authors in Section 3. This claim is 3 as it provides a specific observation about the proof technique and references a section where the authors acknowledge the issue. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the proof to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also highlights that this is acknowledged by the authors in Section 3, where they mention the need for normalization to make the results from Theorem 1 applicable. This feedback is 3 as it points out a potential weakness in the proof and provides a clear direction for the authors to address this issue by normalizing the input. However, the comment could be more helpful if it offered suggestions on how to normalize the input or provided additional guidance on how to resolve the contradiction. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance for implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. It provides a specific example of GDSS, which is a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This provides a clear and concrete action for the authors to take, as they are directed to include the continuous diffusion model as a baseline in Table 3. The comment also offers a specific example and reference, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. The comment further provides a specific example of GDSS and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model should be compared as a baseline in Table 3, based on its performance in Table 2. It provides a specific example of GDSS, which is a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This provides a clear rationale for the claim, as it is supported by both the performance data and a relevant reference. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a strong basis for the claim but lacks some depth in its explanation.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. It provides a specific example of GDSS, a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This feedback is clear and actionable, as it directs the authors to include the continuous diffusion model as a baseline in their analysis. The comment also offers a specific example and reference, making it 5 for the authors to enhance the comprehensiveness and accuracy of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task and provides a rationale for this belief. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this belief or incorporate it into their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the choice of using object detection as the downstream task and expresses a personal belief that LiDARbased segmentation is the best choice. It also mentions that colorizationbased pretraining learns semantics and that object detection requires accurate locations and poses, particularly in benchmarks like KITTI and Waymo. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the choice of downstream task and the importance of accurate locations and poses, but it lacks grounding as it does not reference specific parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on the author\"s personal opinion, which may not be universally accepted or verifiable. Without additional justification or references, the claim remains subjective and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose, particularly in benchmarks like KITTI and Waymo. While the comment provides a perspective on the choice of downstream task, it lacks actionable feedback or suggestions for the authors to consider. It does not offer specific guidance on how the authors might address this belief or incorporate it into their work, leaving the authors without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide explicit guidance on how the authors should address this contradiction or what changes they should make to resolve it. The comment lacks specific suggestions or detailed instructions on how to align the objective with the theory proof. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (12)\" and \"IPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the objective of Equation (12) and the theory proof. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a contradiction between the objective of Equation (12) and the theory proof provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting a contradiction between the objective of Equation (12) and the theory proof provided. This feedback is clear and actionable, as it highlights a potential weakness in the paper that the authors need to address. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the contradiction. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also states that allowing \"t\" to be arbitrary does not add value. This feedback is explicit and provides a clear action for the authors to take, which is to make the suggested change for clarity. The comment is concrete, as it specifies what needs to be done and why it is beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity and explains that allowing \"t\" to be arbitrary does not add value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also claims that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific reasoning or examples to support why this change would improve clarity or why allowing \"t\" to be arbitrary is unnecessary. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. It also critiques the practice of allowing \"t\" to be arbitrary, stating that it does not add value. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and precision of their work. By addressing this suggestion, the authors can improve the comprehensibility of their draft, making the comment 4. However, it could be more helpful if it provided additional context or examples to further support the claim. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not be able to produce meaningful embeddings for such concepts. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or methods to enhance the adaptation capacity. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It mentions the use of DINO representations, which are known for containing rich geometric information, and questions whether the adaptation capacity still holds for such concepts. However, the comment does not specify which part of the paper discusses the adaptation capacity or the proposed visual memory, making it weakly grounded. The comment is specific in its critique of the adaptation capacity for certain types of concepts, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not be able to produce meaningful embeddings for such concepts. The reviewer provides a logical reasoning by comparing the adaptation capacity with DINO representations, which are known for containing rich geometric information. However, the comment lacks specific examples or references to support the claim about the limitations of the image encoder for semantic concepts. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not be able to produce meaningful embeddings for such concepts, which could be a limitation. The comment provides a logical reasoning by comparing the adaptation capacity with DINO representations, which are known for containing rich geometric information. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the adaptation capacity. While it identifies a potential weakness, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a clear and direct action for the authors to take, as it provides a specific and concrete suggestion for enhancing the paper. The comment does not leave any ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. While it does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the methodology or results section where comparisons are typically made. The comment is specific in suggesting which loss functions should be included in the comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a logical suggestion based on the field\"s standards and practices, as these loss functions are commonly used in biometric verification. However, the comment does not provide specific references or examples of how these loss functions are typically used or why they are relevant to the paper\"s focus on biometric verification learning. This lack of detailed justification makes the claim 3, as the authors would need to infer the relevance and importance of these loss functions on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of a comparison against stateoftheart loss functions commonly used in face/iris verification. This includes specific examples such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. By suggesting these comparisons, the comment offers a concrete way for the authors to enhance the relevance and impact of their work. However, the comment could be more helpful if it provided additional context or reasoning on why these specific loss functions are relevant or how they might influence the results. Despite this, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides a series of explicit and concrete actions for the authors to take. It suggests corrections to grammatical errors, such as \"Line 029: \u201c\u2026 as it a lightweight \u2026\u201d > shouldn\u2019t this be \u201c\u2026 as in a lightweight \u2026\u201d,\" and offers specific suggestions for clarifying terminology, like \"Line 188: PLN > NLP.\" It also points out a repetition of words in Table 3 and provides detailed guidance on correcting the DOI number and table formatting. Each suggestion is clear and actionable, giving the authors a straightforward path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides a series of specific corrections and suggestions for improving the draft, including grammatical corrections, terminology clarification, and formatting issues. It explicitly mentions line numbers and table references, allowing the authors to accurately identify the parts of the paper needing attention. The comment is fully grounded as it provides clear references to specific lines and elements in the paper, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections and suggestions for improving the draft, such as grammatical corrections, terminology clarification, and formatting issues. These are factual statements that do not require verification or evidence. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of actionable suggestions for improving the draft, including grammatical corrections, terminology clarification, and formatting issues. It specifically points out errors in punctuation, spelling, and formatting, such as \"Line 029: \u2018\u2026 as it a lightweight \u2026\u2019 > shouldn\u2019t this be \u2018\u2026 as in a lightweight \u2026\u2019,\" and \"Table 3, row 2, column 3: 72,0 > 72.0.\" These suggestions are clear and directly address the manuscript, offering the authors a straightforward way to enhance the clarity and professionalism of their work. However, the comment could be more helpful if it provided additional context or reasoning for why these corrections are necessary. Overall, the comment is 4 as it provides valuable feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several explicit actions for the authors to take. It suggests clarifying the notation by spelling out \"F.L.T.R\" in Figure 4, addressing the issue of small text in Figure 1, and recommending crossreferencing notation with figures. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. The comment also identifies specific areas for clarification, making it 5.", "grounding_specificity_rationale": "The comment addresses multiple issues, including notation confusion, the need to define M and N, and the small size of text in Figure 1. It also suggests crossreferencing notation with figures. While the comment does not explicitly mention specific sections or figures, the authors can infer that it pertains to the sections where M and N are used without definition and the figures mentioned. The suggestion to spell out \"F.L.T.R\" in Figure 4 provides a clear action, but the comment lacks specificity in detailing how to address the issue of small text in Figure 1. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of several suggestions for improving the clarity and presentation of the paper. It identifies issues with notation, figure size, and crossreferencing, but it does not provide specific examples or detailed reasoning to support these claims. The suggestions are logical and reasonable, but without additional context or evidence, they remain 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including notation confusion, the need to define variables like M and N, and the small size of text in Figure 1. It provides actionable suggestions, such as spelling out \"F.L.T.R\" in Figure 4 and recommending crossreferencing notation with figures. These suggestions are clear and provide the authors with concrete steps to improve the clarity and presentation of their work. However, the comment could be more helpful if it offered additional guidance on how to address the notation confusion or provided examples of how to improve the figure size. Overall, the feedback is 4, as it effectively directs the authors toward specific improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or relabel the variables to avoid confusion, but the comment lacks concrete suggestions or examples of how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out potential confusion regarding the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify or relabel variables to improve the clarity of their algorithm. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion, such as proposing alternative labels or explanations. Overall, the comment is 4 as it directs the authors to an area that needs attention but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that a more detailed mathematical formulation, such as in the appendix, would be beneficial to complement the highlevel description. It also provides specific feedback on the figure, suggesting that it is confusing due to its abstraction and misalignment with the main contribution of the paper. The reviewer suggests adding more text labels to the figure and reworking it to better depict the WiC task. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. The authors know exactly what actions to take to address the feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the highlevel description, suggesting a more detailed mathematical formulation in the appendix, and with the figure, recommending the addition of text labels and reworking it to better align with the main contribution of the paper, the WiC task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that a more detailed mathematical formulation would be helpful to complement the highlevel description and that the figure is confusing due to its abstraction and misalignment with the main contribution of the paper. The reviewer provides specific suggestions for improvement, such as adding more text labels to the figure and reworking it to better depict the WiC task. These suggestions are clear and provide actionable feedback, making the claim 4. However, the comment could be strengthened by providing examples or references to support the claim about the figure\"s abstraction or misalignment with the main contribution. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting that a more detailed mathematical formulation, such as in the appendix, would complement the highlevel description. It also identifies specific issues with the figure, noting that it is confusing due to its abstraction and misalignment with the main contribution of the paper, which is improvements on the WiC task. The reviewer offers concrete suggestions for improvement, such as adding more text labels to the figure and reworking it to better depict the WiC task. This feedback is clear and provides the authors with specific steps to enhance their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide specific guidance on which tasks to include or how they would enhance the paper. The action is implicit, as the authors need to infer that they should expand the benchmarking tasks, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies a potential improvement but does not provide explicit instructions on how to achieve it.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this recommendation pertains to, such as the experimental section or the results. This makes it difficult for the authors to identify the exact area where the suggestion should be applied. The comment is specific in its suggestion to include more benchmarking tasks, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide any specific examples or reasoning to support why these additional tasks would be beneficial or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks to include or how they would enhance the paper. The feedback is 3 as it points out a potential weakness but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several specific questions and suggestions for improvement regarding the experiments section. It explicitly asks for the comparison result of YOSO with linformer on iterationwise convergence and whether there is any comparison to explain the difference in performance on downstream tasks like SST2. These requests provide clear and concrete actions for the authors to take, such as including specific comparisons in the figures or providing an analysis of the performance differences. The feedback is explicit and detailed, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the lack of comparison results of YOSO with linformer on iterationwise convergence and the need for an explanation of the difference in performance on downstream tasks like SST2. This provides clear guidance on what the authors need to include or explain in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the experimental setup and results, specifically regarding the comparison of YOSO with linformer. It requests clarification on the comparison results of YOSO with linformer on iterationwise convergence and an explanation for the difference in performance on downstream tasks like SST2. While the comment identifies areas for improvement, it does not provide specific evidence or reasoning to support the need for these clarifications. The request for an explanation of the performance difference is a logical inference, but without detailed justification or references, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, particularly in the experiments section. It points out that the pretraining experiment does not provide a comparison of YOSO with linformer, specifically asking for the steps and perplexity results in Figure 4. Additionally, it questions the performance difference between YOSO and linformer on downstream tasks like SST2 and suggests an explanation for this difference. These suggestions are clear and actionable, providing the authors with specific areas to address and improve in their draft. However, the comment could be more helpful if it offered additional guidance or examples on how to analyze and present these comparisons. Overall, the feedback is 4, as it effectively directs the authors to enhance the clarity and depth of their experimental results and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the requirement mentioned in the abstract and the clarification provided in the text. It explicitly states that the requirement is not true, as the authors themselves clarify elsewhere. However, the comment does not provide any guidance or suggestions on how the authors should address this discrepancy or clarify the abstract. The action is implicit and lacks concrete details, making it 3. The authors know that the abstract needs to be corrected, but the comment does not specify how to do so, leaving them with a vague understanding of what needs to be done.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the requirement mentioned in the abstract, which is not true as the authors clarify in the text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the requirement mentioned in the abstract is not true, as it contradicts the clarification provided in the text. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the requirement mentioned in the abstract and the clarification provided in the text. It points out that the requirement is not true, as the authors themselves clarify elsewhere. This feedback is 3 as it highlights a potential inconsistency that the authors need to address. However, the comment lacks depth and does not provide specific guidance on how the authors should resolve this issue or improve the clarity of their presentation. To be more helpful, the comment could include suggestions on how to correct the abstract or clarify the text to align with the authors\" own clarification. Therefore, the comment is rated as 3, as it provides a starting point for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a confusion in Figure 1 regarding the reference to \"PointNet\" and provides a specific reference to a paper by Qi et al. that clarifies the issue. This feedback is clear and actionable, as it instructs the authors to correct the reference in Figure 1 to avoid confusion. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a specific reference to a paper by Qi et al. that clarifies the confusion. This level of detail helps the authors understand what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reference to \"PointNet\" in Figure 1 is confusing because it does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Qi et al., which clarifies the issue. This provides a clear and specific example of the confusion, making the claim 4. However, the comment could be strengthened by explaining why the reference is confusing or how it affects the paper\"s clarity. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear in the paper and there is another paper with the same name. It provides a clear and specific reference, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Qi et al., which clarifies the confusion. This feedback is actionable and provides the authors with a direct way to correct the reference, enhancing the clarity and accuracy of their work. The comment is detailed and constructive, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This raises a concern that needs clarification. The second part points out a minor issue with the line \"but also on learning  on is unnecessary.\" These comments provide explicit actions for the authors to take, such as clarifying the policy gradient\"s optimality and removing unnecessary text. The feedback is concrete and actionable, guiding the authors on what specific changes to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 6\" and \"Line 78,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, such as whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. Additionally, it points out a minor issue with the line \"but also on learning  on is unnecessary.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the optimality of the policy gradient in Equation 6, suggesting that it might be better to clarify this. The second part points out a minor issue with the line \"but also on learning  on is unnecessary.\" These comments are factual observations and requests for clarification, which do not require verification or evidence. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific points for improvement. It questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This raises an important point about the clarity of the methodology and the results. Additionally, it points out a minor issue with the line \"but also on learning  on is unnecessary,\" suggesting a correction. These comments are clear and actionable, offering the authors specific areas to clarify and improve in their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to address these issues. Overall, the feedback is 4, as it guides the authors toward improving the clarity and precision of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks about the difference between the two. While the comment highlights an area for consideration, it does not provide explicit guidance or suggestions on how the authors should address this question or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of assuming a general Gaussian distribution and compare it to the isotropic Gaussian. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the difference between the two distributions, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on the difference between these two distributions. While the comment identifies a potential area for improvement or clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithm could be affected by this assumption. The feedback is 3 as it prompts the authors to consider the implications of their assumptions, but it lacks depth and actionable advice, leaving the authors with a general direction to explore without detailed guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, as it makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to include a discussion on the limitations of this choice. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment suggests that the authors should discuss the limitations of this choice, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that the authors should discuss the limitations of this choice. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that this choice is risky or assumptions are being made. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable piece of feedback. By pointing out this limitation, the comment encourages the authors to consider and address potential weaknesses in their methodology, thereby enhancing the robustness and transparency of their work. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects of the coverage should be considered. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or improve the section. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the intent of Section 5.2, but it does not specify which part of the paper this section is located in. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in questioning the intent of the section, but without clear grounding, it is challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid inquiry that could help the authors clarify their objectives and structure their discussion. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the section. Without actionable feedback or specific advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It also mentions that the paper delves into technical details without providing a clear overview of the approach. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the clarity of the approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the approach, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It mentions that the paper delves into technical details without providing a clear overview of the approach. However, the comment does not specify which part of the paper is unclear or lacks explanation, making it weakly grounded. The comment is specific in identifying the issue of clarity and the need for better explanation, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the nature of the issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might clarify their approach or address the issue of reporting bias. The feedback is 3 as it directs the authors\" attention to a specific area needing improvement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly. It provides concrete guidance on what needs to be included, such as specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail and specificity makes the action clear and actionable, allowing the authors to directly address the feedback and improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as defining the assumed threat model more explicitly by specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly. It provides a clear and specific suggestion for improvement, which is to include a dedicated section that specifies the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is logical and provides a clear rationale for why the clarification is necessary, making it 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, including details such as the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their work, making it 4. However, it could be more helpful if it included specific examples or references to similar works that have effectively addressed this issue. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This feedback provides a clear and direct action for the authors to take, which is to justify their choice of using link prediction accuracy for early stopping. The comment is explicit and concrete, as it specifies what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use link prediction accuracy for early stopping, suggesting that it should be explained why this choice was made over using average accuracy with type accuracy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or why other metrics might be more appropriate. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the decision to use link prediction accuracy for early stopping, suggesting that the authors should explain why this choice was made over using average accuracy with type accuracy. This feedback is clear and actionable, as it provides a direct suggestion for the authors to justify their methodological choices. By addressing this point, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to justify the choice of metrics. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to explain how to set a reasonable classimbalanced task in the fewshot learning setting, providing a clear and direct action for the authors to take. The request for \"concrete details\" indicates that the authors should provide specific examples or methods to support their explanation. This level of specificity and directness makes the comment 5, as it gives the authors a clear path to follow in improving their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, \"sampling classimbalanced tasks.\" This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue, which is the need for a reasonable explanation on how to set a classimbalanced task in the fewshot learning setting. The authors are directed to provide concrete details, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the setting of classimbalanced tasks in the context of fewshot learning, asking for a reasonable explanation. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the setting of classimbalanced tasks in the context of fewshot learning, which is a relevant and important aspect of the paper. It prompts the authors to provide a detailed explanation or justification for their approach, which could enhance the clarity and comprehensiveness of the paper. However, the comment does not offer suggestions or guidance on how to address the issue or improve the draft. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the chatgpt baseline is rudimentary and lacks testing for fewshot approaches. It suggests including discourse relation information in prompts, possibly using a ChainofThought style, which could improve the results. The comment also notes that this addition would enhance the paper\"s evaluation but is not directly relevant to the current evaluation framework. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes or explain how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and lacks testing for fewshot approaches. It also recommends including discourse relation information in prompts, possibly using a ChainofThought style, which could enhance the paper\"s evaluation. However, the comment does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. While the suggestion is specific in terms of what could be improved, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and lacks testing for fewshot approaches. It also suggests that including discourse relation information in prompts could yield good results, which would enhance the paper\"s evaluation. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to include discourse relation information is a logical one, but without detailed reasoning or evidence, it remains somewhat vague. Therefore, the comment is categorized as 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a weakness in the paper\"s evaluation by noting that the chatgpt baseline is rudimentary and lacks testing for fewshot approaches. It suggests that including discourse relation information in prompts, possibly using a ChainofThought style, could improve the results and enhance the paper\"s evaluation. This feedback is clear and actionable, as it provides specific suggestions for enhancing the evaluation framework. However, the comment could be more helpful if it included examples or detailed explanations of how these changes would be implemented. Overall, the comment is 4 as it guides the authors towards potential improvements, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It explicitly states that the authors should provide more details on how actual pruning was done. This feedback is clear and direct, giving the authors a specific action to take: to include more details on the pruning process. The comment is explicit and concrete, providing clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detail on how the ground truth of sensitivity is achieved and the actual pruning process. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the authors mention estimating a layer\"s sensitivity by pruning, but without providing details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more detailed information on the pruning process to enhance the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it suggested specific details or examples of what kind of information should be included. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific parts of the text that could be written more clearly, such as explaining what a proper rotation matrix is in line 97 and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite\" in lines 105106. While the comment does not explicitly instruct the authors to make these clarifications, it provides clear guidance on what needs to be addressed. The authors can infer that they should provide more detailed explanations in these sections to improve the clarity of the text. Therefore, the comment is 4, as it provides concrete guidance on what needs to be done but requires some inference from the authors.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, such as \"line 97\" and \"lines 105106,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as explaining what a proper rotation matrix is and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite.\" This provides clear guidance on how to improve the clarity of the text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions seeking clarification on specific parts of the text. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be written more clearly, providing examples such as explaining what a proper rotation matrix is and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite.\" This feedback is actionable and provides clear guidance on how the authors can improve the clarity and understanding of their text. By addressing these points, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to rephrase or explain these concepts more effectively. Overall, the comment is 4, as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a potential change in terminology, suggesting that the \"g activation function\" might be more accurately referred to as a \"binary operator,\" aligning with the approach taken by Cohen and Shashua (2016). The comment provides a specific reference to support this suggestion, \"Cohen and Shashua, 2016,\" which helps the authors understand the basis of the recommendation. However, it does not explicitly instruct the authors to make this change, leaving them to infer that it is a suggested improvement. The action is concrete but implicit, as the authors need to infer the exact action to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential change in terminology, suggesting that the \"g activation function\" might be more accurately referred to as a \"binary operator,\" aligning with the approach taken by Cohen and Shashua (2016). The comment provides a clear rationale and a specific reference, making it easy for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential change in terminology, suggesting that the \"g activation function\" might be more accurately referred to as a \"binary operator,\" aligning with the approach taken by Cohen and Shashua (2016). The comment provides a specific reference to support the suggestion, which is a clear and logical reasoning. However, it lacks detailed justification or examples of how this change would impact the paper or its understanding. While the suggestion is based on a specific reference, the lack of detailed explanation makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for terminology, suggesting that the \"g activation function\" might be more accurately referred to as a \"binary operator,\" aligning with the approach taken by Cohen and Shashua (2016). This feedback is actionable and provides a clear direction for improving the clarity and accuracy of the terminology used in the paper. By suggesting a specific change and referencing a relevant source, the comment offers a valuable insight that can enhance the paper\"s precision and understanding. However, it could be more helpful if it included additional context or reasoning about why this change is beneficial. Overall, the comment is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Figures 1 and 2 to provide more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their paper. The comment provides a specific suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they have large overlaps with the content and recommending a solution to shrink them to provide more space for methods or related work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the captions of Figures 1 and 2 have large overlaps with the content, and it recommends shrinking the captions to provide more space for methods or related work. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change that would require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the figures in the paper, noting that the captions have large overlaps with the content. It provides a clear and actionable suggestion by recommending that the authors consider shrinking the captions to leave more space for their methods or related work. This feedback is valuable as it helps the authors improve the clarity and presentation of their figures, which is an important aspect of a technical paper. However, the comment could be more helpful if it included specific examples of how to shrink the captions or suggested alternative methods for doing so. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear direction for action."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the exclusion of a specific dataset, Vidgen et al, 2021, from Table 2. It suggests that this dataset might be relevant for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or why this dataset should be included. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this dataset as a potential benchmark. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the exclusion of a particular dataset, Vidgen et al, 2021, and suggests that it might be relevant for evaluation in investigating the role of context in detecting hate. The comment provides a clear rationale for why this dataset should be considered, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the exclusion of a specific dataset, Vidgen et al, 2021, from Table 2. It suggests that this dataset might be relevant for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this dataset should be included or why it is relevant. Without additional context or explanation, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in Table 2, questioning the exclusion of a dataset by Vidgen et al, 2021, which might be relevant for evaluating the role of context in detecting hate. The comment suggests that this dataset could be used as a benchmark for evaluation, providing a clear and actionable suggestion for improvement. However, the feedback could be more helpful if it included a detailed explanation of why this dataset is relevant or how its inclusion could enhance the paper. Overall, the comment is 4 as it directs the authors to consider a potentially valuable addition to their evaluation framework, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs, ideally with error bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations, and suggests that the models are small, making it necessary to provide statistics. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve the presentation of the results. This level of detail and specificity makes the feedback 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results comparing standard vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be improved, such as presenting the results as a mean over many runs with error bars, and points out that the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs with error bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. While the comment provides a logical argument for the need to present results with error bars and statistics, it lacks specific examples or references to support the claim about the models being small. This makes the claim 3, as it provides a basis for the suggestion but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific issue with the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs with error bars, which is a common practice to ensure statistical significance and reliability. Additionally, the comment points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and emphasizes the need to provide statistics for the models. This feedback is 5 as it offers concrete steps for the authors to improve the presentation and robustness of their results, enabling them to enhance the quality and credibility of their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not provide specific guidance on how the authors might improve their approach or address the limitations mentioned. The feedback lacks actionable steps or suggestions for the authors to consider, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights the need for careful selection of basis functions, meshes, and stiffness matrix assembly, and notes that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It also notes that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. The comment provides some logical reasoning by comparing the proposed approach to specialized numerical solvers and operator learning methods. However, it lacks specific examples or references to support the claim about the limitations of operator learning methods. This makes the claim 3, as it provides a general understanding but could benefit from more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve their approach. The feedback is 3 as it provides a direction for consideration but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the need to describe the CUDA version and the PyTorch version. This feedback is clear and direct, as it specifies exactly what additional information is required to improve the draft. The authors know exactly how to address this feedback by providing the requested details, making the comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This feedback is fully grounded as it explicitly mentions the need for additional details about the experimental setup. However, it does not specify what aspects of the experimental environment should be described in more detail, such as hardware specifications or software configurations. This lack of specificity reduces the comment to a fully grounded but underspecific category. Therefore, the comment aligns with category 4.", "verifiability_rationale": "The review point claims that different versions of the experimental environment can impact training and inference speeds. This is a logical claim that aligns with common knowledge in the field. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the impact of different versions on training and inference speeds, which adds a layer of uncertainty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for more detailed description of the experimental environment, such as the CUDA and PyTorch versions. This feedback is clear and actionable, as it provides a specific guideline for enhancing the transparency and reproducibility of the experimental setup. By addressing this suggestion, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it included additional details on why these specific versions are important or how they might affect the results. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement that there is no immediate societal impact, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the concern about using fully realistic datasets and the difficulty in controlling multiple aspects of variation with precision. It also agrees with the authors\" judgement that there is no immediate societal impact. However, the comment does not specify which part of the paper this concern is related to, making it weakly grounded. The authors can infer that it relates to the methodology or discussion sections, but this inference is not explicit. The comment is specific in its agreement with the authors\" judgement, but it lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point acknowledges the authors\" judgement that there is no immediate societal impact, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of the claim or how it relates to their work. Without this context, the authors are left without guidance on how to address the concern or improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement that there is no immediate societal impact, which could be a valid observation. However, it does not provide any constructive feedback or suggestions on how the authors might address this concern or improve their work. Without actionable advice or specific guidance, the comment does not offer the authors meaningful insights or steps to enhance their draft. Therefore, it is rated as 2, as it fails to provide actionable feedback that could aid the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues: the paragraph from L156166 is difficult to understand, and the figure is unclear. It suggests that there are bandit algorithms that plan to explore, such as the Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain. Additionally, it points out that the phrase \"Dashed lines indicate that the agent can plan ahead\" is vague. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what changes should be made. The authors are left to infer that they need to clarify the paragraph and the figure, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, such as the difficulty in understanding it and the unclear nature of the figure. The comment provides specific feedback on the need for clarification regarding bandit algorithms and the Gittins strategy, as well as the vagueness of the figure description. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and suggests that the figure is unclear. It provides specific examples of what is unclear, such as the mention of bandit algorithms and the Gittins strategy, as well as the vague description of the figure. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to infer the exact issues from the comment, which limits its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the text: the paragraph from L156166 is difficult to understand, and the figure is unclear. It provides a clear explanation of the problem, noting that the phrase \"Dashed lines indicate that the agent can plan ahead\" is vague. This feedback is actionable as it directs the authors to clarify the text and improve the figure\"s clarity. However, the comment could be more helpful if it offered suggestions on how to rephrase the paragraph or provide additional details for the figure. Overall, the comment is 4 as it highlights areas for improvement and provides some guidance, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation metric should be mentioned in lines 078079 and 08 to enhance clarity and comparability of the results. It provides a specific example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020), which the authors can reference. This feedback is explicit and provides concrete guidance on what needs to be added to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078079 and 08, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the evaluation metric to enhance clarity and comparability of the results. The comment provides a reference to a specific work, \"Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020),\" which could be used as a basis for understanding the scale of the improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that mentioning the evaluation metric would enhance clarity and comparability of the results. It provides a specific example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in a referenced work, which could be used as a basis for understanding the scale of the improvement. This provides a clear and specific reference for the authors to follow, making the claim 4. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting that the evaluation metric should be mentioned in the paper to enhance clarity and comparability of the results. It provides a concrete example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in a referenced work, which the authors can use as a basis for understanding the scale of the improvement. This feedback is actionable and provides a clear direction for the authors to improve their draft, making it 4. However, it could be more helpful if it included additional suggestions or examples to further guide the authors in implementing the change. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, which appears to be lower than expected. It suggests that the authors should study the behavior of the model under higher noise levels. While the comment implies that the authors should investigate this further, it does not provide explicit instructions on how to conduct the study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"observations in the plot compared to the true trajectories,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, suggesting that the noise value is not as high as it should be. The comment further specifies that the authors should study the behavior of the model under higher noise levels. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise stated in the simulation study (3) is not a very high noise value, as it appears lower than expected from the observations in the plot compared to the true trajectories. The reviewer suggests that the authors should study the behavior of the model under higher noise levels. While the comment provides a logical reasoning based on the comparison between the stated noise value and the observed noise level, it lacks specific examples or references to support the claim fully. This makes the claim 3, as the authors would need to conduct their own analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, suggesting that the noise value is not as high as it should be. It provides a clear suggestion for the authors to study the behavior of the model under higher noise levels. This feedback is actionable and provides a specific direction for the authors to improve their understanding of the model\"s performance under varying noise conditions. However, the comment could be more helpful if it included specific recommendations on how to conduct this study or what aspects to focus on. Overall, the comment is 4 as it guides the authors towards a meaningful area for further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and suggests that the improvement over previously known results is limited to arbitrarily long inputs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to expand the applicability of their approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the bounds and their potential limitations, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the bounds are problematic or limit the applicability of the approach. Without specific examples or references, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. It questions the size of the inputs required for improvement, suggesting that this could limit the practical use of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand the applicability of their approach. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general understanding of the concern but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what aspects of the performance they should focus on. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any details on what aspects of the performance should be considered or how the authors might address this question. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question about the performance of DVP on video with different lengths, which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any context, analysis, or suggestions on how the authors might address this question or what aspects of the performance should be considered. Without actionable feedback or guidance, the authors are left without a clear direction for improvement. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should clarify this in their draft. The action is implicit, as the authors need to infer that they should clarify the distinction between singletoken and multitoken cloze queries in their paper. However, the comment lacks concrete details on how to achieve this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"singletoken cloze queries\" and \"multitoken ones,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of clarity until the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the distinction between singletoken cloze queries and multitoken ones. It notes that this clarification is not clearly explained until the conclusion, which could be confusing for readers. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is 3 as it points out a potential area of improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to address the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This is a clear and direct action that provides specific guidance on how to address the issue in Section 3.3. The comment also mentions \"Experiments,\" which implies that the authors should include this evaluation in their experiments. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). The comment further instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests that the authors should evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This claim is 3 as it points out a specific oversight in the training objective but lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to calculate the actual KLdivergence provides a clear direction for the authors to address the issue, but the comment could be strengthened with additional justification or references to support the importance of this evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This feedback is valuable as it directs the authors to a specific area of improvement, offering a concrete step to enhance the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or guidance on why this evaluation is important or how it could impact the results. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be further enhanced with additional context or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to [1]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology section, nor is there any suggestion for enhancing the theoretical analysis. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to [1]. However, it does not specify which part of Section 2 is being discussed or how it is disconnected from the methodology section. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its critique of the theoretical analysis being simplistic and related to [1], but it does not provide detailed guidance on how to improve the connection between Section 2 and the methodology section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to [1]. However, the comment does not provide specific examples or detailed reasoning to support these claims. The reference to [1] is not elaborated upon, leaving the authors without a clear understanding of how the theoretical analysis is simplistic or related to [1]. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to [1]. While it identifies a potential issue with the coherence between sections, it lacks specific suggestions or guidance on how to improve the connection or enhance the theoretical analysis. The comment provides a general critique but does not offer actionable feedback or detailed advice, making it 3. The authors may find it useful to consider the critique but would need to seek additional guidance to address the issue effectively. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful for, such as mostly for specular areas. While the comment implies that the authors should consider expanding their discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional discussion on the topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations where the losses are particularly helpful, such as mostly for specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the effectiveness of losses in certain situations, particularly for specular areas. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to discuss which situations the losses are particularly helpful for, such as mostly for specular areas. However, it does not provide any specific reasoning, examples, or references to support why this discussion would be valuable or how it could enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful for, such as mostly for specular areas. While the comment identifies a potential area for further exploration, it lacks specificity and does not provide actionable guidance on how to expand this discussion. The authors are left with a general suggestion but without clear direction on what aspects to focus on or how to structure this discussion. Therefore, the comment is 3, as it points out an area for potential improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the paper to address this concern or what specific aspects need to be strengthened. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength for ICLR, but it does not specify which part of the paper is being evaluated or what specific issues are causing this doubt. Without any grounding or specificity, the authors cannot determine which aspects of the paper need improvement or clarification. This lack of detail makes the comment 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references, the authors are left without guidance on how to address the concern or improve the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength for ICLR, but it does not provide any specific feedback or suggestions on what aspects of the paper might be lacking or how they could be improved. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what needs to be addressed to strengthen their submission. This lack of specificity and actionable advice makes the comment 2, as it does not provide the authors with a clear path to improve their draft. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the major contributions of the paper and suggests that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their contributions or what specific aspects need to be revised. As a result, the authors are left without a clear understanding of what changes are necessary to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the paper\"s contributions and suggests that analyzing previous work does not constitute a contribution. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in terms of what aspects of the contributions are unclear or how they should be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that analyzing previous work does not constitute a contribution, which is a subjective judgment. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity regarding its contributions. It points out that analyzing previous work does not constitute a contribution, which is a critical observation that could help the authors refine their understanding of what constitutes a contribution in their field. However, the comment lacks specific guidance or suggestions on how the authors might clarify their contributions or improve the paper\"s clarity. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a critical issue but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the lack of explanation for determining n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. It also notes that the answer is not found in reference [30]. While the comment identifies a specific issue with the clarity of the algorithm, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to clarify the determination of n_t and the meaning of \"appropriate number,\" but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights a specific area for clarification but does not provide detailed guidance on how to implement the change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of explanation for determining n_t and the ambiguity of the term \"appropriate number.\" The comment further notes that the answer is not found in reference [30], providing specific guidance on where to look for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the lack of explanation for determining n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. It also notes that the answer is not found in reference [30]. While the comment identifies a specific issue with the clarity of the algorithm, it does not provide detailed reasoning or evidence to support the claim that this is a significant issue. The lack of specific examples or references to substantiate the claim makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is not found in reference [30], which provides a clear and actionable suggestion for the authors to clarify this aspect of their algorithm. By highlighting a gap in the documentation and offering a specific reference for further exploration, the comment is 4 as it guides the authors toward improving the clarity and completeness of their draft. However, it could be more helpful if it provided additional context or suggestions on how to address the issue, such as proposing alternative explanations or methods for determining n_t. Overall, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the reproducibility issue or what steps they should take to ensure their results are reproducible. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft in this regard. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not specify which part of the paper this issue is related to, such as the methods section or the results section. Without explicit references to specific parts of the paper, the authors may find it challenging to identify the exact area needing attention. Additionally, the comment lacks specificity regarding the reproducibility issue, as it does not provide details on what aspects of the results are difficult to reproduce or how the code could be made more accessible. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made public. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. While it identifies an important issue related to the transparency and replicability of the research, it lacks depth and specificity. It does not provide any suggestions or guidance on how the authors might address this concern or improve the reproducibility of their results. Without actionable advice or detailed feedback, the comment is not helpful in guiding the authors towards improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not provide specific guidance or suggestions on how the authors might strengthen their evidence or improve their claims. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the evidence provided, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evidence supporting the claim that \"in practice the mixing time is even better\" is not sufficiently supported by experiments. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. This feedback highlights a potential weakness in the paper\"s evidence and suggests that the authors need to provide more robust experimental evidence to substantiate their claims. However, the comment does not offer specific suggestions or guidance on how the authors might strengthen their evidence or improve their claims. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This is an explicit suggestion that provides a clear direction for the authors to consider. However, it does not specify how this extension should be implemented or what specific attributes should be included in the vector form. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the extension should be considered or how it should be implemented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, it does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it could improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This feedback is 3 as it provides a specific suggestion for improving the paper by suggesting a potential extension of the protected feature. However, the comment lacks detailed guidance on how to implement this extension or what specific attributes should be included in the vector form. To be more helpful, the comment could provide additional context or examples to support the suggestion, making it more actionable for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests denoting the vector representations of words in the equation and following ones, and it asks for clarification on whether the vectors are L2normalized before the process and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. These actions are clear and provide specific guidance on what information needs to be added or clarified in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as denoting the vector representations of words, checking if the vectors are L2normalized, and clarifying the metric used for computing \u201cnearest neighbor\u201d examples. This provides clear guidance on what information is missing or needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the notation used for vectors, whether they are L2normalized, and the metric used for computing \u201cnearest neighbor\u201d examples. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the clarity and completeness of the paper. It identifies a potential area of confusion regarding the notation used for vectors in the equation and suggests denoting them appropriately. Additionally, it raises questions about whether the vectors are L2normalized and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. This feedback is clear and provides detailed guidance on how the authors can improve the clarity and accuracy of their presentation. By addressing these points, the authors can enhance the comprehensibility and rigor of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments in the paper should be run multiple times to improve reproducibility, citing a recent suggestion for a community effort towards reproducibility. It also mentions the need to report statistics. While the comment implies that the authors should conduct multiple experiments and report statistics, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments in the paper should be run multiple times to improve reproducibility, citing a recent suggestion for a community effort towards reproducibility. It also mentions the need to report statistics. However, the comment does not specify which part of the paper these experiments are in or where the statistics are discussed. This makes it difficult for the authors to identify the exact sections that need attention. While the comment provides some guidance on the issue of reproducibility, it lacks full grounding and specificity, as it does not clearly indicate the parts of the paper that need to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experiments in the paper should be run multiple times to improve reproducibility, citing a recent suggestion for a community effort towards reproducibility. It references a specific paper by Henderson et al. (2018) as a source for this suggestion. This provides a clear and specific reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how running multiple experiments would enhance reproducibility. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a critical issue in deep reinforcement learning (RL) experiments, namely reproducibility, and suggests that the experiments should be run multiple times to address this concern. It references a recent suggestion for a community effort towards reproducibility and emphasizes the importance of reporting statistics. This feedback is valuable as it points out a significant weakness in the current state of deep RL research and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct multiple experiments or report statistics effectively. Overall, the comment is 4 as it identifies a critical area for improvement and provides a starting point for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to check Figure 2, Line 433, and Line 468, pointing out that some equations end with a period while others end with a comma. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in terms of punctuation consistency. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" \"Line 433,\" and \"Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with punctuation consistency, noting that some equations end with a period while others end with a comma. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to check specific parts of the paper for punctuation consistency, specifically mentioning Figure 2, Line 433, and Line 468. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with punctuation consistency in the paper, specifically mentioning Figure 2, Line 433, and Line 468. It provides a clear and actionable suggestion for the authors to ensure consistency in punctuation, which is an important aspect of maintaining clarity and professionalism in academic writing. However, the comment could be more helpful if it provided additional context or examples of how punctuation inconsistencies might affect the paper\"s readability or professionalism. Despite this, the feedback is 4 as it directs the authors to a specific area that needs attention, allowing them to make a straightforward correction. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might differentiate their work or enhance its technical contribution. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the similarity between $kNNECD$ and $kNNMT$, suggesting that the technical contribution of the paper is limited due to this similarity. However, it does not specify which part of the paper discusses these methods or how they are compared, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the technical contribution but lacks grounding, as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical contribution by pointing out that $kNNECD$ is very similar to $kNNMT$. This observation is relevant and could prompt the authors to consider whether their work offers a unique or significant advancement. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s contribution. Without actionable feedback or detailed advice, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether the figures in Figure 1 are generated by real experiments or artificially. It also suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback provides a clear and direct action for the authors to take, which is to either confirm the authenticity of the figures or conduct additional experiments to validate the results. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, it is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authenticity of the figures and suggests that realworld experiments should be conducted to support the observed phenomenon. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authenticity of the figures in Figure 1 and suggests that realworld experiments should be conducted to support the phenomenon observed in the figures. This is a claim that requires the authors to provide evidence or justification for the authenticity of the figures. The comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional information or evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the authenticity of the figures in Figure 1, specifically asking whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is 5 as it provides a clear direction for the authors to improve the credibility and validity of their results. By suggesting a specific experiment to conduct, the comment offers a concrete way for the authors to strengthen their paper. Therefore, the comment is rated as 5, as it not only identifies a potential issue but also provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the number of parameters used in each approach in Section B.3. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting they clarify the numbers or provide additional details. The comment lacks specificity and does not offer guidance on how to address the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the number of parameters used in each approach, specifically in Section B.3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach, particularly in Section B.3. This feedback is valuable as it highlights a potential issue that could affect the understanding of the paper by readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the section. While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an example and perhaps a figure would be beneficial in explaining the definition of uniform shattering. While the action is explicit, it is somewhat vague as it does not specify which part of the paper this explanation should be included in or how the example or figure should be structured. The authors know that they need to provide additional explanation or visual aids, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its suggestion to include an example and a figure, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning, evidence, or examples to support why this would be beneficial or how it would improve the clarity of the definition. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where additional clarification could be beneficial. However, it lacks depth and does not provide detailed guidance on how to incorporate these elements or what specific aspects of the definition could be clarified. The authors are given a direction to improve their draft, but the comment could be more comprehensive and actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the novelty of their method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed transductive method, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not specify which part of the paper discusses the transductive method or how it is related to selftraining methods. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the method\"s novelty but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. While it identifies a potential issue with the novelty of the method, it lacks specific details or examples to support this claim. The comment does not provide actionable feedback or suggestions for the authors to address this concern or improve the novelty of their approach. Without actionable guidance, the comment is not helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the assumption among classes is not a practical one, despite the trivial formulation or definition in the manuscript. It suggests that the highlight of the work lies in optimization and theoretical property analysis, which could lead to some conclusions or insights. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the practicality of their assumption or explore its implications further. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the manuscript, namely the assumption among classes, which is not considered practical. It provides some context by mentioning the formulation or definition in the manuscript, but it does not specify which part of the paper this assumption is discussed in. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. However, the comment is specific in pointing out the practicality of the assumption and suggesting that the highlight lies in optimization and theoretical property analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, despite the formulation or definition being somewhat trivial. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. It acknowledges that the formulation or definition is somewhat trivial but highlights the significance of optimization and theoretical property analysis in the manuscript. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their work. While it points out an area for consideration, it does not provide actionable feedback or detailed advice, making it 3. The authors are left to infer potential improvements but without clear direction, which limits the comment\"s usefulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation results reported in Table 1, noting that the results are based on only three trials for each case. It suggests that this is statistically not significant and questions the reporting of deviations, particularly why the deviation is 0 in many cases. The reviewer also points out that statements about performance being at least two standard deviations better than the next best baseline are not justified. While the comment identifies specific issues with the evaluation and reporting, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit, as the authors need to infer that they should conduct more trials or provide a more robust statistical analysis, but it lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the evaluation results, noting that the results are based on only three trials for each case, which is statistically not significant. The comment further explains why reporting deviations is not meaningful and questions the validity of statements about performance being at least two standard deviations better than the next best baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically not significant. The reviewer suggests that this is why the deviations are reported as zero in many cases and questions the validity of statements about performance being at least two standard deviations better than the next best baseline. While the comment provides a logical reasoning for the claim, it lacks specific references or examples to fully substantiate the argument. The authors would need to conduct additional trials or provide a more robust statistical analysis to address this concern. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results reported in Table 1, noting that the results are based on only three trials for each case, which is statistically not significant. It questions the reporting of deviations and why the deviation is 0 in many cases, suggesting that the reported statements about performance being at least two standard deviations better than the next best baseline are not justified. This feedback is clear and actionable, as it provides a specific area for improvement in the statistical analysis and reporting of results. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending additional trials or a more robust statistical analysis. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should include these missing papers in their comparison, but it does not specify how to integrate them or what specific aspects should be covered. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison, mentioning that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is in, making it weakly grounded. The comment is specific in pointing out the missing papers, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, the comment does not provide specific examples or detailed reasoning to support why these papers are relevant or how their inclusion would improve the comparison. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing papers to enhance the depth and comprehensiveness of their comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate these papers or what specific aspects of the comparison should be expanded upon. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific guidance on how to modify the usage of this word or what alternative terms might be more appropriate. The action is implicit, as the authors can infer that they should be more cautious with the use of \"equivalent,\" but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the use of the word \"equivalent,\" suggesting a more cautious approach, especially when the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific examples or reasoning to support why this is a concern or how it affects the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, suggesting that it should be used more cautiously, especially when the equivalence is not verified. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address the issue. By highlighting the need for caution, the comment helps the authors to refine their language and ensure clarity in their writing. However, it could be more helpful if it provided examples of how to use the word \"equivalent\" more cautiously or suggested alternative phrasing. Overall, the comment is 4, as it directs the authors to an important area for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors should provide a more detailed explanation of the architecture within the paper itself, rather than relying on external references. However, the comment does not explicitly instruct the authors to include this information or how to do so, leaving the action somewhat implicit. The authors can infer that they need to provide a clearer explanation of the architecture, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This provides some grounding as it mentions a specific reference, but it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the architecture, which is a clear issue for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, and the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The claim is supported by the observation that the paper lacks a detailed explanation of the architecture, which is a critical aspect of the work. However, the comment could be strengthened by providing specific examples or details of what is missing or unclear in the explanation. The reference to Jiang et al. (2019) provides some context, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the explanation of the architecture used for the experiments. It points out that the authors refer to Jiang et al. (2019) for details, which makes the paper not selfcontained. This feedback is clear and actionable, as it highlights a gap in the paper\"s selfsufficiency and suggests that the authors should provide a more detailed explanation of the architecture within the paper itself. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of what should be included. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests maintaining consistency in the typesetting of BertScore and BLEURT throughout the paper, recommending the use of either \"Bertscore\" or \"Bleurt\" consistently. This provides a clear and direct action for the authors to take, ensuring that the typesetting is uniform throughout the document. The suggestion is concrete, as it specifies the changes needed to achieve consistency. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the typesetting of BertScore and BLEURT throughout the paper, suggesting that consistency should be maintained. However, it does not specify which parts of the paper are affected by this inconsistency, making it weakly grounded. The comment is specific in its suggestion to maintain consistency, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that BertScore and BLEURT are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any specific examples or reasoning to support why this inconsistency is problematic or how it might affect the paper\"s clarity or professionalism. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor but noticeable inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would improve the paper\"s professionalism and readability. While the comment points out a specific issue, it does not provide detailed guidance on how to achieve consistency or why it is important. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with a general idea of what needs to be addressed but without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include detailed experimental results to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment specifies the need for detailed experimental results, it does not provide specific guidance on what aspects of the results should be detailed or how they should be presented. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the scaling law does not apply to dense retrieval models or that the results on Wikipedia are not sufficient. The reference to Ni et al. provides some context, but the comment does not fully substantiate the claim or guide the authors on how to address the issue. Therefore, the comment is considered 2, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. While the comment identifies a potential weakness in the paper\"s findings, it lacks specific guidance on how to present or interpret these results. The authors are left with a general suggestion to include more detailed experimental results, but without further direction, the feedback remains 3. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to improve the presentation quality, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not provide clear guidance on execution.", "grounding_specificity_rationale": "The comment provides a list of specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not explicitly mention which sections or figures are being discussed, making it weakly grounded. The comment is specific in detailing the issues, but without explicit references, the authors may find it challenging to pinpoint the exact parts of the paper needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, citing specific examples such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, the comment does not provide detailed reasoning or evidence to support these claims, such as explaining why these aspects are problematic or how they impact the overall quality of the publication. Without specific examples or detailed justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not provide detailed guidance on how to address these issues or suggest specific improvements. While it highlights areas for improvement, the feedback lacks depth and actionable advice, making it 3. The authors are given a starting point for addressing the issues but need more detailed guidance to effectively improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include related experiments to demonstrate how the information axis tool can be applied. While the comment implies that such experiments are necessary, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to design them. The action is implicit and somewhat vague, as the authors need to infer that they should include experiments to support the utility of the information axis tool. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"conclusion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is related experiments demonstrating the utility of the information axis tool. This provides clear guidance on what needs to be added to the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support the claim that such experiments are necessary. The comment lacks detailed reasoning or evidence to justify why these experiments are crucial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s contribution and provide more evidence for the effectiveness of the tool. However, the comment lacks depth and does not offer detailed guidance on how to design or conduct these experiments, which would be beneficial for the authors. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate this issue or what steps they should consider. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the Greek language, but it lacks detailed guidance on how the authors might address this issue or what aspects of their work could be improved in relation to multilingual pretraining. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for information, expressing interest in understanding whether other multilingual pretraining setups also struggle with Greek. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. While it identifies a potential area of concern, it does not provide any specific guidance or suggestions for the authors to address this issue. The comment lacks actionable feedback or detailed insights that could help the authors improve their work. As a result, it is 2, as it provides a general direction for further exploration but does not offer concrete steps or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the text in lines 293295, stating that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should address this issue by providing a clearer explanation or justification. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors know they need to clarify the text but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the unclear nature of the text and the difficulty for readers to understand and evaluate it. The comment suggests that the authors should provide a clearer explanation or justification, which is a direct and specific action for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification to address this issue. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to enhance clarity. The feedback is 3 as it points out a potential weakness but could be more comprehensive by offering actionable advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. While the comment implies that the authors should consider using realworld datasets, it does not provide specific guidance on which realworld datasets to use or how to conduct the experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the use of synthetic datasets or the outofdistribution setting, making it weakly grounded. The comment is specific in its suggestion to use realworld datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, the comment does not provide any reasoning or evidence to support why realworld datasets are more appropriate or why synthetic datasets are insufficient for the outofdistribution setting. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential limitation in the current experimental setup and provides a direction for improvement. However, the comment lacks specific guidance on which realworld datasets to use or how to conduct the experiments, which limits its usefulness. The authors are given a direction to consider, but the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a vague explanation in the last paragraph of Section 3, specifically mentioning lines 207210. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment consists of questions or comments, which imply that the authors should clarify the explanation, but it does not offer concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific part of the paper, mentioning the last paragraph of Section 3 (lines 207210) on the single image case. This provides full grounding, allowing the authors to accurately identify the section being addressed. The comment also specifies the issue by noting that the explanations are vague, giving the authors a clear idea of what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and comments regarding the clarity of explanations, specifically mentioning the last paragraph of Section 3. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any suggestions or guidance on how to improve the clarity of the explanation. While it highlights a potential issue, it lacks actionable feedback or detailed advice, making it 2. The authors are left with a general understanding of the problem but without clear steps to address it. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. While the comment implies that the current setup might be limiting, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should consider extending the model to multiple vehicles, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it prompts the authors to consider a potential extension but does not provide specific steps or suggestions for implementation.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its inquiry about scalability, but without clear grounding, it is challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not provide any supporting evidence, reasoning, or examples to justify why this might be a concern or how it could be addressed. The comment lacks specific details or references that would help the authors understand the implications of this question or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the need for an extension to multiple vehicles.", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the approach, specifically asking if it is feasible to extend the model to multiple trucks and drones. This feedback is valuable as it challenges the authors to consider the practicality and applicability of their work beyond the current singletruck and singledrone scenario. By prompting the authors to think about scalability, the comment encourages them to explore a more comprehensive and potentially more impactful setting for their research. However, the comment could be more helpful if it provided suggestions or guidance on how to address this scalability issue, such as potential methods or frameworks to consider. Overall, the comment is 3 as it identifies a relevant area for improvement but lacks depth in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the novelty of their approach or what specific aspects of the pretraining strategy could be improved. Without actionable suggestions or directions, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not specify which part of the paper discusses the pretraining approach or how it is similar to or different from the strategies used in ELECTRA. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential lack of novelty in the proposed approach to pretraining, suggesting that it follows strategies used in the ELECTRA model. While it points out a potential issue, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it provides a starting point for consideration but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for using the Newton algorithm in section 4 is lacking and questions its necessity. It points out that a simple line search on a convex function would converge linearly, and asks whether the quadratic convergence of the Newton algorithm has a significant impact on the runtime of the algorithm. The reviewer implies that additional experiments could help justify the need for the analysis or algorithm. While the comment suggests a specific action (conducting experiments), it does not provide explicit guidance on how to perform these experiments or what specific results would be most beneficial. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the motivation for using the Newton algorithm, questioning its necessity and suggesting that additional experiments could help justify its use. The comment provides a clear direction for improvement by suggesting experiments to better motivate the need for the analysis or algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of using the Newton algorithm in section 4, suggesting that a simple line search on a convex function would suffice. It points out that even a bisecting line search would converge linearly, questioning the impact on runtime. The reviewer implies that additional experiments could help justify the need for the analysis or algorithm. While the comment raises a valid concern, it lacks specific examples or references to support the claim about the impact on runtime. The suggestion to conduct experiments is a logical step but is not fully supported by the comment. Therefore, the claim is 3, as it provides a basis for questioning but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation for using the Newton algorithm in section 4, suggesting that a simpler line search on a convex function would suffice. It questions the significance of quadratic convergence over linear convergence in terms of runtime impact. The reviewer suggests that additional experiments could help justify the need for the analysis or algorithm. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a method to strengthen the paper\"s argument. However, it could be more helpful if it offered guidance on how to design and conduct these experiments or what specific results would be most beneficial. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical aspect of their work that needs further exploration."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. It suggests that the results imply that better NMT systems are also better at idiomatic translations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methods. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the impact of the proposed upweighing and KNN methods on idiomatic vs random data, providing a clear indication of what needs to be addressed. The comment specifies that the results imply that better NMT systems are also better at idiomatic translations, which is a specific issue that the authors should consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the impact of the proposed upweighing and KNN methods on idiomatic vs random data is similar for most language and score combinations, suggesting that the methods are not idiomspecific. This claim is 3 as it provides a logical reasoning based on the observation of similar impacts in Figure 3. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it 3. The authors would need to delve deeper into the data or methodology to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods by noting that their impact on idiomatic vs random data is similar for most language and score combinations. This observation suggests that the methods may not be as idiomspecific as initially claimed. The comment implies that the results imply that better NMT systems are also better at idiomatic translations, which could be a significant insight for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methods. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not explicitly instruct the authors to make these changes. The comment implies that the authors should address this inconsistency, but it lacks concrete guidance on how to implement the suggested changes. The action is implicit and somewhat vague, as the authors know they need to address the inconsistency but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the number of biases in the paper, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not specify why this is a concern or what the implications are. The comment is fully grounded as it references a specific section of the paper, allowing the authors to accurately identify the part being addressed. However, it is underspecific because it lacks detailed explanation of the issue or suggestions for improvement. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper, particularly regarding the resulting volume and the presence of C biases. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not provide specific examples or references to support these claims. The comment lacks detailed reasoning or evidence to substantiate the assertion about the inconsistency, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper regarding the number of biases, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, which is a clear and actionable point for the authors to consider. However, the comment lacks depth and does not provide detailed guidance on how to address this issue or what implications it might have for the overall analysis. While it highlights a potential area for improvement, it could be more helpful with additional context or suggestions for resolution. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, suggesting that subtracting s from the dynamic information may lead to the loss of some dynamic information, making it challenging for the LSTM module to capture the complete dynamic changes. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to mitigate the loss of dynamic information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation 8, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in the equation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information may lead to the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This feedback is 3 as it points out a specific area where the authors might need to reconsider their approach. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as alternative methods or strategies to mitigate the loss of dynamic information. While it highlights a potential problem, it does not provide actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended and do not offer guidance on how the authors should address these issues in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not specify which part of the paper these questions relate to, such as a particular section, figure, or table. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment is specific in asking about the empirical impact of the number of MC samples and the influence of network structure, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two questions asking about the empirical impact of the number of MC samples on performance and the influence of network structure on this aspect. These questions are factual inquiries seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. While these questions are relevant and could help the authors explore important factors affecting their results, they do not provide specific guidance or suggestions on how to address these issues in the draft. The feedback lacks actionable advice or detailed insights that would enable the authors to improve their work. As a result, the comment is 3, as it identifies areas for further investigation but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This explicit suggestion provides clear guidance on what needs to be done to improve the paper. The authors are given a direct action to enhance the clarity of the reconstruction quality, making the comment 5.", "grounding_specificity_rationale": "The comment suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include smoothed GT shapes, but without explicit references to the figures, the authors may find it challenging to pinpoint the exact sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This feedback is clear and actionable, as it provides a direct way for the authors to enhance the clarity of their reconstruction quality. By following this suggestion, the authors can improve the readers\" understanding of their work. However, the comment could be more helpful if it explained why showing these smoothed shapes is important or how it would benefit the readers. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of direct comparisons between the proposed approach and the baseline PRANC, specifically in terms of test accuracy, which is crucial for evaluating the improvement over the baseline. It suggests that the authors should include a direct comparison of test accuracy in their evaluation. While the action is explicit, it does not provide specific guidance on how to conduct this comparison or which metrics to use. The authors are aware of what needs to be done but may require additional information to fully implement the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, which is crucial for evaluating the improvement over the baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, which is crucial for evaluating the improvement over the baseline. The comment provides specific sections (3.4 and 3.5) where comparisons are made, but it lacks detailed reasoning or examples to fully substantiate the claim. While the mention of specific sections provides some context, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons of test accuracy with the baseline PRANC. It highlights that while there are comparisons of training loss and the rank of possible solutions, these do not provide a comprehensive evaluation of the proposed approach\"s performance. The comment is clear and actionable, as it directs the authors to include a direct comparison of test accuracy, which is crucial for assessing the improvement over the baseline. This feedback is valuable as it guides the authors in enhancing the robustness and comprehensiveness of their evaluation, making the comment 4. However, it could be more helpful if it provided specific suggestions on how to conduct this comparison or which metrics to use. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and detailing the coverage. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the method to other domains and questions the selection of event types from Freebase. It asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about generalizability. The request for clarification on the selection process and coverage provides some guidance but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to address but requires additional detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the selection process and coverage, which is crucial for understanding the applicability of their method. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it suggested specific ways to improve the generalizability or provided examples of how the method could be applied to other domains. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a potential issue with the paper\"s claim about the importance of language modeling capability of pretrained models. It suggests that the authors should conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. This feedback is explicit and provides a clear action for the authors to take, which is to include these tasks in their experiments. The suggestion is concrete, as it specifies the types of tasks that should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper\"s claim about the importance of language modeling capability, suggesting that the authors should conduct experiments on generation tasks like language modeling, machine translation, or text summarization to strengthen this part. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim about the importance of language modeling capability is not supported by the experiments conducted, specifically mentioning that the experiments on word similarity and SquAD in section 5.3 do not reflect the capability of language modeling. The reviewer suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. While the comment provides a logical argument for the need to include these tasks, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a basis for the suggestion but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s claim about the importance of language modeling capability of pretrained models. It points out that the experiments conducted, such as those on word similarity and SquAD, do not fully reflect the language modeling capability. The comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By suggesting additional tasks that could better demonstrate the language modeling capability, the comment offers valuable guidance for enhancing the paper\"s claims and experimental design. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"cite and discuss\" certain references related to domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, specifying what needs to be added and how to implement the change. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment highlights a lack of important references for domain adaptation, suggesting that the authors should cite and discuss these references in the revised manuscript. However, it does not specify which references are missing or what specific domain adaptationrelated references should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are important. This lack of detail makes it difficult for the authors to understand the scope of the issue and how to address it. As a result, the claim is considered 2, as it provides some direction but lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks important references related to domain adaptation. It provides a clear and actionable suggestion for the authors to include and discuss these references in the revised manuscript. This feedback is valuable as it guides the authors on how to improve the comprehensiveness and depth of their work by incorporating relevant literature. However, the comment could be more helpful if it specified which references are missing or provided examples of relevant works. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether EMAweighting is used for other baseline models in Table 3. It suggests that knowing if all models being compared utilize the EMA benefits would ensure a fair comparison. While the comment does not explicitly instruct the authors to make this change, it provides a clear and specific action that the authors can take to address the issue. The suggestion is concrete, as it outlines a specific aspect of the comparison that needs clarification. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether EMAweighting is used for other baseline models, such as \"Supervised,\" and suggests that knowing this would ensure a fair comparison. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of EMAweighting in other baseline models, specifically in Table 3. It suggests that knowing if all models use EMA benefits would ensure a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the use of EMAweighting in other baseline models, such as \"Supervised,\" in Table 3. It suggests that knowing if all models utilize the EMA benefits would ensure a fair comparison. This feedback is clear and actionable, as it points out a potential issue with the comparison methodology that the authors should address. By addressing this concern, the authors can improve the fairness and comprehensiveness of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to implement this change. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. The comment also provides a presentation suggestion. While the action of questioning the hyperparameters and suggesting a presentation improvement is explicit, the comment lacks concrete guidance on how to address the issue of the SCNN\"s performance or how to implement the presentation suggestion. The authors know they need to investigate the hyperparameters and consider the presentation suggestion, but the feedback is somewhat vague in terms of execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. However, the comment does not specify which part of the paper discusses the hyperparameters or the results related to domain pricing, making it weakly grounded. The suggestion for presentation is specific, but the lack of grounding in the paper\"s content limits the effectiveness of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. However, the comment lacks specific evidence or detailed reasoning to support these claims, making it difficult for the authors to address the issue effectively. The suggestion for presentation is separate from the claim and does not affect the verifiability of the initial claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. While the comment identifies a potential issue with the model\"s performance, it lacks specific guidance on how to address the concern about the hyperparameters or how to implement the presentation suggestion. The feedback is 3 as it highlights an area for improvement but could be more comprehensive and actionable to be fully beneficial for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what aspects need clarification or how to improve the motivation. The comment lacks concrete details or suggestions on how the authors should address these issues, leaving the authors uncertain about the specific steps to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can infer that it relates to the experimental setup, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the areas of concern, such as corpora and datasets, but without detailed guidance on how to address these issues, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. However, it lacks detail and does not provide specific suggestions or examples of what aspects are unclear or how they could be improved. This makes it difficult for the authors to address the feedback effectively. While it highlights an important area for improvement, the comment is incomplete and lacks actionable guidance, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the improvement of the proposed method over existing RL methods is not impressive, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the proposed method could be improved. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique pertains to, such as the results section or a specific experimental comparison. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity as it does not detail what aspects of the improvement are not impressive or suggest how the authors might address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or detailed explanations, the authors are left without guidance on how to address the issue or improve their method. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the improvement of the proposed method over existing RL methods, stating that it is not impressive. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this issue or improve their method. Without actionable feedback or guidance, the comment does not help the authors enhance their draft. Therefore, it is rated as 1."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison of the model size (in terms of depth or number of parameters) to competing approaches. It also points out that the authors mention the number of hourglass modules but do not specify their size. This comment implies that the authors should provide more detailed information about the model size to facilitate a comprehensive comparison. While the action is implicit, it is clear and specific, guiding the authors on what additional information is needed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the model size to competing approaches, specifically mentioning the number of hourglass modules. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in asking for clarification on the size of the model, including the number of parameters or depth, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This comment is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This feedback is 3 as it identifies a gap in the paper\"s presentation, prompting the authors to provide more detailed information about the model size. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or why it is important for the comparison. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim that the proposed PACE treats climate emulation as a diagnostictype prediction, which is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the relationship between their work and existing literature. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about PACE treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of misrepresentation by not clarifying that prior work already addresses this aspect. The comment provides a clear direction for the authors to address the claim, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about PACE treating climate emulation as a diagnostictype prediction is misleading without providing clear evidence or references to prior work (such as ClimateBench or ClimateSet) that already addresses this aspect. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that PACE treats climate emulation as a diagnostictype prediction, noting that prior work (such as ClimateBench or ClimateSet) already addresses this aspect. This feedback is 3 as it points out a potential gap in the authors\" claim and suggests that they should clarify the novelty or differentiation of their approach. However, the comment lacks specific guidance on how the authors might address this issue or what additional information is needed to support their claim. To be more helpful, the comment could provide suggestions on how to clarify the novelty of PACE or how it differs from existing work. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, stating that it does not provide better results compared to previous theoretical results. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the metric perspective analysis, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the metric perspective analysis is not better. The reference to Bartlett et al. (2017) provides some context, but it does not substantiate the claim. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, suggesting that it does not provide better results compared to previous theoretical results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential weakness, it does not offer actionable feedback or detailed advice on how to enhance the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests moving some visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also provides a concrete suggestion to condense the existing figures on the network architecture to make room for additional visual results. This feedback is clear and provides specific guidance on how the authors can improve their draft by enhancing the visual representation of their work. The action is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also suggests condensing the existing figures on the network architecture to make room for additional visual results. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the main paper and the supplementary material. The suggestion to condense figures is specific, providing a clear direction for the authors to follow. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. The reviewer provides a specific suggestion to condense existing figures on the network architecture to make room for additional visual results. This feedback is based on a logical reasoning that the inclusion of more visual results would enhance the paper\"s presentation and understanding of the main experiment. However, the comment lacks specific examples or references to support the claim that the current figures are redundant or how the additional visual results would improve the paper. While the suggestion is clear, the lack of detailed justification makes it 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to move visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also offers a specific suggestion to condense existing figures on the network architecture to make room for additional visual results. This feedback is valuable as it directs the authors to enhance the visual representation of their work, which can improve the clarity and impact of the paper. However, the comment could be more helpful if it provided specific examples of which visual results should be moved or how the additional visual results could be integrated. Overall, the comment is 4 as it offers clear guidance for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential confusion in notation, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is explicit in identifying the issue, but it does not provide specific guidance on how to resolve the confusion. The authors are left to infer that they should clarify the notation or provide a consistent explanation for the use of \"r\" in different contexts. While the action is implied, it is concrete enough for the authors to understand the need for clarification. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This provides full grounding as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies the issue with the notation, which is the potential confusion it may cause. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems is confusing. This is a subjective observation that lacks specific examples or references to support the claim. The comment does not provide detailed reasoning or evidence to substantiate why this notation is confusing, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their notation. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion, such as proposing alternative notations or explaining the rationale behind the current notation. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to incorporate the corpus residual value into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of corpus residual value to detect such differences. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. The comment suggests that this issue could be detected using the corpus residual value, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the corpus residual value could be used for this purpose. Without additional justification or references, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value, which is a constructive and insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or incorporate the corpus residual value into their analysis. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable steps. Therefore, the comment is 3, as it provides a valuable insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. However, the reasoning provided gives the authors a clear understanding of the benefits of using WebQuestions, making the action somewhat explicit. The authors know what needs to be done but may need to infer the exact steps to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of dataset used in the study, specifically mentioning WebQuestionsSP and suggesting the use of the more popular WebQuestions benchmark set (Berant et al., 2013). It provides a rationale for why using WebQuestions would be more intuitive and facilitate comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the dataset choice, making it weakly grounded. The suggestion is specific, as it clearly identifies the issue of dataset choice and provides a rationale for the change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the suggestion is logical and based on common knowledge in the field, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the choice of dataset used in the study. It suggests using the WebQuestions benchmark set instead of WebQuestionsSP, reasoning that this would be more intuitive and facilitate direct comparison with mainstream QA research. This feedback is valuable as it offers a specific and logical alternative that could enhance the relevance and impact of the study. However, the comment could be more helpful if it included additional details on why WebQuestions might be a better choice or how it could improve the study\"s outcomes. Overall, the comment is 4 as it directs the authors to a more appropriate dataset choice, but it could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not explicitly instruct the authors to remove or modify these claims, nor does it provide specific guidance on how to demonstrate the benefits. The action is implicit and somewhat vague, as the authors can infer the need for demonstration but lack concrete steps on how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. However, the comment does not specify which part of the paper these claims are made in, making it weakly grounded. The authors can infer that it relates to the discussion of sparsity or related sections, but this inference is not precise. The comment is specific in detailing what needs to be addressed, namely, the demonstration of the benefits of sparsity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. While the comment provides a logical argument questioning the desirability of sparsity, it lacks specific examples or references to support the claim. The suggestion to demonstrate the benefits or provide evidence of cost savings is a reasonable request, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the claim is 3, as it provides a basis for questioning but lacks comprehensive support.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. This feedback is 4 as it identifies a potential weakness in the paper\"s claims and offers a clear direction for improvement. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate the benefits or evidence of cost savings. Overall, the comment provides valuable insights that can guide the authors in refining their claims and improving the paper\"s argumentation. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the novelty of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or method. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the novelty of the work, stating that the design is not entirely new as attention for motion learning has been widely used in video understanding. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should analyze or present results on other datasets, such as ImageNet1k or ImageNet100, to verify the effectiveness of their framework. This feedback is clear and provides a direct action for the authors to take, which is to include additional results in their paper. The suggestion is concrete, as it specifies the datasets to be analyzed and the importance of presenting these results in the main paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR derivatives\" and \"ImageNet derivatives,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the paper lacks analysis or results on other datasets, such as ImageNet1k or ImageNet100, and emphasizes the importance of verifying the effectiveness of the framework on these datasets. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, such as ImageNet derivatives, and that verifying the effectiveness of the framework on these datasets is important. The comment provides a logical reasoning by highlighting the need for additional results to support the claims made in the paper. However, it lacks specific examples or references to external works that could further substantiate the claim. While the suggestion is clear, the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the lack of analysis or results on other datasets, such as ImageNet derivatives, despite the paper\"s improvements on CIFAR derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets, which are widely recognized in the field. The comment provides a clear and actionable suggestion for the authors to include additional results in their paper, which would enhance the comprehensiveness and impact of their work. This feedback is valuable as it guides the authors towards a more robust evaluation of their framework, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a plot of the model illustration, a pseudocode table, or a code repository to clarify the model design and facilitate reproducibility. The suggestion is clear and concrete, as it specifies the exact actions the authors need to take to address the issue of unclear model design. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of unclear model design, specifically mentioning the fragmentation or absence of details regarding the model architecture and learning process. It suggests providing a plot, pseudocode table, or code repository to clarify these aspects. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the methodology or results sections where the model design is discussed. The suggestion to demonstrate integrated details for reproducibility is clear and specific, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details about the model architecture and learning process. The reviewer suggests providing a plot, pseudocode table, or code repository to clarify these aspects. However, the comment lacks specific examples or references to support the claim that Neurochaos Learning is not wellknown, which could strengthen the argument for demonstrating integrated details. The suggestion to provide additional information is logical and reasonable, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the model design, noting that the model architecture and learning details are fragmented or missing. It provides actionable suggestions for improvement, such as providing a plot of the model illustration, a pseudocode table, or a code repository, to enhance transparency and reproducibility. This feedback is clear and constructive, offering the authors a concrete path to address the identified weakness and improve the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to present the model details effectively. Overall, the comment is 4, as it provides valuable insights and actionable steps for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for addressing them as models. This feedback provides a clear and explicit action for the authors to take, which is to ensure consistency in the terminology throughout the paper. The suggestion is concrete, as it specifies the action needed to resolve the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the inconsistency in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The authors can identify the sections where this inconsistency occurs, such as the Abstract and Introduction, as well as the Experiments section. This provides full grounding, allowing the authors to accurately pinpoint the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the inconsistent use of these terms and suggests a more consistent approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for addressing them as models. This claim is 3 as it points out a logical inconsistency in the paper\"s terminology. However, it lacks specific examples or references to support the suggestion, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be more consistent to refer to them as datasets unless there is a specific reason for addressing them as models. This feedback is clear and actionable, as it provides a straightforward suggestion for improving the consistency and clarity of the paper\"s terminology. By addressing this issue, the authors can enhance the coherence and professionalism of their draft. Therefore, the comment is rated as 5, as it offers a specific and actionable way to improve the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates in their experiments or to view misclassifications as rejections. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies what needs to be included in the results section to address the issue of rejection rate. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of rejection rate in the experiments and suggests including it or viewing misclassifications as rejections. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that rejection rates should be included in the experiments or viewed as misclassifications. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of rejection rates in the experiments. It suggests that the authors should include rejection rates or view misclassifications as rejections, which is a clear and actionable suggestion. This feedback provides the authors with a concrete step to take to improve the completeness and accuracy of their results section. However, the comment could be more helpful if it offered additional guidance on how to present these rejection rates or discussed the potential impact of including them. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization to specific TSP instances in the paper, particularly in the context of the finetuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a clear direction for improvement, it does not specify how to achieve these clarifications or comparisons. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take to address the suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the generalization to specific TSP instances, specifically mentioning the finetuning step in DIMES. It suggests clarifying the generalization gaps and provides a specific recommendation to compare DIMES with other methods on TSP100. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the generalization gaps and comparing with other methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the generalization to specific TSP instances should be clarified, particularly in the context of the finetuning step in DIMES. It acknowledges that DIMES has advantages in direct RL training for largescale problems and meta finetuning, but it questions the clarity of these advantages. The reviewer also suggests comparing DIMES with other methods on TSP100 to provide a more comprehensive evaluation. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the generalization gaps. The suggestion to compare with other methods is a logical extension but remains somewhat vague without detailed guidance. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the generalization to specific TSP instances, particularly in the context of the finetuning step in DIMES. It acknowledges the advantages of DIMES but suggests that the paper should clarify these advantages and provide a more detailed comparison with other methods. The comment also recommends testing DIMES on TSP100 with and without metalearning, which could provide valuable insights. While the feedback is clear and actionable, it could be more helpful if it included specific suggestions on how to clarify the generalization gaps or how to conduct the comparison. Overall, the comment is 4 as it guides the authors towards improving the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to provide the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility. This request is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what information needs to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"final thresholds\" and \"hyperparameters,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the sharing of thresholds and hyperparameters for reproducibility. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two requests for information: the final thresholds used for the results and the sharing of full hyperparameters for reproducibility. These are factual requests for additional information that do not require any justification or evidence. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, providing specific requests for information that would enhance the reproducibility and transparency of the results. By asking for the final thresholds used for the results and suggesting the sharing of full hyperparameters, the comment offers concrete steps for the authors to take to improve the clarity and reproducibility of their work. This feedback is valuable as it helps the authors address potential concerns about the reliability and replicability of their findings, making the comment 4. However, it could be more helpful if it included suggestions on how to present this information or why it is important for reproducibility. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the authors\" claim that the readability of RC datasets does not directly affect question difficulty, but it points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment highlights a potential limitation of the claim, it does not provide explicit guidance or suggestions on how the authors might address this issue or further explore the impact of different features on question difficulty. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of various features on their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and their effect on question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this inference is not explicit. The comment is specific in detailing the dependency on features for answer detection, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges a claim made by the authors about the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or detailed reasoning to support the claim that the method or features are indeed responsible for the observed impact. The lack of detailed evidence or examples makes the claim 3, as the authors would need to further explore the impact of different features to fully understand the reasoning behind the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges a claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it highlights a potential limitation of the authors\" claim and suggests that the authors should consider the impact of different features on their analysis. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might address this issue or further explore the impact of features on their results. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While it implies that the authors should make an effort to reduce whitespace, it does not provide specific guidance on how to achieve this optimization. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the optimization of the figure to use less whitespace. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace, but it does not provide any reasoning, examples, or specific guidance on how to achieve this optimization. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this is a specific and actionable suggestion, it lacks context or explanation as to why this optimization is necessary or how it could impact the clarity or effectiveness of the figure. Without additional guidance or examples, the authors may find it challenging to fully understand the rationale behind the suggestion or how to implement it effectively. Therefore, the comment is 3, as it provides a specific area for improvement but lacks depth and context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence of the meaningfulness of the space. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process, specifically asking if the geometry of the space is meaningful. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections where the morphfitting process is discussed, but this inference is not explicit. The comment is specific in its request for evidence or analysis to support the meaningfulness of the space. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. However, the comment does not provide specific examples or references to support the claim that the geometry of the space is meaningful. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment raises a critical question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. This feedback is valuable as it prompts the authors to consider the interpretability and utility of their results, which is essential for understanding the implications of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or suggested potential methods for demonstrating meaningfulness. Overall, the comment is 4 as it identifies a significant area for improvement and offers a direction for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically mentioning the need to address the repetition of explaining basic memory networks and the forward model. It also points out that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not provide specific guidance on how to improve the writing quality or what aspects of the related work should be expanded. The authors are left with a general understanding of what needs to be addressed but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not specify which sections of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing quality is being evaluated in general, but the lack of specific references or examples makes it difficult to pinpoint the exact parts needing improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for improvement in the writing quality of the paper, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also points out a gap in the related work section, suggesting that more reinforcement learning tasks should be included. However, the comment lacks specific guidance or suggestions on how to address these issues, such as providing examples of how to improve the writing or what additional tasks should be included in the related work section. While it highlights areas for improvement, the feedback is 3 as it provides a general direction but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper regarding the replacement of the first column of Qo with vo to form P\"o, which results in the first state becoming unreachability. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (finite length of an option) should be considered. However, the comment does not provide explicit instructions on how the authors should address this issue or which assumption should be prioritized. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly modify their assumptions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo with vo to form P\"o, which results in the first state becoming unreachability. The comment further suggests that either Assumption 1 or Assumption 2 should be considered, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the replacement of the first column of Qo with vo to form P\"o, which results in the first state becoming unreachability. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (finite length of an option) should be considered. However, the comment does not provide specific reasoning or evidence to support why these assumptions are relevant or how they relate to the issue described. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the replacement of the first column of Qo with vo to form P\"o, which results in the first state becoming unreachability. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (finite length of an option) should be considered to address this issue. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, it could be more helpful if it offered additional guidance or suggestions on how to implement these assumptions or address the issue. Overall, the comment provides some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to investigate these aspects, but it lacks concrete guidance on how to carry out this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as accuracy and modeling sequential relationships, but without explicit references to sections or figures, the authors may struggle to pinpoint where these suggestions apply. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these specific properties might be more relevant or why they should be prioritized over FLOPs or inference time. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. This feedback is 3 as it provides a direction for the authors to explore alternative areas for improvement beyond FLOPs and inference time. However, the comment lacks specificity and does not offer detailed guidance on how to assess or improve these properties. To be more helpful, the comment could include specific metrics or methods for evaluating accuracy or provide examples of how to model sequential relationships with a recurrent model. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this assumption should be tested or how it could be tested. The comment lacks specificity and does not offer any concrete steps for the authors to follow, making it 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not specify which part of the paper this assumption is made in. The authors may infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in questioning the assumption, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or references to external works that might support the claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that d_e are good replacements for entity embeddings, which is an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might test or address this assumption. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the threshold values/ranges. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting specific sections to review or methods to clarify the derivation of these components. Without actionable steps or detailed suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the \"threshold values/ranges,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is unclear: the derivation of the components of the scoring function and the threshold values/ranges. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the authors\" derivation of the components of the \"scoring function\" and the threshold values/ranges. However, it does not provide any specific examples, reasoning, or references to support why this is unclear. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the derivation of the components of the \"scoring function\" and the threshold values/ranges. It highlights a gap in the paper\"s clarity, which is important for readers to understand the methodology and results. However, the comment does not provide any suggestions or guidance on how the authors might clarify these aspects, such as recommending specific sections to revisit or offering alternative explanations. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that presenting factors in a table does not convey more information than pure text, implying that the authors should consider alternative ways to present the information. However, the comment does not provide specific guidance on what those alternative ways might be or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different presentation methods but are not given concrete suggestions on what those might be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique, as it clearly identifies the problem with the current presentation method. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that presenting factors in a table does not convey more information than pure text, suggesting that there is no additional information provided. However, the comment lacks specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might improve the presentation or convey more information. Without actionable feedback or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it points out a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of their work might be affected by this inquiry. The comment lacks any explicit or implicit actions for the authors to take, leaving them without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or guidance on how the authors might address this question or what aspects of their work might be affected by it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of their work might be affected by it. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for consideration but does not offer substantial guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should consider including more datasets with categorical features or employing onehot encoding for the existing dataset. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions on how to implement these changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features and that the authors do not employ onehot encoding for this dataset. This provides clear guidance on what needs to be addressed to improve the paper\"s contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dataset selection is inadequate because it lacks datasets with categorical features, which are generally more challenging for deep learning models. The reviewer provides a logical reasoning by explaining that the absence of categorical features in most datasets could affect the conclusions drawn from the model comparison. However, the comment lacks specific examples or references to support the claim that onehot encoding is necessary for all datasets. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it highlights a potential weakness in the paper\"s contribution and provides specific guidance on how to address it. By suggesting the inclusion of more datasets with categorical features or the use of onehot encoding, the comment offers concrete steps for improvement. However, it could be more helpful if it provided additional context or examples of how these changes could affect the results. Overall, the comment is 4, as it effectively guides the authors towards enhancing the robustness and validity of their model comparison."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses dissatisfaction with the choice of two IoT datasets, suggesting that they are unpopular and not wellsuited for benchmarking. It implies that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should proceed or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to find better datasets but are not given concrete suggestions on where to look or how to evaluate the suitability of potential options. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of IoT datasets, noting that they are unpopular and not wellsuited for benchmarking. The reviewer suggests that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of two IoT datasets is \"unpopular\" and \"weird,\" suggesting that the datasets are not wellsuited for benchmarking. The reviewer provides reasoning by noting that the FlatCam Face dataset is relatively recent but not substantially followed, and the Headpose detection dataset was published in 2004 and is no longer widely used. This provides some logical reasoning and context for the claim, making it 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets in Section 4, specifically the IoT datasets used for benchmarking. It points out that the datasets are unpopular and not widely used, suggesting that the authors should have considered better options for IoT benchmarking, such as wearable health or mobile activity recognition data. This feedback is clear and actionable, as it provides specific suggestions for improving the dataset selection and benchmarking results. However, the comment could be more helpful if it offered additional guidance on how to evaluate the suitability of the suggested datasets or provided examples of what constitutes better options. Overall, the comment is 4 as it directs the authors to consider alternative datasets that could enhance the robustness and relevance of their benchmarking results."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to pruning and its potential impact on large networks trained in distributed settings. It highlights the need to consider finding global top Q values of the metric over the average of gradients, which could affect acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion on pruning or related techniques, but without explicit references, the comment lacks full grounding. The specificity is clear as it points out a potential issue with the methodology that could affect the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and raises a concern about the necessity of finding global top Q values of the metric over the average of gradients. This claim is 3 as it provides a logical reasoning about the potential impact of pruning on large networks and distributed training. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to further investigate the claim to fully understand its implications and address it in their work.", "helpfulness_rationale": "The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could break a significant portion of acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. This feedback is 3 as it points out a critical aspect that the authors should consider to ensure the robustness of their pruning approach. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or if it expanded on the potential impact of this oversight. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they check the figures or provide a correction. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. This provides full grounding as it explicitly mentions the figures being addressed, allowing the authors to accurately identify the parts of the paper being discussed. The comment is also specific because it clearly specifies the issue of potential swapping, giving the authors a clear direction to investigate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the figures in Figs 1 and 2, questioning whether they have been swapped by mistake. This is a straightforward statement of fact without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the figures in Figs 1 and 2, suggesting that they may have been swapped by mistake. While this observation is important for the authors to address, the comment lacks actionable guidance or suggestions on how to verify or correct the issue. It does not provide any context or reasoning to support the claim, nor does it offer any advice on how the authors might investigate or resolve the potential error. As a result, the comment is 2, as it identifies a potential issue but does not provide actionable feedback for the authors to improve their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. While the comment acknowledges the benefits of the probe, it suggests that this should be a substantial part of the discussion. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the dropout probe and its potential impact on sensitivity and the identification of causal roles for syntactic representations. It raises a concern about the risk of false positives, suggesting that this should be a substantial part of the discussion. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but the lack of explicit mention of specific sections makes it difficult to pinpoint. The comment is specific in identifying the concern about false positives and suggesting a discussion, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. The reviewer acknowledges the benefits of the probe but suggests that this should be a substantial part of the discussion. However, the comment lacks specific examples or references to support the claim about false positives, making it difficult for the authors to fully understand and address the concern. The reasoning is logical but lacks detailed evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the benefits of the dropout probe in improving sensitivity and finding causal roles for syntactic representations. However, it raises a concern about the potential increase in false positives, which is a valid point to consider. The comment suggests that this aspect should be a substantial part of the discussion, providing a clear direction for the authors to address. While the comment identifies a potential issue, it could be more helpful if it offered specific suggestions on how to discuss and mitigate the risk of false positives. Overall, the comment is 4 as it highlights an important consideration for the authors to address in their discussion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the regret bound for the proposed minibatch method, stating that it is claimed to be in the appendix but not found in the supplementary material. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as whether they should clarify the location of the regret bound or provide it in the main text. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regret bound for the minibatch estimator,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of the regret bound in the supplementary material, despite the authors\" claim that it is there. The comment provides a clear reference to a specific external work, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which helps the authors understand the context of the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the regret bound for the minibatch method being in the appendix is not supported by the supplementary material. The reviewer provides a specific reference to an external work, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which could be relevant to the discussion of regret bounds. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference provides a potential source of information, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim regarding the regret bound for the minibatch method, noting that the claim is made in the appendix but the regret bound is not found in the supplementary material. This is a clear and actionable feedback that highlights a potential inconsistency or error in the paper. By pointing out this discrepancy, the comment provides the authors with a specific area to address, which could be crucial for the integrity and clarity of their work. However, the comment could be more helpful if it suggested how the authors might resolve this issue or where the regret bound should be located. Overall, the comment is 4 as it directs the authors\" attention to a critical oversight, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out issues with the paper formatting, specifically mentioning that it does not follow the NeurIPS formatting style, the abstract font size being too large, and the bottom page margins being altered. It suggests that fixing the paper style would provide more space and allow the NLP experiments to be included in the main body of the paper. While the comment identifies specific formatting issues and suggests a potential solution, it does not provide explicit instructions on how to correct the formatting or where to include the NLP experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the formatting issues and integrate the NLP experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific formatting issues, such as the NeurIPS formatting style, font size, and page margins, which are mentioned explicitly. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment also suggests that fixing the formatting issues would provide more space and allow the NLP experiments to be included in the main body of the paper. This is specific because it clearly outlines what needs to be addressed and how it could improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style. It specifies issues with the abstract font size and page margins, suggesting that fixing these issues would provide more space and allow the NLP experiments to be included in the main body of the paper. While the comment provides specific examples of formatting issues, it lacks detailed reasoning or references to support the claim that these issues are significant or how they might impact the paper\"s presentation. The suggestion to include NLP experiments in the main body is a logical inference but lacks explicit justification. Therefore, the comment is 3, as it provides some evidence but could benefit from more detailed reasoning or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies specific formatting issues with the paper, such as not following the NeurIPS formatting style, having an oversized abstract font, and altered bottom page margins. It suggests that fixing these issues would provide more space and allow the NLP experiments to be included in the main body of the paper. This feedback is actionable and provides clear guidance on how the authors can improve the paper\"s presentation and content organization. However, the comment could be more helpful if it offered suggestions on how to address the formatting issues or provided examples of how to integrate the NLP experiments. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a significant issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on which specific exploration methods should be discussed or compared, or how these comparisons could be made. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support the claim that these methods are essential or relevant to the paper\"s focus. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of related work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which exploration methods should be discussed or how they could be compared. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 should be enlarged for better visibility. This is an explicit action that the authors can take to improve the figure. However, the comment does not provide specific guidance on how much enlargement is necessary or how to achieve it. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the enlargement of annotations for better visibility. This provides clear guidance on what the authors need to do to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 should be enlarged for better visibility. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the figure. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 4, suggesting that the annotations should be enlarged for better visibility. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it lacks depth and does not offer additional guidance on how to achieve the enlargement or what specific changes might be necessary. While it points out a clear area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a common issue in the field of natural language processing, specifically regarding the existence of multiple entities in sentences and documents, which is relevant to relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or where it might be relevant in their paper. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a common issue in the field of natural language processing, specifically regarding the existence of multiple entities in sentences and documents, which is relevant to relation classification. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a common issue in the field of natural language processing, specifically regarding the existence of multiple entities in sentences and documents, which is relevant to relation classification. However, it does not provide any actionable feedback or suggestions on how the authors might address this issue in their paper. Without specific guidance or examples, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential area of concern but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that one of the labels on the color bar in Figure 4 should say \"worse.\" This is a clear and direct instruction for the authors to make a specific correction. The action is explicit and concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the labeling of the color bar, suggesting that one of the labels should say \"worse.\" This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the labeling of a figure, specifically Fig. 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a straightforward statement of fact, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, identifying a particular issue with the labeling of a figure in the paper. It points out that one of the labels on the color bar in Figure 4 should say \"worse.\" This feedback is clear and provides a direct correction that the authors can implement to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it offered additional guidance on why this labeling is important or how it affects the overall interpretation of the figure. Despite this, the comment is 4 as it directs the authors to a specific area needing attention and correction. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the inference process, provide the coefficient value, and ensure thorough hyperparameter tuning and ablation studies. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the inference process, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. It provides clear guidance on what needs to be addressed, such as clarifying the inference process, explaining the coefficient value, and ensuring thorough hyperparameter tuning and ablation studies. The comment is fully grounded as it references specific parts of the paper, such as line 307, and is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several concerns about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several critical issues in the paper, including concerns about the inference process, missing hyperparameter details, and unclear writing. It questions the impact of inference slowing down and whether it\"s possible to perform inference alone, suggesting that this might not be fatal. The comment also points out the absence of the coefficient of the p(L, E | X) term and questions its value of 1. Additionally, it highlights the need for detailed hyperparameter information and confident results from ablation studies. However, the comment lacks specific suggestions or guidance on how to address these issues, such as providing examples or detailed explanations. While it raises important points, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes adding an extra pair of brackets around the term or defining the bracketed term separately if there is enough space. This feedback provides a clear and explicit action for the authors to take, which is to make a specific change to the definition or provide additional explanation. The suggestion is concrete, as it specifies what needs to be done to improve the clarity of the definition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential issue with the definition and provides a concrete suggestion for improvement by adding an extra pair of brackets or defining the bracketed term separately. This level of detail helps the authors understand what needs to be addressed and how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes a potential improvement by adding an extra pair of brackets or defining the bracketed term separately. However, the comment does not provide any specific reasoning or examples to support why the definition is confusing or how the suggested changes would clarify it. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile. It provides a clear and actionable suggestion by suggesting a potential improvement, such as adding an extra pair of brackets or defining the bracketed term separately. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and understanding of their work. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on the importance of this clarification. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify why this change is necessary or how it would improve the paper. While the action is clear, the lack of detailed reasoning or explanation makes it somewhat vague. Therefore, the comment is 4, as it provides a direct action but lacks full guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" However, it does not provide any reasoning or evidence to support why this model is no longer stateoftheart or why it should be replaced. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This feedback is 3 as it identifies a potential issue with the description of the model\"s status, which could be misleading or outdated. However, the comment lacks depth and does not provide specific guidance on why this change is necessary or how it would improve the clarity of the paper. To be more helpful, the comment could include an explanation of why the model is no longer stateoftheart or why the change is important. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this comparison or where the authors should focus their efforts to improve the method. The authors can infer that it relates to the comparison section or results, but the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in identifying the weakness of the proposed method, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. However, the comment does not provide any supporting evidence, such as specific results or comparisons, to substantiate this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a valuable observation that highlights an area where the authors need to improve their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance their method. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a weakness but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some subjective statements in the paper are inappropriate and recommends providing proofs and references to support the statements. It also points out that the image recovery performance is sensitive to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific proofs or references to include. The authors are left with a general understanding of what needs to be improved but lack concrete steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses subjective statements in the paper and suggests the need for proofs and references to support them. It also points out the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. However, the comment does not specify which parts of the paper contain these subjective statements or where the proofs and references should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections to address. The comment is specific in detailing what needs to be addressed, such as providing proofs and references, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some subjective statements in the paper are inappropriate and suggests the need for proofs and references to support them. It also points out the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment provides some reasoning by mentioning the sensitivity of performance and the challenge of multiscale architecture design, but it lacks specific examples or references to substantiate the claims fully. This makes the claim 3, as it provides some support but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements, proofs, and references. It suggests that some statements are inappropriate and recommends providing proofs and references to support them. Additionally, it points out the sensitivity of image recovery performance to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment also mentions the use of skip connections as an implicit way of using multiscale information. However, the feedback lacks detailed guidance on how to address these issues or provide the necessary proofs and references. While it provides some insight into potential improvements, the comment could be more helpful with specific suggestions or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks about the comparison of the proposed method with prior art, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to conduct this comparison or what specific aspects should be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method compares with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in asking for a comparison with prior work, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question asking for a comparison with prior art, which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art. While it identifies a gap in the paper\"s analysis, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of prior work should be considered. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area for enhancement but does not offer concrete steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that the authors should consider comparing biases towards different languages/nationalities. While the comment suggests an area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the inclusion of various languages and suggests an interesting observation to compare biases towards different languages/nationalities. This provides clear guidance on what the authors should consider in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that there might be interesting observations comparing biases towards different languages/nationalities. However, the comment does not provide specific examples or detailed reasoning to support the claim that these comparisons would be interesting or necessary. The suggestion lacks concrete evidence or examples to substantiate the claim, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It points out the inclusion of various languages and suggests that comparing biases towards different languages/nationalities could lead to interesting observations. This feedback is 3 as it provides a specific suggestion for enhancing the analysis, but it lacks detailed guidance on how to conduct these comparisons or what specific observations might be made. The authors are given a direction for improvement but would benefit from more detailed instructions or examples to fully implement the suggestion. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests exploring additional properties of features beyond the norm, which is necessary and helpful for the approach design. However, it does not provide specific guidance on which properties to consider or how to incorporate them into the approach. The action is implicit, as the authors need to infer that they should explore other properties, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring additional properties of features beyond the norm, which is necessary and helpful for the approach design. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore other properties, but without grounding, the authors may struggle to identify the exact section where this suggestion is relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring additional properties of features beyond the norm, which is necessary and helpful for the approach design. However, it does not provide any specific reasoning, examples, or references to support why these additional properties are necessary or how they would enhance the approach. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring additional properties of features beyond the norm, which is necessary and helpful for the approach design. This feedback is 3 as it identifies a potential area for improvement in the approach design. However, it lacks specificity and does not provide guidance on which properties to explore or how they might enhance the approach. The authors are left with a general suggestion but without actionable steps to follow. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this topic numerically. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of learning F^dagger or the experimental results, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely the conservation properties of learning F^dagger. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that learning F^dagger should conserve these properties. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. This feedback is valuable as it prompts the authors to consider a critical aspect of their work that may impact its applicability and accuracy. However, the comment could be more helpful if it included specific guidance on how to investigate this issue or suggested methods for conserving properties during training. Overall, the comment is 4 as it identifies a significant area for improvement and provides a clear direction for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness in the paper, specifically noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. While the comment points out a potential issue, it does not explicitly instruct the authors to make changes or provide specific guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the network for d. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific weakness in the paper, noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or figure. While the authors can infer that it relates to the method or experimental setup, the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the method being mostly constructed on top of previous methods without significant network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. While the comment identifies a potential issue with the method\"s novelty, it lacks specific reasoning or evidence to fully substantiate the claim. The suggestion to simplify the network for d is a logical point, but without further elaboration or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper, specifically noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer raises a question about the use of two SIRENs for f and d, suggesting that d should be a simpler network. This feedback is 3 as it points out a potential area for improvement in the method\"s novelty and suggests a possible simplification. However, the comment could be more helpful if it provided specific suggestions or examples of how to simplify the network for d or how to enhance the method\"s novelty. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. This feedback is explicit in suggesting that the authors should consider a different research question or analysis, and it provides a specific direction for improvement. However, the comment does not offer detailed guidance on how to implement this suggestion or what specific aspects of the analysis should be changed. While the action is clear, the lack of concrete details on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the RQ1 is redundant and proposes an alternative research question related to the percentage of explicit hate information in the dataset affecting implicit hate speech detection performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. The comment provides a reference to support the suggestion, which is a helpful addition. However, the claim could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is 4, as it offers a logical basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a redundancy in the RQ1 mentioned in the paper, suggesting that it does not provide additional information for the audience. It proposes an alternative research question that could be more insightful, focusing on the impact of explicit hate information on implicit hate speech detection performance and vice versa. This feedback is clear and actionable, as it guides the authors to consider a more meaningful research question that could enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific suggestions on how to integrate this new research question into the paper or how it could be tested. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to address this expectation. The comment lacks specificity and does not provide any concrete steps or suggestions for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not specify which part of the paper this feedback pertains to, such as a particular section, table, or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity as it does not provide examples or detailed suggestions on how to address the expectation of seeing a variety of tasks where PE is important. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or references, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it is expected to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. While this observation is relevant and could be insightful for the authors, it lacks specificity and actionable guidance. It does not provide any suggestions on how the authors might address this expectation or where they might explore these additional tasks. Without detailed feedback or concrete steps, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it provides a general observation but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of the authors\" work with other papers focusing on semantic face editing, specifically mentioning the ability to achieve continuous control over attributes. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in identifying the need for elaboration on the differences between the authors\" work and these papers, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are other works in the field of semantic face editing that achieve continuous control over attributes, and it suggests that the authors should elaborate on the differences between their work and these papers. However, the comment does not provide specific examples or references to these other works, making it difficult for the authors to understand the context or relevance of the comparison. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to support the assertion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. This feedback is 3 as it highlights a potential area for improvement by pointing out the need for a more detailed comparison with existing literature. However, the comment lacks specific guidance on how to elaborate on the differences or what aspects should be emphasized, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to move important content from footnotes into the main body of the paper, suggesting that much of the content is actually important and should be included in the main text. It also provides a specific example of moving details around parameter settings into the appendix to make space. This feedback is clear and provides concrete guidance on how the authors can improve their draft by reorganizing the content. The action is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of footnotes in the paper, specifically mentioning that they are used too extensively and are distracting. It suggests moving important content from footnotes into the main body of the paper and provides an example of moving details around parameter settings into the appendix. This feedback is fully grounded as it explicitly mentions the use of footnotes and provides a specific suggestion for improvement. The comment is also specific, as it clearly identifies the issue with the extensive use of footnotes and offers a solution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used too extensively in the paper, which is distracting and suggests moving important content into the main body. The reviewer provides a specific suggestion to move details around parameter settings into the appendix to make space. This feedback is 4 as it offers a logical reasoning for the suggestion and provides a specific example of how to address the issue. However, it could be strengthened by providing more detailed examples or references to support the claim about the excessive use of footnotes. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of footnotes in the paper, noting that they are used too extensively and are distracting. It provides a clear and actionable suggestion to move important content from footnotes into the main body of the paper, which would improve the flow and clarity of the text. Additionally, it offers a specific example of moving details around parameter settings into the appendix to make space. This feedback is clear and provides a concrete way for the authors to enhance the organization and readability of their draft, making it 4. However, it could be more helpful if it included additional suggestions or examples of how to effectively integrate the content into the main body. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zeroshot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not provide explicit guidance on how to address these issues or what specific aspects of the fewshot demonstrations should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and possibly clarify the relevance of the zeroshot results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zeroshot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors might infer that it relates to the experimental section or results, but this is not explicitly stated. The comment is specific in its suggestion to include a discussion about fewshot demonstrations and questions the relevance of zeroshot results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of zeroshot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not provide specific reasoning or evidence to support why these results are strange or irrelevant. The suggestion to include a discussion about fewshot demonstrations is also made without detailed justification or examples of how this would enhance the paper. As a result, the claim is 3, as it provides a general observation but lacks detailed support or evidence to fully substantiate the claim. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that they might not be relevant to the main focus of the paper. It also suggests that a discussion about fewshot demonstrations could be beneficial, possibly with the help of domain experts. While the comment highlights a potential area for improvement, it lacks specific guidance on how to address these issues or what aspects of the fewshot demonstrations should be discussed. The feedback is 3 as it points out a potential weakness in the paper\"s experimental setup but does not provide detailed suggestions for improvement, leaving the authors with a general direction to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue regarding Figure 3, specifically mentioning that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is outdated. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it. The authors can infer that they need to ensure the caption is uptodate and that all relevant content is included, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that \"OAA\" is never referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a minor issue regarding Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment points out a potential inconsistency, it does not provide specific guidance on how to address this issue or what additional content might be missing. The feedback is 3 as it highlights a specific area for improvement, but it lacks depth and actionable suggestions, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the introduction that the proposed solution is a \"fix\" of [12], rather than a new PIC approach. It provides a specific action by suggesting the authors mention the existing work by [12] in the introduction. This feedback is clear and concrete, giving the authors a direct path to improve their draft by addressing the need for clarification. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for clarity in the introduction regarding the proposed solution being a \"fix\" of [12] rather than a new PIC approach. The comment provides a clear action for the authors to take, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors must clarify in the introduction that the proposed solution is a \"fix\" of [12], rather than a new PIC approach. The comment provides a specific suggestion for clarification, which is a logical and reasonable request. However, it lacks detailed reasoning or references to support why this clarification is necessary or how it would impact the paper\"s clarity. The claim is 3 as it points out a potential issue but lacks comprehensive justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the introduction, suggesting that the authors should clarify that their proposed solution is a \"fix\" of [12], rather than a new PIC approach. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity of their work. By addressing this point, the authors can enhance the understanding of their contribution and its relation to existing work. However, the comment could be more helpful if it provided additional context or examples of how to achieve this clarification. Overall, the comment is 4 as it guides the authors towards a specific improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, [2], which suggests that the authors should compute the effective receptive field. However, the comment does not provide explicit instructions or guidance on how to compute the effective receptive field or what specific improvements should be expected. The action is implicit and somewhat vague, as the authors need to infer that they should compute the effective receptive field and compare it before and after applying the GS module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the GS module for propagating context information over different spatial locations and questions whether the effective receptive field is improved. It references a specific source, [2], which suggests that the authors should compute the effective receptive field. However, the comment does not explicitly mention which part of the paper discusses the GS module or the effective receptive field, making it weakly grounded. The comment is specific in its inquiry about the effective receptive field and its improvement after applying the GS module, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, [2], which suggests that the authors should compute the effective receptive field. However, the comment does not provide detailed reasoning or evidence to support the claim that the effective receptive field is improved. The reference to [2] is a step towards verification, but it lacks specific examples or detailed explanations of how the effective receptive field is computed or improved. Therefore, the comment is 3, as it provides a direction for the authors to explore but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, [2], which suggests that the authors should compute the effective receptive field. This feedback is 3 as it prompts the authors to consider a specific aspect of their work that could be improved or further explored. However, the comment lacks detailed guidance on how to compute the effective receptive field or what specific improvements to expect. To be more helpful, the comment could provide more detailed instructions or examples on how to compute the effective receptive field and how it relates to the effectiveness of the GS module. Therefore, the comment is rated as 3, as it identifies an area for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This comment provides a clear and explicit action for the authors to take, which is to clarify the objective for the LSTM part and add a head for value function computation in the finetuning stage. The suggestion is concrete, as it specifies what needs to be done and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network computing the value functions for the states. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the LSTM part, but this inference is not explicit. The comment is specific in its suggestion to clarify the objective and add a head for value function computation, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network computing the value functions for the states. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network computing the value functions for the states. This feedback is clear and actionable, providing a specific suggestion for improving the clarity and effectiveness of the LSTM part. By adding a head for value function computation, the authors can enhance the model\"s capabilities and potentially improve its performance. The comment is 4 as it offers a concrete direction for improvement, but it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation for this combination, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the combination. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the rationale behind the combination, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\"s regularization in the latent space. This question is a request for clarification and does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information to understand the methodology better. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\"s regularization in the latent space. This question prompts the authors to provide a clear explanation of their methodology, which is valuable for improving the clarity and understanding of their work. However, the comment does not offer suggestions or guidance on how to address this question or what specific aspects of the combination need further clarification. While it identifies an area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning that there is a long line of work using supervised, multilingual systems. While the comment implies that the authors should include these older works, it does not provide explicit instructions on which specific works to acknowledge or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include older works but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning that there is a long line of work using supervised, multilingual systems. However, the comment does not provide specific examples or references to these older works, making it difficult for the authors to identify which works to include. This lack of detailed guidance limits the verifiability of the claim, as it does not provide a clear path for the authors to follow. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning that there is a long line of work using supervised, multilingual systems. This feedback is 3 as it points out a potential oversight in the literature review, encouraging the authors to broaden their perspective and include foundational works in their discussion. However, the comment lacks specificity regarding which older works should be acknowledged or how they might impact the paper\"s narrative. To be more helpful, the comment could provide examples of specific older works or suggest how including them could enhance the paper. Therefore, the comment is rated as 3, as it offers a direction for improvement but could be more detailed."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that the authors\" argument about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming predicted architectures. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their results or analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly revise their results or analysis to align with the suggested argument. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, specifically the confusion regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. The comment provides a clear rationale for this confusion, suggesting that the authors\" argument about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming predicted architectures. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that the authors\" argument about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming predicted architectures. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are confusing or that the sampling strategy should perform better. The suggestion is based on a logical argument but lacks concrete evidence or references to substantiate the claim fully. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the results presented in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" argument about the predictor being accurate on the good subregion, suggesting that increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to resolve the issue, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues contributing to the high time complexity of the proposed method. It points out the use of an itemoriented autoencoder, which may involve many users associated with a typical item, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for reducing the time complexity. The authors are left to infer that they need to optimize the model or explore alternative approaches, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of high time complexity in the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues related to time complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment lacks specific examples or detailed reasoning to support these claims. While the reviewer identifies potential sources of high time complexity, the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several factors contributing to the high time complexity of the proposed method, including the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback is 3 as it points out specific areas where the authors might need to focus on to improve the efficiency of their approach. However, the comment lacks detailed suggestions or guidance on how to address these issues, such as proposing alternative methods or optimizations. While it provides a starting point for the authors to consider, the feedback could be more actionable with additional insights or concrete steps. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" This feedback provides a clear and explicit action for the authors to take, as it directly instructs them to clarify the types of autoencoders used in the figures. The suggestion is concrete, as it specifies what needs to be changed and how to make the figures more informative. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" While it does not explicitly mention which figures are being referred to, the authors can infer that it pertains to figures related to the use of autoencoders in the paper. The comment is specific in suggesting a clearer labeling of the types of autoencoders used, which helps the authors understand what needs to be addressed. However, the lack of explicit mention of specific figures makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" This is a logical suggestion based on the reviewer\"s understanding of the terminology and the types of autoencoders used in the paper. However, the comment does not provide specific examples or references to support the claim that this change would make the figures clearer. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. It suggests that specifying \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders\" would make the figures clearer. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and precision of their figures. By addressing this suggestion, the authors can improve the comprehensibility of their work for readers. Therefore, the comment is rated as 5, as it offers a concrete and valuable piece of advice for enhancing the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple suggestions for the authors to include comparisons with specific methods, such as NeRFbased methods like Zero1to3 and pointe. It also recommends removing the occlusion experiment as it does not seem relevant to the proposed method. While the suggestions are explicit, they do not provide detailed guidance on how to implement these changes or why they are important. The authors are given a clear direction to follow but may need to infer the exact steps to take, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific comparisons, such as with NeRFbased methods like Zero1to3 and pointe, and it also questions the relevance of the occlusion experiment. This provides clear guidance on what parts of the paper need attention and what specific comparisons or changes are recommended. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several suggestions for the authors to include comparisons with specific methods, such as NeRFbased methods like Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it does not seem to propose anything specific to occlusion. However, the comment lacks detailed reasoning or evidence to support why these comparisons are necessary or why the occlusion experiment is irrelevant. The suggestions are based on the reviewer\"s personal opinion or preferences, which may not be universally accepted. Therefore, the claim is 3, as it provides some basis for the suggestions but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should include comparisons with NeRFbased methods, such as Zero1to3 and pointe, which could enhance the paper\"s comprehensiveness and relevance. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it may not be aligned with the proposed method\"s focus. This feedback is clear and provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance on how to conduct these comparisons or why they are important. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful, which is an explicit action for the authors to take. However, it does not specify what aspects of \"multiaspect\" need to be explained or how this explanation should be integrated into the text. The comment also mentions a specific issue with Figure 1, suggesting that the subscripts s and t should be 1 and 2, respectively. While this part is explicit, the overall comment lacks detailed guidance on how to address the explanation of \"multiaspect\" and the correction in Figure 1. Therefore, the comment is 3, as it provides a clear direction for the authors to improve their draft but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, a brief explanation of \"multiaspect\" and a correction in Figure 1 regarding the subscripts s and t. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful, and it mentions a specific issue with Figure 1 regarding the subscripts s and t. However, the comment does not provide any reasoning or evidence to support why these explanations are necessary or how they would improve the paper. The suggestion to correct the subscripts is specific but lacks context or justification for why this correction is important. Therefore, the comment is considered 2, as it provides some guidance but lacks detailed reasoning or evidence to fully support the claim.", "helpfulness_rationale": "The review comment is 3 as it identifies two specific areas for improvement. First, it suggests that a brief explanation of \"multiaspect\" would be beneficial, which could enhance the clarity of the paper. This is a clear and actionable suggestion that provides the authors with a specific area to address. Second, the comment points out a specific issue with Figure 1, noting that the subscripts s and t should be corrected to 1 and 2, respectively. This feedback is clear and actionable, as it provides a direct correction that the authors can implement to improve the accuracy of their figures. However, the comment could be more helpful if it offered additional guidance on how to explain \"multiaspect\" or suggested ways to enhance the clarity of the explanation. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. While the comment implies that a more detailed analysis is needed, it does not explicitly instruct the authors to provide this information. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the extraction process, but the comment does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the parts of sentences and documents are extracted and whether the rules of extraction affect the experiment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the extraction of parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the extraction process more thoroughly, but it does not offer actionable steps or detailed analysis. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide information about the computational requirements of the experiments, including the time taken and the hardware used. This request is clear and direct, giving the authors a specific action to take in terms of providing additional details about the computational aspects of their work. The comment is explicit and concrete, as it directly instructs the authors on what information to include, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the computation required to implement the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the time taken for the experiments and the hardware used, providing clear guidance on what additional details are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements of the experiments, specifically asking for details on the time taken and the hardware used. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide additional information about the computational requirements of their experiments. This includes details on the time taken for the experiments and the hardware used. By addressing this request, the authors can provide more context and transparency about their experimental setup, which is valuable for readers and reviewers. However, the comment could be more helpful if it suggested specific ways to present this information or highlighted the importance of this information for the readers. Overall, the comment is 4 as it directs the authors to include important details that enhance the comprehensiveness of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The comment implies that the authors should provide more discussion on this aspect and specify when the meta sampler is applied (i.e., at which epoch). While the action is implicit, it is clear and concrete, as it specifies what additional information the authors need to include. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a specific part of the paper where this information should be addressed. However, the comment does not explicitly mention a section or provide a specific reference, making it weakly grounded. The question is specific in its inquiry about the decoupled application and the timing of the meta sampler\"s use. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The reviewer asks for more discussion on this and when the meta sampler is applied. However, the comment does not provide any evidence, reasoning, or references to support the claim that the meta sampler is only used in a decoupled way. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the authors\" approach to applying the meta sampler, particularly whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a need for more discussion on this aspect. While the comment identifies a potential area for clarification, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests that the authors use related fairnessaware metrics like Equality Odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. The comment also provides a specific reference, the AAAI paper cited, which guides the authors on how to proceed with their experiments. This level of detail and directness makes the actions concrete and actionable, allowing the authors to clearly understand what changes are needed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the use of a \"vanilla metric\" defined by the authors and suggests the inclusion of fairnessaware metrics like Equality Odds (EO). It also recommends conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper for guidance. However, the comment does not specify which part of the paper discusses the vanilla metric or the experiments, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that require attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack related fairnessaware metrics like Equality Odds (EO) and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are necessary or how they would improve the study. The mention of a specific AAAI paper for guidance is a positive aspect, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides some direction but lacks comprehensive justification and examples.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper by noting the lack of fairnessaware metrics like Equality Odds (EO) and suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption. It provides a clear direction for improvement by referencing a specific AAAI paper that the authors have cited, which could serve as a guide for their experiments. This feedback is actionable and provides the authors with a clear path to enhance their work by incorporating relevant metrics and datasets. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific aspects of the experiments should be focused on. Overall, the comment is 4, as it effectively directs the authors towards improving their draft by addressing a significant gap in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the content in lines 107114 is speculative or overly opinionated and suggests that it should be stated as a remark, an aside in the Discussion section, or removed. This provides a clear and direct action for the authors to take, specifying the exact changes needed to address the issue. The feedback is explicit and concrete, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the content, suggesting that it should be stated as a remark, an aside in the Discussion section, or removed. This provides clear guidance on how to address the concern, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the content in lines 107114 is speculative or overly opinionated and suggests it should be stated as a remark, an aside in the Discussion section, or removed. However, the comment does not provide specific examples or reasoning to support why this content is speculative or opinionated, nor does it explain why it should be removed or repositioned. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the content in lines 107114, noting that it seems speculative or overly opinionated. It provides actionable feedback by suggesting that this content should be stated as a remark, an aside in the Discussion section, or removed. This guidance helps the authors understand how to improve the clarity and presentation of their work, making the comment 4. However, it could be more helpful if it provided additional context or examples of what constitutes speculative or opinionated content. Overall, the feedback is clear and actionable, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines to validate their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. The authors can infer that it pertains to the discussion or results sections, but this inference is not explicit. The comment is specific in its suggestion to include these baselines for verification, but it lacks grounding as it does not mention specific sections or experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, the comment does not provide any specific reasoning or evidence to support why these baselines are relevant or how they would improve the verification process. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. This feedback is 3 as it provides a specific suggestion for additional experiments that could enhance the validation of the results. However, the comment lacks depth and does not offer detailed guidance on how to implement these baselines or what specific aspects of the results should be compared. To be more helpful, the comment could include more detailed reasoning or examples of how these baselines would contribute to the analysis. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks the value of the neighborhood size h and an analysis of its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and direct, giving the authors a specific action to take: to include the value of h and analyze its influence, as well as to provide insights into performance variations with a constant set of parameters. The suggestion is concrete, as it outlines what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, such as the need for an analysis of the robustness of the method with respect to larger or smaller neighborhoods. Additionally, it points out the use of different hyperparameter sets per dataset, which is not ideal, and suggests that the authors provide insights into performance variations with a constant set of parameters. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks the value of the neighborhood size h and an analysis of its influence on the model\"s performance. It also notes that different hyperparameter sets are used per dataset, which is not ideal. The comment provides a logical reasoning by stating that the value of h is a key parameter of the proposed strategy and that providing readers with an understanding of its influence is essential. However, the comment lacks specific examples or references to support the claim about the use of different hyperparameter sets per dataset. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it provides a basis for the claim but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two critical areas for improvement in the paper: the lack of information on the value of the neighborhood size h and an analysis of its influence on the model\"s performance. It also points out the use of different hyperparameter sets per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters, which is a valuable suggestion for improving the robustness and generalizability of the proposed strategy. This feedback is clear and actionable, offering specific guidance on what the authors need to address to enhance their draft. However, the comment could be more helpful if it provided examples or detailed suggestions on how to analyze the influence of h or how to achieve a constant set of parameters. Overall, the comment is 4, as it directs the authors to important areas for improvement and provides a solid foundation for enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of missing data on the model and its ability to leverage additional modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the issue of missing data and its potential impact on the model, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or examples, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It prompts the authors to consider whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. This question is relevant and could lead to valuable insights into the robustness and generalizability of the model. However, the comment does not provide specific guidance or suggestions on how the authors might explore or address this issue, such as through additional experiments or analyses. While it identifies a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is explicit and concrete, as it clearly outlines what information should be included and how it should be presented. The authors are given a direct action to take, which is to include these statistics in their analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely, to show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This provides a clear direction for the authors to enhance their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This is a logical suggestion based on the observation that the SST dataset has phraselevel annotations. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this suggestion based on the context of the paper, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. By including these statistics, the authors can better demonstrate the effectiveness of their approach and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is 4 as it offers a clear and actionable improvement to the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of verification of the stability of the OGEAug on OOD benchmarks, specifically on the DrugOOD dataset, where SPE is validated. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to verify the stability. The comment implies that the authors should conduct additional experiments or analyses to assess the stability of OGEAug on DrugOOD, but it does not offer concrete instructions or suggestions on how to implement these steps. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of verification of the stability of the OGEAug on OOD benchmarks, particularly on the DrugOOD dataset. It specifies that the authors should address this by validating the stability of their method on this dataset, where SPE is already validated. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the verification of stability on DrugOOD. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of their method, OGEAug, on OOD benchmarks such as DrugOOD, where another method, SPE, is validated. However, the comment does not provide specific examples or detailed reasoning to support why this is a concern or how it affects the paper\"s claims. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the authors\" work could be improved, namely the lack of verification of the stability of their method, OGEAug, on outofdistribution (OOD) benchmarks such as DrugOOD. It highlights that another method, SPE, is validated on this dataset, suggesting that the authors should conduct similar evaluations to ensure the robustness of their approach. However, the comment does not provide detailed guidance on how to perform these evaluations or what specific aspects should be considered, leaving the authors with a general direction but without actionable steps. This makes the comment 3, as it points out a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. While the comment implies that these methods are natural to consider and could provide valuable experimental comparisons, it does not explicitly instruct the authors to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or methodology, but this inference is not explicit. The comment is specific in suggesting alternative methods that could be explored, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. This is a suggestion for further exploration rather than a claim. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. This feedback is 3 as it provides a direction for the authors to explore additional techniques that could enhance their work. However, the comment lacks specific guidance on how to implement these suggestions or what benefits they might offer, which limits its usefulness. The authors are given a direction for improvement but need more detailed information to fully act on the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their approach to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, specifying what needs to be added or improved in the related work section. The comment is explicit and concrete, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, but without explicit references to the related work section, the authors may find it challenging to pinpoint the exact area needing expansion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not provide any specific examples or references to support the claim that such comparisons are necessary or beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the approach to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for the authors to enhance their paper by including relevant comparisons. However, the comment could be more helpful if it provided examples of strong baselines or detailed guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments in the paper should be expanded to include multiple seed experiments, which would provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The suggestion is concrete, as it specifies the type of experiments that should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Single Seed Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, which are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests a solution by recommending multiple seed experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. While the claim is logical and makes sense, it lacks specific examples or references to support the assertion that multiple seed experiments would indeed provide a more robust evaluation. This makes the claim 3, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it points out a critical area for improvement and offers a specific suggestion for enhancing the experimental methodology. By addressing this feedback, the authors can strengthen the validity and reliability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether they should explain their choice, provide alternative distributions, or clarify the rationale behind their selection. Without specific suggestions or actions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions or provides context for the question. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the motivation behind the choice of distributions, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these distributions are unclear or inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It questions the motivation behind this selection, which is a crucial aspect of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but lacks actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggestions for alternative approaches that could make the method more accessible. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the accessibility challenge but lacks grounding, as the authors cannot confidently determine which section of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts the accessibility of the method. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential accessibility issue with the proposed method, noting that it requires an entire multiGPU setup for optimizations. This observation is relevant and could be helpful for the authors to consider when discussing the practical implications of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make their method more accessible. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there is a missing citation for the public skipgram data set in line 425. This provides a clear and direct action for the authors to take, which is to include the necessary citation. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing citation for the public skipgram data set. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement that identifies a missing citation for a public skipgram data set in line 425. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, namely the missing citation for the public skipgram data set in line 425. This is a clear and actionable feedback that helps the authors correct an oversight in their paper. By pointing out this omission, the comment provides a direct path for the authors to improve the accuracy and completeness of their references. However, the comment could be more helpful if it offered additional guidance on how to find or cite the appropriate data set. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref[2] as a strong baseline for performance comparison. While the comment provides explicit suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions or what specific aspects to focus on when comparing the systems. The authors are given a clear direction but may need to infer the exact steps to take, making the comment 4.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref[2] as a strong baseline for performance comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to compare with another system and use Ref[2] as a baseline, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref[2] as a strong baseline for performance comparison. While the suggestion to compare with another system is logical, the comment lacks specific details or evidence to support why this comparison is necessary or how it would enhance the paper. The mention of Ref[2] as a baseline provides some context, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a suggestion but lacks comprehensive justification or evidence.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref[2] as a strong baseline for performance comparison. This feedback is clear and actionable, providing the authors with specific steps to enhance their work by including additional comparisons and baselines. By following this suggestion, the authors can improve the robustness and comprehensiveness of their study. However, the comment could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific aspects to focus on when using Ref[2] as a baseline. Overall, the comment is 4, as it offers clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on how the quantitative results are obtained, specifically questioning what data is used for training, validating, and testing. This request provides a clear and direct action for the authors to take, which is to provide more detailed information about the data used in their experiments. The comment is explicit and concrete, giving the authors a straightforward path to improve their draft by addressing this gap in clarity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"quantitative results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how quantitative results are obtained, specifically asking for details on the data used for training, validating, and testing. This is a factual inquiry seeking clarification, not an opinion or claim. It does not require verification as it is a request for information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the quantitative results in the paper. It questions the clarity of how these results are obtained, specifically asking for details on the data used for training, validating, and testing. This feedback is clear and actionable, as it provides a direct request for additional information that could enhance the transparency and reproducibility of the results. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to clarify this aspect. Overall, the comment is 4 as it guides the authors toward improving the clarity of their results section, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions might be at fault. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what assumptions might not be satisfied or what learning difficulties are present. Without clear grounding or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties, but it does not provide any specific details or guidance on how to address these issues. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to explain how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what has been achieved. This feedback is clear and direct, providing a concrete action for the authors to take. The comment also includes a reference to a related work, which could guide the authors in their explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SE framework\" and references a specific work by Luo et al. (2020), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly requests a detailed explanation of how the SE framework can help improve the work, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" explanation of how the SE framework can help improve their work, suggesting that it lacks depth and requires a more detailed justification. The comment references a specific work by Luo et al. (2020) as a potential source of inspiration or comparison, which could provide a basis for the authors to expand their explanation. However, the comment does not fully explain why the reference is relevant or how it could be used to enhance the authors\" argument. While the reference is a step in the right direction, the lack of detailed reasoning or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the lack of explanation of how the SE framework can help improve the work. It provides a clear and actionable suggestion for the authors to include a detailed explanation of the benefits and mechanisms of the SE framework. By referencing a related work, the comment offers a potential direction for the authors to explore and expand upon. However, the comment could be more helpful if it provided specific examples or guidance on how to structure this explanation. Overall, the feedback is clear and actionable, but it could be further enhanced with more detailed suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what steps they should consider to improve the generalizability of their approach. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach are limited to two views or how the generalizability to more views could be improved. Without clear grounding or specific guidance, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without too much difficulty. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without too much difficulty. This feedback is 3 as it points out a potential area for improvement in the generalizability of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance the generalizability of their system. To be more helpful, the comment could provide examples of how other systems have successfully generalized to multiple views or offer suggestions on how to adapt the current approach to accommodate more views. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not fully guide the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It suggests that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or whether they should consider alternative metrics. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not specify which part of the paper discusses these metrics or where the authors might need to address this limitation. This makes it difficult for the authors to pinpoint the exact sections that need revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, specifically loss after switch and recovery time after switch, may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. This feedback is 3 as it highlights an area that the authors might need to consider when evaluating their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or explore alternative metrics. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the user decoder\"s information usage, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify this question or suggest why this might be problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. This question highlights a potential gap in the paper\"s methodology or explanation, prompting the authors to clarify or justify their approach. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the discussion on the hyperparameter gamma is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment specifies what needs to be addressed, making it 5. The authors know exactly what information is missing and how to improve their draft by adding this discussion. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the discussion on arbitrary hyperparameter \u03b3,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely, the discussion on how to set the hyperparameter in practice for a given graph and analyzing its sensitivity. This provides clear guidance on what needs to be included, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the hyperparameter gamma is missing, which would make it difficult for researchers to follow. However, the comment does not provide any specific examples, reasoning, or references to support why this is a significant issue or how it affects the paper\"s comprehensibility. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the discussion on the hyperparameter gamma. It points out that this omission makes it difficult for researchers to follow the work, as it is crucial for understanding the practical application and sensitivity of the hyperparameter. By highlighting this gap, the comment provides clear and actionable feedback, encouraging the authors to include a discussion on setting the hyperparameter and analyzing its sensitivity. This feedback is valuable as it directs the authors to a specific area that needs improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of similar analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement this suggestion or specify how to design the controlled baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of different locations (layers) of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting ICL performance when ablating these heads. It implies that a controlled baseline should be established to ablate heads at different locations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for a controlled baseline to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that location is a confounding factor. The suggestion for a controlled baseline is clear, but the claim itself is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the model\"s performance, specifically the location of induction heads and FV heads within the model. It suggests that a controlled baseline should be established to ablate heads at different locations, which could help clarify the impact of these factors on ICL performance. This feedback is clear and actionable, providing the authors with a specific direction for improving their analysis and experimental design. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or discussed the potential implications of this approach. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under the similarity measurement section, specifying that it should describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, namely to include a section on synonym identification that explains the approach to the multiplechoice task. The comment is explicit and concrete, offering a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"a section on synonym identification\" and specifies that it is missing under the \"similarity measurement\" section. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a section on synonym identification that explains the approach to the multiplechoice task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, specifically regarding the multiplechoice task. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence affects the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the significance of the missing section. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of a section on synonym identification under the similarity measurement section. It specifies that this section should describe how the multiplechoice task is approached, providing a clear and actionable suggestion for improvement. By highlighting this omission, the comment helps the authors understand where their draft needs to be strengthened, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to structure this section. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the comment implies that such an overview would be beneficial, it does not explicitly instruct the authors to include it or provide specific guidance on how to structure this overview. The action is implicit and somewhat vague, as the authors can infer the need for an overview but may not know how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, making it weakly grounded. The comment is specific in its suggestion that an overview would be beneficial, but without explicit references to sections or parts of the paper, the authors may struggle to identify where to incorporate this overview. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to structure or present this overview. The authors may find it challenging to implement this suggestion without additional context or examples. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The reviewer suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem and highlights areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to address these concerns but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its potential impact, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors may find it challenging to address the issue without additional context or examples. Therefore, the comment is 3, as it provides a logical argument but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing process, specifically noting the need to know the statistical dimension d_lambda of the design matrix A. It points out that accurately computing this dimension would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment highlights that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment raises an important point about the limitations of the approach, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a potential weakness but does not provide detailed actionable advice, leaving the authors to infer the necessary steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3, stating that the expected quantities are scalars but are currently shown as a vector. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are currently shown as a vector. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 should be redefined because the expected quantities are scalars but are currently shown as a vector. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the redefinition of Figure 3. It identifies a particular issue with the figure, noting that the expected quantities are scalars but are currently shown as a vector. This feedback is clear and directly addresses a potential confusion or misrepresentation in the figure, offering a straightforward way for the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided additional context or guidance on how to redefine the figure to better align with the expected quantities. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific guidance on what aspects of the experimental setup need improvement or how to address these questions. The comment lacks explicit instructions or concrete details on how to enhance the experimental setup, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not specify which part of the paper these ablation experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestion that the experiments deserve better setup, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, the comment does not provide specific examples or reasoning to support why the current setup is inadequate or what improvements are needed. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific details or examples of what these questions are or how the experimental setup could be improved. This lack of specificity and actionable guidance makes it difficult for the authors to address the feedback effectively. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps or suggestions for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment implies that the authors should provide empirical evidence and clarify their explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence and clarify their explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about the usefulness of the proposed models for learning representations for lowfrequency words. It highlights the lack of empirical evidence to support this claim and suggests that the authors should provide such evidence. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion of the models\" utility and the results presented in the paper. The authors can infer that it relates to the sections discussing the models and their performance. However, the comment lacks specificity in detailing exactly what needs to be addressed or improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide such evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Additionally, the comment mentions that the explanation of improvements is not clear, particularly regarding the word similarity data sets, but it does not provide detailed feedback on how to improve this aspect. Therefore, the claim is 3, as it highlights a gap in the paper\"s evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide such evidence, which is a clear and actionable suggestion. Additionally, the comment notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets, which contain frequent word pairs. This feedback is 3 as it points out specific areas where the paper could be improved, but it could be more helpful if it provided more detailed guidance or examples on how to address these issues. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment also mentions a specific scenario where the resolution is reduced to 1x1x1, which is equivalent to using a single global feature. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the comparison themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the resolution of the 3D voxel and its impact on the computational and memory cost of the network. The comment suggests a comparison with different resolutions of voxel features to study the importance of the global feature. The mention of a specific scenario where the resolution is reduced to 1x1x1 provides a clear example of the proposed comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment provides a logical reasoning by pointing out that reducing the resolution to 1x1x1 is equivalent to using a single global feature. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to conduct additional research or experimentation to fully address the suggestion, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment provides a specific scenario where the resolution is reduced to 1x1x1, which is equivalent to using a single global feature. This feedback is clear and actionable, as it guides the authors to conduct a more comprehensive analysis of the global feature\"s importance. However, the comment could be more helpful if it included specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear direction for further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing, and it suggests that other researchers need to know which cases the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis on the movie dataset. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of an error analysis on the movie dataset to provide information on cases where the model fails. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual statement rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of an error analysis on the movie dataset. It highlights the importance of providing this information, as it would help other researchers understand the cases where the model fails. This feedback is clear and actionable, as it directs the authors to include an error analysis to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to conduct or present the error analysis. Overall, the comment is 4 as it points out a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment implies that the authors should investigate and present these trends, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to explore and present development set trends, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in discerning trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment identifies a potential issue with the table, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to explore development set trends is a logical extension of the observation but is not explicitly supported by evidence or references. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This feedback is clear and actionable, as it directs the authors to investigate and present trends in a way that could enhance the interpretability and utility of their results. However, the comment could be more helpful if it provided additional guidance on how to present these trends or what specific aspects should be focused on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the difficulty in understanding Figure 5 due to the clutter of lines. It suggests that the authors could report additional metrics like flops or model size to make the figure more concrete and easier to interpret. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the clarity of their figure and the report, ensuring a direct path to enhancing the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the difficulty in understanding the figure due to the clutter of lines and suggests reporting additional metrics like flops or model size to make the figure more concrete. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the clutter of lines, and suggests reporting additional metrics like flops or model size to make the figure more concrete. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to report additional metrics is a logical step to improve clarity, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the clutter of lines. It provides a clear suggestion for improvement by recommending that the authors report additional metrics such as flops or model size to make the figure more concrete and easier to interpret. This feedback is actionable and provides a direct path for the authors to enhance the clarity and comprehensiveness of their figure. However, the comment could be more helpful if it included specific examples of how these additional metrics could be incorporated or how they might improve the figure. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that some details of the proposed method are missing, but it does not provide specific guidance on what these details are or how they should be addressed. The comment mentions \"questions section below,\" which implies that the authors should refer to that section for more information, but it does not explicitly instruct the authors to do so. The lack of specific details or instructions makes it difficult for the authors to know exactly what needs to be added or clarified. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some details of the proposed method are missing,\" but it does not specify which part of the paper these details are missing from. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in noting that details are missing, but without explicit references, it is weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, but it does not provide any specific examples or reasoning to support this claim. Without detailed information or references, the authors may find it challenging to understand what specific details are missing and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting that some details of the proposed method are missing. However, it does not provide any further context, examples, or suggestions on what these details might be or how they could be addressed. This lack of specificity and guidance makes it difficult for the authors to understand the nature of the missing details and how to improve their draft. As a result, the comment is 2, as it provides a general observation but does not offer actionable feedback. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides specific recommendations to simplify the description and improve the explanation of the architecture and computations. The comment suggests reducing Figure 7, Section 8, and lines 3964 to gain more space. These actions are clear and concrete, giving the authors a specific direction on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of the paper being too dense and difficult to follow, suggesting simplification and better explanation of the architecture and computations. It specifically mentions Figure 7, Section 8, and lines 3964 as areas that can be reduced to gain more space. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed in these sections, such as simplifying the description and improving the explanation of the architecture and computations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and improving the explanation of the architecture and computations. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is too dense or difficult to follow. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides specific recommendations for improvement, such as simplifying the description and explaining the architecture and computations better. The comment highlights specific sections, including Figure 7, Section 8, and lines 3964, suggesting that these areas can be reduced to gain more space. This feedback is clear and actionable, offering the authors a concrete path to improve the clarity and accessibility of their draft. However, the comment could be more helpful if it provided additional guidance on how to simplify the content or suggested specific changes to make the paper more readable. Overall, the comment is 4, as it provides valuable insights and actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate the EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that address oversmoothing, like the setting used in GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this evaluation in their study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the EIGNN with respect to oversmoothing under standard settings on realworld datasets, comparing it with variants that address oversmoothing, such as the setting used in GCNII. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate oversmoothing and compare with existing methods, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the EIGNN with respect to oversmoothing under standard settings on realworld datasets, comparing it with variants that address oversmoothing, such as the setting used in GCNII. While the comment implies that such an evaluation would be interesting, it does not provide specific reasoning or evidence to support why this evaluation is necessary or how it would contribute to the paper. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for evaluating the EIGNN by comparing it with variants that address oversmoothing, such as the setting used in GCNII. This feedback provides a specific and actionable suggestion for enhancing the evaluation section of the paper, offering a potential area for improvement. By including this comparison, the authors could demonstrate the effectiveness of their model in addressing oversmoothing, which is a critical issue in graph neural networks. However, the comment could be more helpful if it included specific examples or references to the GCNII setting, which would further guide the authors in implementing the suggested evaluation. Overall, the comment is 4 as it identifies a valuable direction for enhancing the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to include such a section or subsection in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of such a section or subsection. By addressing this feedback, the authors can enhance the clarity and completeness of their approach, making the comment 4. However, it could be more helpful if it offered additional guidance on how to structure this section or what specific details should be included. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 is confusing and lacks clarity regarding the meaning of the columns. It specifies that the issue is not addressed in either the text or the caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in Figure 4. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by noting that the meaning of the columns is not clear and is not explained in the text or caption. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, and this is not explained in the text or caption. This is a factual observation rather than a subjective claim or suggestion, as it does not express an opinion or require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing because the meaning of the columns is not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the content of the figure, which is essential for improving the clarity and understanding of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify the figure, such as adding a detailed caption or explaining the columns in the text. Despite this, the feedback is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions whether the conclusion drawn from the Streetview experiment is valid, suggesting that MaxGapTop2UCB might be better than other methods. Second, it points out that the realworld applications of the new problem setting are not clear, particularly regarding the applicability to sorting/ranking and the computational complexity of the proposed algorithms. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes. The authors are left to infer that they need to clarify the conclusions and provide more detailed explanations of the computational complexity. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete instructions on how to implement them.", "grounding_specificity_rationale": "The comment addresses two main points: the discussion of experiment results and the clarity of realworld applications. It raises questions about the conclusions drawn from the Streetview experiment and the computational complexity of the proposed algorithms. However, it does not specify which part of the paper these concerns relate to, such as the results section or the discussion section. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in its questions about the conclusions and computational complexity, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the conclusion drawn from the Streetview experiment, suggesting that MaxGapTop2UCB might be better than other methods. This claim is 3 as it provides a logical basis for questioning the conclusion, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Second, it points out the lack of clarity regarding realworld applications, particularly the applicability to sorting/ranking and the computational complexity of the proposed algorithms. This part of the comment is 3 as it identifies a gap in the paper\"s discussion but does not provide specific examples or references to support the claim. Overall, the comment is 4, as it provides some reasoning and examples but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it questions the conclusions drawn from the Streetview experiment, suggesting that the results may not fully support the claim that MaxGapTop2UCB is better than other methods. This feedback prompts the authors to reconsider their conclusions and provide a more nuanced discussion of the results. Second, the comment points out the lack of clarity regarding the realworld applications of the new problem setting, specifically the applicability to sorting/ranking and the computational complexity of the proposed algorithms. It highlights the need for a more detailed explanation of how the proposed algorithms could be applied in practice. While the comment provides valuable insights, it could be more helpful if it offered suggestions on how to address these issues or provided specific examples. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to clarify their discussion, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods. It suggests that more explanations could be provided. While the comment implies that the authors should offer additional explanations, it does not explicitly instruct them to do so or provide specific guidance on what aspects to explain. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be given. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity in terms of what aspects of the explanations are needed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are indeed lower than expected. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be given, implying that the authors should provide additional context or analysis to clarify why the results are lower than expected. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how to address this concern or what additional explanations might be necessary. The feedback is 3 as it points out a potential weakness but does not offer detailed advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of an ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this lack. The action is implicit, as the authors need to infer that they should include an ablation analysis to better understand the performance gains. However, the comment lacks concrete details on how to conduct the analysis or what specific components should be analyzed. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper should include this analysis or provide guidance on how to conduct it. The authors can infer that the main paper is being referred to, but the lack of specific guidance makes it challenging to pinpoint the exact section needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the lack of an ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of an ablation analysis, which makes it difficult to determine the source of the small performance gain. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to improve the clarity and robustness of their results. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation analysis or what specific components should be analyzed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a finding in Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this finding should be addressed or incorporated into the paper. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to Figure 2, providing a specific reference to the part of the paper being addressed, which makes it fully grounded. It also specifies the issue by mentioning the finding that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). This level of detail allows the authors to accurately identify the part of the paper being discussed and understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the findings in Figure 2, which show that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any reasoning, evidence, or references to support the claim that the authors should use \"Th.\" as a result of this finding. Without additional context or justification, the claim remains 1, as it lacks the necessary support to guide the authors in understanding or addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a specific finding from Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, the comment does not provide any actionable feedback or suggestions on how this finding should be addressed or incorporated into the paper. It lacks depth and does not offer guidance on how the authors might use this information to improve their work. As a result, the comment is not helpful, as it does not provide the authors with actionable insights or suggestions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It suggests that comparing the model trained on the original dataset with one trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. The comment implies that the authors should modify their experimental setup to include this comparison, which is a clear and concrete action. However, it does not provide specific guidance on how to implement this change, such as which models or datasets to use. While the action is explicit, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental design, suggesting that the authors should compare the model trained on the original dataset with one trained on a mixture of the original and adversarial examples to better highlight the impact of the augmented adversarial examples. This provides clear guidance on how to improve the experimental setup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not wellverified by the designed experiment, particularly noting that the models in conventional methods are trained on the original training set plus adversarial examples, while the base model is trained only on adversarial examples. The reviewer suggests that comparing the model trained on the original dataset with one trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. This claim is 3 as it provides a logical reasoning for the need to make the experiment more convincing, but it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate this suggestion to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It points out a discrepancy in the training of models, suggesting that comparing the model trained on the original dataset with one trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental design to better support the hypothesis. However, the comment could be more helpful if it offered additional guidance on how to implement this change or if it provided examples of how this could be done. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on what aspects of the experiments are lacking or how they could be improved. Without explicit guidance or concrete steps for the authors to take, the comment lacks actionable information. The authors are left without a clear understanding of what needs to be addressed or how to enhance the convincingness of the experiments. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"CNN experiments,\" but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not precise. The comment is specific in its claim that the CNN experiments are not fully convincing, but it does not provide details on what aspects are lacking or how they could be improved. This lack of specificity makes it difficult for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue or improve the convincingness of the experiments. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the CNN experiments, stating that they are not fully convincing. However, it does not provide any further details or suggestions on what aspects of the experiments are lacking or how they could be improved to enhance their convincingness. Without additional context or guidance, the authors are left without a clear understanding of how to address the issue or improve the experiments. Therefore, the comment is 2, as it highlights a problem but does not offer actionable feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the results for model (3) in Table 1, which are not reported in the paper, should be mentioned if they were computed by the authors themselves. This provides a clear and direct action for the authors to take, which is to include a note about the computation of these results. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the results for model (3) are not reported in the paper and should be mentioned if computed by the authors themselves. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) in Table 1 are not reported in the paper and should be mentioned if computed by the authors themselves. The comment provides a specific example of a missing result, which is \"CsEn,\" and suggests that the authors should include a note about the computation of these results. This claim is supported by logical reasoning and a specific example, making it 4. However, it could be strengthened by providing additional context or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it directs the authors to address a potential oversight in their presentation. By providing a specific example and a clear suggestion for improvement, the comment offers valuable guidance for enhancing the transparency and completeness of the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. This feedback is clear and provides a direct action for the authors to take, namely to give more attention to prompt design and its implications. The comment is concrete, as it specifies the area of focus and the action required, making it 5.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table. While the authors can infer that it relates to the discussion of prompts, the lack of explicit grounding makes it difficult for them to pinpoint the exact area needing attention. The comment is specific in its suggestion to discuss prompt design, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. The claim is 3 as it highlights the importance of prompt design, but it lacks specific examples or detailed reasoning to fully substantiate the need for more emphasis. The authors would need to infer the exact aspects of prompt design that need further attention, such as the criteria for effective prompt design or the potential impact on performance outcomes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, suggesting that more emphasis should be placed on prompt design. It highlights the importance of discussing how to design prompts effectively, given that different prompts can result in varying performance outcomes. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by focusing on prompt design. However, the comment could be more helpful if it offered specific guidance or examples on how to improve prompt design. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the action is explicit, it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. The authors are given a clear direction to follow but are left to infer the exact steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. The authors can infer that it relates to the results section or discussion, but this inference is not explicit. The comment is specific in suggesting a comparison with HateXplain models, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a specific direction for the authors to enhance their work by comparing their results with existing models. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to structure the comparison or what metrics to use for evaluation. Overall, the feedback is 3 as it points out a potential area for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment implies that the authors should consider using the adaptive method, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method and justify its use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use of freezing, making it weakly grounded. The comment is specific in its critique of the methodological choice, suggesting a potential improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be more appropriate or why freezing is problematic. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. This feedback is 3 as it identifies a potential area for improvement in the methodology. However, it lacks depth and does not provide specific guidance on how the authors might implement the adaptive method or why it would be beneficial. To be more helpful, the comment could include suggestions for how to integrate the adaptive method or discuss its advantages over freezing. Therefore, the comment is rated as 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be done, namely, to provide a detailed plan for addressing the limitations, making it 5.", "grounding_specificity_rationale": "The comment addresses the limitations section of the paper, which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the part being addressed. The comment is also specific because it suggests that the authors should provide a more detailed plan on how they plan to address these limitations in their future work. This feedback is clear and actionable, allowing the authors to understand exactly what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment does not provide any specific examples or reasoning to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks sufficiency, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs further development. By addressing this suggestion, the authors can enhance the transparency and feasibility of their future work, making the comment 4. However, it could be more helpful if it provided additional guidance or examples on how to develop this plan. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) that involves adding negation or changing entities in text to test the model\"s robustness. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the suggested analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the robustness of the model, but the lack of explicit reference to a specific section or part of the paper makes it difficult to pinpoint. The comment is specific in suggesting a method for testing robustness, but the lack of grounding makes it challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness. While the comment provides a reference to existing work, it does not offer specific details or examples of how the analysis should be conducted or what aspects of robustness should be tested. This lack of detailed guidance makes the claim 3, as the authors would need to infer the specific steps to take based on the reference provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness by adding negation or changing entities in text. This feedback is 3 as it identifies a potential area for improvement and provides a specific reference for the authors to follow. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the analysis or what specific aspects of robustness should be tested. Overall, the comment provides a clear direction for the authors to enhance their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises two issues: the inconsistency in using p m in the numerator and p c in the denominator in Eq. 3, and the lack of consideration for adding the variance in Alg. 2 for further improvement. It also suggests using \u03bc g instead of \u03bc f for consistency with Eq. However, the comment does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors are left to infer that they need to correct the inconsistency and consider adding the variance, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the use of p m and p c in the equations and suggests adding the variance for further improvement. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises two claims. First, it claims that the use of p m in the numerator and p c in the denominator in Eq. 3 is confusing. This claim is 3 as it points out a potential inconsistency in notation, but it lacks specific reasoning or examples to fully substantiate the claim. Second, the comment suggests that the authors should consider adding the variance in Alg. 2 for further improvement. This suggestion is 3 as it provides a logical reasoning for the addition of variance, but it lacks specific examples or references to support the claim. Overall, the comment is 3 due to the presence of logical reasoning and suggestions for improvement, but it could be strengthened with more detailed justification or references.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the inconsistency in notation in Eq. 3 and the lack of variance consideration in Alg. 2. It provides clear and actionable feedback by pointing out the confusion caused by using different symbols for the same variable and suggesting that the authors consider adding the variance for further improvement. Additionally, it offers a suggestion to use \u03bc g instead of \u03bc f for consistency with Eq. This feedback is detailed and constructive, guiding the authors on how to improve the clarity and completeness of their work. Therefore, the comment is 5, as it provides clear and actionable suggestions for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for a more comprehensive discussion on the computational complexity of the proposal, noting that the paper does not provide a clear explanation for why the additional cost did not lead to significant delays in computation. It also raises a question about whether the proposed approach becomes prohibitive in certain settings. While the comment implies that the authors should provide a more detailed discussion on computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the computational complexity in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"Computational cost\" aspect of the paper, specifically mentioning that the paper does not provide a clear explanation for why the additional cost did not lead to significant delays in computation. It also raises a question about whether the proposed approach becomes prohibitive in some settings. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion on computational complexity. The comment is specific in detailing what needs to be addressed regarding the computational complexity of the proposal. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational complexity of the proposed approach, noting that the paper does not provide a clear explanation for why the additional cost did not lead to significant delays in computation. The reviewer suggests that the paper deserves a more comprehensive discussion on computational complexity and questions whether the proposed approach becomes prohibitive in some settings. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the computational complexity is not adequately addressed. The reasoning is somewhat vague, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement regarding the discussion of computational cost in the paper. It points out that while the paper mentions the additional cost, it does not provide a clear explanation for why this cost did not lead to significant delays in computation. The reviewer suggests that a more comprehensive discussion on computational complexity is warranted, which is a valuable insight for the authors to consider. Additionally, the comment raises a question about whether the proposed approach becomes prohibitive in some settings, which could lead the authors to explore the practical implications of their work. While the comment provides some guidance, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that needs further exploration and explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide more explanation on how novel values in the test set are handled. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the clarity of the paper. The comment is concrete, as it directly instructs the authors to provide more explanation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more explanation on how novel values in the test set are handled. This provides clear guidance on what the authors need to do to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more explanation on how novel values in the test set are handled. This is a clear and actionable suggestion that can help the authors clarify their methodology and improve the clarity of their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to handle novel values in the test set. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar methods have been proposed for multitask learning and suggests that they have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Similar methods have already been proposed for multitask learning,\" but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what specific aspects of the paper need to be addressed or how the authors should incorporate the mentioned methods. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that similar methods have been proposed for multitask learning but are not discussed in the paper. However, it does not provide any specific references or examples of these methods, nor does it explain why their inclusion would be beneficial or how it relates to the current work. Without detailed evidence or reasoning, the claim remains 1, as the authors are left without guidance on how to address the issue or what specific aspects of the paper need improvement. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out that similar methods have been proposed for multitask learning but are not discussed in the paper. This observation highlights a potential gap in the literature review or discussion section, suggesting that the authors may need to include these methods to provide a comprehensive overview of the field. However, the comment does not provide specific guidance on which methods to include or how they should be integrated into the paper. While it identifies an area for improvement, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion to conduct a comparison or provide details on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the experimental results or methodology sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost should be compared or how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the comment provides a potential solution, it lacks explicit instructions on how the authors should implement this suggestion or address the confusion in the writing. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to resolve the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses issues 1) and 2) and suggests using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these issues are found in, making it weakly grounded. The comment is specific in suggesting a solution to the issues, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as shown in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the suggestion is logical and supported by the reference to Figure 3, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the confusion in the writing. This makes the claim 3, as it provides a potential solution but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two issues (1) and (2) that can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. This provides a clear and actionable suggestion for improvement, offering a potential solution to the problems mentioned. However, the comment also notes that the writing is confusing, which is a separate issue that needs to be addressed. While the suggestion is helpful, the comment could be more comprehensive by providing specific examples or guidance on how to clarify the writing. Overall, the comment is 4 as it offers a clear direction for improvement but could be more detailed in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the choice of 0.6 for glove embedding similarity and the potential impact of this decision. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should explore alternative loss functions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 0.6 for glove embedding similarity and the potential impact of this decision. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. However, the comment does not specify which part of the paper this relates to, making it weakly grounded. The authors can infer that it pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, such as the choice of similarity threshold and the exploration of alternative loss functions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and suggestions for improvement regarding the choice of 0.6 for glove embedding similarity and the potential impact of this decision. It also suggests exploring other influential losses, such as replacing the min with a mean or NDCG. While the comment identifies areas for further exploration and improvement, it lacks specific guidance or detailed suggestions on how to implement these changes. The authors are left with a general understanding of what needs to be addressed but without actionable steps to take. Therefore, the comment is 3, as it provides some insight but does not fully guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a missing aspect in the paper, specifically the lack of indepth analysis on experimental results. It questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct a more detailed analysis of the experimental results, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment highlights a missing aspect in the paper, specifically the lack of indepth analysis on experimental results. It questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing what is missing, namely an indepth analysis of the experimental results, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis on experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an indepth analysis of experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is valuable as it highlights an area where the authors can provide more detailed explanations or analyses to enhance the comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions for the authors to consider, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. However, the comment does not provide specific guidance on how to implement these suggestions or what constitutes an appropriate number of convolutional layers. While the actions are explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. However, it does not specify which part of the paper these suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its suggestions but lacks grounding, as it does not reference any specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a specific approach for training on labeled data and incorporating input mask explanation annotations for a few examples. It also recommends using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. However, the comment does not provide any justification or evidence for why these suggestions would be effective or why the current approach is insufficient. The claim that \"3 conv layers is definitely too small for anything nonsynthetic\" is a subjective observation without supporting evidence or references. Additionally, the reviewer expresses skepticism about the effectiveness of the proposed approach, but this skepticism is not substantiated with specific examples or references. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper, such as training on labeled data and incorporating input mask explanation annotations for a few examples. It also recommends using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete and actionable suggestion. However, the comment lacks depth and does not explain why these changes are necessary or how they might impact the results. Additionally, the reviewer expresses skepticism about the effectiveness of the proposed approach, which could be helpful if it were supported with evidence or examples. Overall, the comment is 4 as it offers actionable advice but could be more comprehensive with additional context and reasoning."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to achieve this. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of hyperparameters and suggests that the baseline should be fully tuned with the same resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in its suggestion to ensure a fair comparison, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that this is an important consideration, it does not provide specific reasoning or evidence to support why this is necessary. The claim is 3 as it highlights a potential issue with the comparison, but it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search conducted for the proposed method. It suggests that the baseline should also be fully tuned with the same resources as the proposed method for a fair comparison. This feedback is 3 as it points out a critical aspect that could affect the validity of the results. However, the comment lacks specific guidance on how to achieve this or what resources should be considered, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a discrepancy in the definition of perplexity, stating that it is not what perplexity is and that Eq1 does not resemble perplexity. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should correct this misunderstanding or clarify the definition of perplexity. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity, noting that it is not what perplexity is and that Eq1 does not resemble perplexity. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements about the definitions of perplexity and crossentropy, which are clear and accurate. However, it does not provide any additional context, reasoning, or references to support the claim that Eq1 does not resemble perplexity. While the statements are correct, the lack of supporting evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the definition of perplexity, pointing out that the explanation provided in the text does not accurately describe what perplexity is. It also notes that Eq1 does not resemble perplexity, suggesting that it might be a different measure, such as crossentropy. This feedback is 3 as it highlights a potential confusion in the paper\"s explanation of perplexity, which could be clarified by the authors. However, the comment could be more helpful if it provided suggestions on how to correct the misunderstanding or offered a clearer explanation of perplexity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action that provides specific guidance on what needs to be done to improve the paper. The comment is 5 because it gives the authors a clear path forward in addressing the issue of insufficient baseline comparison in the graph classification task.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and specifies the issue with the lack of sufficient baselines, such as MVGRL[4] and gptgnn[5]. This provides clear guidance on which part of the paper needs attention. The comment is also specific because it suggests adding more baselines of graph contrastive learning and testing them on common datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline comparison in the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gptgnn[5]. The reviewer suggests adding more baselines of graph contrastive learning and testing them on common datasets. While the comment identifies a potential issue with the baseline comparison, it lacks specific examples or references to support the claim that these particular baselines are essential or that their inclusion would significantly improve the study. The suggestion to add more baselines is a logical one, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the baseline comparison in the graph classification task, noting that the current baseline is insufficient. It suggests adding more baselines of graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a specific direction to improve their study by expanding the baseline comparison. However, the comment could be more helpful if it offered additional guidance on which specific baselines to consider or how to effectively test them. Despite this, the feedback is 4 as it directs the authors to a clear area for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a major concern regarding the evaluation of the proposed strategies, specifically the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. While the comment identifies a critical issue, it does not provide explicit guidance on how the authors should address this concern. The suggestion to evaluate the defense against such an attack is implicit and lacks concrete details on how to implement this evaluation. The authors are left with a general understanding of what needs to be done but without specific instructions on how to carry out the evaluation. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the evaluation of the proposed strategies, particularly the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the evaluation against an adversarial attack that minimally alters the edge map. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically regarding the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. The comment provides a logical reasoning by suggesting that the current evaluation does not fully address the robustness of the defense against such attacks. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the suggested evaluation, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the evaluation of the proposed strategies, specifically the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. This is a significant point that highlights a potential weakness in the current evaluation framework. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to consider a more comprehensive evaluation that aligns with common practices in the field. By addressing this feedback, the authors can enhance the robustness and validity of their defense strategies. However, the comment could be more helpful if it offered specific guidance on how to implement this evaluation or examples of similar approaches. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends of Tables 1, 2, and 3 longer and to clarify whether the numbers represent % errors or % correct (assuming MNIST and CIFAR are the respective datasets). This feedback is clear and direct, providing specific guidance on how to improve the clarity of the tables. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the legends, requesting that they be longer and clarifying whether the numbers represent % errors or % correct. This provides clear guidance on what needs to be addressed in these tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends of Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct. This is a factual observation rather than a claim or suggestion that requires verification. It is a straightforward request for clarification, which does not require evidence or justification beyond the information provided in the comment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the legends in Tables 1, 2, and 3. It suggests that the legends should be longer and clarifies whether the numbers represent % errors or % correct, assuming MNIST and CIFAR are the respective datasets. This feedback is clear and actionable, providing the authors with a specific and direct way to improve the clarity and accuracy of their tables. By addressing this issue, the authors can enhance the readability and understanding of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to include standard deviations or any other statistical measures to enhance the significance of the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of standard deviations, which makes it difficult to judge the significance of the results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect that the authors need to address to improve the interpretability and robustness of their findings. However, the comment could be more helpful if it provided suggestions on how to include standard deviations or other statistical measures to enhance the significance of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis in the paper is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed analysis or references to support their claims, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer specific guidance on how to implement those improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical work on sampling and particlebased optimization methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This provides clear guidance on what the authors need to address in their analysis. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. While the comment identifies areas for improvement, it does not provide specific references or detailed reasoning to support the claim that the analysis is weak. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis by pointing out that the theoretical work on sampling and particlebased optimization methods is not adequately addressed. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed analysis or references to support their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how other works have addressed similar concerns. Overall, the comment is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or what specific steps to take to enhance realism. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper discusses the generated images or the results, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited realism, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer concrete steps or examples for the authors to enhance the realism of their generated images. Therefore, the comment is rated as 3, as it provides a starting point for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It instructs them to describe how G is built using the human skeleton, to provide details on the size and elements of G, and to include the dimensions of G, X, and W. These actions are clear and concrete, giving the authors a specific path to follow in revising their draft. The comment also suggests adding dimensions to improve understanding of the DGCN, which further clarifies the action needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as describing how G is built using the human skeleton, detailing the size and elements of G, and adding dimensions for G, X, and W to better understand the DGCN. This provides clear guidance on what the authors need to revise in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more details about how G is built using the human skeleton and include dimensions for G, X, and W to better understand the DGCN. While the comment implies that these additions would enhance the clarity of the paper, it does not provide specific examples or references to support why this is necessary. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these additions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a gap in the description of how G is built using the human skeleton in Section 3.3. It suggests that providing details on the size and elements of G would enhance the clarity of the paper. Additionally, the comment recommends adding dimensions for G, X, and W to better understand the functionality of the DGCN. This feedback is clear and actionable, offering the authors a straightforward way to improve their draft by providing additional context and clarity. However, it could be more helpful if it included specific examples or references to support the need for these additions. Overall, the comment is 4, as it guides the authors in making meaningful improvements to their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not explicitly instruct the authors to make this correction or provide guidance on how to incorporate this information into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement about Cycle Consistency loss and provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This explanation is logical and provides a clear correction to the original claim, making the comment 4. However, it could be strengthened by providing specific references or examples to support the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper\"s description of Cycle Consistency loss, pointing out that the statement is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This feedback is clear and actionable, as it guides the authors to correct a potential misunderstanding in their paper. However, the comment could be more helpful if it included specific suggestions on how to incorporate this correction into the draft or provided additional context to enhance the authors\" understanding. Overall, the comment is 4, as it offers valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is explicit and provides a concrete action for the authors to take, which is to clarify the usage of the term \"hyperspectral\" in their paper. The comment is 5 as it directly guides the authors on how to improve their draft by correcting the terminology. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the term \"hyperspectral,\" which is a specific aspect of the paper. It provides a clear explanation of what hyperspectral imaging entails, which helps the authors identify the part of the paper where the term is being used. However, the comment does not specify which section or part of the paper is being discussed, making it weakly grounded. Despite this, the comment is specific in its critique of the term \"hyperspectral,\" providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. The reviewer provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This explanation supports the claim by offering a logical and specific definition of the term, making the comment 4. However, the comment could be strengthened by providing examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in terminology, specifically regarding the term \"hyperspectral.\" It provides a clear and accurate definition of hyperspectral imaging, which is the technique that obtains the spectrum for each pixel in an image. This feedback is valuable as it helps the authors clarify their terminology and ensures that their work is understood by readers who may not be familiar with the specific terms used. By correcting this confusion, the authors can improve the clarity and accessibility of their draft. However, the comment could be more helpful if it suggested how the authors might rephrase or clarify the term in their paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the concept of energy should be refreshed in Section 5.2, where it is used several times, and provides a specific suggestion on how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement these suggestions, such as specific examples or references to related literature. The authors know what needs to be done but may need additional information to fully execute the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as refreshing the concept of energy in Section 5.2 and providing hints on how to interpret it. Additionally, it mentions the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and should be refreshed in Section 5.2, where it is used several times. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for revisiting the concept of energy and clarifying the peak in Figure 5, it lacks specific examples or references to support the claim. The suggestion is 3 as it highlights areas for improvement but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the concept of energy in the paper. It suggests that the concept should be refreshed in Section 5.2, where it is used several times, and provides a specific suggestion on how to interpret it. Additionally, it points out that the concept of peak in Figure 5 is not described, which is another area for improvement. The comment is clear and actionable, offering specific guidance on how the authors can enhance their draft by providing additional context and clarification. This feedback is 4 as it provides clear directions for improvement, allowing the authors to effectively address the identified issues. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, specifically mentioning the example of combining Linformer and window attention in Big Bird using contrition. While the comment implies that the authors should include such explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for more detailed explanations, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to specific points mentioned in the paper, \"1), 2), and 3) mentioned above,\" which suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. However, it does not explicitly mention which sections or parts of the paper these points are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, providing more detailed explanations of the contributions of each component. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while some ablation studies are provided, it would be beneficial to include more detailed explanations of how each component contributes to the final performance improvements. The comment provides a specific example, \"how the performance of simply combining the Linformer and the window attention in BigBird using contrition,\" which could be used to illustrate the point. However, the comment does not provide explicit reasoning or references to support why this additional explanation is necessary, making it 3. The authors would need to infer the importance of this additional information, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that while some ablation studies are provided, it would be beneficial to include more detailed explanations of how each component contributes to the final performance improvements. The comment provides a specific example, \"how the performance of simply combining the Linformer and the window attention in BigBird using contrition,\" which could be used to illustrate the need for additional explanations. This feedback is clear and actionable, as it directs the authors to provide more detailed insights into the contributions of each component. However, the comment could be more helpful if it offered suggestions on how to structure these explanations or what specific aspects should be emphasized. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details of the models are missing, specifically mentioning the lack of explanation for the grammar over kernels. It suggests that there are probabilities associated with the grammar that define a hypothesis space of kernels and asks how inference is performed. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to add specific details or explanations. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information, but the comment does not provide concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detail regarding the models, specifically mentioning the grammar over kernels and the probabilities associated with it. It also questions how inference is performed. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the explanation of the grammar over kernels and the inference process. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of detail regarding the models, specifically the grammar over kernels and the probabilities associated with it. It questions how inference is performed, which is a logical and reasonable inquiry. However, the comment does not provide specific examples or references to support the claim that these details are missing or that they are not explained in detail. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides a logical question but lacks sufficient support or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks detail, specifically the grammar over kernels and the probabilities associated with it. It questions how inference is performed, which is a valid concern for understanding the practical application of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their explanation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the \"w/o perception\" model, and the questionable significance of the improvements based on the sample size. While the comment identifies these issues, it does not provide specific guidance or suggestions on how the authors should address them. The lack of actionable steps or concrete advice makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the \"w/o perception\" model, and the questionable significance of the improvements based on the sample size. It also mentions Table 10, which is a specific part of the paper. This provides full grounding as the authors can accurately identify the sections being addressed. The comment is also specific because it details what needs to be addressed, such as the need for explicit verification and detailed implementation information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several concerns about the paper\"s methodology and results. It claims that the effectiveness of the visual information is unknown, as the ablation study does not explicitly verify it. The comment also questions the implementation details of the \"w/o perception\" model and the significance of the improvements based on the sample size. While the reviewer provides some reasoning, such as the lack of explicit verification and the questionable significance of the improvements, the claim could be strengthened with more detailed examples or references to support the assertion. The comment is 4 as it provides some logical reasoning but lacks specific evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, unclear implementation details of the \"w/o perception\" model, and the questionable significance of the improvements based on the sample size. By pointing out these specific areas of concern, the comment provides valuable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as recommending specific methods for verification or suggesting ways to clarify the implementation details. Overall, the comment is 4 as it highlights important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening, as it does not cite or compare previous works on Lasso screening, such as Ren et al.\"s paper. The comment explicitly instructs the authors to cite and compare these previous works, providing a clear and concrete action for them to take. This feedback is actionable because it gives the authors a specific task to perform, which is to include relevant citations and comparisons to strengthen their argument. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of citation and comparison to previous works on Lasso screening, such as Ren et al.\"s paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about Transfer Lasso showing the best accuracy in feature screening is not supported by citing or comparing it with previous works on Lasso screening, such as Ren et al.\"s paper. The comment provides a specific reference to a previous work, which could be used to substantiate the claim. However, the comment does not include direct comparisons or detailed reasoning about why the cited work is relevant or why it should be included. This makes the claim 3, as it provides a direction for the authors to explore but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening. It points out that the paper does not cite or compare previous works on Lasso screening, such as Ren et al.\"s paper, which could provide a more comprehensive understanding of the topic. By suggesting that the authors include these references, the comment offers a clear and actionable feedback that would help the authors strengthen their argument and provide a more robust comparison. This feedback is valuable as it guides the authors towards improving the depth and accuracy of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they provide the missing hyperparameters or clarify their implementation in the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the model, noting that it has many components with unspecified hyperparameters. However, it does not specify which parts of the paper discuss these components or provide details on the hyperparameters. The authors can infer that the issue relates to the model description or implementation, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the need for more detailed information on hyperparameters, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that it has many components with unspecified hyperparameters. This is a relevant observation that could impact the reproducibility and replicability of the model. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing the missing hyperparameters or clarifying their implementation in the paper. Without actionable feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation used for results, specifically questioning what \"%p\" stands for in the context of the paper\"s claims about the improvement on CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights a specific area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results\" and specifically questions the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This provides clear guidance on where the authors need to clarify their notation. The comment is specific because it identifies the exact part of the paper that needs clarification and what aspect of the notation is unclear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of notation in the paper, specifically regarding the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual observation about the clarity of notation, which is a matter of fact and does not require evidence or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation in the paper, specifically questioning the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This feedback is clear and actionable, as it points out a potential source of confusion for readers. By highlighting this issue, the authors are prompted to clarify their notation, which is an important step in improving the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered alternative ways to express the results. Overall, the comment is 4 as it directs the authors to an area that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include qualitative results, possibly with zoomedin views, for cases where previous methods failed but the proposed method worked well. It also recommends showing failure cases and analyzing the limitations. While the comment provides specific suggestions for what should be included, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not specify which sections of the paper these results should be included in, making it weakly grounded. The comment is specific in its suggestions for what should be included, such as qualitative results and failure cases, and it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not provide specific examples or references to support the claim that these additions would be beneficial. The comment lacks detailed reasoning or evidence to justify why qualitative results or failure cases would be inspiring or necessary. As a result, the claim is 3, as it provides a general suggestion but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including qualitative results, possibly with zoomedin views, for cases where previous methods failed but the proposed method worked well, would be beneficial. It also recommends showing failure cases and analyzing the limitations of the proposed method. This feedback is specific and actionable, providing clear guidance on how the authors can enhance their paper by demonstrating the effectiveness of their method in different scenarios. However, the comment could be more helpful if it included examples or detailed suggestions on how to present these results or analyses. Overall, the comment is 4 as it offers valuable insights for improving the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a specific action by suggesting that the title should be clarified to avoid confusion. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft by making a specific change to the title. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the ambiguity in the title and suggesting a clearer distinction between machine and human reading comprehension. However, it lacks specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the title of the paper, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the title. By addressing this issue, the authors can enhance the precision of their work and better communicate their focus on machine comprehension. However, the comment could be more helpful if it offered additional guidance on how to rephrase the title or provided examples of clearer titles in the field. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point critiques a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It explicitly states that the claim is incorrect and provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime or for a finite linear combination of arbitrary random variables. This feedback is explicit and provides concrete details on how the authors can correct their understanding or presentation of the CLT. The authors are given a clear and actionable path to improve their draft by addressing the inaccuracies in their claim. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides detailed reasoning and examples to support the claim that the statement is incorrect, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This critique is supported by logical reasoning and specific references to the limitations of the CLT, making the claim 5. The authors would benefit from this feedback as it provides a clear understanding of the limitations of their claim and how to correct it.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It critiques the claim by explaining that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is 5 as it provides clear and actionable guidance for the authors to correct their understanding or presentation of the CLT. By addressing this critique, the authors can improve the accuracy and clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for improvement and gives a clear direction on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action required, which is to analyze the time complexity of the proposed policies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to analyze the time complexity of the proposed policies mentioned in Section 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional analysis, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment is clear and actionable, instructing the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a specific and important aspect of the paper that needs attention, as it relates to the efficiency and scalability of the proposed methods. By addressing this, the authors can provide a more comprehensive understanding of their work. However, the comment could be more helpful if it provided additional guidance or examples on how to analyze the time complexity. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative metrics they should use. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their choice of metrics. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the human evaluation section. The comment is also specific because it clearly specifies the issue with the use of TSS and suggests that this choice weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an automatic metric (TSS) instead of a human metric weakens the convincingness of the human evaluation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is problematic or how it affects the evaluation. Without specific details or references, the claim remains 1, as the authors are left without guidance on how to address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the human evaluation process, specifically questioning the use of an automatic metric (TSS) instead of a human metric for evaluating style control. This feedback highlights a gap in the evaluation methodology, suggesting that the choice of metrics could impact the credibility of the evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it points out a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. While the comment implies that the authors should expand their experiments to cover a broader range of domains, it does not provide explicit guidance on how to achieve this or which specific domains to include. The action is somewhat implicit and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. However, the comment does not specify which part of the paper these experiments are in or how they relate to the broader discussion. The authors can infer that it pertains to the experimental section, but the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting a direction for improvement, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains. However, the comment does not provide any specific examples or reasoning to support the claim that the experiments are not diverse enough. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges that the experiments effectively prove the authors\" point but suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental validation. However, the comment lacks specific guidance on how to expand the experiments or which additional domains to explore. To be more helpful, the comment could provide more detailed suggestions or examples of how to diversify the experiments. Therefore, the comment is rated as 3, as it offers a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. While the comment identifies these issues, it does not provide specific guidance on how to address them. The authors are left to infer that they should include confidence intervals and consider evaluating on more datasets, but the comment lacks concrete steps or examples on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the lack of confidence intervals and the evaluation on standard datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. It also notes that the evaluation is only conducted on two standard datasets in the RNP community. The comment provides references to relevant literature, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022, which could be used to support the claim. However, the comment lacks specific examples or detailed reasoning about why these references are relevant, making it 3. The authors would need to explore these references further to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. It provides references to relevant literature, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022, which could be used to support the claim. However, the comment does not offer detailed guidance on how to address these issues or provide specific examples of how to include confidence intervals or evaluate on more datasets. While it highlights important areas for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the interpretability tax they should evaluate. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or table. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on what aspects of the interpretability tax should be evaluated or how to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of the interpretability tax associated with the method. However, it does not provide any guidance or suggestions on how the authors might address this issue or what aspects of the interpretability tax should be evaluated. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve good accuracy, rather than proposing novel techniques. While the comment identifies a potential area of contribution, it does not provide explicit guidance or suggestions on how the authors might enhance their paper to better highlight their novel aspects or contributions. The action is implicit and somewhat vague, as the authors are left to infer that they should emphasize the simplicity and sufficiency of their approach rather than novelty. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the paper\"s contribution, suggesting that the main contribution lies in demonstrating the sufficiency of existing techniques rather than proposing novel ones. The comment provides a logical reasoning for this perspective, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the sufficiency of a simple combination of existing techniques rather than proposing novel techniques. While the comment provides some logical reasoning by pointing out the standard nature of the approaches, it lacks specific references or detailed examples to fully substantiate the claim. This makes the claim 3, as the authors would need to further explore the literature to fully understand the context and relevance of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve good accuracy, rather than proposing novel techniques. This feedback provides a clear perspective on the paper\"s contribution and highlights an important aspect of its value. However, the comment could be more helpful if it offered specific suggestions on how the authors might emphasize the sufficiency of their approach or differentiate it from previous work. Overall, the comment is 4 as it directs the authors\" attention to a key aspect of their contribution, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While the comment explicitly states that the authors should provide training losses, it does not provide specific guidance on how to obtain or present these losses. The action is clear, but the comment lacks concrete details on how to implement this suggestion, such as which specific metrics or methods should be used to generate the training losses. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its request for training losses, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While it identifies a potential issue, it lacks specificity and does not provide guidance on how to address the concern or what aspects of the training process should be examined. The comment is vague and does not offer actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area for concern but does not provide sufficient guidance for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the paper\"s claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claims. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s claim about the strength of the proposed BC loss, specifically mentioning the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specificity by identifying the issues, it lacks full grounding as the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper overstates the strength of the proposed BC loss by suggesting that geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to the parts of the paper where these elements are discussed, making it difficult for the authors to address the critique effectively. Without detailed evidence or examples, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment critiques the paper\"s claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. This feedback identifies a potential overstatement in the paper\"s claims, which could be valuable for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their claims. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It suggests that the proposed framework FFAEVAL and similar systems like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to reconsider the relevance of their method to their motivations and the evaluation systems used. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically mentioning the use of automatic scores and human evaluation scores. It also questions the applicability of the proposed framework FFAEVAL and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the abstract section, but this inference is not explicit. The comment is specific in detailing the concerns about the relevance of the proposed method to the authors\" motivations and the evaluation systems used. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework FFAEVAL and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment lacks specific examples or references to support the claim that these systems are not suitable for evaluating a single dialogue system. The reasoning is based on a general observation about the limitations of the proposed framework, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework FFAEVAL and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. This feedback is 3 as it identifies a potential limitation in the proposed method\"s applicability and suggests that the current evaluation systems may not be suitable for evaluating a single dialogue system. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this limitation or improve the relevance of their method. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. The authors are informed that this might affect the fairness of comparisons with other methods. However, the comment does not provide explicit guidance on how to address this issue or suggest ways to mitigate the impact on the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact on running speed and fairness, but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. It also mentions that this might affect the fairness of comparisons with other methods. However, the comment does not specify which part of the paper discusses the training speed or the comparison with other methods, making it weakly grounded. The comment is specific in identifying the issue with the training speed and its potential impact on fairness, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speeds and an unfair comparison with other methods. The reviewer provides a logical reasoning by stating that the increased sample rate might affect the fairness of the comparison. However, the comment lacks specific examples or references to support the claim about the unfair comparison, making it 3. The authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. The reviewer also points out that this might affect the fairness of comparisons with other methods. While the comment highlights an important consideration for the authors, it lacks specific suggestions or guidance on how to address this issue or mitigate its impact on the comparison. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional advice or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue or what alternative approaches they might consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the implications of using focal loss in regression tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or the regression tasks, making it weakly grounded. The comment is specific in identifying the issue with the use of focal loss in regression tasks and the potential impact on accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence or examples makes the claim 2.", "helpfulness_rationale": "The review comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. The feedback is 3 as it prompts the authors to consider the implications of their choice of loss function, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of scalability they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references or detailed context, the authors may find it challenging to identify the exact area being addressed. The comment is specific in its inquiry about scalability, but it lacks grounding, making it weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question asking about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies an important aspect that the authors should consider, it does not provide any specific guidance or suggestions on how to address this issue. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer actionable insights or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the statistical significance of the improvements in the proposed model compared to the RL without feedback model. It suggests that the authors should verify the statistical significance of these improvements. While the comment implies that the authors should conduct a statistical analysis to confirm the significance, it does not provide explicit instructions on how to perform this verification or which statistical tests to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements of the proposed model over the RL without feedback model, particularly noting that the improvements are not statistically significant. The comment provides a clear direction for the authors to verify the statistical significance of the improvements, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not statistically significant, based on a comparison in row 3 vs. row 4 of table 6. The reviewer suggests that the authors verify the statistical significance of these improvements. However, the comment lacks specific details or references to support the claim about the statistical significance, such as the exact statistical tests used or the criteria for determining significance. This makes the claim 3, as the authors would need to conduct their own analysis to confirm the statistical significance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant. It suggests that the authors should verify the statistical significance of these improvements, which is a valuable piece of feedback. However, the comment lacks detailed guidance on how to conduct the statistical analysis or which specific tests to use. While it points out a critical area for improvement, the lack of actionable steps limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This question provides a clear and direct action for the authors to take, which is to explore the assumptions and potential outcomes of partial coverage. The comment is explicit and concrete, guiding the authors on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly references a previous remark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration and what would happen if they partially cover them. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification or guidance on a specific aspect of the paper, rather than an opinion, judgment, or suggestion. It does not contain any subjective claims or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a continuation of a previous remark, asking the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This feedback is clear and actionable, providing the authors with a specific direction to explore and address in their draft. By asking about assumptions and potential outcomes, the comment encourages the authors to delve deeper into the problem and potentially improve their approach. However, it could be more helpful if it included specific suggestions or examples of how to relax the requirement or what assumptions might be necessary. Overall, the comment is 4 as it guides the authors towards a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to explore this possibility. As a result, the authors are left without a clear understanding of what actions to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper would benefit from using a better encoder or how this change could be implemented. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations to substantiate the suggestion, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for further exploration, it does not provide any specific guidance or suggestions on how the authors might investigate this question or what improvements might be expected. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to address the issue. Therefore, the comment is rated as 2, as it provides a starting point for consideration but does not offer sufficient depth or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of the proposed technique across tasks with varying reasoning requirements. While the comment implies that additional datasets should be included, it does not specify which datasets should be used or how they should be integrated into the paper. The action is somewhat explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors may infer that it relates to the experimental results or the evaluation section, but this inference is not explicit. The comment is specific in its suggestion to include more datasets, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, the comment does not provide any specific reasoning or evidence to support why these datasets are particularly relevant or why including them would enhance the generalizability of the technique. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it provides a specific direction for enhancing the paper\"s experimental validation. However, it lacks detailed guidance on which datasets to include or how to integrate them into the analysis, which could limit its effectiveness in guiding the authors toward actionable improvements. Therefore, the comment is rated as 3, as it offers a clear direction but lacks depth in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It explicitly recommends comparing the methods to existing baselines, such as RefNeRF, which contains appearance decomposition, and MipNerf for larger outdoor scenes. This feedback provides clear and concrete actions for the authors to take, specifying which baselines to consider and why. The comment is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are specific suggestions. However, the comment does not explicitly mention which part of the paper this evaluation should be applied to, making it weakly grounded. The authors can infer that it pertains to the evaluation section or methodology, but this inference is not direct. The comment is specific in suggesting which baselines to consider, making it specific in terms of content. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are specific suggestions. However, the comment does not provide detailed reasoning or evidence to support why these particular baselines are more suitable or why the current choice is inadequate. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting improvements to the choice of baseline methods, particularly for evaluating the appearance decomposition part of the work. It explicitly recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are relevant and specific suggestions. This feedback is clear and provides the authors with a concrete direction for enhancing the evaluation and comparison of their work. However, the comment could be more helpful if it included further details on why these specific baselines are recommended or how they might enhance the analysis. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without significantly impacting the performance of the predictive model. While the action is explicit, it lacks concrete guidance on how to implement this demonstration or what specific aspects of the method should be highlighted. The authors are aware of the action required but may need more detailed instructions to effectively address the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method description. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method should be demonstrated or how the demonstration should be structured. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it could be achieved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. This is a constructive suggestion that highlights an important aspect of the method\"s application, which could be a significant contribution to the field. However, the comment lacks specific guidance on how to achieve this demonstration or what aspects of the method should be emphasized. While it provides a clear direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide more implementation details of the proposed methods, which is a clear and direct action for the authors to take. It specifies the section where this information should be included, making the action concrete and actionable. The authors know exactly what needs to be done to address the concern, which is to add more details in Section 4.1. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4.1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of implementation details of the proposed methods, which is a clear and specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details in the paper is a significant issue, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples or reasoning to support why this is a concern or how it affects the paper\"s comprehensibility or reproducibility. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for reproducibility and understanding of the work. It provides a clear and actionable suggestion by specifying that the implementation details should be included in Section 4.1. This feedback is valuable as it guides the authors on what needs to be addressed to improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance or examples of what specific implementation details should be included. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the paper, noting that there is no empirical evaluation and no comparison with other methods. It emphasizes the lack of practical value and suggests that the paper is not suitable for publication at NeurIPS. While the comment identifies a critical gap in the paper, it does not provide specific guidance on how to address this issue or what kind of empirical evaluation or comparison would be necessary. The authors are left with a general understanding of what needs to be improved but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it points out a significant problem but lacks detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation and comparison with other methods, noting that the paper does not provide a practical value for its contributions. It also critiques the theoretical contributions, stating that the paper is not suitable for publication at NeurIPS due to the absence of empirical evidence. However, the comment does not specify which part of the paper lacks empirical evaluation or comparison, making it weakly grounded. The feedback is specific in identifying the need for empirical evaluation and comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. The reviewer suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The claim is 3 as it points out a significant gap in the paper\"s evaluation and provides a logical argument for why empirical evaluation is crucial. However, the comment could be strengthened by providing specific examples of other methods that could be compared or by referencing relevant literature that emphasizes the importance of empirical evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that there is no empirical evaluation or comparison with other methods, which makes it unclear what the practical value of the contribution is. It suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. While the comment highlights a critical gap in the paper, it does not provide specific guidance on how to address this issue or what kind of empirical evaluation or comparison would be necessary. The feedback is 3 as it points out a significant weakness, but it lacks depth and actionable suggestions, leaving the authors with a general understanding of what needs to be improved but without detailed guidance on how to proceed."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in the manuscript regarding the use of \"P\" as both a probability and a cumulative distribution function. It explicitly states that this inconsistency leads to confusion, but it does not provide specific guidance on how the authors should address this issue. The comment does not offer suggestions for redefining \"P\" or revising the equations to clarify their usage. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line in the text (L44) in the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the confusion caused by the use of \"P\" as both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"P mostly represents a probability but sometimes for a cumulative distribution function,\" which leads to confusion. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion. Without detailed examples or references, the claim remains vague and lacks sufficient evidence to be 5. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \"P\" in the manuscript, noting that it is sometimes used to represent a probability and sometimes a cumulative distribution function, which can lead to confusion. This feedback is clear and actionable, as it points out a potential source of ambiguity that the authors should address. By highlighting this issue, the comment provides a concrete direction for the authors to improve the clarity of their manuscript. However, the comment could be more helpful if it suggested specific ways to resolve the confusion, such as recommending the use of different symbols or providing clearer explanations. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL [1] and asks whether the algorithms can be applied in more general tasks. While the comment implies that the authors should consider expanding the scope of their work, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not specify which part of the paper discusses the limitations to navigation problems or the potential applications in general tasks. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in suggesting a potential extension, it lacks full grounding as it does not explicitly mention the relevant sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is limited to navigation problems or that combining RL and planning has already been discussed in PRMRL. The reference to PRMRL provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL [1] as a related work and suggests that the algorithms could be applied in more general tasks. This feedback is 3 as it points out a limitation of the paper\"s scope and suggests a potential area for expansion. However, the comment could be more helpful if it provided specific guidance on how to apply the algorithms in broader tasks or discussed the implications of this limitation. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be wellsuited for 1NN if they are not close to a spherical Gaussian. It also offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. While the comment implies that the authors should consider this suggestion, it does not explicitly instruct them to make this change. The action is concrete, as it provides a clear direction for improvement, but it is somewhat implicit because it does not explicitly instruct the authors to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces and suggests a potential solution by recommending that feature dimensions be individually standardized. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that feature spaces may not be wellsuited for 1NN if they are not close to a spherical Gaussian, and suggests that individual standardization of feature dimensions could address this issue. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that feature spaces need to be close to a spherical Gaussian for 1NN performance. This makes the claim 3, as it provides a basis for the suggestion but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be wellsuited for 1NN if they are not close to a spherical Gaussian. It offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. This feedback is clear and actionable, as it identifies a potential weakness in the methodology and provides a concrete suggestion for improvement. However, the comment could be more helpful if it included additional context or examples to further explain the importance of this issue and the benefits of the suggested solution. Overall, the comment is 4 as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the proposed \"contrastive gap,\" which is central to the work. It suggests that while an intuitive example is provided, the setting of this example is less convincing, and a formal definition is still missing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap to enhance the clarity of their work. However, it does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to define it. The action is implicit and somewhat vague, as the authors know they need to provide a definition but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of a clear definition and the less convincing setting of the example on the \"idealized\" dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" has never been defined clearly, despite being central to the work. It provides an example on the \"idealized\" dataset to demonstrate the concept, but the setting of this example is less convincing. The comment suggests that a clear, formal definition is still lacking. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the definition is unclear. The reasoning is based on the authors\" perception of the lack of clarity, which is subjective and requires further elaboration to be 5. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the proposed \"contrastive gap,\" which is central to the work. It highlights that while an example is provided, the setting of this example is less convincing, and a formal definition is still missing. This feedback is valuable as it points out a significant gap in the paper\"s clarity and provides a clear direction for improvement. By suggesting the need for a formal definition, the comment empowers the authors to enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered specific guidance on how to define the contrastive gap or provided examples of how this could be achieved. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional baselines, such as those mentioned in the related work section, would enhance the paper. It also acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment does not provide explicit instructions on how to include these additional baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing the remaining unclear parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. It also mentions that the authors explained why the chosen baseline makes sense. However, the comment does not specify which part of the paper this suggestion pertains to, such as the related work section or the experimental setup. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional baselines and asking for clarification on testing, but it lacks grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. However, it does not provide specific reasoning or evidence to support the claim that including these baselines would enhance the paper. The comment lacks detailed justification or examples of how these additional baselines would improve the study, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests including additional baselines in the paper, such as those mentioned in the related work section, which could enhance the study\"s comprehensiveness. It acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment lacks specificity in terms of which baselines should be included or how they would improve the paper. Additionally, the question about testing beforehand is not fully addressed, leaving the authors with incomplete guidance. While the comment provides some direction, it could be more helpful with more detailed suggestions or examples. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification about the meaning of \u0394 in the statement of Lemma 5. This is a direct and specific request for information, providing the authors with a clear action to take. By asking for clarification, the comment guides the authors to address a specific issue in their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification about the meaning of \u0394 in the statement of Lemma 5. This provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification about the meaning of \u0394 in the statement of Lemma 5. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking for clarification about the meaning of \u0394 in the statement of Lemma 5. This is a specific and direct request that helps the authors understand and address a potential confusion in their draft. By providing this feedback, the reviewer is guiding the authors to improve the clarity and precision of their work, which is beneficial for enhancing the overall quality of the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is important. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their approach. The comment implies that the authors should consider dynamic weighting, but it lacks concrete suggestions or examples of how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the uniform weighting of modalities and suggests that dynamically weighting them is important, as evidenced by works in multimodal fusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the uniform weighting of modalities is not ideal, as it implies equal contributions from all modalities. The reviewer supports this claim by referencing works in multimodal fusion that emphasize the importance of dynamically weighting modalities. This provides a logical basis for the claim, as it draws on established practices in the field. However, the comment could be strengthened by providing specific examples or references to these works, which would enhance its verifiability. Therefore, the comment is 4, as it offers a reasonable basis for the claim but lacks full detail.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform weighting of modalities in the paper, suggesting that dynamically weighting them is more important. This feedback is 3 as it points out a common pitfall in multimodal fusion research and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to dynamically weight the modalities or referenced relevant literature that could guide the authors in implementing this approach. Overall, the comment provides a useful insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear understanding of what steps to take to resolve the problem. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280 is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this usage is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in a sentence, noting that it is difficult to understand. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the clarity of the sentence. Without additional context or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a potential problem but does not provide actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but as L_class in the figure. This comment explicitly instructs the authors to ensure consistency in notation, which is a clear and direct action. The authors know exactly what needs to be done to improve the draft, namely, to correct the notation in the figure to match the text. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in notation between the text and the figure, where the task loss is referred to as L_task in the text but as L_class in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about a discrepancy in notation between the text and figure 1, specifically regarding the labeling of the task loss. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but as L_class in the figure. This is a clear and actionable feedback that highlights a potential source of confusion for readers. By pointing out this inconsistency, the authors are given a straightforward task to correct the notation, ensuring consistency throughout the paper. This feedback is valuable as it helps the authors improve the clarity and professionalism of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this limitation or what specific aspects they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may have to infer that it relates to the discussion of the method or the results section, but this inference is not explicit. The comment is specific in questioning the limitations of the method, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It suggests that this might be the case in the current work and asks for clarification. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable feedback or suggestions for addressing the limitations. The authors are left with a question but without guidance on how to explore or address the limitations further. Therefore, the comment is 2, as it provides a starting point for consideration but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work would be more convincing if it were also evaluated in machine translation, as this would provide a more rigorous test of the proposed method. However, the comment does not provide specific guidance on how to implement this evaluation or what aspects of machine translation should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should include machine translation evaluations but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluation methods used in the paper, specifically mentioning the use of answer generation and summarization. It suggests that these tasks are more akin to \"open domain\" generation rather than \"close domain\" generation, such as machine translation. The comment also recommends evaluating the method in machine translation, which exhibits lower uncertainties per word. However, it does not specify which part of the paper discusses the evaluation methods or where the recommendation for machine translation evaluation should be included. While the authors can infer that it relates to the evaluation section, the comment lacks explicit grounding and is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the work\"s evaluation is limited because it only uses answer generation and summarization, which are more akin to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This claim is 3 as it provides a logical reasoning based on the nature of the tasks and their relationship to different domains. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are more akin to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This feedback is 3 as it points out a gap in the evaluation that could strengthen the paper\"s claims. However, the comment could be more helpful if it provided specific guidance on how to conduct the machine translation evaluation or what aspects of machine translation should be considered. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dropping rate and the number of masks generated for the dropout technique. While it does not explicitly instruct the authors to provide this information, the question is clear and specific, allowing the authors to understand what additional details are needed. The action is implicit but concrete, as the authors know exactly what information is required to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and references the response letter, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what information is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the dropping rate and the number of masks generated for the dropout technique. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout technique, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the clarity and completeness of their explanation. By addressing this question, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific aspects of the dropout technique might be affected by the lack of this information. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justifications. It provides a clear action by suggesting that the authors should compare their approach with other singlestage attacks and provide proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This guidance is concrete and provides a direct path for the authors to improve their draft by offering specific comparisons and benchmarks. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the effectiveness of the proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for further justifications and comparisons with other singlestage attacks and SOTA algorithms. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justifications, as only showing the performance drop on fusion models is not sufficient. The reviewer suggests comparing the approach with other singlestage attacks and providing proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This claim is supported by logical reasoning, as it highlights the importance of comprehensive comparisons to validate the effectiveness of the proposed approach. However, the comment could be strengthened by providing specific examples or references to similar studies that have effectively demonstrated the effectiveness of their methods. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justifications of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is not sufficient and suggests comparing the approach with other singlestage attacks and providing proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This feedback is clear and actionable, as it provides specific guidance on how the authors can strengthen their paper by offering additional comparisons and justifications. However, the comment could be more helpful if it included specific examples or references to similar studies that have effectively demonstrated the effectiveness of their methods. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper does not provide information about the type of GPUs used and the inference time during testing. This feedback is clear and direct, instructing the authors to include this information in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information is missing, making it weakly grounded. The comment is specific in identifying the missing details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a critical piece of information that could significantly impact the reproducibility and reliability of the results. By pointing out this omission, the comment provides clear and actionable feedback that would help the authors improve their draft. However, the comment could be more helpful if it suggested how to include this information or provided examples of how it could be presented. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should investigate the performance of RSD4PG when lambda is even smaller, which is a specific and concrete action. The second part points out missing elements in the text, such as the symbols \"\u03c4\" and \"\u03b7\" in the equation on page 3, line 2, and the notation \"s\" in the equation on page 4, line 4. These are also concrete actions that the authors can take to improve their draft. However, the first part is an implicit suggestion, as it does not explicitly instruct the authors to investigate the performance. Overall, the comment provides clear and actionable feedback, making it 4.", "grounding_specificity_rationale": "The comment addresses two separate issues. The first part is weakly grounded as it does not specify which part of the paper the \"table 1\" refers to, making it difficult for the authors to identify the exact section being discussed. The second part is fully grounded as it explicitly mentions \"page 3, line 2\" and \"page 4, line 4,\" allowing the authors to accurately pinpoint the sections needing attention. However, the comment lacks specificity in the first part, as it does not explain what is missing or unclear in the table. In the second part, it specifies the missing elements, such as \"\u03c4\" and \"\u03b7,\" and the corrected notation \"s\".\" Therefore, the comment is 3 overall, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two parts. The first part suggests that the authors should investigate the performance of RSD4PG when lambda is even smaller, which is a request for further exploration rather than a claim. The second part points out missing elements in the text, such as symbols and notation, which are factual statements that do not require verification. Therefore, the comment is 4, as it provides specific requests for clarification but lacks the depth of a 5 claim. The overall score is 3.", "helpfulness_rationale": "The review comment addresses two specific issues in the paper. First, it suggests that the authors investigate the performance of RSD4PG when lambda is even smaller, which is a concrete and actionable suggestion for further exploration. This feedback provides a clear direction for the authors to enhance their analysis. Second, the comment points out missing elements in the text, such as symbols and notation, which are crucial for clarity and understanding. These suggestions are clear and actionable, offering the authors a path to improve the draft. However, the comment could be more helpful if it provided additional context or guidance on how to address these issues. Overall, the comment is 4, as it provides valuable feedback that can significantly enhance the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, rather than the Images Masked by Second Masks. This provides a clear and direct action for the authors to take, which is to correct the connections in the figure. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the connections in the figure, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the connections in Figure 2 should be corrected, specifically suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the connections in Figure 2, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific correction to make in their draft. By addressing this issue, the authors can improve the clarity and accuracy of their visual representation. However, the comment could be more helpful if it explained why this correction is important or how it affects the interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a confusing sentence in the paper and suggests that it is not immediately clear what is meant. The reviewer provides context by mentioning that they understood it after rereading it and subsequent sentences, but this does not offer explicit guidance on how the authors should address the confusion. The comment implies that the authors should clarify the sentence, but it lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, \"9395,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the sentence is confusing and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence is confusing, but it does not provide any specific reasoning, examples, or references to support this claim. The reviewer mentions that they understood it after rereading it and subsequent sentences, but this does not substantiate the claim. Without additional context or evidence, the comment lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a confusing sentence in the paper, specifically mentioning line numbers 9395. It notes that the sentence is not immediately clear and suggests that it was understood after rereading it and subsequent sentences. While the comment highlights a potential issue, it lacks specific guidance or suggestions on how the authors might clarify the sentence or address the confusion. This limits the usefulness of the feedback, as the authors are left without actionable steps to improve the draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several instances where citations are needed to support claims made in the paper. It explicitly instructs the authors to include citations in specific lines, such as lines 7879, 129130, 156158, and 217218. Each instance is clearly identified, and the comment provides a direct action for the authors to take. The feedback is concrete and specific, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides specific references to lines in the paper where citations are needed, such as lines 7879, 129130, 156158, and 217218. This allows the authors to accurately identify the parts of the paper that require citations. The comment is specific in detailing what needs to be addressed, such as the need for citations to support claims about diffusion models outperforming generative adversarial networks, previous work on image generation, and the efficiency of diffusion models. However, it does not specify what specific citations are needed or how they should be integrated into the text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of claims that require citations or evidence to support them. For example, the comment suggests that diffusion models have outperformed generative adversarial networks on image generation benchmarks, but it lacks specific citations or references to substantiate this claim. Similarly, the comment requests citations for previous work on image generation and the efficiency of diffusion models. The lack of detailed justification or references makes it difficult for the authors to understand and address the claims effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several instances where citations are needed to support claims made in the paper. It provides specific lines in the manuscript where references should be included, such as lines 7879, 129130, 156158, and 217218. This feedback is clear and actionable, guiding the authors to improve the verifiability of their claims by providing necessary citations. However, the comment could be more helpful if it suggested specific references or explained why these citations are important. Overall, the comment is 4 as it directs the authors to improve the verifiability of their claims, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between Fig 1 and Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This observation highlights a potential inconsistency in the figures. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes are necessary. The action is implicit and somewhat vague, as the authors need to infer that they should ensure consistency between the figures. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the inconsistency between the figures, noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This is a factual observation that does not require verification, as it is a direct comparison between two figures. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency between two figures, Fig 1 and Fig 2, regarding the representation of encoderdecoder structures for auxiliary tasks. It points out that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it highlights a discrepancy that needs to be addressed to ensure consistency in the figures. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or if it pointed out the potential impact of this inconsistency on the interpretation of the results. Despite this, the comment is 4 as it directs the authors to a specific area that requires attention for improving the clarity and accuracy of their figures. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of equation 2. It suggests that only neighboring nodes are attended to, which implies that the authors should clarify this aspect. While the comment does not explicitly instruct the authors to make this clarification, it is clear that addressing this issue would help improve the clarity of the paper. The action is implicit but concrete, as the authors know exactly what needs to be clarified. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the functionality of nodes in the context of the paper, specifically regarding whether each node can attend to its own lowerlevel representation. The comment is based on the description of equation 2, which suggests that only neighboring nodes are attended to. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the functionality of nodes in the context of the paper, particularly regarding whether each node can attend to its own lowerlevel representation. It references equation 2 and points out a potential limitation based on the description of N_l^(s). This feedback is clear and actionable, as it prompts the authors to clarify this aspect of their work, which could impact the understanding and interpretation of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It provides a specific request for the authors to explain the connection between the lemma and the inequality, which is a direct and concrete action. This feedback gives the authors a clear direction on what needs to be addressed to improve the clarity of their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of how the inequality follows from Lemma 7. This provides clear guidance on what the authors need to do to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the derivation of an inequality from Lemma 7, suggesting that it may follow from a combination of previous inequalities. The reviewer requests clarification on how Lemma 7 is applied in this context. While the comment raises a valid concern about the logical connection, it lacks specific examples or references to support the claim. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is 3, as it points out a potential gap in the logical flow but does not provide sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the derivation of an inequality from Lemma 7. It points out that the connection between the lemma and the inequality is not clearly explained, suggesting that the authors facilitate the reading by providing a clearer explanation. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their work. However, it could be more helpful if it provided specific suggestions on how to improve the explanation or if it highlighted the broader implications of this clarification. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the main contribution of the paper and the proposed method\"s ability to cope with dynamic largescale multitasking. It also questions the applicability of the method and the process of automation. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically mentioning the proposed method\"s novel properties and the main idea of coping with dynamic largescale multitasking. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the main contribution and the proposed method\"s applicability and automation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability and applicability are overstated or not wellsupported. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references to other works or detailed explanations of what aspects are unclear or overstated. As a result, the claim is difficult for the authors to verify and address, making it 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the proposed method\"s novel properties are either overstated or not wellsupported. It also highlights the lack of clarity regarding how the proposed method copes with dynamic largescale multitasking and how automation is achieved. While the comment points out important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors to focus on clarifying their main contribution and the workings of their proposed method, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be improved."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including the results of the bottomup method [9] on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. The comment provides a specific action to take, which is to include the results in the tables and conduct the evaluation on the MS Coco dataset. This is a clear and direct instruction, making the comment 5. The authors know exactly what needs to be done to improve their draft based on the feedback provided.", "grounding_specificity_rationale": "The comment suggests including the results of the bottomup method [9] on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. It also mentions a potential drop in performance in easy (nonoccluded) settings. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific table or section. While the authors can infer that it relates to the results section or tables, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing what needs to be included or evaluated, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the results of a specific method, the bottomup method [9], on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset to assess its performance in easy (nonoccluded) settings. The comment provides a logical reasoning for including these results, as it highlights the potential for improvement in the paper\"s evaluation. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to conduct additional research or analysis to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including the results of a specific method, the bottomup method [9], on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset to assess its performance in easy (nonoccluded) settings. This feedback is clear and actionable, providing the authors with specific steps to enhance the comprehensiveness and robustness of their evaluation. By following this suggestion, the authors can improve the comparability and relevance of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim of using an \"annotation guideline\" and suggests that it may be an overstatement. It provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve their claim. The action is implicit and vague, as the authors are left to infer that they need to clarify or substantiate their claim regarding the use of annotation guidelines. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim and references a specific example from the TACRED slot filling guidelines. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the complexity of annotation guidelines in the IE domain and provides an example to illustrate the depth of true guideline understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that the paper makes use of an \"annotation guideline\" by pointing out that the guidelines in the IE domain are complex and were curated by linguists. It provides a specific example from the TACRED slot filling guidelines to illustrate the depth of these guidelines. This provides a clear and detailed explanation of the claim, making it 5. The authors are given a concrete example and reasoning to understand the complexity of the guidelines, allowing them to address the critique effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper\"s claim of using an \"annotation guideline.\" It points out that the guidelines in the IE domain are complex and were curated by linguists, providing a specific example from the TACRED slot filling guidelines. The comment highlights that the paper\"s prompts may not fully capture the depth of true guideline understanding. This feedback is clear and actionable, as it directs the authors to consider the complexity of annotation guidelines and the need for more detailed guidance in their work. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how to improve the paper. Overall, the comment is 4, as it provides valuable insights for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the existing BERTbaseline comparison. This provides a clear and direct action for the authors to take, specifying what additional comparisons are needed to strengthen the experiment section. The feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment comparison,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparing the method to token pruning and token combination baselines, in addition to the existing BERTbaseline comparison. This provides clear guidance on how to enhance the experiment section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. The reviewer suggests that the authors should also compare their method to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need to expand the comparison, but it lacks specific examples or references to support the suggestion. The authors would need to infer the relevance of these additional comparisons, making the claim 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section of the paper, noting that the comparison is weak because it only compares the proposed method to the BERTbaseline. It provides a clear and actionable suggestion by recommending that the authors should also compare their method to token pruning and token combination baselines. This feedback is valuable as it guides the authors on how to strengthen their experimental evaluation, making the comment 4. However, it could be more helpful if it included specific details on how these additional comparisons might be conducted or what insights they might provide. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, which are not currently included in the comparison. This feedback is explicit and provides a clear action for the authors to take, as it specifies which type of methods should be added to the comparison. The suggestion is concrete, as it gives a specific direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison to coordinateaware methods like TFN or SchNet. This provides clear guidance on how to improve the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, which are not currently included. This claim is 3 as it provides a logical reasoning for the inclusion of these methods, suggesting that they are relevant and could enhance the comparison. However, the comment lacks specific examples or references to support the claim fully. The authors would need to conduct additional research or provide more detailed reasoning to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental section by suggesting that the comparison should include coordinateaware methods, such as TFN or SchNet, which are not currently included. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental setup. By including these methods, the authors can better demonstrate the effectiveness of their approach and address a relevant aspect of the field. However, the comment could be more helpful if it provided additional context or reasoning for why these methods are important or how they might impact the results. Overall, the comment is 4 as it guides the authors towards a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors did not address the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific areas to explore or methods to identify weaknesses. Without concrete instructions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of discussion on the weaknesses of the proposed model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the absence of a discussion on weaknesses, but it lacks grounding as it does not provide a clear reference to the part of the paper where this discussion should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by pointing out that they did not discuss the possible weaknesses of the proposed model. This feedback is clear and actionable, as it directs the authors to consider and address potential limitations or drawbacks of their model. However, the comment could be more helpful if it provided examples of what these weaknesses might be or suggested ways to address them. Overall, the comment is 4 as it highlights an important aspect for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. While the comment highlights a potential issue with the paper\"s lack of context and comparison, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a related work section and compare their system with other extractthengenerate methodologies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It also points out the absence of a related work section and suggests that the paper lacks a comparison with other extractthengenerate approaches. However, the comment does not specify which part of the paper should include a related work section or how the comparison should be made. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific enough to provide clear guidance on what needs to be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. However, the comment does not provide specific examples or references to support the claim that the methodology is not novel or that the paper lacks a related work section. This makes the claim 3, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It questions the lack of a related work section and suggests that the paper does not compare its system with other extractthengenerate approaches. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and encourages the authors to include a related work section and compare their system with existing methodologies. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of related work to include. Overall, the comment offers some guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The suggestion is vague and lacks concrete guidance on how to implement these ideas. The authors are left to infer that they should explore these directions, but without specific instructions, the action remains implicit and somewhat vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, it does not specify which part of the paper this feedback pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestions for alternative approaches but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, the comment does not provide specific evidence, examples, or references to support the claim that training a large number of models is impractical or that the suggested alternatives are more effective. The reasoning is based on a subjective assessment of the feasibility of the approach, which lacks detailed justification or evidence. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. This feedback is 3 as it identifies a potential limitation of the current approach and provides suggestions for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback offers a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. While the comment implies that more work on GLN should be included, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate this information. The action is implicit and somewhat vague, as the authors can infer the need for additional content but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, it does not specify which part of the paper the introduction of related work is located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in suggesting that more information on GLN should be included, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, the comment does not provide specific examples or references to support the claim that the introduction is insufficient or how GLN should be discussed. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s introduction, noting that the discussion of related work is insufficient. It suggests that more information on GLN should be provided to reflect the advantages or differences of the proposed method compared to BGLN. This feedback is clear and actionable, as it directs the authors to enhance their introduction by including additional details on GLN. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this information effectively. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the use of \"hyperparameters\" and \"dropout rate\" in the paper. It questions why only one dropout rate is used for Moon\"s approach, while Variational dropout has inputoutput and recurrent dropout parameters. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify the use of different dropout parameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the use of \"hyperparameters\" and \"dropout rate\" in the paper, specifically questioning the discrepancy in the number of dropout parameters used for different approaches. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the discrepancy and suggesting a potential area for clarification, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of \"hyperparameters\" and \"dropout rate\" in the paper, specifically why only one dropout rate is used for Moon\"s approach while Variational dropout has inputoutput and recurrent dropout parameters. The comment raises a logical question about the consistency and necessity of these parameters, but it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making the comment barely verifiable. Therefore, the label \"2\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the use of \"hyperparameters\" and \"dropout rate\" in the paper, questioning why only one dropout rate is used for Moon\"s approach while Variational dropout has inputoutput and recurrent dropout parameters. This feedback highlights a potential inconsistency in the methodology or implementation that the authors should address. However, the comment does not provide any suggestions or guidance on how to resolve this issue or improve the clarity of the paper. While it points out an area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This suggestion provides a clear and concrete action for the authors to take, as it specifies the type of experiments that would be beneficial and offers a solution. The feedback is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This provides a clear and specific suggestion for the authors to conduct additional experiments. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or experiments. While the authors can infer that it relates to the experimental section, the comment lacks full grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. The reviewer suggests that the absence of these experiments makes it difficult to judge whether the method has scalability issues or if it was due to a lack of time. The comment proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This provides a clear suggestion for additional experiments that could be conducted to address the scalability concern. However, the comment lacks specific examples or references to support the claim about the scalability of the method, making it 3. The authors would need to conduct further research or experimentation to fully address the concern, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s experimental setup by noting the absence of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. This is a relevant observation as it questions the scalability of the method and whether the lack of these experiments is due to a lack of time or inherent limitations. The reviewer suggests that conducting experiments on simple videogame domains, which have a lowcardinality discrete state and actionspace, would provide convincing evidence of the method\"s scalability. This feedback is clear and actionable, offering a specific direction for the authors to improve their experimental validation. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct these experiments or analyze the results. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear path for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific metrics or methods to quantify the extent of occupation bias. Without concrete instructions or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the absence of quantitative measurement for the extent of occupation bias, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement for the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their work by pointing out the lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, as it directs the authors to consider incorporating quantitative metrics or methods to assess and address this issue. However, the comment could be more helpful if it provided examples of existing methods or suggested specific metrics that could be used. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the potential impact of the method on their findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its inquiry about the potential impact of the method on findings, but without clear grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or suggest how the use of adaptive gradient methods could impact the findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might address this concern or what implications it might have for their results. The feedback is 3 as it prompts the authors to consider the impact of their choice of optimization method, but it does not provide actionable steps or detailed insights to enhance the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional experiments, updating the compared methods, or expanding the types of teacher architectures. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The mention of \"Tab.\" suggests that the issue might be related to a table, but it is not explicitly mentioned, leaving the authors without full grounding. The comment is specific in detailing the issues but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient due to limited types of teacher architectures and outdated compared methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not provide any suggestions or guidance on how the authors might address these issues or improve their experiments. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. The authors are left without a clear understanding of what steps to take to enhance their draft, making the comment 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what steps to take to improve the clarity of the method. As a result, the authors are left without any actionable steps to follow, making this comment 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the effectiveness of the method but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is simple but unclear why it is effective. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is simple but unclear why it is effective. However, the comment lacks actionable feedback or suggestions on how the authors might address this issue or improve the clarity of their method. Without specific guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential weakness but does not provide actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speeds between different methods. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is 5 as it offers concrete steps for the authors to take to enhance their work.", "grounding_specificity_rationale": "The comment suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speeds between different methods. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental setup or methodology. The authors can infer that it relates to the data used in the experiments or the comparison of methods. The comment is specific in detailing what needs to be addressed, such as the choice of data and the need for inference speed comparisons. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using real dicom images instead of png images for experiments and recommends the FastMRI challenge dataset for comparison. It also suggests comparing inference speeds between different methods. While the comment provides a logical reasoning for using dicom images and the FastMRI dataset, it lacks specific examples or references to support the claim that dicom images are more suitable or that the FastMRI dataset is a good choice. The suggestion to compare inference speeds is clear, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of real dicom images instead of png images for experiments, which is a relevant and practical improvement. It also recommends the FastMRI challenge dataset for comparison, which can enhance the relevance and applicability of the study. Additionally, the comment suggests comparing inference speeds between different methods, which is a valuable addition to the experimental evaluation. This feedback is clear and provides the authors with concrete steps to improve their draft, making it 4. However, it could be more helpful if it included specific guidance on how to implement these suggestions or examples of how to compare inference speeds. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the current approach of using ProtPainter for binder design is empirical and lacks optimization and validation. It implies that the authors should consider further optimization and validation of the conformation estimation process. However, the comment does not explicitly instruct the authors to perform these optimizations or provide specific guidance on how to validate the results. The action is implicit and somewhat vague, as the authors need to infer the need for optimization and validation and how to implement these steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of binder design, specifically mentioning ProtPainter and its empirical conformation estimation. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design and implies that further optimization and validation are needed. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current approach is empirical or lacks optimization. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the binder design process, where the current approach using ProtPainter is described as empirical and lacks optimization and validation. This feedback is 3 as it points out a potential weakness in the methodology and suggests that further optimization and validation are necessary. However, the comment does not provide specific guidance or suggestions on how to achieve this optimization or validation, which would make it more actionable. Therefore, the comment is rated as 3, as it highlights an important area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically regarding the training on full field flicker stimulus changing contrast with a fixed cycle. It also raises a question about how the duration of the cycle changes and whether it affects the time scale of adaptation, referencing a specific study (Smirnakis et al. Nature 1997) for context. This feedback provides a clear and direct action for the authors to take, which is to clarify the training process and its implications. The comment is explicit and concrete, offering a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how the model in Figure 7 was trained, and it raises a question about the impact of cycle duration changes on the time scale of adaptation. The comment references a specific study (Smirnakis et al. Nature 1997) to provide context for the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and observations regarding the training of a model depicted in Figure 7. It seeks clarification on the training process, particularly regarding the stimulus and cycle duration. The comment also raises a question about the model\"s ability to handle longer time scales, referencing a specific study (Smirnakis et al. Nature 1997) for context. While the comment does not contain an explicit claim, it poses a series of logical questions that the authors should address to clarify their methodology and findings. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it provides a clear and specific question regarding the training of the model depicted in Figure 7. It asks for clarification on the training process, particularly regarding the stimulus and cycle duration. Additionally, it raises a concern about the model\"s ability to handle longer time scales, referencing a specific study for context. This feedback is actionable and prompts the authors to provide detailed information about their methodology, which can enhance the clarity and robustness of their paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context for the authors to consider. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what implications it might have for their work. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having an original CAD model associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper this question relates to or what implications it might have. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario related to the original CAD model and spatiallyvarying BRDF maps. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of having an original CAD model associated with spatiallyvarying BRDF maps. While it identifies a potential area for exploration or consideration, it does not provide any guidance or suggestions on how the authors might address this issue or what implications it might have for their work. The comment lacks actionable advice or specific recommendations, making it difficult for the authors to use this feedback to improve their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it implies that additional evaluation is needed, it does not explicitly instruct the authors to conduct these evaluations or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors can infer the need for more evaluation but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, nor does it provide detailed guidance on what specific aspects of the evaluation should be expanded upon. The authors can infer that it relates to the experimental results or discussion sections, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting additional evaluation areas but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, the comment does not provide any specific reasoning, examples, or references to support why this additional evaluation is necessary or how it would improve the paper. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it identifies an area for improvement, the comment lacks specificity and does not provide detailed guidance on what specific aspects of the evaluation should be expanded upon or how additional evaluation could enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and clarity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides specific examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. While the comment identifies a potential issue, it does not explicitly instruct the authors to make these comparisons or provide guidance on how to address the problem. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons to ensure a fair comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison in the table, noting that comparisons should be made between using the same amount of data. The comment provides examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides specific examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is 3 as it identifies a potential issue with the data comparison in the table, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to investigate further to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is clear and actionable, as it directs the authors to ensure that their comparisons are consistent and fair. By addressing this issue, the authors can improve the validity and reliability of their results. However, the comment could be more helpful if it suggested specific ways to make these comparisons or provided examples of how to do so. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two issues: the counterintuitive placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps in the text. The first comment suggests that the authors should clarify the iterative process, particularly for larger iterations T, which is a concrete action. However, the second comment about the lack of reference to Laplacian eigenmaps is not explicitly actionable and does not provide guidance on how to address it. The overall comment is 4 due to the explicit suggestion in the first part, but the second part lacks actionable details. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment addresses two specific issues: the placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps. It provides explicit references to specific lines (224) and figures, allowing the authors to accurately identify the parts of the paper being addressed. This makes the comment fully grounded. Additionally, it specifies what needs to be addressed in each part, such as clarifying the iterative process and referencing Laplacian eigenmaps. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two issues: the counterintuitive placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first claim about the counterintuitive placement is 3 as it suggests that the addition should be placed earlier in the paper, but it lacks specific reasoning or examples to support this claim. The second claim about the lack of reference to Laplacian eigenmaps is not supported by any evidence or reasoning, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 2, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the counterintuitive placement of an addition at the end of the paper and the lack of reference to Laplacian eigenmaps in the text. It also points out a potential issue with the iterative algorithm, suggesting that it should run until a criterion is fulfilled, with T potentially being much larger than 2. However, the comment lacks detailed guidance on how to address these issues, such as suggesting alternative placements or providing specific references for Laplacian eigenmaps. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive to be rated as 5. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 2.1 is unnecessary because it discusses Batch Normalization and Conditional Batch Normalization (CBN), which are general techniques. The reviewer also recommends that the description of the proposed methodology should be independent of the choice of model and suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and how they present their methodology, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should restructure their presentation to better motivate their CBN approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of Section 2.1, suggesting that the description of the proposed methodology is independent of the choice of model and could be better used to provide greater motivation and intuition for the proposed CBN approach. The reviewer also suggests that the time spent on describing the ResNet architecture could be better utilized. This provides detailed guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Section 2.1 is unnecessary because Batch Normalization and Conditional Batch Normalization are general techniques, and the description of the proposed methodology is independent of the choice of model. The reviewer suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment provides a logical argument for the redundancy of Section 2.1, it lacks specific examples or references to support the claim that the description of the proposed methodology is independent of the choice of model. This makes the claim 3, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Section 2.1, suggesting that the discussion of Batch Normalization and Conditional Batch Normalization is general and does not add significant value to the paper. It recommends that the description of the proposed methodology should be independent of the choice of model and suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is clear and actionable, as it provides specific suggestions for improving the paper by focusing on the relevance and motivation of the proposed methodology. However, the comment could be more helpful if it offered additional guidance on how to enhance the motivation and intuition for the CBN approach. Overall, the comment is 4, as it directs the authors to a specific area for improvement and provides a clear direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix in equation (1) and how it relates to the expectation of sparsity. While the comment highlights a potential inconsistency, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or correct the assumption regarding sparsity. However, the comment lacks concrete details on how to implement this correction, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying by a dense projection matrix and its implications for sparsity, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. While it does not contain an explicit claim or suggestion, it poses a logical question that requires clarification. The comment does not provide any supporting evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. While it identifies a potential inconsistency, it does not provide any guidance or suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 2, as it points out a potential area of concern but does not offer actionable advice or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time to support their claim. This is a clear and direct action that the authors can take to address the issue of indirect evidence for the motivation. The comment provides a specific and concrete suggestion on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first question,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to plot a figure showing the decline in accuracy of a predictor over time to support the claim. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evidence for the motivation is not direct and proposes a specific action to support the claim by plotting a figure showing the decline in accuracy of a predictor over time. This is a logical suggestion based on the problem description, which provides a clear rationale for the need to include such a figure. However, the comment does not provide specific examples or references to support the claim further. While the suggestion is reasonable, it lacks detailed justification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence supporting the motivation of the paper. It points out that the current evidence is indirect and suggests a direct approach by proposing the inclusion of a figure showing the decline in accuracy of a predictor over time. This feedback is clear and actionable, providing a concrete suggestion for improvement. However, it could be more helpful if it included additional guidance on how to create an effective figure or what specific aspects of the decline in accuracy should be highlighted. Despite this, the comment is 4 as it directs the authors to a specific area for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the definition and calculation of excessive risk, specifically in terms of expectation. It asks for clarification on how to calculate excessive risk and whether the values are comparable among different groups. While the comment identifies areas that need further explanation, it does not provide explicit instructions or suggestions on how the authors should address these issues. The questions are clear and specific, but the lack of direct guidance on how to implement the suggested clarifications makes the comment 3. The authors know what information is needed but may need to infer the exact steps to take to address these questions. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103\" and references specific figures (Figure 3 and Figure 7), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the definition of excessive risk, how it is calculated, and whether the values are comparable among different groups. The reviewer raises several points that need clarification, such as the calculation method, the possibility of negative values, and the comparability of excessive risk values. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definition and calculation of excessive risk, specifically in terms of expectation. It points out that the optimal solution \u03b8* is not the optimal solution for the loss function w.r.t. data of group a, which could lead to negative values for excessive risk. However, the reviewer notes that all excessive risk values in Figures 3 and 7 are positive, questioning the comparability of values among different groups. While the comment raises valid concerns, it lacks specific examples or references to support the claim about the possibility of negative values or the comparability of excessive risk values. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for questioning but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises several important questions about the definition and calculation of excessive risk, specifically in terms of expectation. It points out potential issues with the calculation method and the comparability of excessive risk values among different groups. By asking for clarification on how to calculate excessive risk and whether the values are comparable, the comment provides actionable feedback that can help the authors improve their understanding and presentation of the concept. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to calculate excessive risk. Overall, the comment is 4 as it identifies areas for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It also provides a reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should revisit and possibly revise their statement about initialization, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should make a more careful statement and consider the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"initialization\" and references a specific work by Kunstner, Hennig, and Balles (2019), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about initialization should be more carefully stated, referencing a specific work by Kunstner, Hennig, and Balles (2019) as a source of evidence. This provides a clear and specific reference to support the claim, making it 5. The reviewer\"s reasoning is based on the relevance of the reference to the topic of initialization and the potential impact on the statement about NGD being a discretization of NGF. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It provides a specific reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is valuable as it directs the authors to a source that could help them refine their understanding and presentation of initialization in the context of their work. However, the comment could be more helpful if it offered additional guidance on how to incorporate this reference or address the issue in the paper. Overall, the comment is 4 as it provides a clear direction for improvement but lacks depth in its suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. First, it highlights the lack of clarity regarding how named entities were extracted from the datasets, which is an explicit action for the authors to address. Second, it suggests that an Englishproofreading would significantly improve the readability of the paper, providing a concrete and actionable suggestion for improvement. However, the comment does not specify which parts of the paper need Englishproofreading or how it would enhance readability. While the actions are clear, the lack of detailed guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the extraction of named entities from the datasets and the need for Englishproofreading to improve the paper\"s readability. However, it does not specify which part of the paper discusses the extraction of named entities, making it weakly grounded. The comment is specific about the need for clarity in the extraction process and the potential benefits of Englishproofreading, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: the first claims that it is unclear how named entities were extracted from the datasets, and the second suggests that Englishproofreading would improve the paper\"s readability. The first claim is 3 as it points out a lack of clarity, but it lacks specific details or examples to substantiate the claim. The second part is a suggestion for improvement, which is not a claim. Therefore, the overall verifiability of the comment is 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the clarity of how named entities were extracted from the datasets and the need for Englishproofreading to enhance the paper\"s readability. While the comment highlights important issues, it lacks detailed guidance or suggestions on how to address these concerns. For example, it does not specify which sections or parts of the paper need clarification or how Englishproofreading could be implemented. This limits the usefulness of the feedback, as the authors may find it challenging to effectively incorporate the suggestions. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part, \"L200: \u201cfor every arm a\u201d implies there is a single optimistic parameter, but of course it depends on a,\" suggests that the authors should clarify the relationship between the optimistic parameter and the arms. However, it does not provide specific guidance on how to address this issue or what changes should be made. The second part, \"L303: Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" offers a suggestion for improving the condition, but it does not provide explicit instructions on how to implement this change. The authors are left to infer that they should consider this suggestion, but without detailed guidance, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L200\" and \"L303,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as clarifying the relationship between the optimistic parameter and the arms, and suggesting a change to the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests a clarification regarding the relationship between the optimistic parameter and the arms, which is a logical observation. The second part offers a suggestion for improving the condition, which is a specific and logical suggestion. However, the comment lacks detailed reasoning or references to support the claim that the suggested change improves the condition. While the suggestion is reasonable, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation and suggests a clarification regarding the optimistic parameter and its relationship to the arms. It also offers a specific suggestion for improving the condition by proposing a different choice for T_0. This feedback is clear and actionable, providing the authors with a concrete way to enhance their draft. However, the comment could be more helpful if it explained why the suggested change is beneficial or provided additional context on the implications of the change. Overall, the comment is 4 as it guides the authors towards improving their draft, but it could be more comprehensive with additional explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. However, the comment does not provide specific guidance on how to address this issue, such as recommending a particular section or suggesting a specific format for defining these terms. The action is implicit and somewhat vague, as the authors can infer that they need to address the formatting inconsistency but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296\" and \"Line 302,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point highlights a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. This feedback is specific and actionable, as it provides clear guidance on how to improve the clarity and consistency of the text. By addressing this issue, the authors can enhance the readability and professionalism of their draft. However, the comment could be more helpful if it included suggestions on how to define L and E or provided examples of consistent usage. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental section is weak and requires more experiments. However, it does not provide specific guidance on what additional experiments are needed or how they should be conducted. The authors are left with a general understanding that more experiments are necessary but without concrete steps or suggestions on what those experiments should be. This makes the comment 3, as it identifies a need for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and requires more experiments. However, it does not specify which part of the experimental section is weak or what specific aspects need improvement. This lack of detail makes it difficult for the authors to identify the exact areas that need attention. Without specific guidance, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and requires more experiments. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section of the paper, noting that it is weak and suggesting the need for more experiments. However, the comment lacks detail on what specific aspects of the experimental section are weak or how additional experiments could address these weaknesses. Without actionable guidance or specific suggestions, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a critical area for enhancement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct additional comparisons, it does not provide specific guidance on which models or techniques to include or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these comparisons should be made. This lack of grounding makes it difficult for the authors to identify the exact area needing improvement. The comment is specific in suggesting additional comparisons, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support the claim that these additional comparisons would be beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement by recommending additional comparisons that could enhance the manuscript\"s comprehensiveness and depth. However, the comment lacks specific guidance on which models or techniques to include, making it somewhat limited in its usefulness. To be more helpful, the comment could provide examples or references to specific models or techniques that could be compared, offering the authors a clearer path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and concrete, providing the authors with clear instructions on how to improve the draft. The reviewer identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity ensures that the authors know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections for grammatical errors and punctuation in the manuscript, such as \"Despite of being compact\u00e2\u0080\u009d > \u00e2\u0080\u009cDespite being compact\u00e2\u0080\u009d,\" \"We refer multiway arrays\u00e2\u0080\u009d > \u00e2\u0080\u009cWe refer to multiway arrays\u00e2\u0080\u009d,\" \"HPFN to a even deeper ConAC\u00e2\u0080\u009d > \u00e2\u0080\u009cHPFN to an even deeper ConAC\u00e2\u0080\u009d,\" and \"Effect of the modelling mixed temporalmodality features.\" > I\"m not sure what this means, it\"s not grammatically correct.\" These corrections are clearly identified and specify what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of corrections for grammatical errors and punctuation, which are factual statements without any claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and actionable, helping the authors to improve the clarity and professionalism of their draft. The comment identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity is beneficial for the authors, as it allows them to make direct improvements to their manuscript. However, the comment could be more helpful if it provided additional context or suggestions for how to address the grammatical issues or improve the overall clarity of the text. Despite this, the feedback is 4 as it provides clear guidance for enhancing the manuscript\"s quality."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address the issue or what specific changes are needed. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not specify which part of the paper these equations are located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in questioning the inversion or division, but without clear grounding, it is challenging for the authors to pinpoint the exact issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify the question or the claim that these are mistakes. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any context, explanation, or guidance on why this is a concern or how it affects the paper. Without additional information or suggestions for improvement, the authors are left without actionable feedback. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived incremental nature of their work or improve the originality of their contribution. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the model or methodology are considered incremental. Without specific references to sections or elements of the paper, the authors cannot confidently determine which parts need revision or improvement. Additionally, the comment lacks specificity regarding what aspects of the model or methodology are considered incremental or straightforward. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. While it identifies a potential issue with the originality of the work, it lacks specificity and actionable feedback. The comment does not provide any guidance on how the authors might address this concern or improve the originality of their contribution. Without detailed suggestions or examples, the authors are left without a clear path for enhancing their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the comparison and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs to be addressed. The comment is specific in its suggestion to compare sequential and combinational designs, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a comparison between sequential design and combinational design, implying that the proposed method may perform better in pure combinational logic without registers. This is a valuable suggestion as it provides a direction for further exploration and evaluation of the method\"s performance. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it offers a potential area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. While it implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this performance metric in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. This provides clear guidance on what needs to be addressed in the experiment section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the performance of a baseline in terms of a specific metric. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance of a baseline, LDA+LSTM, in terms of the topic switch percent metric. This feedback is 3 as it prompts the authors to consider evaluating their baseline\"s performance in a specific way, which could provide additional insights into the effectiveness of their approach. However, the comment lacks detailed guidance or suggestions on how to conduct this evaluation or what specific aspects of the performance should be highlighted. To be more helpful, the comment could include more detailed questions or suggestions for how to measure and report the performance of the baseline. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It suggests that the authors should clarify the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment implies that the authors should address these aspects, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the introduction or motivation section, but this is not explicitly mentioned. The comment is specific in detailing the issues with the motivation and potential applications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment highlights a valid concern, it lacks specific examples or references to support the claim that the motivation is unclear. The suggestion to clarify potential applications or benefits is a logical response to the issue, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. This feedback is 4 as it provides clear and actionable suggestions for improving the motivation and clarity of the paper. However, it could be more helpful if it offered specific examples or references to support the potential applications or benefits of amodal tracking. Overall, the comment is 4, as it guides the authors in enhancing the clarity and relevance of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This action is clear and concrete, as it specifies the exact change needed to improve the draft. The authors know exactly what action to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5 to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of GPT4\"s cost, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting a change to include GPT3.5 experiments, which would enhance the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 to provide a more comprehensive evaluation of the proposed approach. The reviewer acknowledges the expense of GPT4 but recommends using GPT3.5 as a more affordable alternative. This suggestion is based on a logical reasoning that the inclusion of GPT3.5 experiments would enhance the evaluation, but it lacks specific examples or references to support the claim. The reasoning is clear but could be strengthened with additional evidence or examples. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed support.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific and practical suggestion for improving the draft. By recommending the use of GPT3.5, the authors can enhance the evaluation of their approach and potentially address concerns about the costeffectiveness of their experiments. This feedback is 4 as it provides a clear direction for improvement, but it could be more helpful if it included specific guidance on how to integrate GPT3.5 into the experiments or what aspects of the evaluation would benefit from this change. Overall, the comment is valuable and actionable, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It specifies the exact example, \"WMT17WIKT,\" and highlights that the best result in terms of BLEU is actually in the baselines. This provides clear and concrete guidance on what needs to be done to improve the table, making the action explicit and actionable. The authors know exactly how to implement the suggested change, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: including bold numbers for the baselines of previous work, particularly for the example \"WMT17WIKT,\" and noting that the best result in terms of BLEU is actually in the baselines. This provides clear guidance on what needs to be revised in the table, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the baselines of previous work should include bold numbers in Table 4, specifically mentioning \"WMT17WIKT\" as an example where the best result in terms of BLEU is in the baselines. This claim is 3 as it provides a specific example and highlights a potential issue with the presentation of results. However, it lacks detailed reasoning or references to support the claim that bold numbers should be included for the baselines, which could make the suggestion clearer. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the presentation of results in Table 4. It highlights the need to include bold numbers for the baselines of previous work, particularly for the example \"WMT17WIKT,\" where the best result in terms of BLEU is actually in the baselines. This feedback is clear and directly addresses a potential issue with the clarity and accuracy of the data presentation. By following this suggestion, the authors can enhance the readability and effectiveness of their results section, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for examples of \"unreliable neighbors\" in lines 170 to 171. This request provides a clear and direct action for the authors to take, which is to include specific examples to clarify the concept of \"unreliable neighbors.\" The comment is explicit and concrete, giving the authors a straightforward task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly requests examples of \"unreliable neighbors,\" providing a clear direction for the authors to address the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for examples of \"unreliable neighbors\" in lines 170 to 171. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly requests examples of \"unreliable neighbors\" in lines 170 to 171. This feedback provides a specific direction for the authors to improve their draft by clarifying the concept of \"unreliable neighbors.\" By addressing this request, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to identify or define \"unreliable neighbors\" or provided examples from the literature. Overall, the comment is 4 as it guides the authors towards a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of mention of TD3GA in the main paper. It also suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and emphasize the comparison to TD3GA in their paper. However, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of mention of TD3GA in the main paper and the need for a comparison to TD3GA to support the central claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, particularly due to the absence of mention of TD3GA in the main paper. The reviewer suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that TD3GA is crucial for understanding the synergies. The suggestion to include a comparison to TD3GA provides a direction for improvement, but the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention TD3GA, which is crucial for understanding these synergies. It also highlights a central claim that using onpolicy RL better fits the DQD framework and suggests that the comparison to TD3GA should be central to this claim. This feedback is clear and actionable, as it directs the authors to include a discussion of TD3GA and emphasize the comparison to TD3GA in their paper. By providing specific guidance on how to strengthen the paper, the comment is 4, as it empowers the authors to make significant improvements to their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, prompting the authors to provide an explanation for this observation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. However, it does not provide any supporting evidence, reasoning, or references to justify why this performance is surprising or how it should be explained. The lack of detailed explanation or context makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. While it identifies an area of interest, it does not provide any guidance or suggestions on how the authors might address this observation or explain the performance difference. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area of interest but does not offer meaningful guidance for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaning of \"confident\" in the context of the paper, suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. However, the comment does not explicitly instruct the authors to rephrase or clarify the term, leaving the action somewhat vague. The authors can infer that they should address the ambiguity, but the lack of specific guidance makes the action somewhat implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific phrase, \"ceterus paribus convexity,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"confident\" and suggesting that it might refer to model confidence or human interpretability. The comment is specific in its request for rephrasing to clarify the intended meaning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the meaning of \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the ambiguity or suggest how the term should be rephrased. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential ambiguity in the text, it does not provide specific guidance or suggestions on how to rephrase or clarify the term. This limits the usefulness of the feedback, as the authors may still struggle to address the issue effectively without additional direction. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which is to use known causal relationships between features. It highlights that prior knowledge is not always available and might be inaccurate for specific subpopulations, leading most researchers to focus on mining causal relationships from data automatically. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of prior knowledge and explore alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a concern about the practicality of using known causal relationships between features, as it acknowledges that prior knowledge is not always available and might be inaccurate for specific subpopulations. However, it does not specify which part of the paper discusses this approach or where the authors might need to address this concern. The authors can infer that it relates to the methodology or discussion sections, but the lack of explicit grounding makes it difficult to pinpoint the exact sections. The comment is specific in detailing the practicality issue but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of using known causal relationships between features, noting that prior knowledge is not always available and might be inaccurate for specific subpopulations. This is a logical and reasonable concern, as it highlights a potential limitation of the proposed approach. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of this concern to their work, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential practicality issue with the paper\"s approach, which is to use known causal relationships between features. It points out that prior knowledge is not always available and might be inaccurate for specific subpopulations, which is a common concern in many fields. This feedback is 3 as it highlights a potential limitation of the proposed methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the practicality of their work. While it raises an important point, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper\"s empirical findings, including the lack of polishing of figures and empirical results, which impede clarity and confidence in the results. It specifies specific areas for improvement, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. Additionally, it notes that the core findings in section one are conducted on two smallscale datasets and a single architecture type. While the comment provides a clear list of issues, it does not offer explicit guidance on how to address these concerns or suggest specific changes. The authors are left to infer the necessary actions, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the lack of polishing in figures and empirical results, which affects the clarity and confidence in the findings. It specifies issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. However, it does not explicitly mention which sections or figures are affected, making it weakly grounded. The comment is specific in detailing the issues with the empirical findings, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks confidence in its empirical findings due to issues with the figures and empirical results. It provides specific examples, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and limited scope of the core findings in section one. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion about the impact of these issues on the confidence in the findings. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s empirical findings, including the lack of polishing in figures and empirical results, which impede clarity and confidence in the results. It provides detailed examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. This feedback is actionable and provides clear guidance for the authors to improve the clarity and robustness of their empirical results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the figures and results. Overall, the comment is 4 as it directs the authors\" attention to critical areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or enhance the novelty of their work. The comment lacks guidance on how the authors might improve their findings or present them in a more novel way. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not specify which part of the paper discusses these findings or where the novelty is limited. The authors may have an idea of where the novelty is being discussed, but the comment lacks explicit references to specific sections or figures. Additionally, the comment provides some reasoning about the expected observation, but it does not specify what aspects of the findings could be improved or how the authors might enhance the novelty of their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. The reviewer provides a logical reasoning based on common knowledge in the field, stating that taskspecific finetuning generally increases confidence for a specific task while potentially reducing generalizability. This reasoning is clear and provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the expected observation, which would make it 5. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment acknowledges the interesting findings presented in the work but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. The reviewer provides a logical explanation based on common knowledge in the field, stating that taskspecific finetuning generally increases confidence for a specific task while potentially reducing generalizability. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. The feedback is 3 as it points out an area for improvement but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This action is explicit and provides a clear direction for the authors to enhance their analysis. The comment also mentions that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion. However, the comment does not provide specific guidance on how to present or analyze these numbers, leaving some room for interpretation. Overall, the comment is 4 as it provides a clear action but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This provides a clear and specific suggestion for additional analysis, making the comment fully grounded. The authors can accurately identify the part of the paper being addressed, which is the label noise experiment, and the comment specifies what needs to be addressed, namely, reporting the numbers on ImageNet with 1000 classes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper. This is a logical suggestion based on the reviewer\"s understanding of the experiment and its potential impact on the results. However, the comment does not provide specific examples or references to support the claim that this would significantly stress test the conjecture or that the phenomenon would weaken in this setting. The suggestion is 3, as it offers a clear direction for improvement but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This is a clear and actionable suggestion that provides a specific way to enhance the robustness of the paper\"s findings. By including these additional results, the authors can further stress test their conjecture and provide a more comprehensive analysis. The comment also acknowledges that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion for further exploration. Overall, the comment is 4 as it offers a clear direction for improvement and enhances the paper\"s depth and rigor. However, it could be more helpful if it provided specific guidance on how to present or analyze these additional results. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what additional feedback might be beneficial. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the metric choice but lacks grounding, as it does not reference a particular section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. This question prompts the authors to consider the validity of their chosen metric and encourages them to provide additional feedback or justification for their choice. However, the comment does not offer specific guidance or suggestions on how to address this question or improve the paper. While it prompts the authors to think critically about their methodology, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the applicability of adversarial prediction accuracy, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the applicability of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the paper could be improved to better address this concern. The comment lacks depth and actionable feedback, leaving the authors with a general idea of what to consider but without concrete steps to take. Therefore, it is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the authors should provide more details about the experiment setup and explore the effects of varying the number of InContext Examples. However, while the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details several issues, such as the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. Additionally, it suggests exploring the effects of varying the number of InContext Examples. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information about the number of different sets of incontent examples used and the reliance on a single dataset, which limits the generalizability of the results. These points are wellsupported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation section of the paper, including the lack of transparency in the experiment setup and the reliance on a single dataset. It points out specific areas that need improvement, such as the absence of information about the number of different sets of incontent examples used and the need to explore the effects of varying the number of InContext Examples. This feedback is 5 as it provides clear and actionable suggestions for enhancing the comprehensiveness and robustness of the evaluation. By addressing these points, the authors can significantly improve the quality and reliability of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or whether it requires any changes to the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contrastive learning framework are similar to SimCLR or what implications this similarity has for the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the contrastive learning framework is the same as SimCLR, which is a relevant observation. However, it does not provide any further context, analysis, or suggestions on how this observation might impact the paper or what implications it has for the authors. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2 in Section 4.3. It suggests that including these comparisons would provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. This feedback is clear and direct, giving the authors a specific action to take: conduct additional experiments and include them in the paper. The comment provides concrete guidance on what needs to be added to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides clear guidance on what needs to be added to improve the paper, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, which could provide a broader context for the proposed method. However, the comment does not provide specific examples or references to support the claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed reasoning or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by highlighting the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it provides a direct suggestion for additional experiments that could enhance the paper\"s comprehensiveness and provide a broader context for the proposed method. By addressing this feedback, the authors can strengthen their work by demonstrating the unique advantages or potential shortcomings of their approach. However, the comment could be more helpful if it included specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples [1], [2], and [3]. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors can infer that they need to consider and integrate these references, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it provides a direction but lacks specific instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples [1], [2], and [3]. However, it does not specify which part of the paper this feedback pertains to, such as the introduction or discussion sections, making it weakly grounded. The comment is specific in identifying the need for additional attention to related work, but without explicit grounding, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples [1], [2], and [3]. However, the comment does not provide any reasoning, evidence, or justification for why these references are relevant or how they could improve the paper. Without specific examples or explanations, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples [1], [2], and [3]. While this feedback highlights the need for more comprehensive referencing, it lacks specific guidance on how to integrate these references or what aspects of the related work should be considered. The comment provides a general direction but does not offer actionable steps or detailed suggestions, making it 3. The authors are aware of the need for additional references but may need to seek further guidance to effectively incorporate them into their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the absence of a comparison against existing text GANs, noting that many of these models have opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include a comparison with existing text GANs, including SeqGAN with a pretrained version. However, the comment lacks concrete details on which specific text GANs to compare against or how to conduct the comparison, making it 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, noting that many of these models have opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the comparison section or the discussion of related work. The authors can infer that it relates to the comparison section, but the comment does not provide explicit guidance on which part of the paper this issue is addressed in. Therefore, the comment is weakly grounded as it does not specify the exact part of the paper being addressed, but it is specific in detailing what needs to be addressed. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, noting that many of these models have opensource implementations. While the comment highlights a potential area for improvement, it does not provide specific examples of which text GANs should be compared against or how the comparison should be conducted. This lack of detail makes the claim 3, as the authors would need to infer the specific comparisons to be made. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation by noting the absence of a comparison against existing text GANs, despite the availability of opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version, which is a critical oversight. This feedback is clear and actionable, as it highlights a specific area where the authors can enhance the robustness and relevance of their work. By addressing this issue, the authors can provide a more comprehensive analysis of their proposed method\"s performance and its applicability in the field of text generation. However, the comment could be more helpful if it suggested specific text GANs to compare against or provided guidance on how to conduct the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not provide specific guidance on how to incorporate these aspects or what algorithmic elements should be emphasized. The comment implies that the authors should consider expanding their focus, but it lacks concrete details or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to focus on algorithmic aspects, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper is limited after the concept of Blackwell winner is proposed. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. This feedback highlights a potential area for improvement in the paper\"s scope and depth. However, the comment lacks specific guidance or suggestions on how to incorporate these algorithmic aspects or what specific elements should be emphasized. While it identifies a relevant area for expansion, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is 3, as it provides a direction for improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests a specific action to improve the readability of Tables 4 and 5. It recommends splitting the tables into two separate tables, one for each measure, to enhance clarity. This feedback is clear and provides a concrete step for the authors to take, making it 5. The authors know exactly what changes to make to improve the presentation of the data in the tables.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two separate tables, one for each measure. This detailed guidance helps the authors understand exactly what needs to be done to enhance the presentation of their data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific improvement to the presentation of data in Tables 4 and 5, recommending that they be split into two separate tables for each measure. This suggestion is based on the rationale that splitting the tables would improve readability. While the comment provides a logical reason for the suggestion, it lacks specific examples or references to support the claim that this change would indeed enhance readability. The feedback is 3 as it offers a clear suggestion but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that the tables be split into two separate tables, one for each measure, the reviewer offers a clear and practical way to enhance the clarity and organization of the data presented. This feedback is valuable as it directly addresses a potential issue in the manuscript and provides a straightforward solution. However, the comment could be more helpful if it included additional guidance on how to present the data in a more effective manner. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that specifying what \"valid\" and \"orig\" differ in would be helpful in Fig. 5. While it implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to clarify what \"valid\" and \"orig\" differ in. This provides clear guidance on what the authors should focus on improving in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that specifying what \"valid\" and \"orig\" differ in would be helpful in Fig. 5. However, it does not provide any reasoning, examples, or references to support why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area in Fig. 5 where clarification is needed, suggesting that specifying what \"valid\" and \"orig\" differ in would be helpful. This feedback is clear and actionable, as it directs the authors to a specific aspect of their figure that requires further explanation. By addressing this suggestion, the authors can enhance the clarity and interpretability of their results, making the comment 4. However, it could be more helpful if it provided additional context or examples of how this clarification could be implemented. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. While the comment implies that the authors should conduct more systematic comparisons, it does not provide explicit instructions on how to achieve this or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Zemel et al. (2013)\" and \"the present paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparisons with this work could be improved by making them more systematic with respect to the tuning of each method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons should be more systematic or how they could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand and address the suggestion effectively. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with Zemel et al. (2013) could be made more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and actionable suggestion for enhancing the paper\"s analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or which aspects to focus on. Overall, the feedback is 4 as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete steps on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the comparison to the computer vision method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to a specific method from the computer vision setting, which would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or table. This makes it difficult for the authors to identify the exact area where the suggestion should be applied. Additionally, the comment lacks specificity in detailing what aspects of the comparison would be more useful or how the adaptation to language tasks could be achieved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the suggested comparison would be more useful. The authors are left to infer the potential benefits of this comparison, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. This feedback provides a clear direction for the authors to consider a more relevant comparison, which could enhance the paper\"s utility and relevance. However, the comment could be more helpful if it offered specific examples of the methods from the computer vision setting or detailed guidance on how to adapt them for language tasks. Overall, the comment is 4 as it directs the authors towards a potentially more effective comparison, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove the scalability properties. This is a clear and direct action that provides the authors with a specific task to perform. The comment also specifies what needs to be done, making it 5. The authors know exactly how to address the feedback by estimating the time complexity, which is a concrete step towards improving the scalability analysis of the learning algorithm.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is estimating the time complexity to prove the scalability properties. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be estimated to prove the scalability properties. However, the comment does not provide any reasoning, examples, or references to support why this estimation is necessary or how it would impact the scalability. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be estimated to prove the scalability properties. This feedback is clear and actionable, providing the authors with a concrete step to take in order to enhance the scalability analysis of their learning algorithm. By estimating the time complexity, the authors can demonstrate the scalability of their approach, which is a critical aspect for practical applications. However, the comment could be more helpful if it offered additional guidance on how to estimate the time complexity or provided examples of similar approaches. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this connection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection to properties of universal kernels and references a specific chapter for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This provides a clear and specific reference to external literature that could support the claim, making the comment 4. However, the comment could be strengthened by including a brief explanation of why this connection is relevant or how it could impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This feedback is 3 as it prompts the authors to consider a potential connection that could enhance their work. However, it lacks depth and does not provide specific guidance on how to explore this connection or why it might be relevant. The comment could be more helpful with additional context or suggestions on how to integrate this information into the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion around equation (10) is very brief and not wellexplained. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the explanation or what specific aspects need clarification. Without actionable advice or suggestions, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment does not specify what is unclear or missing in the discussion around equation (10), leaving the authors without guidance on how to improve it. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is very terse and not wellexplained. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is very brief and not wellexplained. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity and depth of their explanation. However, the comment could be more helpful if it provided suggestions on how to enhance the explanation or what specific aspects need further elaboration. Overall, the comment is 4 as it highlights a specific area for improvement but lacks detailed guidance."}
