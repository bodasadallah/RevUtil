{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. It implies that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the dataset used in the study, specifically mentioning that it is artificially created and may contain noise, such as misinformation or outofcontext images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment does not specify which part of the paper discusses the dataset or the analysis, making it weakly grounded. The authors can infer that it relates to the dataset section, but this inference is not explicit. The comment is specific in detailing the issue with the dataset quality and the need for further analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. The reviewer suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment lacks specific examples or references to support the claim about the dataset\"s noise, making it difficult for the authors to fully understand and address the issue. The suggestion for more analysis is clear, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the study, noting that it is artificially created and may contain noise, such as misinformation or outofcontext images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. This feedback is 3 as it points out a critical aspect of the dataset that could impact the study\"s validity and suggests a direction for further investigation. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or examples of how to measure the noise in the dataset. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not delve into the theoretical aspects of the proposed algorithm, specifically the convergence properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting the inclusion of theoretical analysis or references to relevant literature. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of theoretical analysis, specifically the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the theoretical section, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. This feedback is valuable as it highlights an area where the authors can enhance the depth and rigor of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending relevant literature or methods to explore the convergence properties. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While the comment implies that the authors should explain their rationale for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in questioning the selection process and its impact on the results, but without explicit grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not provide any supporting evidence, reasoning, or examples to justify why this selection might affect the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it identifies a specific area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. The comment lacks depth and actionable feedback, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as 2, as it provides some insight but does not offer meaningful guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. It does not explicitly instruct the authors to provide this explanation, but it does imply that they should include a supporting explanation. The action is implicit, as the authors can infer that they need to clarify the purpose of the average duration, but it lacks concrete details on how to implement this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and requests an explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the purpose of the average duration reported in Table 1, without any claim or suggestion that requires verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. This feedback is 3 as it prompts the authors to clarify the meaning and context of the reported duration, which could be important for understanding the results or methodology. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what additional information might be needed. To be more helpful, the comment could suggest including a detailed explanation or justification for the reported duration in the table. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. This is a direct request for additional information, providing the authors with a clear action to take. The comment is explicit and concrete, as it specifies exactly what information is needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the splits used for obtaining the ATIS numbers. The comment provides a direct request for additional information, which is clear and specific. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any claims, opinions, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper that requires clarification, namely Table 4. It asks for more information about the splits used for obtaining the ATIS numbers, which is a direct and actionable request for additional details. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or presentation of the information. While it prompts the authors to address a specific issue, it does not offer comprehensive guidance or insights that could enhance the draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the overall appearance and readability of the tables. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to correct the formatting or improve the tables\" appearance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the presence of spaces between accuracy and standard deviation in some items but not in others, which affects the appearance and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the appearance and readability of the tables. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this issue is problematic or how it impacts the overall quality of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting the presence of spaces between accuracy and standard deviation in some items but not in others. This observation is relevant as it affects the appearance and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting style or offering alternative solutions. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights a potential issue but lacks depth and actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of novelty in the paper\"s contribution, noting that adversarial attacks by perturbing text have been done on many NLP and imagetext models. It suggests that the only new effort is applying similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects they should focus on to differentiate their contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of novelty in the paper\"s contribution, specifically mentioning adversarial attacks by perturbing text on NLP and imagetext models. It highlights that the only new effort is applying similar ideas to videotext models. However, the comment does not specify which part of the paper discusses the novelty or lack thereof, making it weakly grounded. The comment is specific in identifying the issue of lack of novelty and suggesting that the paper lacks originality in its approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty due to the similarity of adversarial attacks by perturbing text on NLP and imagetext models, which have been previously explored. The comment provides a logical reasoning by referencing the related work section of the paper, suggesting that the only new effort is applying these ideas to videotext models. However, the comment lacks specific examples or references to the related work, making it 3. The authors would need to explore the related work section to fully understand the claim, which adds a layer of complexity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper\"s contribution, noting that adversarial attacks by perturbing text have been explored in NLP and imagetext models. It suggests that the only novelty lies in applying these ideas to videotext models. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or differentiate it from existing research. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by dedicating separate paragraphs to each of the lexical and sentencelevel features. This provides a clear and direct action for the authors to take, which is to reorganize the section to improve clarity. The suggestion is concrete, as it specifies the action of adding separate paragraphs, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current organization of the section, suggesting that more separate paragraphs should be dedicated to each of the lexical and sentencelevel features to improve coherence. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested changes would improve clarity. Without additional context or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are somewhat intertwined and confusing. It provides a clear and actionable suggestion to improve the coherence of the section by dedicating separate paragraphs to each of the lexical and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and organization of their paper, making it 4. However, it could be more helpful if it included specific examples of how the current organization is confusing or suggestions on how to restructure the section. Overall, the comment provides a solid foundation for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be a lot of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the paper. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the amount of space dedicated to fleshing out the assumptions, specifically mentioning that it is a \"whole section of the paper plus experimental results.\" This provides some grounding as it indicates a specific part of the paper being discussed, but it does not specify which section or table this refers to, making it weakly grounded. The comment is specific in its critique of the amount of space dedicated to the assumptions, but it lacks detailed guidance on how the authors might address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the amount of space dedicated to fleshing out assumptions, suggesting that it is a \"lot of space.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is considered excessive. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be excessive. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this concern or improve the presentation of their assumptions. Without additional guidance or examples, the authors are left without a clear direction for improvement. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency mentioned, specifically regarding the evaluation with gold answers being inconsistent with human evaluation. While the comment implies that an example should be given, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to provide an example, but it lacks concrete details on how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by suggesting that an example of the inconsistency mentioned in the abstract should be given. This feedback is detailed and actionable, providing a clear direction for the authors to enhance their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract could be improved by providing an example of the inconsistency mentioned regarding the evaluation with gold answers being inconsistent with human evaluation. However, the comment does not provide specific examples or detailed reasoning to support the claim that such an inconsistency exists or how it affects the evaluation. This lack of detailed justification makes the claim 3, as the authors would need to infer the nature of the inconsistency themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and intriguing, which is a positive observation. However, it suggests that the abstract could be improved by providing an example of the inconsistency mentioned regarding the evaluation with gold answers being inconsistent with human evaluation. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address this issue. The feedback is 3 as it highlights a potential weakness but does not offer comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN. It also questions how the stable points in probabilistic metric space are obtained, implying that this information is crucial for readers to understand and replicate the results. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to include more detailed discussions, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more detailed explanations on the convergence process and the derivation of stable points. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. This feedback is 3 as it identifies a gap in the paper\"s explanation, which could be crucial for readers to understand and replicate the results. However, the comment lacks specific guidance on how to address this issue or what aspects of the convergence process should be discussed. To be more helpful, the comment could provide examples or references to similar works that address this topic, offering a clearer path for the authors to improve their draft. Therefore, the comment is rated as 3, as it points out an area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2. The comment also raises a question about why \"latent in verbs\" is not mentioned in the context of objects. These actions are clear and concrete, giving the authors a specific set of tasks to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). The comment further clarifies the need to use consistent terminology for the model in Tables 1 and 2 and questions the absence of \"latent in verbs\" in the context of objects. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests and suggestions for the authors to improve their paper. It does not contain any subjective opinions, claims, or judgments that require verification. The comments are factual and descriptive, making them \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback to the authors, guiding them on how to improve their paper. It explicitly instructs the authors to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, which is a valuable piece of advice for clarity and coherence. The comment also raises a question about the absence of \"latent in verbs\" in the context of objects, prompting the authors to consider this aspect in their discussion. This feedback is clear, detailed, and provides concrete steps for improvement, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific error in the sentence at line 212, suggesting that the correct way to describe the process is to use a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is explicit and provides a clear action for the authors to take, which is to correct the sentence to accurately reflect the process described in Figure 2. The comment is concrete, as it specifies the exact sentence to be revised and the correct way to describe the process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sentence is not strictly correct and suggests a more accurate description involving a bidirectional encoder. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a more accurate description involving a bidirectional encoder. The reviewer provides a specific correction, \"do a bidirectional encoder that encodes the source sentence into a set of vectors,\" which is a clear and logical suggestion. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to verify the accuracy of the correction themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific error in the sentence at line 212, suggesting that the description of the process is not accurate. It provides a clear and actionable correction by recommending that the sentence should describe the process as a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is valuable as it helps the authors improve the accuracy and clarity of their description, which is crucial for understanding the methodology. However, the comment could be more helpful if it explained why this correction is important or provided additional context on the significance of the bidirectional encoder. Overall, the comment is 4, as it guides the authors toward a more precise and accurate description, but it could be further enhanced with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional baselines, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this extension is discussed in, making it difficult for the authors to identify the exact section that needs further development. The comment is specific in suggesting additional baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support why these additional baselines are necessary or how they would enhance the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment identifies a potential area for improvement by suggesting additional baselines, it lacks specific guidance or examples on how these baselines should be incorporated or what benefits they might offer. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is an explicit and concrete suggestion, as it provides a clear action for the authors to take. It specifies what needs to be changed and how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the yaxis label, suggesting that it should use \"Exact Match ratio\" directly. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a specific change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio.\" This is a factual statement that does not express an opinion, judgment, or suggestion. It does not require any verification or evidence, as it is a straightforward request for a change in labeling. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the labeling of the yaxis in Figure 5. It recommends using \"Exact Match ratio\" directly, which is a clear and direct improvement to the clarity and accuracy of the figure. This feedback is valuable as it helps the authors enhance the presentation and interpretation of their results, making the comment 4. However, it could be more helpful if it included additional context or reasoning about why \"Exact Match ratio\" is more appropriate. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of the reasoning chains in addressing implicit offensive texts. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what specific steps to take to address the concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses two main points: the absence of information regarding societal biases in the knowledge bases and the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the lack of information on societal biases and the example provided in Fig., but it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of Fig. suggests that the example is related to the effectiveness of reasoning chains, but without further details, the claim remains vague. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises two concerns: first, it questions whether the knowledge bases used are free from societal biases, and second, it expresses skepticism about the effectiveness of reasoning chains in addressing implicit offensive texts, using Fig. as an example. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it points out areas for consideration but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to demonstrate that something, such as attention in a seq2seq multitask learning (MTL) model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to improve its performance. While the comment implies that the authors should investigate the reasons for failure and make necessary changes, it does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the difficulty of demonstrating that attention in a seq2seq multitask learning model is not working and suggests that the value lies in understanding why it fails and making changes to the attention mechanism. However, it does not specify which part of the paper this discussion pertains to, making it weakly grounded. The comment is specific in its suggestion to understand why attention fails and make changes to the mechanism, but without grounding, the authors cannot confidently identify the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something, such as attention in a seq2seq multitask learning model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism. This claim is 3 as it provides a logical reasoning that aligns with common knowledge in the field. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the difficulty in demonstrating that attention in a seq2seq multitask learning model is not working, but it emphasizes the importance of understanding why it fails and making changes to the attention mechanism to improve its performance. This feedback highlights a critical aspect of the paper\"s analysis and suggests a direction for improvement. However, the comment lacks specific guidance or actionable steps for the authors to take, such as identifying potential causes of failure or suggesting methods to enhance the attention mechanism. While it provides a valuable insight, the feedback could be more helpful with additional details or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning MCNC and suggesting that the paper should include more baselines like those in 1. However, the comment does not provide explicit guidance on how to address this issue or what specific baselines should be included. The action is implicit and somewhat vague, as the authors can infer that they need to add more baselines, but they are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the lack of strong baselines in MCNC and suggests including baselines from a specific reference, 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 3 lacks strong baselines, specifically mentioning MCNC and suggesting that the paper should include more baselines like those in 1. However, the comment does not provide specific examples or detailed reasoning to support why these baselines are missing or why they are important. The suggestion to include more baselines from 1 is a logical response to the claim, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3, as it provides a basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, particularly those mentioned in 1. It suggests that the paper should include more baselines to provide a comprehensive comparison. While the comment highlights an important area for improvement, it does not provide detailed guidance on which specific baselines should be included or how they should be integrated into the table. This limits the comment\"s helpfulness, as it offers a clear direction but lacks depth and specificity. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on supplemental space to contain the paper, noting that this makes the paper less independent. It specifically mentions references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the paper more independent, but the comment does not offer concrete steps or examples of how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reliance on supplemental space to contain the paper, specifically mentioning references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. This provides some grounding as it allows the authors to identify the relevant sections of the paper, but it does not specify exactly what needs to be addressed or improved. The comment is specific in pointing out the issue with the reliance on supplemental space, but it lacks detailed guidance on how to resolve it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, making it less independent. This claim is 3 as it points out specific references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the extent of the issue and how it affects the paper\"s independence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s reliance on supplemental space to contain certain content, such as figures and details of the span vs. sentence investigation. This highlights a potential problem with the paper\"s independence and comprehensiveness. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as recommending ways to integrate the supplemental content into the main text or providing alternative solutions. While it points out a critical area for improvement, the feedback is incomplete and does not offer detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed set of questions that the authors should address to improve their draft. It explicitly instructs the authors to describe the traits of the experts, justify the need for expert annotation, and provide context on whether the experts were linguistic or domain experts. The comment also asks about the differences between expert and nonexpert annotation and whether it introduced linguistic challenges. These questions are clear and specific, guiding the authors on what information to include and how to address the points raised. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and addressing differences between expert and nonexpert annotation. The comment also raises questions about linguistic challenges introduced by expert annotation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts and the necessity of expert annotation, suggesting that the authors should provide more context. However, it does not provide specific examples or references to support the claim that expert annotation is necessary or how it differs from nonexpert annotation. The comment lacks detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to provide additional information or references to fully address the reviewer\"s concerns.", "helpfulness_rationale": "The review comment provides a detailed set of questions that the authors should address to improve their draft. It prompts the authors to describe the traits of the experts and justify the need for expert annotation, which is crucial for understanding the methodology and its implications. The comment also raises questions about the expertise of the annotators and whether their annotation introduces linguistic challenges, which are important considerations for the validity of the study. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the feedback is 4 as it guides the authors in improving their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these examples. The action is implicit and somewhat vague, as the authors need to infer that they should include examples of the system in action. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, which implies that it addresses the methodology or results section of the paper. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples of the system on actual texts, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific examples or reasoning to support why this would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, as it does not offer a clear explanation or evidence for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific suggestion for improving the paper by offering more concrete examples of the system in action. However, the comment lacks depth and does not provide detailed guidance on how to incorporate these examples or what specific aspects of the system should be highlighted. While it offers a direction for improvement, it does not fully address the authors\" needs for enhancing the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or what aspects of these claims need further analysis. Without explicit guidance on which claims to focus on or how to conduct the analysis, the authors are left without a clear understanding of what actions to take. The comment lacks both specificity and directness, making it 1.", "grounding_specificity_rationale": "The comment suggests that certain claims in the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or what aspects of these claims need further analysis. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment does not provide any guidance on how to conduct this analysis or what specific issues should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that certain claims in the paper would benefit from more indepth analysis, but it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand which claims need further analysis or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide examples of what aspects of these claims need further analysis. Without specific guidance or examples, the authors are left without actionable feedback on how to improve their draft. The comment lacks depth and clarity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer suggests that the paper is misleading and would have preferred a deeper exploration of these topics. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to study these hypotheses. The action is implicit and vague, as the authors are left to infer that they need to conduct further research or analysis on the hypotheses. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the hypotheses, noting that they are not tested as given but are valuable in their underlying ideas. The comment further highlights that the paper does not study these hypotheses and suggests that it is misleading and would have preferred a deeper exploration of the topics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer finds this misleading and suggests that the paper should go deeper into these topics. However, the comment does not provide specific examples or references to support the claim that the hypotheses are not tested as given or that they should be studied further. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s hypotheses regarding multilinguality and country/languagespecific bias, noting that they are not studied or discussed again after being raised in lines 078086. The reviewer finds this misleading and suggests that the paper should go deeper into these topics, at least to some extent. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s analysis and provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific aspects of the hypotheses could be explored further. Overall, the comment is 4 as it directs the authors\" attention to a significant area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of feature engineering and suggests that using the same feature set as Uto et al. (2020) could improve the results. While the comment implies that the authors should consider feature engineering, it does not explicitly instruct them to do so or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore feature engineering and potentially follow up with Uto et al. (2020) for more details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of feature engineering and references Uto et al. (2020) as a system that achieves a QWK of 0.801 with handcrafted features. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in suggesting that using the same feature set as Uto et al. (2020) could improve the results, but without explicit grounding, it remains weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of feature engineering and references Uto et al. (2020) as a system that achieves a QWK of 0.801 with handcrafted features. This provides a specific example of a system that could potentially improve the results of the current work. However, the comment does not offer detailed reasoning or evidence to support the claim that feature engineering would be beneficial or how it could be implemented. The reference to Uto et al. (2020) provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of feature engineering and references a specific study (Uto et al., 2020) that achieved a QWK of 0.801 using handcrafted features. This suggests that the authors might consider using a similar feature set to improve their results. However, the comment does not provide detailed guidance or suggestions on how to implement feature engineering or what specific features might be beneficial. While it identifies an area for potential improvement, the feedback lacks depth and actionable advice, making it 3. The authors are given a direction to explore but are left without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the use of the Challenge Set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the methodology or experimental setup. The authors can infer that it relates to the sections discussing the experimental setup or the use of the Challenge Set. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in its inquiry about the use of the Challenge Set, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. The comment does not contain any subjective claims or opinions, making it a factual statement that requires clarification. It does not express an opinion, judgment, or suggestion that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. This feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, it lacks depth and does not provide specific guidance on how the authors might address this issue or improve their draft. The comment could be more helpful if it offered suggestions or examples of how to clarify the use of the Challenge Set. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of \"knowledge\" in the context of constituent parse and suggests that it might be misleading. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their claims. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model generalizes to different knowledge,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the representation of substructure as a sequence of words and suggesting that the term \"knowledge\" might be misleading. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" in the context of constituent parse, suggesting that it might be misleading. However, the comment lacks specific examples or references to support the claim that the model does not generalize or that the term \"knowledge\" is misused. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is categorized as 3, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a concern about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" in the context of constituent parse, suggesting that it might be misleading. The comment provides a clear critique of the terminology and its implications, which could help the authors clarify their claims and improve the clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided alternative terminology that could be used. Overall, the comment is 3 as it identifies a potential issue but lacks depth in terms of actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It suggests that the authors should provide a better understanding of the gap between the performance of the clustering approach and the oracle GAP for PPDBClus. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance gap and its implications, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"124126\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the concern about the relatively poor performance on nouns, the contradiction with the claim of generalizability, and the need for a better understanding of the gap between the clustering approach and the oracle GAP for PPDBClus. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim of generalizability. The comment provides logical reasoning and specific examples to support the claim, making it 4. However, it could be strengthened by providing more detailed comparisons or references to other clustering approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific concern about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, based on the observed performance gap. This feedback is clear and actionable, as it directs the authors to address the performance issue and clarify the generalizability claim. However, the comment could be more helpful if it provided suggestions on how to improve the performance or address the generalizability issue. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify why the new model is better than MH. This is a clear and direct action, giving the authors a specific task to perform. The comment also specifies what needs to be addressed, making it 5. The authors know exactly what information is needed to improve their draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is its abstract nature and the lack of clarity on why the new model is better than MH. The request for examples of spurious structures provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is abstract and lacks clarity on why the new model is better than MH. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or explanation to fully substantiate the assertion that the discussion is abstract or lacks clarity. As a result, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks clarity on why the new model is better than MH. It provides a clear and actionable suggestion by asking the authors to provide examples of spurious structures. This feedback is helpful as it directs the authors to a specific area for improvement, offering a concrete way to enhance the clarity and understanding of their work. However, the comment could be more helpful if it included additional guidance or examples of what constitutes spurious structures. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the comment explicitly states the action to be taken, it does not provide detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be considered. The authors are aware of the action but may need additional information to fully execute it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the discussion or experimental setup involving PCFGs. The authors can infer that it relates to the sections where PCFGs are discussed or used in the experiments. The comment is specific in suggesting a particular baseline and the comparison to be made, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a baseline PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the suggestion is logical and provides a clear rationale for the proposed baseline, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors are left to infer the potential benefits of this suggestion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding a baseline PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. This suggestion aims to provide a more controlled comparison by ensuring that the baseline and the original PCFG have similar state sizes, which could affect the parsing F1 score. However, the comment notes that parsing F1 might not be directly comparable under this setting, but perplexity can still be compared. This feedback is 3 as it offers a potential method for improving the experimental setup and comparison, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be considered. The authors are aware of the action but may need additional information to fully execute it, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While the action is explicit, it lacks concrete details on how this information should be presented or integrated into the paper. The authors know that they need to provide this information, but the comment does not specify where or how it should be included. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the maximum number of tasks done by any annotator. This provides clear guidance on what additional information should be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning, evidence, or examples to support why this information is important or how it could impact the paper. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While this is a specific piece of information that could enhance the transparency and completeness of the paper, it does not provide any context or reasoning as to why this information is important or how it could impact the analysis or interpretation of the results. The feedback lacks depth and does not offer actionable guidance on how to incorporate this information into the paper. Therefore, it is rated as 2, as it provides a suggestion but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is an explicit action that the authors can take to improve their draft. The comment provides a clear and concrete suggestion, specifying what needs to be added to the table. This level of detail and directness makes the action 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. While it does not explicitly mention a specific table, the authors can infer that it is referring to Table 1, which is mentioned in the context. The comment is specific in its suggestion to include the hard prompt baseline, providing a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. This is a request for additional information, not a claim or opinion. It does not contain any subjective judgment or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is a clear and actionable suggestion that provides the authors with a specific way to enhance their draft by adding relevant information. By following this advice, the authors can improve the comprehensiveness and utility of their results, making the comment 5. However, it could be more helpful if it provided additional context or reasoning about why including the hard prompt baseline is important. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. While the comment implies that the authors should include numerical results to demonstrate the method\"s effectiveness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include them. This makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not reference specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and the application of the method to popular algorithms. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement seeking clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a significant gap in the paper by noting the absence of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy (DP) algorithms. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a missing element but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for empirical evidence, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is 3 as it identifies a specific area where the authors need to provide additional evidence to strengthen their claims. However, the comment lacks depth and does not offer guidance on how to collect or present this evidence, leaving the authors with a general direction but no detailed steps to follow. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could consider to improve the scalability of their approach. As a result, the authors are left without a clear understanding of what changes or considerations are needed to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding the exact nature of the issue or how it could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a logical deduction but lacks detailed justification or references to external works that could substantiate the claim. As a result, the comment is considered 2, as it provides some reasoning but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback is 3 as it identifies a potential limitation of the approach and provides a specific area for improvement. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or explore alternative approaches. To be more helpful, the comment could include specific recommendations or examples of how to mitigate the scalability problem. Therefore, the comment is rated as 3, as it provides a starting point for the authors to consider but does not fully support their efforts to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not. While the comment implies that this distinction should be made, it does not explicitly instruct the authors to do so or provide specific guidance on how to implement this distinction. The action is implicit and somewhat vague, as the authors need to infer the need for this distinction and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates to the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. However, the comment does not provide detailed reasoning or examples to support why this distinction is necessary or how it would improve the paper. The mention of specific works provides some context, but the lack of detailed justification or explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. This feedback is 3 as it identifies a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide specific guidance on how to implement this distinction or why it is important. The authors are left with a general suggestion but without detailed instructions on how to apply it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used for training the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their conclusion. The action is implicit and vague, as the authors are left to infer that they need to investigate the data discrepancy and possibly reevaluate their conclusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the amount of data used for training the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the issue with the conclusion, but without full grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the amount of data used for training the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed comparisons or statistical analysis. The lack of supporting details or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is the better of the two proposed systems, given the small difference in performance and the discrepancy in the amount of data used for training. It raises a valid concern about the reliability of the conclusion based on the data used. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important point, the feedback is 3 as it prompts the authors to consider the impact of data size on their results but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the paper: the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation. It explicitly states that the paper does not provide evidence or justification for GaRare\"s advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is explicit and provides concrete actions for the authors to take, such as providing theoretical justification and enhancing the algorithmic presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide a clear motivation for using GaRare and lacks evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for a more detailed algorithmic presentation is somewhat vague, as it does not specify what aspects of the algorithm should be clarified. Therefore, the comment is 3, as it provides some guidance but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the paper does not provide a clear motivation for using GaRare, suggesting that it lacks evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable, as it directs the authors to provide a more robust theoretical foundation for their choice of method. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it guides the authors to enhance the clarity and comprehensiveness of their methodology. Overall, the comment is 4 as it provides clear and actionable feedback that can significantly improve the draft. However, it could be more helpful if it offered specific examples or suggestions for how to address these issues, which would make it fully comprehensive. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions the performance of the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This provides a clear and explicit action for the authors to take, which is to conduct the ablation study and report the results. The comment also offers a specific example of what to investigate, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"visDial dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting an ablation study on the visDial dataset and asking for the result of a specific experiment involving the \"ATT(+H)\" model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4. While the comment provides a clear suggestion for additional analysis, it lacks detailed reasoning or evidence to fully substantiate the need for this ablation study. The mention of a specific experiment in Figure 4 provides some context, but the comment does not explain why this particular experiment is important or how it would contribute to the validation of the model. Therefore, the claim is 3, as it offers a suggestion but lacks comprehensive justification or evidence.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct an ablation study on the visDial dataset to further validate their proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This feedback is 5 as it directs the authors to a specific area for improvement and provides a clear path for enhancing the robustness of their findings. By addressing this suggestion, the authors can strengthen their paper\"s contribution and provide a more comprehensive evaluation of their model\"s performance. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It also questions the lack of insights into how WPA works, which could be crucial for future research directions. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the model\"s predictions with np.ones input and why Gaussian noise input does not work as well as WPA. The comment further suggests that the authors should provide more insights into how WPA works, which could spark future research directions. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It questions the lack of insights into how WPA works, which could be important for future research directions. However, the comment does not provide specific examples or references to support the claim that Gaussian noise input does not work as well as WPA. The reasoning is based on the observation that Figure 2 suggests this, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by questioning the lack of explanation for why WPA works, particularly with np.ones input. It suggests that the authors should provide insights into this, which could be crucial for future research directions. The comment also points out the discrepancy between the effectiveness of WPA with np.ones and Gaussian noise inputs, prompting the authors to address this issue. While the comment highlights important areas for improvement, it could be more helpful if it provided specific suggestions or examples on how to explain WPA\"s workings or address the discrepancy. Overall, the feedback is 4 as it directs the authors to a critical area for clarification and potential enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It requests more clarification on this similarity. While the comment implies that the authors should provide additional details or context to address this similarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is found in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its request for more clarification on the similarity, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It requests more clarification on this similarity. While the comment identifies a potential overlap, it does not provide specific details or examples of where this similarity exists, nor does it offer suggestions on how the authors might address or clarify this issue. This lack of depth and actionable guidance limits the comment\"s helpfulness, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) whether the proposed method is fairly compared with other methods, and (2) whether the proposed technique promotes existing Class incremental semantic segmentation methods. While the questions imply that the authors should consider these aspects in their evaluation, they do not provide explicit guidance on how to address these concerns. The comments are vague and lack concrete suggestions for improvement, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions about the proposed method: (1) whether it is fairly compared with other methods, and (2) whether it promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address these questions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions regarding the fairness of comparison with other methods and the promotion of existing Class incremental semantic segmentation methods. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the fairness of comparison with other methods and the promotion of existing Class incremental semantic segmentation methods. While these questions are relevant and could prompt the authors to consider these aspects in their evaluation, the comment lacks specific guidance or suggestions on how to address these concerns. It does not provide actionable feedback or detailed advice on how to improve the draft, leaving the authors with a general sense of what might need attention but without clear steps to take. Therefore, the comment is 3, as it identifies areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental section (Sec. 3) does not discuss how the minimum cluster size and conductance threshold parameters are set, nor does it address the sensitivity of performance with respect to these parameters. This provides a clear and direct action for the authors to take, which is to include this information in the experimental section. The comment is explicit and concrete, guiding the authors on exactly what needs to be added or clarified in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 2.\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on how the minimum cluster size and conductance threshold parameters are set and how sensitive the performance is with respect to these parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the minimum cluster size and conductance threshold parameters are set, nor does it address the sensitivity of performance with respect to these parameters. This is a factual statement that does not require verification, as it is based on the observation that the information is missing from the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the lack of discussion on how the minimum cluster size and conductance threshold parameters are set, as well as the sensitivity of performance with respect to these parameters. This feedback is clear and actionable, as it directs the authors to include this information in their experimental section. By addressing this gap, the authors can provide a more comprehensive understanding of their experimental setup and results. However, the comment could be more helpful if it suggested how to present this information or provided examples of how other studies have handled similar parameters. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a personal belief about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it may make the approach less data efficient and harder to train models using gradient descent. However, it does not specify which part of the paper this critique pertains to, nor does it provide detailed guidance on how the authors might address this issue. The lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to improve it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a personal opinion rather than logical reasoning or external references, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less data efficient and harder to train models using gradient descent. However, it does not provide any specific evidence, examples, or reasoning to support this claim. Without detailed analysis or suggestions for improvement, the comment lacks actionable feedback for the authors to address the issue. As a result, the comment is not helpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. The reviewer suggests that the authors should discuss the relationship between their proposed method and ResNeSt, as this could provide a clearer understanding of the novelty. However, the comment does not explicitly instruct the authors to discuss this relationship or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the relationship with ResNeSt. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, suggesting that it is too similar to other attentional modules proposed in previous works. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely discussing the relationship between the proposed method and ResNeSt. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules proposed in previous works. It provides references to specific works (1, 2, 3) and mentions ResNeSt as a related design. However, the comment lacks detailed reasoning or specific examples of how the proposed method is similar to these works, making it 3. The authors would need to delve deeper into the references and the proposed method to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. The comment provides a clear direction for improvement by suggesting that the authors should discuss the relationship between their proposed method and ResNeSt, which could enhance the paper\"s novelty and differentiation. However, the comment could be more helpful if it offered specific suggestions on how to discuss this relationship or provided examples of how to address the issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It also questions how to prove that data processing is superior to model parameter adjustment. While the comment implies that a comparison should be made based on experimental results, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and understand how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It questions how to prove that data processing is superior to model parameter adjustment. However, the comment does not specify which part of the paper should include this comparison or where the discussion of data processing and model parameter adjustment is located. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique, it lacks full grounding as it does not point to a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It questions how to prove that data processing is superior to model parameter adjustment. While the comment provides a logical basis for the claim by mentioning the relevance of TTA methods, it lacks specific examples or references to support the comparison or the argument about superiority. This makes the claim 3, as it provides a direction for the authors to consider but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, such as AB. It questions how the paper can prove that data processing is superior to model parameter adjustment, suggesting that a comparison based on experimental results would be beneficial. This feedback is clear and actionable, as it directs the authors to include a comparison with TTA methods to strengthen their argument. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, specifying that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides a clear and direct action for the authors to take, namely to correct the expression. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J(\u03b8), suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This is a factual statement that does not require verification, as it is a matter of correcting a specific mathematical expression. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific error in the mathematical expression for J(\u03b8) in Section 3.2.1, suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This feedback is clear and actionable, providing the authors with a direct correction to make. By highlighting this error, the comment helps the authors improve the accuracy and clarity of their work. However, it could be more helpful if it explained why this correction is necessary or provided additional context on the importance of the expression. Overall, the comment is 4 as it guides the authors in making a specific and impactful improvement to their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should correct the capitalization of various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and explicit action that the authors can take to improve the formatting of their references. The second part of the comment provides specific examples of references that need capitalization, which further clarifies the action. The second part of the comment is 3, as it suggests a specific correction but does not provide detailed guidance on how to apply it. Overall, the comment is 4 due to the explicit and concrete actions provided in the first part.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.8,\" \"p. 13, supplement, Fig,\" and references, allowing the authors to accurately identify the sections being addressed. It is also specific because it provides detailed feedback on the capitalization of words in the references and suggests corrections for specific examples, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This level of detail helps the authors understand what needs to be addressed and how to make the necessary corrections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests capitalization corrections for specific words in the references, which is a clear and explicit action. The second part provides specific examples of references that need capitalization, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems,\" which supports the claim with detailed examples. This level of detail and specificity makes the claim 5, as it provides clear evidence and examples for the authors to follow. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct aspects of the paper. First, it suggests capitalization corrections for various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and direct way to improve the formatting and consistency of the references, which is an important aspect of academic writing. Second, it points out that \"expensive approaches\" should be corrected to \"expensive approaches,2) allows,\" which is a specific and actionable suggestion for improving the clarity and accuracy of the text. These suggestions are clear and provide the authors with concrete steps to enhance the quality and professionalism of their draft. Therefore, the comment is rated as 5, as it offers valuable guidance for improving the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the parameter values used in the paper, specifically asking for clarification on the model parameters for task 1, the choice of lambda for the Boltzmann policy, and how the parameters were chosen. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, indicating that the authors know what information is missing and how to address it. The request for maximum likelihood estimates adds a concrete detail on how the parameters were chosen, further enhancing the actionability. Therefore, the comment is 4, as it provides explicit guidance on what needs to be clarified and how to address it.", "grounding_specificity_rationale": "The comment raises questions about specific parameter values and their selection, particularly regarding the Boltzmann policy. However, it does not specify which part of the paper these questions relate to, such as a particular section or table where these parameters are discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its requests for clarification on parameter values and their estimation, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific parameter values and their selection, particularly regarding the Boltzmann policy. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the parameter values used in the paper, particularly regarding the Boltzmann policy. It asks for clarification on the model parameters for task 1 and the choice of lambda, as well as how the parameters were chosen. While the comment identifies areas where the paper lacks detail, it does not provide suggestions or guidance on how to address these issues or improve the clarity of the presentation. The feedback is 3 as it highlights gaps in the paper but lacks actionable advice, leaving the authors with a general understanding of what needs to be clarified but without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. However, the comment does not explicitly instruct the authors to perform these comparisons or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons to strengthen their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate this claim. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the results section or the discussion, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the need for comparisons with existing detection methods to substantiate the claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the authors\" claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. The reviewer suggests conducting comparisons with existing detection methods to validate this claim. However, the comment lacks specific examples or references to support the claim that the performance is solely due to the first step, making it difficult for the authors to understand and address the critique effectively. The reasoning is somewhat vague and lacks detailed evidence, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim of achieving stateoftheart results on scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate this claim. While the comment identifies a potential issue with the claim, it lacks specific guidance or suggestions on how to conduct these comparisons or what aspects to focus on. The feedback is 3 as it points out a potential weakness in the paper\"s claims, but it could be more actionable and comprehensive to be fully beneficial for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model. It specifically asks the authors to provide insight into why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. While the comment implies that the authors should explain this phenomenon, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm (CBN) to different layers, particularly layer 2 in addition to layers 3 and 4, compared to applying it to layers 4 and 3 only. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically questioning why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this observation or suggest why this might be the case. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, particularly in the context of the GuessWhat?! dataset. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 results in a deterioration of performance compared to applying it to layers 4 and 3 only. By asking the authors to provide insight into this observation, the comment encourages them to explore and explain the underlying reasons for this performance change. This feedback is clear and actionable, as it prompts the authors to investigate and potentially address a potential weakness in their model. However, the comment could be more helpful if it included suggestions on how to investigate or resolve the issue. Overall, the comment is 4, as it directs the authors to a specific area for improvement and encourages further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed method. It also highlights the absence of performance comparison. This feedback is clear and direct, providing the authors with a specific action to take: include a comparison with the method proposed in 1 and perform a performance comparison. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lack of comparison with a highly relevant method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a comparison with a method proposed in 1 and the lack of performance comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning 1 as a method that proposes a similar approach. However, the comment does not provide specific details or examples of how the proposed method in 1 is relevant or how it could be compared to the current work. Without this additional context or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2, as it provides a general claim but lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method, specifically mentioning 1 as a method that proposes a similar approach. It highlights the absence of a comparison with this method and the lack of performance comparison. This feedback is clear and actionable, as it directs the authors to include a comparison with the method proposed in 1 and perform a performance comparison. By addressing this gap, the authors can enhance the relevance and impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that it is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to handle headpose. The action is implicit and vague, as the authors are left to infer that they need to explore ways to incorporate headpose conditioning into their NeRF model. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method\"s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF model beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the headpose issue or the proposed method, making it weakly grounded. The comment is specific in detailing the issue and referencing a previous work, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that it is deferred to future work. It references a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, questioning why the proposed method cannot condition the headpose parameters in the NeRF model beyond the facial expression. The comment provides a logical reasoning by comparing the proposed method with a previous work, which supports the claim. However, it lacks specific examples or detailed references to the exact aspects of the proposed method that are problematic, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed method, namely its inability to handle headpose, and notes that this issue is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF model beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. This feedback is 3 as it highlights a potential area for improvement and provides a reference for the authors to consider. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or incorporate headpose conditioning into their NeRF model. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The comment implies that the authors should consider the impact of these rare spurious examples on the trained model. However, it does not explicitly instruct the authors to take any specific action, such as addressing the impact of these triggers or providing a detailed analysis. The action is implicit and somewhat vague, as the authors can infer the need for further investigation but lack concrete guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between spurious features and backdoor triggers, providing examples from previous works. The comment specifies what needs to be addressed, namely the impact of rare spurious examples on the trained model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The claim is supported by logical reasoning and references to external works, providing a clear and robust basis for the assertion. This makes the claim 5, as it is wellsupported by both logical reasoning and external references. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides references to previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers, highlighting the potential impact of rare spurious examples on the trained model. This feedback is 3 as it points out a potential weakness in the paper and provides references for further exploration. However, it could be more helpful if it offered suggestions on how to address this issue or provided additional context on the implications of these findings. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the structural optimization is a main component and has been emphasized several times, but it notes that the optimization algorithm is directly from previous works, which can be confusing and reduces the contribution. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The suggestion to clarify or differentiate the contribution is implicit and lacks concrete details on how to implement these changes. As a result, the authors are left with a vague understanding of what actions to take, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is mentioned several times in the paper, indicating that it is a main component. However, it does not specify which part of the paper this component is discussed in, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is a main component emphasized several times, but it notes that the optimization algorithm is directly from previous works, which is confusing and reduces the contribution. The comment provides a logical reasoning by pointing out the repetition of the structural optimization and the lack of originality in the optimization algorithm. However, it lacks specific references or examples to support the claim, making it 3. The authors would need to infer the exact parts of the paper being discussed, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the structural optimization component, noting that it is emphasized several times but seems to be directly from previous works. This observation highlights a lack of originality, which could be confusing for the reader and potentially reduce the paper\"s contribution. The comment provides a clear and actionable suggestion to clarify or differentiate the contribution, which would help the authors improve the clarity and originality of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to address this issue, such as suggesting alternative approaches or references to differentiate the contribution. Overall, the comment is 4 as it directs the authors\" attention to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment identifies specific issues, it does not provide explicit guidance on how to address these problems or improve the results. The authors are left to infer that they need to enhance the performance of their models or provide a more detailed explanation of the baseline models. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method with two models, noting that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the experiments, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the results and the lack of introduction for baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method with two models does not yield better average results for both XVNLI and MaRVL, and that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipeline style method, noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models in the experiments are not well introduced, which is a critical aspect for readers to understand the context and performance of the models. However, the comment lacks actionable suggestions or guidance on how to improve the method or introduce the baseline models more effectively. While it highlights important areas for improvement, the feedback is 3 as it provides a starting point for the authors to address these issues but does not offer detailed steps or examples for implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not explicitly instruct the authors to do so or suggest specific alternative methods. The action is implicit and somewhat vague, as the authors can infer that they need to improve their methodology but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology section or results, but this is not explicitly mentioned. The comment is specific in its critique of the methodology and the need for improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, referencing the common knowledge that language models reproduce the biases of the corpora on which they are trained. However, the comment lacks specific examples or references to support the claim that the methodology is \"coarse\" or that the observation needs to be made again. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might improve their approach. The feedback is 3 as it points out a potential limitation but does not offer actionable advice for the authors to enhance their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. While the comment implies that the authors should include these comparisons to provide a more comprehensive analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons to enhance their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the discussion or comparison of methods, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting that the authors should include comparisons with these methods, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, the comment does not provide specific examples or references to support the claim that these methods are computationally efficient or come with similar guarantees. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the authors primarily focus on a single method, namely SSC, and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is valuable as it encourages the authors to broaden their analysis and provide a more comprehensive comparison of their method with existing literature. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or what aspects of these methods should be highlighted. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. It suggests that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. This feedback is clear and direct, providing the authors with a specific action to take: removing those statements. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term \"lowlevel\" is not accurate. This feedback is fully grounded as it explicitly mentions the issue with the terminology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the removal of statements about semantic segmentation being a lowlevel cue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. This claim is supported by logical reasoning, as it explains that semantic segmentation involves specifying categories for each pixel, which is a more detailed and specific task than lowlevel cues. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples to fully support the claim. This aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term \"lowlevel\" is not accurate. This feedback is clear and actionable, as it provides a direct suggestion to remove statements about semantic segmentation being a lowlevel cue from the paper. By addressing this point, the authors can improve the clarity and accuracy of their terminology. However, the comment could be more helpful if it provided additional context or suggestions for how to rephrase the statements to better align with the intended meaning. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific weakness in the paper, namely the limited consideration of datasets in the experiments section. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. The comment provides a clear and concrete action for the authors to take, which is to broaden their experimental evaluation to include more datasets and model types. This guidance is explicit and provides a clear path for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the limited consideration of datasets in the experiments section, particularly the lack of datasets from Federated learning benchmarks like LEAF. The comment suggests relevant works for the authors to consider, such as FedProx and FedMAX, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main weakness is the limited consideration of datasets in the experiments section, specifically mentioning the CIFAR10 dataset and suggesting that the authors should consider other datasets from Federated learning benchmarks like LEAF. The comment also references specific works (FedProx and FedMAX) for guidance on different datasets and model types. While the comment provides a logical argument for expanding the dataset evaluation, it lacks specific examples or detailed reasoning about why these datasets are crucial or how they would enhance the paper. The references to FedProx and FedMAX provide some support, but the claim could be strengthened with more detailed justification or evidence. Therefore, the comment is 3, as it offers a reasonable basis for the claim but could benefit from additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experimental evaluation, which is only conducted on the CIFAR10 dataset. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. This feedback is clear and actionable, providing the authors with a concrete direction for improvement by recommending additional datasets and model types to consider. By addressing this feedback, the authors can enhance the comprehensiveness and relevance of their experimental evaluation, making the paper more robust and valuable. Therefore, the comment is 5, as it offers detailed and actionable advice that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim that the proposed modules improve accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. While the comment implies that the authors should consider using different datasets for their ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments with different datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, referencing a table. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This level of specificity allows the authors to understand what needs to be addressed, but the lack of grounding makes it challenging to pinpoint the exact section of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. However, the comment does not provide specific reasoning or evidence to support why the current dataset is insufficient or why the proposed modules might not be as effective as claimed. The suggestion to use different datasets is a logical point, but without further justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This feedback is 3 as it prompts the authors to consider alternative datasets for their ablation study, which could strengthen the evaluation of their proposed modules. However, the comment could be more helpful if it provided specific reasons why the current dataset might not be adequate or detailed suggestions on how to conduct the ablation study with different datasets. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It also points out that Theorems 1 and 2 prove the relationship between GCL and a clearer community structure, but the connection between degree bias and this relationship is not intuitive. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for more explanations regarding how a small degree of bias can be achieved from a clear community structure. It specifically mentions Theorems 1 and 2, which are relevant to the discussion, providing full grounding. The comment also specifies what needs to be addressed, namely the lack of intuition in the relationship between degree bias and the community structure. This makes the comment 5, as it clearly identifies the parts of the paper and the issue that needs attention. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which are presumably part of the paper, but does not provide specific details or examples to support the claim. The comment suggests that the relationship between degree bias and the community structure is not intuitive, but it lacks detailed reasoning or evidence to substantiate this claim. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which are presumably part of the paper, but does not provide detailed feedback on how these theorems could be better explained or how the relationship between degree bias and the community structure could be made more intuitive. While the comment highlights an important aspect that needs clarification, it lacks specific suggestions or guidance on how the authors might address this issue. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect in their paper, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it points out a potential area for clarification but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 182183\" and \"Figure 2.c,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. By addressing this question, the authors can improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the comment is 4 as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It explicitly asks for quantitative results on testing images, providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies what additional information is needed to strengthen the evaluation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the evaluation on transformations of training images and requests quantitative results on testing images. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It requests quantitative results on testing images to provide a more robust evaluation. While the comment raises a valid concern, it lacks specific examples or references to support the claim that transformations of training images are insufficient. The request for quantitative results on testing images provides some direction, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It suggests that the authors should provide quantitative results on testing images to strengthen their evaluation. This feedback is clear and actionable, as it directs the authors to a specific area where their work could be improved. By addressing this suggestion, the authors can enhance the robustness and credibility of their findings. However, the comment could be more helpful if it provided additional guidance on how to conduct the evaluation or what specific metrics should be used. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for full comprehensiveness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. The comment implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the stateoftheart. While the comment explicitly states that the paper should be discussed, it does not provide detailed guidance on how to integrate this paper into the draft or what specific aspects should be compared. The action is implicit but concrete, as the authors know what to do but may need some additional direction on how to implement it. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. It implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the stateoftheart. However, the comment does not specify which part of the paper this related work should be discussed in, making it weakly grounded. The comment is specific in suggesting a related work to consider, but without explicit mention of the paper\"s relevance to specific sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, is a related work that was possibly missed by the authors. The comment suggests that this paper deals with hypergraph data and tensors, and it should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment does not provide specific details or examples of how this paper relates to the current work or what aspects should be compared. This lack of detailed justification or examples makes the claim 3, as the authors would need to independently verify the relevance and potential impact of the suggested paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the literature review by suggesting that the authors may have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. The comment highlights that this paper deals with hypergraph data and tensors, which are relevant to the current work. By suggesting that the authors discuss and compare this paper, the comment provides a clear and actionable suggestion for improving the draft. It offers a specific reference that could enhance the authors\" understanding of the stateoftheart in the field. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this paper into the discussion. Overall, the feedback is 4 as it directs the authors to a relevant piece of literature that could enrich their analysis."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It explicitly requests the authors to demonstrate the scalability on normal machines with a couple of cores. Additionally, the comment asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. This feedback is explicit and provides concrete actions for the authors to take, such as demonstrating scalability and explaining the computation of optimal transport. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the scalability of the optimal transport method and questions the authors\" claim about the computation time. It explicitly mentions the \"Approach\" section, allowing the authors to identify the part of the paper being discussed. However, it does not specify which part of the approach is being questioned or what aspects need to be addressed regarding scalability and computation. While the comment is grounded in the \"Approach\" section, it lacks specificity in detailing the exact issues or improvements needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It also asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. While the comment identifies potential issues with scalability and computation, it lacks specific examples or references to support these claims. The reasoning is based on general observations and questions, making it 3. The authors would need to provide additional details or evidence to fully address the concerns raised in the comment.", "helpfulness_rationale": "The review comment raises important questions about the scalability of the optimal transport method and the computation time, which are critical aspects for the authors to address. It points out that while the authors claim the method takes seconds to compute on a 36core machine, it\"s not clear how it scales on normal machines with fewer cores. Additionally, the comment questions the process of computing the optimal transport distance from the doubly stochastic matrix provided by the Sinkhorn method. This feedback is clear and actionable, as it prompts the authors to demonstrate the scalability of their method and clarify the computation of optimal transport. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative approaches for computation. Overall, the comment is 4 as it identifies specific areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of their work. There is no guidance on how to simplify the procedures, clarify the evaluations, or present the information in a more accessible manner. Without specific suggestions or steps, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not specify which sections or parts of the paper are particularly challenging to follow, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance or examples makes it challenging for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references to specific sections or aspects of the paper that are unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, despite multiple readings. However, it does not provide any specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback or detailed examples, the authors are left without a clear understanding of what aspects of the paper need improvement or how to address the issue. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to demonstrate generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the parameters in Table 1 are only applicable to image data and ViT models, suggesting that the authors should consider applying the same principles to other areas such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the method might not generalize to these areas, it does not provide specific examples or references to support this claim. The suggestion is based on a logical assumption about the potential limitations of the method, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate the method\"s generalizability. This feedback is valuable as it encourages the authors to expand their experimental scope and potentially enhance the applicability of their method. However, the comment could be more helpful if it provided specific suggestions or examples of how to adapt the method to these other areas. Overall, the comment is 4 as it identifies a potential limitation and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an interesting observation about the performance of TTA methods on nonstandard benchmarks and suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS 9, could strengthen the paper. While the comment implies that the authors should consider evaluating their methods on additional benchmarks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more conditions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TTA methods, specifically mentioning the observation that using nonstandard benchmarks breaks popular TTA methods. It suggests evaluating TTA on more conditions of natural distribution shift, such as WILDS 9. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation or discussion of TTA methods. The authors can infer that it relates to the experimental results or discussion sections, but the comment does not provide explicit references to specific parts. The suggestion to evaluate TTA on additional conditions is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes a claim about the performance of TTA methods on nonstandard benchmarks, suggesting that it breaks popular TTA methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods on nonstandard benchmarks, noting that it breaks popular TTA methods. It suggests that evaluating TTA on more conditions of natural distribution shift, such as WILDS 9, could strengthen the paper. This feedback is 3 as it points out a potential limitation of the current evaluation and offers a specific direction for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to implement this suggestion or discussed the implications of evaluating TTA on additional conditions. Overall, the comment offers a valuable insight but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the usefulness of the tensor networks in representing the PMF of discrete variables and questions the significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the paper or what specific aspects need clarification. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the usefulness of tensor networks in representing the PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this critique pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area needing improvement. The comment is specific in its critique of the paper\"s significance, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the usefulness of tensor networks in representing the PMF of discrete variables and questions the significance of the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are not useful for machine learning algorithms or the analysis of the algorithm. Without specific examples or detailed explanations, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the usefulness of tensor networks in representing the PMF of discrete variables and questions the significance of the paper. It points out that the results are unclear in terms of their utility for machine learning algorithms or analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the significance of their work. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the lack of experiments on the POMDP problem with nonconvex value functions, specifically mentioning examples like surveillance in museums with thresholded rewards and privacy preserving data collection. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors can infer that more experiments are needed but are not given clear instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experiments on the POMDP problem with nonconvex value functions, particularly in the context of the examples provided. The reviewer questions why there are no experiments on these settings, even in a simulated context, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiments are not useful. The absence of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. This feedback is 3 as it identifies a gap in the experimental validation of the paper\"s claims. However, it could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects of the nonconvex value function should be explored. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It suggests that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it does not explicitly instruct the authors to include this analysis in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion about the potential benefits of epochwise analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to incorporate this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, the comment does not provide specific examples or references to support the claim that epochwise analysis would be beneficial. While the suggestion is logical and could be supported by further evidence, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to implement this analysis or what aspects to focus on. The suggestion is 3 as it points out a potential avenue for enhancing the paper\"s analysis, but it lacks detailed actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the perceived incremental nature of the contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It also suggests that the paper should introduce MedRetriever and KGRAG. However, the comment does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors are left to infer that they need to review and possibly expand their literature review, but the lack of detailed guidance makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code and the article, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the contribution being incremental, the lack of citation of key baselines, and the omission of essential RAG algorithms. The reviewer provides examples of MedRetriever and KGRAG, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental and consists of a combination of GraphRAG and GraphCare. It also points out the lack of citation of key baselines and the omission of essential RAG algorithms. The reviewer provides examples of MedRetriever and KGRAG, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or references to substantiate the claim about the incremental nature of the contribution. Overall, the comment is 4 due to the provision of specific examples and references, but it could be more robust with additional justification.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the perceived incremental nature of the contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It provides specific examples, such as MedRetriever and KGRAG, which helps the authors understand what needs to be addressed. However, the comment could be more helpful if it offered suggestions on how to integrate these references or algorithms into the paper. While it provides valuable feedback, the lack of detailed guidance limits its impact. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This action is clear and direct, providing a specific and concrete step for the authors to take to address the issue of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. The comment also highlights the importance of this analysis and provides a rationale for why it is necessary. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on what specific aspect of the paper needs to be addressed. The comment also specifies the importance of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. The rationale provided explains the importance of this graph in understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the relevance of this analysis in distinguishing between the two factors. However, the comment could be strengthened by providing specific examples or references to support the claim that algorithms skipping layers or channels might have an unfair advantage due to lower resolution. Overall, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This is important for understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the importance of this analysis in distinguishing between the two factors. While the feedback is specific and actionable, it could be more helpful if it included additional guidance on how to interpret the results or what specific insights the graph should provide. Overall, the comment is 4, as it offers clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct, implying that the authors should revise the content to ensure it aligns with mathematical standards. Additionally, it questions the notation \"L_l\" and suggests that it should be introduced beforehand. While the comment implies that changes are necessary, it does not provide explicit instructions on how to make these changes or what specific aspects need to be revised. The action is implicit and somewhat vague, as the authors can infer the need for changes but lack detailed guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"mathematically correct,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the notation \"L_l\" and suggests that it should be introduced beforehand. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct and questions the notation \"L_l.\" However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence to substantiate the need for change, leaving the authors without a clear understanding of what needs to be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical correctness of the text and suggests that it needs to be revised. It also questions the notation \"L_l\" and recommends introducing it beforehand. While the comment highlights areas for improvement, it lacks specific guidance or suggestions on how to make these changes or what aspects of the notation need clarification. The feedback is 3 as it points out areas that need attention but does not provide detailed instructions for improvement, leaving the authors with a general sense of what needs to be addressed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions that this limitation prevents the use of single deep neural networks on homomorphically encrypted data. While the comment emphasizes the need for further research, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this limitation further, but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need to study noise accumulation and its impact on the use of single deep neural networks on homomorphically encrypted data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that it is important to study the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a critical issue. Without specific examples, references, or detailed explanation, the claim remains 1. The authors are left without guidance on how to address this issue or why it is significant, making the comment difficult to act upon. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a critical limitation in the study, specifically the impact of noise accumulation in the context of homomorphic encryption on sequential ensembling. It points out that this limitation prevents the use of single deep neural networks on homomorphically encrypted data, which is a significant concern for the field. However, the comment does not provide specific suggestions or actionable steps for the authors to address this issue, such as proposing alternative methods or approaches to mitigate the effect of noise accumulation. While it identifies a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for consideration but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the action is explicit, it does not provide specific guidance on which regularization trick to use or how to implement it. The comment lacks concrete details on the exact steps to follow, making it 3. The authors know they need to incorporate a regularization trick, but the lack of specific instructions on how to do so limits the level of actionability.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors may infer that it relates to the comparison of complexities or the regularization technique, but this inference is not explicit. The comment is specific in its suggestion to use a standard regularization trick, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the comparison. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the comment identifies a potential improvement in the methodology, it lacks specificity and does not provide detailed guidance on which regularization trick to use or how it would enhance the comparison. The feedback is 3 as it points out a potential area for improvement, but it does not offer actionable steps or detailed suggestions for implementation, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This action is clear and direct, providing the authors with a specific task to perform. The comment also specifies the purpose of this inclusion, which is to determine whether the mean teacher accelerates or slows down learning. This level of detail and specificity makes the action concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the left graph in fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a learning curve for a model without mean teacher or pi regularization for comparison. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This is a request for additional information to provide context for the learning curve presented in the graph. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity and interpretability of Figure 3 by including a learning curve for a model without mean teacher or pi regularization. This addition would help the authors determine whether the mean teacher accelerates or slows down learning, offering a valuable insight into the model\"s performance. The feedback is clear and actionable, guiding the authors on how to enhance their draft with additional data that could strengthen their analysis. However, it could be more helpful if it included a rationale for why this comparison is important or how it could impact the interpretation of the results. Despite this, the comment is 4 as it offers a concrete step for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provide solutions in the paper. It also mentions that the citation seems disordered. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to improve the organization of their paper and discuss input handling, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests that the authors should present their solutions in the paper. It also mentions that the citation seems disordered. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in suggesting the need to discuss input handling and the organization of citations, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provides a suggestion for improvement by mentioning the need to present solutions in the paper. However, it does not provide specific examples or detailed reasoning to support why this is important or how it could be addressed. The comment also mentions that the citation seems disordered, but this is not elaborated upon. Without additional context or evidence, the claim lacks sufficient detail to be 5. Therefore, the comment is categorized as 2, as it provides some support but requires more elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provide solutions in their work. This feedback is valuable as it highlights a potential gap in the paper\"s methodology and encourages the authors to address it. Additionally, the comment notes that the citation seems disordered, which could be a separate issue for the authors to consider. While the comment provides actionable feedback on both fronts, it could be more helpful if it offered specific suggestions or examples for handling different types of inputs or organizing citations. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalization or what steps to take to mitigate the problem. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to question answering, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the question answering process, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue with generalization, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process requires template mapping to transform questions into masked statements, which might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their approach. Without actionable steps or detailed feedback, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"cite the source appropriately\" regarding the rockpaperscissors example, which is inspired by a previous work. This provides a clear and direct action for the authors to take, ensuring they give proper credit to the original source. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to cite the source appropriately. This provides clear guidance on what needs to be done to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work, suggesting that the authors should cite the source appropriately. However, the comment does not provide any specific references or examples of previous work that the example is inspired by, nor does it explain why this is important to cite. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out that the rockpaperscissors example is inspired by previous work. It suggests that the authors should cite the source appropriately. This feedback is clear and actionable, as it provides a specific and straightforward way for the authors to improve their draft by giving proper credit to the original source. However, the comment could be more helpful if it provided additional context or examples of how the citation should be made. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these limitations or improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or where the limitations are most apparent. This makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the innovations are limited or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, suggesting that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. While it points out a potential area for improvement, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it provides some insight but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to compare the performance of the model not only on synthetic data but also on realworld datasets with different losses. This provides a clear and direct action for the authors to take, which is to demonstrate the importance of the three projection errors by showing performance on both synthetic and realworld data. The comment is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"comparing the performance of the model only pretrained on synthetic data,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparison is unfair and recommending that the authors demonstrate the importance of the three projection errors by providing performance on both synthetic and realworld datasets with different losses. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more appropriate. However, the comment lacks specific examples or references to support the claim that the comparison is unfair. While the suggestion to compare performance on realworld datasets is a logical step, the absence of detailed reasoning or evidence makes the claim 3. The authors would need to infer the basis of the claim, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the model\"s performance, specifically noting that comparing it only on synthetic data is unfair. It suggests that demonstrating the importance of the three projection errors would be more appropriate by comparing the model\"s performance on both synthetic and realworld datasets with different losses. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By suggesting a more comprehensive evaluation, the comment helps the authors enhance the robustness and relevance of their findings. However, it could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is 4, as it offers valuable insights and suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the conditions for DICE are not well discussed, particularly regarding how to ensure that DICE meets the conditions of Lemma 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD is not significantly changed by sparsification, and that Lemma 2 requires approximately identical mean as the assumption. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these observations, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. This feedback is 3 as it points out areas where the paper could be improved by providing more detailed explanations or discussions. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these issues. To be more helpful, the comment could include examples or references to similar works that address these concerns, providing the authors with a clearer path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. While the comment implies that the authors should consider integrating over all possible environments to make the update meaningful, it does not explicitly instruct them to do so. Similarly, the suggestion to break out the sections into paragraphs is not explicitly stated but is implied by the reviewer\"s observation. The action is somewhat explicit but lacks concrete details on how to implement these suggestions, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the need to break out the bolded sections into paragraphs for better readability. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. The comment is 4 as it provides a logical reasoning for the suggestion to break out the sections, but it lacks specific examples or references to support the claim about the necessity of integrating over all possible environments. This makes the claim 3, as the authors would need to further investigate the reasoning to fully understand and address the suggestion.", "helpfulness_rationale": "The review comment raises a question about the feasibility of integrating over all possible environments for the update, suggesting that it might be necessary to break out the bolded sections into paragraphs for better readability. While the comment identifies a potential issue with the text\"s organization, it does not provide specific guidance or suggestions on how to address these concerns. The feedback lacks depth and actionable advice, leaving the authors with a general idea of what needs improvement but without clear steps to take. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add a citation on differential privacy, specifically mentioning a standard work like 2. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is specific and concrete, as it specifies the type of citation needed and provides a reference for the authors to follow. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. This is a factual statement that does not contain any subjective opinions, judgments, or suggestions. It is a request for additional information, which is a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors should include a citation on differential privacy, specifically mentioning a standard work like 2. This feedback provides a specific and direct way for the authors to enhance their paper by adding relevant references, which can improve the comprehensiveness and credibility of their work. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how the addition of this citation would benefit the readers. Despite this, the feedback is 4 as it offers a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a clear and explicit action for the authors to consider revising their claim. Second, it points out a specific error in the inequality on line 310, suggesting that the sign is incorrect and should be compared to the inequality on line 227. This part is also explicit and provides a concrete action for the authors to correct the error. Overall, the comment is 5 as it provides clear and specific guidance on both revising the claim and correcting the mathematical error.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the issues with the claim that the methodology requires significant additional assumptions and points out the incorrect sign in the inequality on line 310. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a logical reasoning and common knowledge to support the claim, making it 4. The second part points out a specific error in the inequality on line 310, comparing it to the inequality on line 227. This part is also 4 as it provides a clear correction to the mathematical error. Overall, the comment is 4 due to the logical reasoning and specific examples provided.", "helpfulness_rationale": "The review comment provides valuable feedback by questioning the claim that the methodology requires significant additional assumptions. It points out that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This critique is constructive as it challenges the authors to reconsider their claim and potentially revise it to reflect the actual assumptions involved. Additionally, the comment identifies a specific error in the inequality on line 310, suggesting that the sign is incorrect and should be compared to the inequality on line 227. This feedback is actionable and provides clear guidance for the authors to correct the error. Overall, the comment is 4 as it offers both critical analysis and specific suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. Additionally, it recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment explicitly states these actions, it does not provide specific guidance on how to conduct these comparisons or discuss the advantages and disadvantages. The authors are left with a clear understanding of what needs to be done but without detailed instructions on how to execute these tasks. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for experimental comparisons with methods like CaCE and raw gradients, as well as a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. It also recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the comparison with CaCE or raw gradients. The suggestion for a discussion on the advantages and disadvantages of different methods is a general recommendation that could be improved with more detailed examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s argument for using Shapely value explanations over other methods. It suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their choice. Additionally, the comment recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This feedback is clear and actionable, as it provides specific steps for the authors to take to strengthen their argument and improve the comprehensiveness of their work. By addressing these suggestions, the authors can enhance the rigor and depth of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve or expand upon their experimental setup or results. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions \"experiments\" and \"CATER,\" but it does not specify which part of the paper these experiments are discussed in or how they relate to the main claims or findings. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in describing the comprehensive nature of the experiments, including architectural mismatches and crossdomain imitation, but it does not provide detailed guidance on what aspects of these experiments need improvement or clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point describes the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment consists solely of factual statements about the experiments, making it a normal statement without a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and crossdomain imitation. This feedback provides insight into the thoroughness of the experimental validation, which is valuable information for the authors. However, the comment lacks specific suggestions or guidance on how the authors might further improve or expand their experimental setup or results. While it identifies a strength of the paper, it does not offer actionable advice or detailed feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a clear and direct action for the authors to take, which is to improve the clarity of the representation in Appendix A.2. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides a clear and actionable feedback for the authors to improve the presentation of this information. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or provided examples of how to improve the representation. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems due to the use of current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach for largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems due to the use of current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in identifying the issue of scalability, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems due to the use of current LPsolvers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems due to the use of current LPsolvers. This feedback is 3 as it points out a potential issue that the authors need to consider when scaling their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve their approach for largerscale problems. Without actionable advice, the comment provides only a partial benefit to the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the motivation for using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their motivation or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the motivation for using characteristic function regularization, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or part of the paper the comment refers to, making it weakly grounded. The comment is specific in identifying the issue of unclear motivation, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the motivation for using characteristic function regularization. This feedback is valuable as it points out a potential weakness in the paper that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify their motivation or improve the explanation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, which are standard in contextual linear bandits. The reviewer notes that the combination of these techniques is not surprising and suggests that the contribution may be incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies that the combination of these techniques is not surprising, suggesting that the contribution may be incremental. However, it does not provide specific guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results are a combination of existing techniques, which is not surprising and may suggest that the contribution is incremental. However, the comment does not provide specific examples or references to support the claim that these techniques are indeed standard or widely known. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the results appear to be a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the combination of these techniques is not surprising and may indicate that the contribution is incremental. While the comment highlights a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or enhance their contribution. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to strengthen their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referenced. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It specifies the need for more details in the main paper and the acknowledgment of other architectures\" structure. This provides full grounding as it explicitly mentions the part of the paper being addressed and is specific in detailing what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and recommends providing more details in the main paper. It also advises acknowledging the structure of other architectures if referenced. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these clarifications are necessary. The suggestion is 3 as it points out a potential issue but does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It provides a clear and actionable suggestion by recommending that the authors provide more details in the main paper and acknowledge the structure of other architectures if referenced. This feedback is valuable as it guides the authors in enhancing the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to improve the clarification. Overall, the comment is 4, as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It explicitly asks whether \"100 steps\" refers to 100 sampled strategies. This question provides a clear and direct action for the authors to clarify the meaning of \"100 steps\" in their draft. The comment is explicit and concrete, as it directly instructs the authors to provide clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It asks whether \"100 steps\" refers to 100 sampled strategies, which is a relevant and clarifying question. However, the comment does not provide any additional context or suggestions for how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It suggests repeating the experiments and conducting statistical significance analysis, which provides a clear and explicit action for the authors to take. The suggestion is concrete, as it specifies the steps needed to address the issues, making this comment 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It mentions \"Table 1 and Fig. 5,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be addressed, such as repeating the experiments and conducting statistical significance analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, with a range of 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis. However, the comment lacks specific examples or references to support the claim about the small improvement or the lack of statistical significance. While the suggestion to repeat the experiments and conduct analysis is clear, the initial claim is not 5 due to the lack of detailed evidence or references. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the small improvement over previous methods and the lack of statistical significance analysis in the results. It provides a clear suggestion to repeat the experiments and conduct statistical significance analysis, which is a concrete and actionable step for the authors to take. However, the comment could be more helpful if it offered additional guidance on how to conduct the statistical analysis or provided examples of similar studies that have addressed these issues. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement and provides a clear path forward. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should evaluate their method on a different benchmark, such as Atari, to assess its generalizability to other domains and action spaces. The comment provides a clear and concrete action for the authors to take, specifying the benchmark and the aspects to consider. This level of detail and specificity makes the action explicit and actionable, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the evaluation of the method, specifically mentioning the evaluation on a single domain, which is the Meta World domain. It suggests that the authors should run experiments on a different benchmark, such as Atari, to assess the generalizability of their results. This feedback is fully grounded as it explicitly mentions the Meta World domain and the need for additional benchmarking on Atari. The comment is also specific because it provides a clear suggestion for improvement, namely, to evaluate the method on a different benchmark. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the method is limited to a single domain, making it difficult to judge generalizability. The reviewer suggests running experiments on a different benchmark, such as Atari, to address this limitation. The claim is supported by logical reasoning, as it points out the need for broader evaluation to assess the method\"s generalizability. However, the comment could be strengthened by providing specific examples or references to why Atari is a suitable benchmark for this purpose. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on a single domain, specifically Meta World. This observation is crucial as it questions the generalizability of the results to other domains. The reviewer provides a clear and actionable suggestion by recommending the authors to run experiments on a different benchmark, such as Atari, which is commonly used in the literature. This recommendation not only addresses the limitation but also provides a specific direction for the authors to improve the robustness and applicability of their method. The feedback is detailed and constructive, offering a clear path for the authors to enhance their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which is considered extremely interesting. However, it does not provide specific guidance on what aspects of the model should be analyzed or how this analysis should be conducted. The action is implicit, as the authors need to infer that they should include an analysis, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analysis of the model is missing, despite the presentation of the method and the completeness of the experiments. However, it does not specify which part of the paper this analysis should be included in, nor does it provide guidance on what aspects of the model should be analyzed. The authors can infer that it relates to the analysis section, but the lack of specific guidance makes it difficult to pinpoint the exact part of the paper needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the analysis of the model is missing, despite the presentation of the method and the completeness of the experiments. However, the comment does not provide any specific examples, reasoning, or references to support why this analysis is necessary or what aspects of the model should be analyzed. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the method is presented nicely and the experiments are good and complete, which is a positive assessment. However, it suggests that a deeper analysis of what the model does is missing, which could be considered extremely interesting. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to conduct this analysis or what aspects should be focused on. This limits the usefulness of the feedback for the authors, as it does not offer detailed suggestions or examples to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the \"approach section is missing in the main paper\" and suggests that the supplementary material should be used as additional information rather than an extension to the paper. The reviewer provides a specific reference to a previous comment and indicates that the score has been increased from 3 to 5. This feedback is clear and direct, providing the authors with a specific action to take: ensure the approach section is included in the main paper and that the supplementary material is used appropriately. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach section\" and the \"main paper,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach section is missing and that the supplementary material should be used as additional information rather than an extension to the paper. The comment further references a specific previous comment and indicates that the score has been increased from 3 to 5. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section is missing in the main paper,\" which is a factual statement that does not require verification. The reviewer also suggests that the supplementary material should be used as additional information rather than an extension to the paper, providing a logical reasoning for this claim. However, the comment lacks specific examples or references to support the suggestion that the supplementary material should be used as additional information. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"approach section is missing in the main paper.\" This is a clear and actionable feedback that highlights a critical omission in the manuscript. The reviewer also provides guidance on how the supplementary material should be used, suggesting it should serve as additional information rather than an extension to the paper. This feedback is valuable as it directs the authors\" attention to a crucial aspect of their draft that needs improvement. However, the comment could be more helpful if it offered suggestions on how to integrate the approach section into the main paper or provided examples of how to structure it effectively. Overall, the comment is 4 as it identifies a significant gap in the paper and offers some direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the statement. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about what specific changes to make. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, citing the widespread acceptance of backpropagation as biologically implausible. This claim is supported by common knowledge and logical reasoning, as it aligns with established views in the field. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is 4, as it provides a logical basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This feedback is 3 as it points out a common critique that the authors should address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might strengthen their argument or address this critique. Without additional context or actionable advice, the authors may find it challenging to fully utilize this feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the scalability aspect, but it lacks concrete steps or recommendations on how to mitigate the potential scalability problem. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the modulator, which is a specific element of the paper, providing a clear reference to the part of the paper being discussed. It also raises a concern about scalability and the potential need for tedious hyperparameter tuning for diverse training data. This provides a specific issue for the authors to address, making the comment fully grounded. However, it does not specify how the authors should address the scalability issue or suggest potential solutions. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the modulator, noting that it is heuristically designed and suggesting that there might be scalability concerns. It raises a concern about the need for tedious hyperparameter tuning for diverse training data, which is a valid point that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or strategies for improving scalability. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experiments incorporating a significant amount of domain knowledge, which may make it challenging for less informed f_R/f_P to learn effectively. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments and the incorporation of domain knowledge into their structure, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge of using less informed f_R/f_P, which requires a significant amount of data to learn. However, it lacks detailed guidance on how to address this issue or improve the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments incorporate a significant amount of domain knowledge, which may make it challenging for less informed f_R/f_P to learn effectively. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, noting that the incorporation of a significant amount of domain knowledge into their structure may make it challenging for less informed f_R/f_P to learn effectively. This observation is relevant and could prompt the authors to consider alternative approaches or data structures that might better accommodate less informed models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative methods or data structures. While it highlights a potential weakness, the feedback is incomplete and does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the connection between the necessary conditions and generalization bounds, questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the authors acknowledge this in the conclusion, the comment does not provide explicit guidance on how the authors should address this issue. The feedback suggests that the authors should clarify this connection, but it does not offer specific steps or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more clarity on this topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the connection between overparameterization, robust memorization, and generalization, specifically questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. It also notes that the authors acknowledge this in the conclusion, but it remains a serious question. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the conclusion or a section discussing generalization, but this is not explicitly mentioned. The comment is specific in detailing the concern about the connection between robust memorization and generalization, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between overparameterization, robust memorization, and generalization, questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. The reviewer acknowledges that the authors address this in the conclusion, but finds the question serious. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this connection is not clear. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment raises a critical concern about the connection between overparameterization, robust memorization, and generalization. It questions whether the constructions of ReLU networks for robust memorization lead to robust generalization, which is a significant issue in the field. The comment acknowledges that the authors address this in the conclusion, but it suggests that this is a serious question that needs further clarification. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights an important area for improvement, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand their analysis to other NLP tasks, but it lacks concrete details or actionable steps on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on contrastive learning in code search tasks and suggests that it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper discusses the proposed method or how it could be expanded to other tasks. The authors can infer that the discussion on the proposed method is relevant, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the need for broader exploration of the method\"s implications, but without explicit references or examples, it remains underspecific. Therefore, this comment is weakly grounded and underspecific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant as it highlights an area where the authors could expand their analysis to enhance the generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as which other NLP tasks could be explored or how to structure this exploration. While it points out an important area for improvement, the feedback is 3 as it provides a direction for potential enhancement but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the sample selection mechanism need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim that the mechanism is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. While it identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing the draft. Therefore, it is rated as 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. While it acknowledges the thoroughness of the analysis, it does not provide explicit guidance on how the authors should address this limitation. The comment lacks specific suggestions or actions for the authors to take, such as recommending the inclusion of more recent or larger models, or discussing the implications of using only two models. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation of models, specifically noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the results or analysis sections, the lack of explicit grounding makes it challenging to address the comment effectively. The comment is specific in identifying the issue of limited model evaluation, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim that the models are \"old\" or \"small,\" making it difficult for the authors to fully understand and address the issue. Additionally, the comment does not provide suggestions on how to improve the evaluation or what specific models should be considered. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed evidence or guidance.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of models, noting that only two relatively old and small models are evaluated. While it points out a specific area for improvement, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation. It does not offer alternative models to consider or discuss the implications of using only two models. As a result, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making the necessary changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific claim about the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this discussion is relevant to, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be valuable for the authors to consider. However, the comment lacks depth and does not offer actionable advice or suggestions on how the authors might incorporate this insight into their work. It does not provide specific guidance on how to address this equivalence or its implications for the study, leaving the authors with limited actionable feedback. Therefore, the comment is 3, as it identifies an interesting aspect but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more recent works on dynamicpruning methods and provide results on largescale datasets like ImageNet. While the comment implies that the authors should update their work to include these recent works and results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should update their paper with more recent works and results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the inclusion of outdated competing dynamicpruning methods and the need to include more recent works. Additionally, it suggests that results on largescale datasets, such as ImageNet, should be included to further verify the effectiveness of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more recent works on dynamicpruning methods and provide results on largescale datasets like ImageNet. However, it does not provide specific examples of recent works or detailed reasoning as to why these additions are necessary. The claim is 3 as it highlights a potential area for improvement but lacks detailed justification or references to support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should include more recent works on dynamicpruning methods and provide results on largescale datasets like ImageNet. This feedback is clear and actionable, as it directs the authors to update their work to include more contemporary research and broader datasets, which could enhance the relevance and impact of their findings. However, the comment could be more helpful if it provided specific examples of recent works or detailed guidance on how to incorporate these changes. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results (table 5). This is a clear and direct action, as it specifies what information the authors need to include to address the issue. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results (table 5) and requests clarification on why the performance degrades when using additional information about missing, wrong, or redundant data. This feedback is clear and actionable, as it prompts the authors to provide a detailed explanation or analysis of the performance degradation. However, the comment could be more helpful if it suggested potential causes or methods for addressing the issue. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It asks why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. However, the comment does not explicitly instruct the authors to include such an explanation or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks why this particular dimension of difficulty is interesting. This provides clear guidance on what aspect of the paper needs further explanation or justification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that the authors should provide a rationale for why this particular dimension of difficulty is interesting. However, the comment does not provide any specific reasoning or evidence to support the claim that this choice is not well motivated. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It questions why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. This feedback is 3 as it prompts the authors to consider and articulate the significance of their choice, which could enhance the clarity and impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the issue or if it offered alternative approaches to consider. Overall, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to ensure that the text in the figure is legible without zooming. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the text is too small to read without zooming, and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, suggesting that they should be roughly the same size as the manuscript text. This is a subjective observation that requires the authors to make a judgment about the legibility of the text. However, the comment does not provide any supporting evidence, such as specific measurements or examples, to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the text inside the figure and labels, noting that they are too small to be legible without zooming. It provides a clear and actionable suggestion by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it helps the authors improve the accessibility and clarity of their figures, which is an important aspect of effective communication in scientific writing. However, the comment could be more helpful if it included specific recommendations on how to achieve this size or if it provided examples of how other papers have addressed similar issues. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and offers a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a clear and direct action for the authors to take, which is to revise the introduction. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction needs revision or what aspects of the motivation are unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references to specific sections, and it is not specific enough to guide the authors in addressing the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow, which is a clear and actionable feedback. However, the comment does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. While it highlights a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a significant issue but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the alignment of relabeled reward data with human annotator judgments, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to validate this alignment or what specific steps should be taken to improve it. Without actionable advice or suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue with the alignment, but it lacks grounding because it does not pinpoint the exact section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved, namely the validation of the alignment between relabeled reward data and human annotator judgments. However, it lacks actionable guidance or suggestions on how the authors might address this issue or improve the validation process. Without detailed advice or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the model\"s presentation in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific action for improvement by recommending the authors to replace some natural language descriptions with notation and add breakout diagrams showing attention mechanisms. This feedback is clear and provides concrete steps for the authors to take to enhance the clarity and presentation of their work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved by suggesting a more detailed presentation, replacing natural language descriptions with notation, and adding breakout diagrams to illustrate attention mechanisms. This level of detail provides clear guidance on how to enhance the presentation, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model\"s presentation in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific suggestion for improvement by recommending the use of notation and breakout diagrams to illustrate attention mechanisms. This feedback is 3 as it offers a clear suggestion for improvement but lacks detailed examples or references to specific attention mechanisms. The authors would need to infer how to implement these suggestions effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s presentation in section 4, noting that it is somewhat complicated and requires careful reading, possibly with reference to the supplement. It provides a clear and actionable suggestion for improvement by recommending the use of notation and the addition of breakout diagrams to illustrate attention mechanisms. This feedback is valuable as it guides the authors on how to enhance the clarity and accessibility of their presentation, making it 4. However, it could be more helpful if it included specific examples of attention mechanisms or detailed guidance on how to implement the suggested changes. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their experiments to a broader range of molecules or exploring alternative methods to address the training issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the limited number of molecules and the indistribution testing provided. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation of the method, suggesting that it might be limited if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value would be limited if it requires training for each molecule individually, suggesting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental setup, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the symbols used in the paper are complicated and take a long time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or improve their clarity, nor are there suggestions for alternative approaches. As a result, the authors are left without any actionable steps to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take a long time to understand, but it does not specify which part of the paper these symbols are found in. This makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the symbols are complicated or how they could be simplified. Without clear grounding and specific guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that symbols are complicated and take a long time to understand, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of symbols used in the paper, noting that they take a long time to understand. However, it lacks specificity and does not provide any suggestions or guidance on how to simplify the symbols or improve their clarity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the identified problem. Therefore, the comment is 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how the authors should address this question. The action is implicit, as the authors need to infer that they should clarify the source of the test data and the existence of a ground truth. However, the comment is somewhat specific in its request for clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking where the test data comes from and whether there is a ground truth. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the source of the test data in Figure 3 and whether there is a ground truth. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their figure. By addressing this question, the authors can improve the clarity and understanding of their results, which is beneficial for the overall quality of the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present the data more effectively. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they might need to explore the impact of periodicity on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment does not explicitly mention a specific part of the paper, it is clear that it relates to the experimental results and the comparison between models. The authors can infer that it pertains to the results section or the comparison between models, but the comment lacks explicit grounding. The specificity is clear as it raises a specific question about the impact of periodicity on the results. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors are left to infer the relevance of periodicity to their results, making the claim 3 due to the lack of detailed justification.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then suggests that adding periodicity to the spectral kernel might allow it to capture these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the impact of periodicity on their results and suggests a potential avenue for further exploration. However, the comment could be more helpful if it provided specific guidance on how to investigate this issue or what aspects of the results might be affected by periodicity. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes that there are issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance or suggestions on how to improve these aspects. The authors are left without clear instructions on what changes to make or how to enhance the writing and presentation. As a result, the comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are problematic, making it difficult for the authors to identify the exact areas needing improvement. The lack of specific guidance or examples leaves the authors without clear direction on how to address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or detailed feedback, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific suggestions or actionable feedback on how to improve the writing, presentation, or formatting. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects need improvement and how to address them. As a result, the comment is not helpful, as it does not provide the authors with actionable steps to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction need to be expanded or how to make it more detailed. The action is implicit, as the authors can infer that they need to provide more information about orthogonality, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction or Part 2 is being addressed, making it weakly grounded. The comment is specific in its suggestion to provide more detail on orthogonality, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a specific area for improvement, it lacks specificity and does not provide any guidance on what aspects of the introduction need to be expanded or how to make it more detailed. Without actionable feedback or examples, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, suggesting that prior work already theoretically shows samplewise multiple descent in linear regression. It implies that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings. The reviewer questions whether this is the case and suggests that the paper should better highlight the novelty of its results in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised to better highlight the novelty. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s contribution, specifically questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment mentions being unfamiliar with the techniques and tools used in the paper, which adds to the lack of grounding. While the comment is specific in its critique of the novelty, it lacks full grounding due to the absence of explicit references to specific parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the techniques and tools used in the paper but finds the claims plausible. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of its results in relation to prior results. While the comment identifies a potential issue with the novelty of the paper\"s contribution, it lacks specific guidance or suggestions on how the authors might address this concern or improve the clarity of their results. The feedback is 3 as it points out a potential area for improvement but does not provide detailed actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and have little inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the connection between the methods. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically the contrastive training objective and contrastive search, but does not specify which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment highlights a potential issue with the lack of connection between the methods, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and have little inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed methods, specifically the contrastive training objective and contrastive search, noting that they are independent and have little inner connection in terms of intuition and algorithm. This feedback highlights a gap in the paper that could impact the coherence and effectiveness of the proposed methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the connection between the methods. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the goal of the paper, specifically regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors should clarify whether their claim is that this is a foundation model or a proof of concept, and if it is the latter, to justify a future useful application. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically mentioning the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the introduction or methodology sections where the goal and comparison are discussed. The authors can infer the relevant parts, but the comment lacks explicit grounding. The specificity is clear as it specifies what needs to be addressed regarding the goal and comparison. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the lack of comparison with existing DAS earthquake detectors and the justification for the claim that the paper presents a foundation model. The reviewer suggests that the authors clarify whether their claim is a foundation model or a proof of concept and provide a justification for the latter. While the comment identifies a gap in the paper, it lacks specific examples or references to existing DAS earthquake detectors, making it 3. The authors would need to provide more detailed information to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s goal and methodology. It points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the claim that the paper presents a foundation model. The comment suggests that the authors clarify whether their claim is a foundation model or a proof of concept and, if the latter, to justify a future useful application. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the lack of comparison and justification. However, the comment could be more helpful if it offered suggestions on how to conduct the comparison or what future applications could be explored. Overall, the comment is 4, as it guides the authors in enhancing the clarity and robustness of their claims."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. While the comment implies that the authors should consider this limitation and potentially address it, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about the potential for extension, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a purely factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. This question prompts the authors to consider the scope and potential improvements of their method, which could lead to a more comprehensive approach. However, the comment does not provide specific guidance or suggestions on how to address this limitation or extend the method, leaving the authors with a general direction but no actionable steps. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. While the comment implies that the authors should consider this idea, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they should explore this possibility, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. However, it does not provide any reasoning, evidence, or references to support why this suggestion is necessary or beneficial. The lack of justification or examples makes it difficult for the authors to understand the basis of the claim and how it could improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This feedback is 3 as it provides a potential direction for expanding the scope of the work by integrating AccNet into a more comprehensive system. However, the comment lacks specific guidance on how to implement this suggestion or what benefits it might bring to the research. To be more helpful, the comment could include details on how this integration could enhance the model\"s performance or functionality. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the new proposed metric being tested only on a single dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test the metric on additional datasets, explore alternative datasets, or provide more detailed analysis of the results. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the new proposed metric being tested only on a single dataset. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where the metric is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the limitation of testing the metric on a single dataset, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which is a concern. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed metric, noting that it has only been tested on a single dataset. This feedback is important as it highlights a limitation in the evaluation of the metric, which could affect its generalizability and reliability. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation, such as recommending additional datasets for testing or suggesting ways to improve the metric\"s evaluation. Without actionable advice or further elaboration, the comment is 3, as it points out a potential weakness but does not offer concrete steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the setting in the first three paragraphs of section 2 needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback provides a clear and direct action for the authors to take, which is to clarify the setting. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first three paragraphs, which is the need for clearer explanation of the setting. The comment highlights a potential issue with the authors\" claim of doing something in greater generality than what is presented, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of section 2 need to be clarified, suggesting that the authors may be implying a greater generality than what is actually presented. This claim is 3 as it provides a logical reasoning for the need for clarification, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact issues with the generality claim, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It points out that the authors may be implying a greater generality than what is actually presented, which could lead to confusion. This feedback is clear and actionable, as it directs the authors to clarify the setting to avoid any potential muddling of the exposition. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what could be clarified. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the convincing nature of the experiments, specifically questioning the choice of the old baseline like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the experiments being not quite convincing, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing the issue with the choice of baselines and the need to consider more recent approaches, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experiments being not quite convincing, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. While the comment provides a logical reasoning for considering these alternatives, it lacks specific references or examples to support the claim fully. The suggestion to compare the proposed method with these approaches is a reasonable one, but the comment could be strengthened by providing more detailed reasoning or evidence to support the need for these comparisons. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the convincing nature of the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. This feedback is 3 as it identifies a potential weakness in the experimental setup and provides a clear direction for improvement by suggesting alternative approaches. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement these changes. Overall, the comment provides a good starting point for the authors to consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two points. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. Second, it recommends a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. While the comment provides explicit actions for the authors to take, such as clarifying the bitrate range and incorporating a specific related work, it does not offer detailed guidance on how to implement these actions. The authors are aware of what needs to be done but may require additional information to fully execute the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses two specific issues: the precision of the bitrate range used for BDrate comparison and the suggestion to include a related work on content adaptive algorithm in learned video compression. It provides a clear and specific reference to Guo Lu\"s work, which the authors should consider for discussion or comparison. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two concerns. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. Second, it recommends a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. While the comment provides a specific reference to a related work, it does not offer detailed reasoning or evidence to support the claim that the proposed method is stronger at high bitrate but close to the baselines at low bitrate. The suggestion to include a specific related work is a logical extension of the critique but lacks detailed justification or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to fully substantiate the feedback.", "helpfulness_rationale": "The review comment raises two points for improvement. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. This feedback is specific and actionable, as it directs the authors to provide more detailed information about the bitrate range used in their analysis. Second, the comment recommends a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. This suggestion is relevant and could enhance the paper\"s depth and comprehensiveness. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this related work into the paper. Overall, the comment is 4 as it identifies specific areas for improvement and suggests a relevant reference, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this distinction. The authors may infer that it pertains to the discussion or results sections, but this is not explicitly mentioned. The comment lacks specificity in terms of what needs to be addressed, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While this is a valid point, the comment lacks specificity and does not provide detailed guidance on how the authors should make this distinction or why it is important. Without actionable advice or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, it does not provide specific guidance or suggestions on what additional analysis or improvements the authors should undertake. The action is implicit and vague, as the authors are left to infer that they need to conduct more analysis or improvements, but without concrete details on what aspects to focus on. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements made by the paper over previous works and selfimplemented baselines, stating that the improvements are marginal. However, it does not specify which tasks or experiments are being discussed, making it difficult for the authors to pinpoint the exact part of the paper being critiqued. Additionally, the comment lacks specificity regarding what further analysis or improvements are needed beyond the main experiments. Without clear grounding or detailed feedback, the authors may struggle to understand and address the issues effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any specific examples, data, or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. While it identifies a potential issue with the paper\"s results, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The comment provides a general direction for further investigation but does not offer actionable steps or detailed feedback, making it 3. The authors are left to infer the nature of the additional analysis needed, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the theoretical result, which only provides utility guarantees under the assumption that features and noise are Gaussian. It suggests that this is a strong requirement on the data and that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this limitation or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical result in the paper, specifically noting that it provides utility guarantees only under the assumption that features and noise are Gaussian. This is a strong requirement on the data, and the reviewer suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment does not explicitly mention a specific section, it is clear that it pertains to the theoretical results section. The authors can infer that it relates to the part of the paper discussing the theoretical guarantees. However, the comment does not specify which part of the paper this relates to, making it weakly grounded. It is specific in identifying the issue with the Gaussian assumption and suggesting a comparison to existing rates. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical result in the paper provides utility guarantees only under the assumption that features and noise are Gaussian, which is a strong requirement on the data. The reviewer also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the claim is logical and based on the assumption of Gaussian features and noise, it lacks specific references or examples to fully substantiate the claim. The suggestion to compare rates to existing literature is a reasonable one, but without detailed references or examples, the comment remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the theoretical result, which provides utility guarantees only under the assumption that features and noise are Gaussian. This is a strong requirement on the data, and the reviewer suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This feedback is clear and actionable, as it points out a specific area where the paper\"s results may be limited and suggests a direction for improvement by comparing to existing literature. However, the comment could be more helpful if it provided specific examples or references to existing rates in the literature. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. While the comment implies that such a comparison would be useful, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, it does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to conduct the comparison. The authors can infer that it relates to the proposed extension, but the lack of specific instructions or grounding makes it difficult to pinpoint the exact section or aspect of the paper being addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a comparison with a relevant prior work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific aspects of the original approach should be examined. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works (1, 2, 3) that address similar questions, implying that these comparisons should be included to provide a more comprehensive evaluation. While the comment explicitly states the action needed, it does not provide detailed guidance on which specific aspects of the proposed method should be compared or how to integrate these additional comparisons into the experimental section. The suggestion is concrete in terms of what needs to be added, but the lack of specific details on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of additional experimental comparisons to demonstrate the effectiveness of the proposed method. The comment references specific works (1, 2, 3) that address similar questions, providing a clear direction for the authors to expand their experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works (1, 2, 3) that address similar questions, providing a logical basis for the claim. However, the comment does not provide detailed reasoning or specific examples of how these additional comparisons would enhance the paper\"s effectiveness. While the references are a step towards verification, the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section of the paper, suggesting that the authors should include additional comparisons with other relevant works. It provides a clear and actionable suggestion by referencing specific works (1, 2, 3) that address similar questions, which would help the authors demonstrate the effectiveness of their proposed method. This feedback is valuable as it guides the authors on how to enhance the robustness and comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it offered additional guidance on how to integrate these comparisons or what specific aspects of the proposed method should be compared. Overall, the comment is 4, as it provides clear direction for improvement but could be more detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with error bars under different random seeds, which is a clear and direct action. It also provides a rationale for why this is important, stating that the current results on the dev set are not convincing enough. This feedback is concrete and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should present the average results on the test set with error bars under different random seeds, which is a clear and specific request for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results reported in Tables 1 and 2 are not convincing because they are based on the dev set and suggest that the paper should present average results on the test set with error bars under different random seeds. The reviewer provides a logical reasoning by stating that the results should be more convincing if they are based on the test set, which is a common practice in evaluating models. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact reasoning behind the suggestion, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the authors report the best results on the dev set with hyperparameter search and model selection on the same set. This is considered insufficient to be convincing, as it does not provide a comprehensive evaluation. The reviewer suggests presenting the average results on the test set with error bars under different random seeds, which is a clear and actionable recommendation for improvement. This feedback is valuable as it guides the authors on how to enhance the robustness and reliability of their results, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct an ablation study on the parameter \u03b1, which is currently only set to three values with a large gap between 1e4 and 1e1. The reviewer recommends providing additional values, such as 1e2 and 1e3, to better understand the impact of this parameter. This feedback is clear and specific, providing a direct action for the authors to take. The suggestion is concrete, as it specifies the additional values to consider. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study on \u03b1, noting that it is only set to three values with a large gap between 1e4 and 1e1. The reviewer recommends providing additional values, such as 1e2 and 1e3, to better understand the impact of this parameter. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the ablation study on the parameter \u03b1 is insufficient, as it only considers three values with a large gap between 1e4 and 1e1. The reviewer suggests providing additional values, such as 1e2 and 1e3, to better understand the impact of this parameter. While the comment identifies a potential issue with the current study, it lacks specific reasoning or evidence to fully substantiate the claim. The suggestion to provide additional values is a logical extension of the current study, but without further justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by pointing out an insufficient ablation study on the parameter \u03b1. It highlights that the current study only considers three values with a large gap between 1e4 and 1e1, suggesting that additional values, such as 1e2 and 1e3, should be included to better understand the impact of this parameter. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their study. By addressing this suggestion, the authors can improve the robustness and comprehensiveness of their analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology and dataset used in the paper. It asks for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, and the size of the AG news dataset. Additionally, it suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues or what specific information should be included. The authors are left to infer the details of the response, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the methodology and dataset used in the paper, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment does not explicitly mention specific sections, it is clear that it pertains to the methodology and dataset description sections. The authors can infer that it relates to these parts of the paper, but the comment does not provide explicit references. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology and dataset used in the paper. It asks for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, and the size of the AG news dataset. Additionally, it suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment identifies areas where the paper lacks detail, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their presentation. This limits the comment\"s helpfulness, as it provides some insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether it should be included or removed. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the zeroshot version and its connection to density estimation, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, the comment lacks specific reasoning or evidence to support why these elements are considered distracting or how they impact the main point. The claim is based on the reviewer\"s subjective assessment, which is not fully substantiated by logical reasoning or references. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential distraction in the paper, specifically the zeroshot version and its connection to density estimation, which may divert attention from the main point of learning to produce good prototypes for fewshot learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or whether it should be included or removed. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors might find it useful to consider the reviewer\"s perspective but would need to further explore the implications on their own. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed on the translation and filtering methodology used to create the Arabic climate change QA dataset. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the process. The comment specifies what needs to be addressed, making it 5. The authors know exactly what information to provide to improve the transparency and quality of their dataset description.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more information on the translation and filtering methodology to assess the dataset quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, and more information on the translation and filtering methodology is needed to assess the dataset quality. This claim is 3 as it identifies a specific area where the paper lacks detail, but it does not provide specific examples or references to support the need for additional information. The authors would need to infer the exact nature of the missing details, making the claim 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the importance of providing more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to include additional details that would enhance the transparency and credibility of their dataset. However, the comment could be more helpful if it provided specific suggestions or examples of what kind of information would be beneficial to include. Overall, the comment is 4 as it guides the authors towards improving their draft by addressing a critical gap in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the inclusion of more attacks and the exploration of different thresholds. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. However, the comment does not provide specific examples or references to support the claim that these additions would be beneficial. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved: the inclusion of more attacks with varying strengths and the exploration of how different thresholds affect detection performance. This feedback is clear and actionable, providing the authors with concrete steps to enhance their experimental results. By suggesting these additions, the comment offers a valuable direction for improving the robustness and depth of the study. However, the comment could be more helpful if it provided examples of how these enhancements could be implemented or discussed in the paper. Overall, the feedback is 4 as it guides the authors in making meaningful improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should train a discriminator on generations from the learned model to confirm the reduction of exposure bias, similar to Figure 1. This is an explicit action that the authors can take to address the claim of the paper. The comment also provides a clear rationale by noting the difference between Figure 1 and Figure 4, where the discriminator is coadapting with the generator during training. This gives the authors a concrete understanding of what needs to be done to support their claim. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to train a discriminator on generations from the learned model to confirm the reduction of exposure bias, similar to Figure 1. This provides clear guidance on what needs to be done to support the claim of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should train a discriminator on generations from the learned model to confirm the reduction of exposure bias, similar to Figure 1. This claim is 3 as it provides a logical reasoning for the need to train a discriminator, but it lacks specific examples or references to support the claim fully. The comment mentions that it is different from Figure 4, but it does not provide detailed explanations or references to substantiate the difference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to train a discriminator on generations from the learned model to confirm the reduction of exposure bias, similar to Figure 1. This feedback is specific and offers a concrete method for the authors to substantiate their claim, making it 5. By following this advice, the authors can strengthen their paper\"s evaluation and provide a more robust demonstration of their approach\"s effectiveness. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide information on the performance difference resulting from using different image sizes and different variations of ResNets. This request is clear and direct, giving the authors a specific action to take in their draft. The comment is explicit and concrete, as it clearly outlines what information is needed and how it should be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for information on the performance difference resulting from using different image sizes and different variations of ResNets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for clarification on the performance difference resulting from using different image sizes and ResNet variations. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is 3 as it identifies a specific area where additional information is needed, namely the performance difference resulting from using different image sizes and ResNet variations. This feedback prompts the authors to provide more detailed analysis or results that could enhance the comprehensiveness of their study. However, the comment lacks depth and does not offer specific suggestions on how to present this information or what aspects of the performance difference are most relevant. To be more helpful, the comment could include examples or guidance on how to structure this analysis within the paper. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not provide specific guidance on what aspects of the algorithm should be detailed or how the description should be structured. The action is implicit, as the authors need to infer that they should provide a detailed description of the algorithm, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or subsection. Without explicit references to the paper, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be detailed or how the description should be structured. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to enhance understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not provide specific guidance on what aspects of the algorithm should be detailed or how the description should be structured. While the comment identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. The authors are given a general direction but not enough detail to effectively address the feedback. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that a runtime comparison is necessary and how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, it does not specify which part of the paper discusses the use of Chebyshev polynomials or where the runtime comparison should be included. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to include a runtime comparison, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, the comment does not provide any reasoning, examples, or references to support why such a comparison would be beneficial or how it could be conducted. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a specific comparison that could enhance the paper\"s analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. To be more helpful, the comment could include specific suggestions or examples of how to implement the runtime comparison. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to reorganize the prompts or what specific changes should be made. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve the organization of the prompts. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Tables 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not wellorganized and that sentences squeeze together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides a concrete area for the authors to address in their draft. By highlighting this issue, the comment helps the authors improve the clarity and readability of their presentation. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or provided examples of better organization. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is clear and direct, providing the authors with a specific action to take: improving the clarity of the figures by ensuring that all modules are labeled correctly. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figures are not clear due to confusion in the relation of subfigures and the absence of labels for certain modules, such as CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is based on the observation of the figures and the identification of specific issues, which provides some level of justification. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to address the issues mentioned to improve the clarity of the figures, but the feedback could be strengthened with more detailed examples or explanations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in figure 2, where the relation of 3 subfigures is confusing and some modules are unlabeled. This feedback is clear and actionable, as it provides the authors with a specific area to address in improving the clarity and accuracy of their figures. By highlighting these issues, the comment helps the authors enhance the quality and communicative effectiveness of their visual representations. However, the comment could be more helpful if it offered suggestions on how to improve the labeling or presentation of the figures. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How does the number of images impact the model performance, and (2) whether more training images make the performance worse or better. Additionally, it suggests that BYOL should be explained in the abstract for its first appearance. While the questions provide a clear direction for the authors to explore, the suggestion to explain BYOL is somewhat vague as it does not specify how to explain it. The authors can infer that they need to clarify the role of BYOL in their work, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides explicit actions but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions, as it clearly identifies what needs to be addressed regarding the impact of the number of images and the explanation of BYOL. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions and a suggestion for clarification. The questions are factual inquiries seeking information about the impact of the number of images on model performance and the explanation of BYOL in the abstract. These questions do not contain claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s methodology and performance analysis. The first question explores the impact of the number of images on model performance, which is an important consideration for understanding the model\"s behavior. The second question suggests that the abstract should explain BYOL, which is a relevant technique used in the paper. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs clarification but without detailed steps on how to improve their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should include more detailed explanations, it does not explicitly instruct them to do so or provide specific guidance on how to structure these explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"L_pixel\" component, which is a specific part of the paper, providing full grounding. It also specifies the issue by asking for stronger arguments or intuitions to explain why these particular losses are \"bound to help.\" This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding why the method works, specifically regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current explanation is unclear. This lack of detailed justification makes the claim 3, as the authors would need to infer the nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of improvement regarding the clarity of the explanation for why the method works, particularly focusing on the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and provide more detailed reasoning. However, the comment could be more helpful if it offered specific suggestions or examples of how to strengthen the arguments or intuitions. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors might address this concern or what steps they could take to improve the dataset size or coverage. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the dataset or find a way to ensure its comprehensiveness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of dataset size, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. It also questions the adequacy of the dataset size compared to the typical training data for LLMs, which are trained on trillions of tokens. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about dataset size and its implications, but without explicit references to sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer provides a logical reasoning by comparing the dataset size to the scale of typical LLM training data, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to conduct further analysis or research to address this concern comprehensively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains, which is a valid point. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand the dataset. While it identifies a potential weakness, it does not provide actionable steps or examples for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the justification of using binary classification as a baseline metric, particularly regarding its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The action is implicit and vague, as the authors are left to infer that they need to reconsider their choice of baseline metrics or provide a more detailed justification for their selection. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the baseline metrics or the TAL task, making it weakly grounded. The comment is specific in its critique of the binary classification\"s limitations, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. The reviewer acknowledges the importance of the TAL task but expresses uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that binary classification is not suitable for assessing finegrained errors. This makes the claim 3, as the authors would need to infer the basis of the concern and potentially conduct further analysis to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. This feedback is 3 as it identifies a potential limitation in the methodology and prompts the authors to consider alternative metrics or approaches. However, the comment lacks specific suggestions or guidance on how to address this concern, such as proposing alternative metrics or methods. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors might improve it. Without explicit instructions or concrete examples, the authors are left without a clear understanding of what changes to make or how to address the issues. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or what specific issues need to be addressed. Without explicit references to sections, figures, or specific points, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding the nature of the unclear points. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples or reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed feedback or evidence, the authors are left without guidance on how to improve their writing or address the unclear points. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they might be clarified. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to improve their draft. This lack of specificity and depth makes the comment 2, as it does not effectively support the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors use other metrics, such as BERTScore, to evaluate the results. While the action is explicit, it does not provide specific guidance on how to implement this suggestion or which other metrics might be appropriate. The authors are left with a clear direction but without detailed instructions on how to execute it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or specific experiments. Without explicit references to sections or figures, the authors may find it challenging to determine where to apply this suggestion. Additionally, the comment lacks specificity regarding which other metrics should be considered or how they might improve the evaluation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning, examples, or references to support why these metrics are more appropriate or how they would improve the evaluation. Without such justification, the claim is not verifiable, as it lacks the necessary evidence or explanation to be understood or acted upon by the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. While this is a specific and actionable suggestion, it does not provide any context or reasoning as to why BERTScore might be more appropriate or how it could improve the evaluation. The comment lacks depth and does not offer detailed guidance on how to implement this suggestion, leaving the authors with a clear direction but without comprehensive support or examples. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making the necessary changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. It also questions the conditions under which SynTextBench should be used over other metrics. While the comment implies that the authors should conduct these comparisons, it does not provide explicit instructions on how to perform them or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and references \"other metrics proposed in the literature,\" such as MMLU and Big Bench. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison of SynTextBench to other metrics. The comment is also specific because it clearly specifies what needs to be addressed, namely, understanding the conditions under which SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there has been a large amount of work on LLM evaluation and that some metrics do not satisfy the proposed desiderata. It suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. However, the comment does not provide specific examples or references to support the claim about the metrics that do not satisfy the desiderata, nor does it explain why SynTextBench should be compared to these other metrics. This lack of detailed justification makes the claim 3, as the authors would need to conduct further research to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. This feedback is 3 as it provides a specific direction for the authors to enhance their work by conducting additional comparisons. However, the comment could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment offers a clear suggestion for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the writing and annotations, stating that they are \"a little hard to follow.\" However, it does not provide specific guidance or suggestions on how the authors might improve their writing or annotations. Without actionable advice or examples of what needs to be changed, the authors are left without a clear understanding of how to address the issue. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment mentions \"Poor writing and annotations,\" but it does not specify which sections or parts of the paper are affected. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is specific in its critique of the writing and annotations, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a subjective observation about the writing and annotations being \"a little hard to follow.\" It does not contain any claims, opinions, or suggestions that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks depth and does not provide any specific suggestions or examples of what aspects of the writing or annotations are unclear or difficult to follow. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. As a result, the comment is 2, as it provides a general observation but does not offer meaningful insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting, while not achieving the best F1 score in all single types. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or what specific improvements are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and explain the discrepancies in the evaluation metrics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that only 8 out of 14 evaluation metrics achieve SOTA performances and questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 score in all single types. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 score in all single types. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that the proposed method does not perform well in all metrics. The authors are left to infer the significance of these observations, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 score in all single types. This feedback is 3 as it highlights a potential weakness in the evaluation and encourages the authors to investigate and explain the discrepancies in the evaluation metrics. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into improving the evaluation methodology. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific areas where the paper could be improved: the discussion of scalability bounds and the lack of clarity regarding memory requirements and computational complexity. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to expand their discussion on scalability and provide more detailed analysis of memory requirements and computational complexity. However, the lack of specific suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Scalability Bounds\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the lack of discussion on the upper limits of scalability and the absence of a clear discussion on memory requirements and computational complexity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the upper limits of FedDES\"s scalability and lacks a clear discussion of memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on scalability bounds and the absence of a clear discussion on memory requirements and computational complexity. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to expand the discussion or what specific aspects of scalability and computational complexity should be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the setting of Unsupervised Online Adaptation, noting that it seems contradictory because the training set requires annotations, which implies supervision. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and vague, as the authors are left to infer that they need to clarify or reframe the description of the adaptation process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the setting of Unsupervised Online Adaptation, noting that it seems contradictory because the training set requires annotations, which implies supervision. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with annotations, which implies supervision. However, the comment does not provide specific examples or detailed reasoning to support this claim. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of the Unsupervised Online Adaptation setting, noting that it seems contradictory because the training set requires annotations, which implies supervision. This observation is relevant and could help the authors clarify their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the description. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines should be included or how the authors should incorporate these perspectives. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting ways to improve the performance display, but without grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact suggestions or how to implement them. The lack of detailed guidance or references limits the verifiability of the claim, making it 2.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a clear direction for improvement by suggesting specific areas to explore and compare with existing work. However, the comment lacks detailed guidance on which baselines to include or how to incorporate these perspectives, which limits its comprehensiveness. Therefore, the comment is 3, as it offers a starting point for the authors but could be more detailed to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the synthetic experiment in a nonseparable case, referencing Figure 1. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the ability of the neural network to handle a nonseparable data distribution and asks for an explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthetic experiment in a nonseparable case, questioning the ability of the neural network to handle a nonseparable data distribution as illustrated in Figure 1. This feedback is 3 as it points out a potential weakness in the experimental setup, prompting the authors to consider whether their results are robust or if there are limitations in the experimental design. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or improve the experiment. Therefore, it is rated as 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. It also questions the reason for presenting the results in this way. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the presentation of results. The action is implicit and vague, as the authors are left to infer that they need to clarify or reorganize the results to address the safety violations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and specifies the issue with the presentation, particularly regarding the disregard of safety violations in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details what needs to be addressed, namely, the convoluted presentation and the need to clarify the reason for presenting the results in this manner. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support the claim that the presentation is convoluted or why the safety violations are disregarded. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard the safety violations of the agent in the first 1000 episodes. It questions the reason for presenting the results in this way, which is a valid concern for the authors to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve the presentation or address the safety violations. While it highlights an important area for improvement, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, as it points out a critical issue but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \u03c7_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is defining the bounds for \u03c7_i^l to improve understanding of the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the bounds for \u03c7_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, providing a specific request for the authors to define the bounds for \u03c7_i^l. This is important for understanding the timewarp function, which is a critical aspect of the paper. By addressing this request, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional context or suggestions on how to define these bounds or why they are important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should elaborate more on why the statement in line 134 holds, particularly in the context of the RNN compared to the URNN. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of why the statement holds, particularly in the context of the RNN compared to the URNN. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim that the statement on line 134 is only true for a specific sigmoid function and depends on the maximum slope. It suggests that elaboration is needed to explain why this holds, particularly in the context of RNNs compared to URNNs. While the comment raises a valid point about the need for clarification, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where clarification is needed, namely the statement on line 134 regarding the sigmoid function and its dependence on the maximum slope. It suggests that elaboration is needed to explain why this holds, particularly in the context of RNNs compared to URNNs. This feedback is clear and actionable, as it directs the authors to provide additional context or explanation to clarify the point. However, the comment could be more helpful if it offered suggestions on how to elaborate or what specific aspects to address. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the efficiency or whether there are alternative methods to consider. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the pairwise matching are inefficient or how they can be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the assertion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. As a result, it is rated as 2, as it provides a general insight but does not offer actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific guidance or suggestions on how to improve the allocation of Figure 1 or the editing of the main paper. The authors are left with a vague understanding of what needs to be addressed, making it difficult to know how to implement the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not specify which part of the main paper needs editing or provide details on what aspects should be improved. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment does not provide any guidance on how to address these issues, leaving the authors without clear direction. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment lacks specificity and does not provide actionable guidance on how to improve the allocation of Figure 1 or the editing of the main paper. Without detailed suggestions or examples, the authors are left with a vague understanding of what needs to be addressed, making the feedback 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the sentence needs to be rewritten. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for a specific action, namely to rewrite the first sentence of the abstract. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it directly instructs the authors to rewrite the first sentence of the abstract. This feedback provides a clear direction for improvement, which is valuable for the authors to enhance the clarity and effectiveness of their abstract. However, the comment does not offer additional guidance or suggestions on how to improve the sentence, which could make it more helpful. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. While the comment implies that this is a common practice, it does not explicitly instruct the authors to do so. The action is implicit, as the authors can infer that they should carry out this exercise, but it lacks concrete details on how to implement this suggestion. The authors know what needs to be done but may not know how to execute it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. However, it does not specify which experiments or results are being discussed, making it weakly grounded. The comment is specific in suggesting a methodological improvement, but without explicit references to sections or results, the authors may struggle to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. The reviewer provides a logical reasoning by pointing out that using a single heldout test set may not fully capture the method\"s performance. However, the comment lacks specific examples or references to support the claim that this is a common practice, making it 3. The authors would need to conduct additional research or refer to other papers to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reporting of results, specifically noting that the experiments are based on a single heldout test set. It suggests that using multiple train/test splits or folds is a standard practice in most papers on Gaussian Processes (GPs) and encourages the authors to adopt this approach to provide a more accurate illustration of the method\"s performance. While the comment highlights a common practice in the field, it does not provide specific guidance on how to implement this suggestion or what benefits it might offer. The feedback is 3 as it points out a potential improvement but lacks detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle responsible for the quality gains. However, it does not provide any explicit guidance or suggestions on how the authors might simplify the method or identify this underlying principle. The action is implicit and vague, as the authors are left to infer that they should look for a simpler approach or principle, but without concrete steps or examples, the comment lacks actionable details. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more involved than necessary and implies that there might be a simpler underlying principle responsible for the quality gains. However, it does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the method are overly complex or how the authors might simplify it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method is more complex than necessary and implies that there might be a simpler underlying principle responsible for the quality gains. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method is more complex than it needs to be and implies that there might be a simpler underlying principle responsible for the quality gains. While this observation highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might simplify the method or identify this underlying principle. The comment provides a general direction for exploration but does not offer actionable steps or detailed feedback, making it 3. The authors are left to infer the nature of the simplification or principle, which limits the utility of the feedback. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this idea or whether it should be considered a significant contribution. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the idea of adding a method on top of other methods to improve transferability, but it does not specify which part of the paper this suggestion is related to. The authors cannot confidently determine which section or method this comment pertains to, making it weakly grounded. The comment is specific in suggesting that this approach is good but not significant, providing a clear direction for the authors to consider. However, without explicit grounding, the comment is not fully actionable. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach is not significant. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any further explanation or guidance on why this approach is not considered a significant contribution. The comment lacks depth and actionable feedback, leaving the authors without specific insights or suggestions for improvement. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their approach and Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to clarify the challenges and differences, but it lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the analysis of Adam under the (L0,L1)smoothness condition. It raises a question about the challenges involved and suggests that the authors should explain these challenges, particularly in relation to Zhang et al. This provides some level of grounding as it refers to a specific part of the paper, but it does not specify which section or part of the analysis is being discussed. The comment is specific in its suggestion to explain the challenges and differences, but it lacks full grounding because it does not explicitly mention the relevant section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly in relation to Zhang et al. The comment implies that the analysis is straightforward and does not require additional explanation, but it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly in comparison to Zhang et al. This feedback is 3 as it points out a specific area where the paper could be improved by providing more detailed explanations. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the challenges or differentiate the analysis from Zhang et al. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that most person reID methods are based on pedestrian detectors and that there are endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate this information into their work or whether it is relevant to their research. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment discusses the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not specify which part of the paper this information is relevant to, nor does it provide specific guidance on how the authors should address this point. The authors may infer that it relates to the methodology section, but without explicit mention, it remains unclear. The comment lacks specificity in detailing what needs to be addressed or improved, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point makes a factual statement about the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. This statement is descriptive and does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation that does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual observation about the methods used in person reID, noting that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not offer any specific guidance or suggestions on how this information might be relevant to the authors\" work or how it could be incorporated into their research. Without actionable feedback or insights, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks citations to set it in context with other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider citing. This feedback is clear and provides concrete guidance on what needs to be added to the paper to improve its context and relevance. The authors know exactly what actions to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MARL work\" and provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider citing. This allows the authors to accurately identify the part of the paper that needs to be revised. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of citations to set the work in context with other MARL research on exploration and coordination. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to set it in context with other MARL work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. The comment provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider citing. This provides clear and specific evidence supporting the claim, making it 5. The authors can easily understand and address the feedback by incorporating these references into their paper. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks context and references, namely the lack of citations to set it in context with other MultiAgent Reinforcement Learning (MARL) work, particularly recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider citing. This feedback is clear and actionable, offering the authors a direct path to improve the context and relevance of their work. By addressing this suggestion, the authors can enhance the comprehensiveness and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include additional comparisons in their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. The authors may infer that it relates to the comparison section or the introduction, but this inference is not explicit. The comment is specific in its suggestion to compare with noncontrastive methods, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it would enhance the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is a constructive suggestion as it highlights a potential area for improvement by expanding the scope of the comparison. However, the comment lacks specificity and does not provide guidance on which specific noncontrastive methods should be considered or how the comparison should be conducted. While it identifies a direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. It explicitly requests clarification on this aspect. While the comment does not provide a direct action, it clearly identifies a specific area that needs further explanation. The authors are given a clear direction to address the question, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difference between the abstention process and a decision threshold used by the models, and it requests clarification on this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking how it differs from a decision threshold used by the models. This question is relevant and prompts the authors to clarify a potentially confusing aspect of their work. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the abstention process. While it identifies a gap in the paper, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to strengthen their conclusions. The feedback is 3 as it highlights a potential weakness but lacks detailed instructions on how to improve it. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific claims about the paper\"s conclusions, such as the belief that continuous learning with unlabeled data accumulates noise. It also provides references to external works, including R1, R2, and R3, which offer potential explanations for the observed results. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. This provides some support for the claim by offering examples of alternative approaches. However, the comment lacks detailed reasoning or specific evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that they are not convincing. It provides a detailed critique by pointing out a potential limitation in the paper\"s argument, namely the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The comment suggests that the results might be influenced by limited exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. This feedback is 4 as it offers a clear direction for the authors to consider alternative approaches and references that could strengthen their conclusions. However, it could be more helpful if it provided specific suggestions on how to address the identified issue or further expand on the critique. Overall, the comment provides valuable insights for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment does not explicitly instruct the authors to make a change, it does provide a clear question that prompts them to clarify their pretraining methodology and its implications for generalization. The action is implicit but concrete, as the authors can directly address the question by providing the necessary information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the pretraining process and its implications for generalization, providing clear guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking about the pretraining process of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. The comment does not contain any claims or opinions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it prompts the authors to consider the implications of their pretraining methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended and do not offer guidance on how the authors might address these concerns or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions about the accuracy of the ground truth and the significance of the differences, but without clear references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any context, analysis, or suggestions on how the authors might address these concerns or improve their work. The questions are openended and lack actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that no new evaluation metrics are proposed and that existing metrics are only linearly combined. It also suggests that there should be an indepth exploration of the reasons behind the experimental results in the analysis section. While the comment identifies areas for improvement, it does not explicitly instruct the authors to propose new metrics or conduct a detailed analysis. The action is implicit and somewhat vague, as the authors can infer the need for new metrics and deeper analysis but may not know how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics, specifically mentioning the experimental analysis section. However, it does not specify which part of the paper this issue is found in, making it weakly grounded. The comment is specific in identifying the need for an indepth exploration of the reasons behind the experimental results, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are only linearly combined. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to explore the reasons behind the experimental results is a general observation rather than a claim, as it does not require verification. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of new evaluation metrics and the reliance on linearly combining existing metrics. It also points out the need for an indepth exploration of the reasons behind the experimental results, suggesting that the authors should provide a more detailed analysis. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed steps or examples to follow. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifies that the text mentions separate embedding and addition with positional encoding but lacks details on how these embeddings are combined and fed into the CSCM. This provides a clear and direct action for the authors to take, which is to provide additional explanation or details on this process. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of how historical observations are combined with inputs known over all time, given differences in sequence lengths. The comment provides a clear direction for the authors to improve their draft by offering a specific area for additional explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It requests clarification on how this is achieved, specifically mentioning separate embedding and addition with positional encoding. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for clarification. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, given differences in sequence lengths. It highlights the need for clarification on how these elements are combined and fed into the CSCM, which is a critical aspect of the paper. By pointing out this gap in the explanation, the comment provides a clear and actionable suggestion for the authors to address, enhancing the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance or examples on how to resolve this issue. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is an explicit action that the authors can take to improve their draft by streamlining the presentation of their contributions. The comment provides a clear and concrete direction, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This provides full grounding as the authors can accurately identify the specific part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the combination of the first two points about contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is a suggestion for improving the organization of the text, but it does not contain any claims, opinions, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is a clear and actionable suggestion that could help streamline the presentation of the paper\"s contributions. By combining these points, the authors can improve the clarity and coherence of their introduction. However, the comment does not provide specific guidance on how to combine these points or what the combined statement should look like. While it offers a valuable suggestion for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or where in the paper they should be addressed. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations/social norms (e.g., physical/psychological safety) in the main paper. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the lack of clarity but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, noting that the types of situations/social norms (e.g., physical/psychological safety) are not clear. This feedback is valuable as it highlights a potential gap in the paper\"s clarity, which could impact the reader\"s understanding. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as providing examples or clarifications. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community and appreciates its focus on a specific problem. However, it raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these trends or what specific recent trends to refer to. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on a specific problem that somewhat differs from general segmentation problems and appreciates its potential benefit to the neuroscience community. It raises a question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. However, the comment does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to refer to recent trends in the vision community, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the paper\"s focus on a specific problem and its potential benefit to the neuroscience community. However, it raises a question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a potential area for improvement, it lacks specific examples or references to recent trends in the vision community that the authors should consider. This makes the claim 3, as it provides a general direction but lacks detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s focus on a specific problem and its potential benefit to the neuroscience community. It raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. This feedback is 3 as it identifies a potential area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it offered specific examples or references to recent trends in the vision community that the authors should consider. Overall, the comment provides some actionable guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include more baselines for comparison and test more domains. It also points out that the choices of weighting and learning density functions are not strongly motivated and requests stronger empirical results. The comment provides clear and concrete actions for the authors to take, such as including additional baselines and testing more domains. This level of detail and specificity makes the feedback 5, as it gives the authors a clear path to follow for improving their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"more baselines to be compared\" and \"more domains to be tested,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the current choices of weighting and learning density functions, which are not strongly motivated. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more baselines and test more domains, and it questions the motivation behind the choices of weighting and learning density functions. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for more baselines to be compared and more domains to be tested, which is a constructive suggestion for improving the robustness and comprehensiveness of the study. It also points out that the choices of weighting and learning density functions are not strongly motivated, which is a valid concern. The comment provides clear and actionable feedback, encouraging the authors to strengthen their empirical results by including additional comparisons and testing. This feedback is 4 as it guides the authors on how to enhance the quality and rigor of their work, but it could be more detailed by specifying which baselines or domains would be most beneficial to include. Overall, the comment is valuable in helping the authors improve their draft, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the comparability of their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not specify which part of the paper discusses the results or the proposed methods, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in detailing what aspects of the results are not comparable or what specific methods are being referred to. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references to existing methods or detailed explanations of why the results are not comparable, the authors are left without guidance on how to address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the comparability of the results to existing methods, suggesting that the proposed methods may lack significance. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential problem but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide explicit guidance on how the authors could enhance the novelty or address the lack of insights about unique challenges in recommender systems. The feedback lacks concrete suggestions or actions for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items. However, it does not specify which part of the paper this critique applies to, making it weakly grounded. The comment is specific in identifying the lack of insights about unique challenges in recommender systems, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer supports this claim by noting that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment provides some context and references to existing literature, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of different penalty coefficients for users and items provides some context but does not fully address the novelty claim. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it lacks depth in terms of providing specific suggestions or guidance on how the authors could enhance the novelty or address the lack of insights about unique challenges in recommender systems. The feedback is 3 as it points out a potential issue but does not offer actionable advice for improvement, leaving the authors with limited guidance on how to address the identified concerns."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises an important consideration, it does not explicitly instruct the authors to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of this choice and potentially adjust their methodology accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the issue with the choice of ELM and the need for accuracy calculation after using a gender detection model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the accuracy should be calculated after using a gender detection model. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is valuable as it highlights an important consideration that could impact the accuracy and reliability of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the implications of this choice on the methodology. Overall, the comment is 3 as it identifies a potential weakness but lacks depth in terms of actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide specific guidance on how to simplify the writing or which parts of the paper are particularly challenging to follow. Without concrete suggestions or examples, the authors are left without a clear understanding of what changes to make or how to improve the clarity of their writing. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which parts of the paper are particularly challenging to follow or provide examples of where the writing is unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to simplify the writing or what specific changes should be made. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand which parts of the writing are problematic or how to address them. Without detailed feedback or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing, noting that it is difficult to follow in many places. However, it lacks actionable guidance or suggestions on how to simplify the writing or improve its clarity. Without specific examples or detailed advice, the authors are left without a clear understanding of what changes to make or how to enhance the readability of their draft. As a result, the comment is 2, as it provides a general observation but does not offer actionable feedback. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived lack of technical depth or what specific changes could be made to improve the paper. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper are lacking in terms of technical depth or substance. Without specific references or examples, the authors cannot confidently determine which parts of the paper need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to 31. However, it does not provide any specific details or examples of what aspects of the paper are lacking in terms of technical substance or how the addition of a new loss might be insufficient. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide some intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It also asks how certain distributions $P^*$ might make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the proof and the determination of $P^*$. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing intuition for the proof and questioning the invertible function $f^*$, which depends on the fixed $P^*$. The comment further asks about the ease of determining $f^*$ for certain distributions $P^*$ and how to determine which $P^*$ to fix in practice. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment raises valid questions about the proof and the invertible function, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes the claim 3, as the authors would need to infer the basis of the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors provide more intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It also asks how certain distributions $P^*$ might make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. This feedback is 3 as it identifies specific areas where the authors could improve the clarity and understanding of their work. However, it lacks detailed guidance or suggestions on how to address these issues, such as providing examples or references to similar work. While it prompts the authors to consider these aspects, it does not offer comprehensive or actionable advice, leaving the authors with a general direction to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the difference between Eqs. (7) and (10), specifically why one uses X and the other uses H^(1). While the comment raises a valid concern about the inconsistency in notation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or unify the notation used in these equations. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in notation, specifically why one equation uses \"X\" and the other uses \"H^(1). This provides clear guidance on what needs to be addressed in terms of notation consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inconsistency in notation between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1). This is a factual observation rather than a claim or suggestion, as it does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in notation between Eqs. (7) and (10), questioning why one uses \"X\" and the other uses \"H^(1). This feedback is clear and actionable, as it prompts the authors to clarify or unify the notation used in their equations. However, the comment does not provide suggestions on how to address this issue or offer additional context that could further enhance the draft. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to demonstrate that the proposed model captures these phenomena. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to obtain or present this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the applicability of the model to realworld diffusion processes, specifically mentioning the need for empirical evidence to demonstrate that the proposed model captures these phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the need for empirical evidence to support the model\"s applicability, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that empirical evidence is needed to demonstrate the model\"s capture of these phenomena. However, the comment does not provide specific examples or references to support the claim that the model does not capture realworld diffusion phenomena. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes, which is a significant aspect of the paper\"s relevance and impact. It suggests that the authors provide empirical evidence to demonstrate the model\"s ability to capture these phenomena, which is a constructive and actionable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to obtain or present this empirical evidence, such as suggesting types of experiments or data sources. Overall, the comment is 4 as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the main contribution of combining attention with other linear mechanisms is not novel and mentions that alternatives exist. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their contribution. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of combining attention with other linear mechanisms, noting that it is not novel and that alternatives exist. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the novelty or alternatives are being discussed. Without clear grounding or detailed feedback, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. While it identifies a potential issue with the novelty of the approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their contribution. The comment provides a general observation but does not offer actionable feedback or constructive advice, leaving the authors without a clear path to enhance their draft. Therefore, the comment is rated as 2, consistent with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, stating that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or improve the paper. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions are needed to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and its incremental contribution. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or specific sections where the ENCODE part is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part. However, the comment lacks specific examples or detailed reasoning to support the claim that the decomposition part is a significant contribution. The mention of 10 provides some context, but without further elaboration, the claim remains 3. The authors would need to investigate the reference 10 and the specific aspects of the ENCODE part to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it provides some insight but does not offer sufficient guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in A. While the comment implies that such a comparison is necessary, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a performance comparison but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"proproses a CLN (region proposal generation algorithm)\" and suggests a performance comparison with work A. However, it does not specify which part of the paper this proposal is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting a performance comparison with a particular work, but the lack of grounding makes it challenging for the authors to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a performance comparison with a CLN (region proposal generation algorithm) proposed in A. However, it does not provide any specific reasoning, examples, or references to support why such a comparison is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of this suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in A. While this is a valid suggestion for improving the paper\"s comprehensiveness, the comment lacks specificity and does not provide guidance on how to conduct the comparison or what aspects should be considered. The authors are left with a general idea of what to include but without detailed instructions on how to implement it. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making the necessary enhancements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the presentation is too equationdriven and the notation, particularly in chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure would be beneficial to help clarify the key concepts in section 3. This feedback is clear and provides a direct action for the authors to take, which is to include an illustrative figure to improve the clarity of their presentation. The suggestion is concrete and actionable, as it specifies what needs to be done to enhance the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the presentation is too equationdriven and the notation is convoluted, making it clear what needs to be improved. Additionally, the comment suggests including an illustrative figure to help clarify the key concepts in section 3. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and the notation is convoluted, making it hard to follow. However, the comment does not provide specific examples or detailed reasoning to support these claims. The suggestion to include an illustrative figure is a helpful suggestion but lacks the necessary evidence or justification to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks the depth needed for a 5 claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and the notation is convoluted, making it hard to follow. It provides a clear suggestion for improvement by recommending the inclusion of an illustrative figure to help clarify the key concepts in section 3. This feedback is actionable and provides a concrete way for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to create an effective figure or what specific concepts should be illustrated. Overall, the comment is 4 as it directs the authors toward a specific improvement that could significantly enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. While it implies that the authors should improve the visual presentation, it does not provide specific guidance on how to achieve this enhancement, such as suggesting changes to the font size, color, or layout. The action is implicit and somewhat vague, as the authors know they need to improve the visual presentation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, which need enhancement for better readability and aesthetic appeal. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. The comment lacks specific guidance or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the presentation of data in Figure 3, noting that the visual presentation, particularly the subscripts, could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can address to enhance the clarity and professionalism of their figures. However, the comment could be more helpful if it offered additional guidance on how to achieve this enhancement, such as suggesting specific design changes or referencing best practices in figure design. Overall, the comment is 4 as it directs the authors to a specific area needing attention but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in terms of what specific aspects of the technical details or formulations are limited, and it does not provide guidance on how to address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide specific examples or suggestions on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the update of archetype positions after initialization in Algorithm 2. It explicitly requests the authors to comment on this aspect, providing a clear and direct action for the authors to take. The comment is explicit and concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the archetype positions are updated after initialization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the update of archetype positions after initialization in Algorithm 2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the update of archetype positions after initialization in Algorithm 2. It highlights a potential area of confusion or lack of clarity in the paper, prompting the authors to provide additional explanation or clarification. This feedback is actionable as it directs the authors to address a specific point that may impact the understanding of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include missing information about the empirical study in the supplement, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. These actions are direct and concrete, providing clear guidance on what needs to be added or clarified. The authors know exactly what information to include and where to place it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplement\" and specifies the missing information that should be included, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that there are important details missing from the empirical study that should be included in the supplement, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also recommends mentioning the number of regions in the parcellation in the main text. While the comment identifies these areas as missing, it does not provide specific examples or references to support the claim that these details are crucial. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks important information that should be included, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also suggests mentioning the number of regions in the parcellation in the main text. These are specific and actionable suggestions that can help the authors improve the clarity and completeness of their work. By addressing these points, the authors can enhance the transparency and reproducibility of their study. However, the comment could be more helpful if it provided additional context or examples of how these details might impact the results or analysis. Overall, the feedback is 4, as it guides the authors toward improving their draft with clear and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that overparametrization leads to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that supports the benefits of overparametrization in supervised learning of deep neural networks. However, the comment does not explicitly instruct the authors to address this claim or provide a specific action to take. The suggestion to include references to theoretical work is implicit and somewhat vague, as it does not specify which parts of the paper should be revised or how to incorporate these references. Therefore, the comment is 3, as it provides a direction for the authors to consider but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the claim that overparametrization leads to overfitting and worse performance, providing references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or further elaboration on the theoretical work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This feedback is valuable as it encourages the authors to reconsider their assumptions and potentially revise their claims. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or address the challenge to the claim. Overall, the comment is 4 as it prompts the authors to consider a different perspective and provides a direction for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. While the comment implies that this is an important aspect to address, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to include this information, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of timeconsuming training and testing processes due to the shape model being trained in pixel level and the parsing model being a highorder factor graph with multiple types of factors. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issues with processing efficiency and suggests comparing it with existing work, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the training and testing processes are timeconsuming due to the shape model being trained in pixel level and the parsing model being a highorder factor graph with multiple types of factors. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the training and testing processes due to the shape model being trained in pixel level and the parsing model being a highorder factor graph with multiple types of factors. It suggests that the authors should describe and compare the processing efficiency of their approach with existing work. This feedback is 3 as it points out a potential area for improvement and provides a direction for the authors to enhance their draft. However, it lacks specific guidance on how to compare the efficiency or which existing work to reference, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source in the paper. While the action is explicit, it does not provide specific guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but lack detailed instructions on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the prompt dataset creation and its source, specifically for the fewshot case. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the prompt dataset creation and its source, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this discussion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation and its source should be included, specifically for the fewshot case. However, the comment does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include a discussion on the prompt dataset creation and its source, specifically for the fewshot case. While this is a valid suggestion for improving the paper, it lacks specificity and does not provide detailed guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but may find it challenging to implement the suggestion without additional context or examples. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, which would be beneficial to see. It also points out a specific scenario where the weighting method might have helped, referencing the underperformance of the method in the Atlantis game due to repetitive background sounds. While the comment implies that such an ablation would be valuable, it does not explicitly instruct the authors to conduct this study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This provides some grounding as it relates to a specific part of the paper, but it does not explicitly mention which section or experiment this relates to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing a rationale for its relevance, but it lacks full grounding due to the lack of explicit section references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors are expected to infer the relevance of the weighting method to the performance issue, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, which could provide valuable insights into the performance of the method. It references a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds, indicating that the weighting method might have helped in this context. This feedback is clear and actionable, as it directs the authors to conduct a specific type of analysis that could enhance their understanding of the method\"s effectiveness. However, the comment could be more helpful if it provided additional guidance on how to structure the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It highlights that the paper addresses a specific problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or incremental nature of the work, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions the problem addressed, which is the design of semantic parsers for TexttoSQL, and highlights the design of a new dataset as a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, based on the work addressing a specific problem of column operations in designing semantic parsers for TexttoSQL. It mentions the design of a new dataset as a different train/test split of an existing dataset SQUALL and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim that these contributions are not novel or incremental. The lack of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without specific guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests using solid examples to support this explanation. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be done and how to implement it, ensuring the authors know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"removing some of the assumptions like bounded variance and bounded gradients,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for the authors to explain why these assumptions are important and provide solid examples to support this explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples or reasoning to support why these assumptions are significant or how their removal impacts the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, suggesting that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It provides a clear direction for the authors to enhance their paper by offering a rationale for the significance of these assumptions. However, the comment could be more helpful if it included specific examples or guidance on how to present this explanation effectively. Overall, the feedback is 4 as it directs the authors to a critical aspect of their work that requires further development, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. The reviewer provides references to existing works in the field, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could guide the authors in exploring this idea further. However, the comment does not explicitly instruct the authors to incorporate labeled data into their consistency training or suggest specific steps to do so. While the suggestion is clear, it lacks concrete guidance on how to implement it, making the comment 4.", "grounding_specificity_rationale": "The comment raises a question about the use of labeled data for consistency training in graph anomaly detection, specifically mentioning the potential benefits of using exact labels. It references two papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or method. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to consider using labeled data for consistency training, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It references two papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not provide specific reasoning or evidence to support the claim that labeled data would be beneficial for consistency training. The references are not fully integrated into the argument, leaving the authors without a clear understanding of how these references relate to the question being posed. Therefore, the claim is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training the model. The comment provides references to existing works in the field, which could guide the authors in exploring this idea further. However, the comment does not offer specific guidance or suggestions on how to incorporate labeled data into the consistency training process or what impact it might have on the model\"s performance. While it prompts the authors to consider an alternative approach, it lacks detailed actionable advice, making it 3. The authors would benefit from more detailed guidance on how to implement this suggestion, which would enhance the feedback\"s usefulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific guidance on what should be included in the experimental suggestions. This includes highlighting the superiority of the method and suggesting improvements based on the characteristics of the article. The feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"experimental part\" and \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, such as reorganizing the content to better highlight the superiority of the method. This provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved because the content does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references leaves the claim 3, as it requires the authors to infer the nature of the improvements needed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section of the paper, noting that the content does not effectively highlight the superiority of the method. It provides actionable feedback by suggesting that the experimental section should be reorganized to better showcase the method\"s advantages. The comment also offers specific guidance on what should be included in the experimental suggestions, such as highlighting the method\"s characteristics. This feedback is clear and provides the authors with a concrete direction for enhancing their draft, making it 4. However, it could be more helpful if it included additional suggestions or examples to further guide the authors. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to consider the feasibility of their approach and possibly provide more detailed explanations or evidence. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the feasibility of the argument regarding recognition lists being recalled based on items. It provides a detailed critique, questioning the practicality of an exhaustive list and the ability to test concrete predictions with simulations. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the discussion or methodology sections, but this inference is not direct. The comment is specific in detailing the issue with the argument, making it specific despite the lack of explicit grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. The authors are left to infer the implications of this critique, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is 3 as it points out a potential weakness, but it could be more actionable by offering concrete suggestions or examples for the authors to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for zeroshot learning on the CUB dataset, referencing a specific table and paper for comparison. It provides a concrete suggestion by recommending the use of table 1 from \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This feedback is explicit and provides a clear direction for improvement, making it 5. The authors are given a specific action to take and a reference to follow, ensuring they know exactly what needs to be done to enhance their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7\" and \"Table 1 in \u00e2\u20ac\u0153Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016\u00e2\u20ac\u0153,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that better metadata embeddings should be used for zeroshot learning on the CUB dataset and references a specific paper for comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison but proposes that better metadata embeddings options are available. It references a specific table and paper for comparison, providing a logical basis for the claim. However, the comment lacks detailed reasoning or specific examples of how the proposed method would perform with better metadata embeddings, which could strengthen the argument. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of better metadata embeddings for zeroshot learning on the CUB dataset. It references a specific table and paper for comparison, offering a clear direction for enhancing the performance of the proposed method. This feedback is actionable and provides a concrete way for the authors to improve their draft, making it 5. The comment also acknowledges the authors\" response to the reviews, indicating that the paper is acceptable for NIPS. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide explicit instructions on how to address this issue or what specific aspects of the code should be published. The action is implicit and somewhat vague, as the authors need to infer that they should publish the code to support their results. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the shorter training time for the German and Law school datasets in the context of the experiments. It also suggests that the authors should publish the code to support their findings. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experiments section, but this inference is not explicit. The comment is specific in questioning the reasonableness of the training time and suggesting code publication, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the shorter training time for specific datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide any specific reasoning or evidence to support the claim that the training time is unreasonable or to justify the suggestion to publish the code. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the shorter training time for specific datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings, which is a constructive suggestion for transparency and reproducibility. However, the comment lacks depth and does not provide specific guidance on how to address the issue or what aspects of the code should be published. While it identifies a potential area for improvement, it does not offer detailed feedback or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a strong assumption regarding the termination states of instructions and notes that labeling a large number of data manually is expensive in the general case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in pointing out the issue with the assumption but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption regarding the termination states of instructions is strong and expensive to label a large number of data manually in the general case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. This feedback highlights a critical area for improvement, as it points out a limitation that could impact the validity of the assumptions made in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or refine their assumptions. While it provides a starting point for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, it is rated as 3, as it offers some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the description of the contribution regarding the ECE_sweep method. It suggests that the paper should be more upfront about its contribution, specifically noting that it involves autotuning a hyperparameter in the estimate. While the comment implies that the authors should clarify their contribution, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution but are not given specific steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the description of the contribution regarding the ECE_sweep method, specifically mentioning the need for a more upfront presentation of the contribution. It provides a concrete suggestion to clarify that the method involves autotuning a hyperparameter in the estimate, which is a specific aspect of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed regarding the contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the nature of the contribution with respect to ECE_sweep is not clearly described, suggesting that it amounts to a way to choose the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer argues that this is not fundamentally different from other estimators. The comment provides a logical reasoning based on the nature of the contribution and the method\"s similarity to other estimators, which supports the claim. However, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the description of the contribution regarding the ECE_sweep method. It points out that the paper does not clearly explain how the method involves autotuning a hyperparameter in the estimate, which is a common practice in machine learning. The reviewer suggests that the paper should be more upfront about its contribution, which could help the authors clarify their position and improve the paper\"s clarity. While the comment highlights an important area for improvement, it could be more helpful if it provided specific suggestions on how to clarify the contribution or examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding whether the authors are referring to a specific efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" is not a recognized entity, implying that the authors may be referring to a general concept of efficient proxies. However, the comment does not provide explicit guidance on how the authors should clarify this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"Efficient Proxy\" or provide a more precise definition of what is meant by \"efficient proxies.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It points out that the term is unclear, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the ambiguity of the term \"Efficient Proxy,\" but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"Efficient Proxy,\" suggesting that it could refer to a specific efficient proxy or a family of efficient proxies. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of terminology in the paper, specifically regarding the term \"Efficient Proxy.\" It points out that the term is ambiguous, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. However, the comment could be more helpful if it offered suggestions on how to resolve the ambiguity or provided examples of how to clarify the term. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Grouplearning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or improve their methodology. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the methods used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, and the subsequent use of a classical method, DBSCAN, for clustering. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the methods and the clustering approach, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the methods of Mirzasoleiman et al., 2020 and the Grouplearning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Grouplearning setting are stacked, and then a classical method, DBSCAN, is used for clustering. This feedback is 3 as it points out a potential inconsistency or lack of integration between the methods used. However, the comment lacks depth and does not provide guidance on how the authors might address this issue or improve their methodology. Without additional context or suggestions for improvement, the authors may find it challenging to fully understand and act upon the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the model is simple, which can be both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the simplicity of the model or whether it should be considered a feature or a bug. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or method. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why the model is considered simple or how it might be improved. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model\"s simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are explicit and provide clear guidance on what the authors should include in their draft to enhance its motivation and applicability. The actions are concrete, as they specify exactly what needs to be added or included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of runtimes in the experiments. However, it does not specify which part of the main paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to include computational cost and runtime examples, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of runtimes in the experiments. However, the comment does not provide any justification or evidence for why this information is important or how it would enhance the paper. Without specific reasoning or examples, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper, which is currently detailed in the appendix. This addition could help motivate the method by highlighting its efficiency. Additionally, the comment recommends including a rough example of runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are clear and actionable, providing the authors with specific ways to enhance the motivation and applicability of their work. However, the comment could be more helpful if it offered more detailed guidance on how to present this information or examples of how it could be incorporated into the main paper. Overall, the feedback is 4 as it offers valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being discussed. The comment is specific in pointing out the issue with the approach but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, the comment lacks specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach taken by the authors, specifically regarding the complexity of checking on the Witness oracle, which is polynomial time in the tabular case. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or enhance their approach. As a result, the comment is 2, as it provides a general observation but does not offer concrete steps for the authors to take to improve their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their code completion task with existing commercial applications like Copilot. It provides a specific example of a stateoftheart code completion system and recommends testing on a smaller subset of the RepoEval dataset. This feedback is clear and direct, giving the authors a concrete action to take in improving their draft. The suggestion is specific and actionable, as it outlines what needs to be added and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their code completion task with existing commercial applications, such as Copilot, and provides a specific example of a stateoftheart code completion system. It also recommends testing on a smaller subset of the RepoEval dataset. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the experimental setup or results, the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in its suggestion to include additional baselines and testing, but without full grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their code completion task with existing commercial applications like Copilot. This is a logical suggestion based on the current state of the field, as it provides a benchmark for evaluating the performance of the proposed method. However, the comment does not provide specific examples or references to support the claim that Copilot is a stateoftheart code completion system or that it is essential to include it in the comparison. The suggestion is 3 as it offers a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include additional baselines in their code completion task, specifically comparing with existing commercial applications like Copilot. It offers a specific example of a stateoftheart code completion system and recommends testing on a smaller subset of the RepoEval dataset. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness of their experimental evaluation, which is crucial for establishing the novelty and effectiveness of their proposed method. The suggestion is clear and provides a concrete direction for improvement, making it 4. However, it could be more helpful if it included specific details on how to integrate these baselines into the study or what aspects of the comparison would be most informative. Overall, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the introduction regarding what is being modelled, specifically mentioning the second paragraph where it discusses modelling curves. However, it does not provide explicit guidance on how the authors should address this issue or what specific details need to be clarified. The comment implies that the authors should provide more context or explanation about what is being modelled, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding what is being modelled, particularly in the context of tumour growth. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning \"modeling curves.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modeling curves but does not clarify what is being modeled, particularly in the context of tumor growth. This feedback is clear and actionable, as it directs the authors to provide more context or explanation about the modeling process. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to improve clarity. Overall, the comment is 4 as it highlights a specific area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. This feedback is explicit and provides a clear action for the authors to take, which is to include this performance evaluation in their draft. The suggestion is concrete, as it specifies what needs to be added to the paper to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of the performance of the model and baselines on test samples from the observational (in) distribution, specifically questioning the reason for the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ) . It suggests that the authors should demonstrate this performance on test samples from the observational distribution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific as it clearly outlines what the authors need to demonstrate to address the concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically questioning why shift=0 is much better than shift~ N ( 0 , \u03c3 2 ) , given that both cases incorporate a domain shift. The comment suggests that the authors should demonstrate this performance on test samples from the observational distribution. While the comment raises a valid concern, it lacks specific examples or references to support the claim that shift=0 is better. The suggestion to show performance on test samples from the observational distribution is a logical step to address the concern, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically questioning why shift=0 is much better than shift~ N ( 0 , \u03c3 2 ) , given that both cases incorporate a domain shift. It suggests that the authors should demonstrate this performance on test samples from the observational distribution. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. By suggesting a performance evaluation on test samples from the observational distribution, the comment offers a concrete way for the authors to improve the clarity and robustness of their results. However, the comment could be more helpful if it provided additional guidance or examples on how to conduct this evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more explanation to clarify the \"expected\" result and that the main contribution of the paper, the CBR, should be discussed in more detail. It specifically asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or just the first term. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. The authors are given a clear direction on what additional information or discussion is required, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"expected\" and \"Eq 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, providing more explanation and discussion on the CBR, different optimization strategies, and their results. This includes asking about the impact of minimizing both inter and intra terms or just the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation for the \"expected\" result and discusses the main contribution of the paper, the CBR. It asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or just the first term. While the comment provides a logical reasoning for the need for additional explanation, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance of these questions to the paper\"s contribution and methodology. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for more explanation regarding the \"expected\" result. It suggests that the paper should provide a clearer discussion on the contributions, particularly focusing on the CBR and its optimization strategies. The comment raises a question about the impact of minimizing both inter and intra terms in Equation 3 or just the first term, which could lead to a more detailed analysis of the results. This feedback is clear and actionable, offering the authors a specific direction for enhancing the clarity and depth of their discussion. However, it could be more helpful if it provided additional context or examples to further guide the authors. Overall, the comment is 4, as it effectively directs the authors to improve their draft by addressing a key area of weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors to include such a definition or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a definition and how to integrate it into their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or proof. The authors can infer that it relates to the proofs or definitions section, but this inference is not explicit. The comment is specific in its suggestion to include a definition of treewidth, but it lacks grounding as it does not specify the exact part of the paper where this definition should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion and how it would enhance their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is 3 as it identifies a potential area for improvement by pointing out the importance of the treewidth concept in the paper. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this definition or why it is crucial. To be more helpful, the comment could include examples of how a definition might enhance the paper or suggest specific sections where it could be included. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically asks how this redundancy is built into these algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what aspects of the algorithms need further clarification. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically references a sentence that discusses the robustness of Cans coming from the information redundancy in the weight pool. This provides some grounding as it mentions a specific sentence, allowing the authors to identify the relevant part of the paper. However, the comment lacks specificity as it does not detail how the information redundancy is built into the algorithms or what aspects of the algorithms need further clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically references a sentence that discusses the robustness of Cans coming from the information redundancy in the weight pool. While the comment identifies a specific area for clarification, it does not provide any additional context, suggestions, or guidance on how the authors might address this issue or improve their draft. Without further elaboration or actionable feedback, the comment is limited in its usefulness to the authors. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the model\"s design choice involving multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific experiments or analyses could be conducted to explore this issue. The action is implicit and vague, as the authors are left to infer that they should conduct additional experiments or analyses to determine the importance of the design choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific feature of the model, the use of multiple INs at different speeds in the dynamics predictor, which is a novel aspect of the model. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the importance of this design choice and whether one IN would suffice, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is important or why it might be better to use a single IN. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. This feedback is 3 as it prompts the authors to consider the significance of their design choice and potentially conduct further analysis or experimentation to justify its necessity. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue or what additional experiments might be necessary. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the experiments, suggesting that the opponent might not aim to maximize the multiagent payoff proposed by the authors. However, it does not provide explicit guidance on how the authors should address this concern or what steps they should take to improve their experiments. The comment lacks concrete suggestions or actions for the authors to take, making it 1. The authors are left without a clear understanding of what changes or additions are needed to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the opponent\"s performance, suggesting that the opponent does not aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a rationale for this observation, mentioning that the opponent maximizes classical SE and AE instead. This level of detail helps the authors understand what needs to be addressed in their experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent\"s performance can be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. However, the comment lacks specific examples or detailed reasoning to support this claim. It mentions that the opponent maximizes classical SE and AE, but this does not provide a comprehensive explanation of why this is a concern or how it affects the experiments. Without further elaboration or evidence, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, specifically noting that the opponent\"s performance might be outperformed due to the opponent\"s lack of aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a rationale by mentioning that the opponent maximizes classical SE and AE instead. This feedback is 3 as it highlights a potential weakness in the experimental design and suggests an area for improvement. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or provide additional context to support their experimental choices. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this confusion or what steps they should take to clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment lacks specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This feedback is 3 as it points out a potential issue that could be clarified or addressed in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this confusion or improve the clarity of the theorem. To be more helpful, the comment could include additional context, examples, or references to support the claim or offer actionable steps for the authors to take. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results that exclude the mixup technique from the proposed method. This action is clear and direct, as it specifies what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides a concrete and actionable suggestion, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from their proposed method to demonstrate its pure contribution. This claim is 3 as it provides a logical reasoning for the inclusion of such results, but it lacks specific examples or references to support the necessity of this inclusion. The authors would need to infer the importance of this suggestion based on the context of the paper, making the claim 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include experimental results that exclude the mixup technique from their proposed method. This is important because it allows the authors to demonstrate the pure contribution of their method without the influence of the mixup technique. By following this suggestion, the authors can better understand the impact of the mixup technique on their results and provide a more comprehensive analysis. However, the comment could be more helpful if it provided additional context or guidance on how to interpret these results or what specific outcomes to expect. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the object detection or attention mechanisms discussed in the paper. The authors can infer that it relates to the methods or results sections, but the comment does not provide explicit references to specific parts. The comment is specific in detailing what needs clarification, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the object detectionbased attention process and whether it is performed on the image or a convolutional feature map. It also inquires about rescaling based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not contain an explicit claim or suggestion, it raises a logical question that requires clarification. The authors are prompted to provide additional details or explanations to address the inquiry, but the comment does not make a claim that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about rescaling based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. While the comment implies that the authors should address this gap in their theoretical analysis, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed analysis of the theoretical support for Fourier features. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the theoretical section or discussion on Fourier features, but this inference is not precise. The comment is specific in questioning the theoretical support for Fourier features, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without guidance on how to address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed, which is an important consideration for the theoretical underpinnings of the work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional analysis might be necessary. While it identifies a potential gap in the theoretical analysis, it lacks actionable advice, making it 3. The authors are prompted to consider a theoretical aspect of their work, but the feedback could be more comprehensive and actionable to be rated higher."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about potential errors in the initial calibration steps (steps 1 & 2) of the original algorithm, which the authors used. It suggests that this might explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to investigate or correct the potential error. The action is implicit and vague, as the authors are left to infer that they should look into the calibration steps and possibly conduct further analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III\" of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what the authors need to investigate. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about potential errors in the initial calibration steps of the original algorithm, suggesting that this might explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide specific evidence, examples, or references to support the claim of an error. The reasoning is based on the reviewer\"s observation of the disparities, but without detailed justification or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about potential errors in the initial calibration steps of the original algorithm, suggesting that this might explain the speed disparities observed between the RSPs and FDs. This feedback is 3 as it identifies a specific area for improvement and provides a potential explanation for the observed discrepancies. However, the comment lacks detailed guidance or suggestions on how the authors might investigate or address this issue, such as specific steps or methods to verify the calibration steps. While it prompts the authors to consider a possible cause for the disparities, it does not offer actionable advice or detailed recommendations for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their work based on this observation. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment discusses the comparison between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or discussion. The authors may infer that it relates to the comparison of methods or results, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the comparison are arguable or why it is not more significant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not provide any specific evidence, examples, or reasoning to support this claim. The comment lacks actionable feedback or suggestions for the authors to address this issue or improve their work. As a result, the comment is not helpful, as it does not offer any guidance or insights that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a specific area of inquiry, it does not provide explicit guidance or suggestions on how the authors should address this question. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of nonparametric emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is specific and provides a clear direction for the authors to address, as it prompts them to consider the implications of their work on inference tasks. However, the comment does not explicitly mention a specific section of the paper, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is logical and seeks clarification on a specific aspect of the paper\"s methodology. However, it does not contain any claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is valuable as it prompts the authors to consider the implications of their work on inference tasks, which could be an important aspect of their research. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or explore these tasks in their paper. While it identifies a relevant area for further investigation, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider expanding the comparison to the remaining 110 datasets. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to conduct this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider expanding the comparison to the remaining 110 datasets. However, the comment does not specify which part of the paper this discussion is related to, such as a specific section or table where the comparison is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the rationale behind the dataset selection, but without explicit grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It suggests that the authors should consider expanding the comparison to the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. The feedback is 3 as it points out a limitation in the current analysis, but it does not provide detailed advice on how to address it, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation in the introduction about lowrank factorization is unnecessary, given that the main result is about polytopes. It also requests that the implications of the result for lowrank matrix factorization be explicitly discussed. While the comment implies that the authors should remove the unnecessary motivation and discuss the implications, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address both the unnecessary motivation and the implications for lowrank matrix factorization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation section in the introduction, specifically mentioning the lowrank factorization and its relevance to the main result about polytopes. It suggests that the motivation is unnecessary and requests that the implications for lowrank matrix factorization be discussed explicitly. However, the comment does not specify which part of the introduction this relates to, making it weakly grounded. The feedback is specific in identifying the issue with the motivation and the need for discussion on implications, but without explicit references to sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation in the introduction about lowrank factorization is unnecessary given that the main result is about polytopes. It also suggests that the implications of the result for lowrank matrix factorization should be discussed explicitly. The comment provides a logical reasoning by pointing out the relevance of the main result and the need for discussion on implications. However, it lacks specific examples or references to support the claim fully. The suggestion to discuss implications is clear, but the comment could be strengthened by providing more detailed reasoning or examples to fully justify the claim. Therefore, the comment is 3, as it provides a logical basis but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the introduction, suggesting that the motivation about lowrank factorization is unnecessary given the main focus on polytopes. It also provides a constructive suggestion by asking the authors to discuss the implications of their result for lowrank matrix factorization if it has any. This feedback is clear and actionable, as it directs the authors to refine their introduction and consider the broader implications of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to discuss these implications effectively. Overall, the comment is 4 as it offers valuable insights for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper is incremental with respect to 31 and describes the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this incremental nature or improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions \"with respect to 31,\" indicating that it is referring to a specific reference or work, but it does not specify which part of the paper this relates to. The authors can infer that it pertains to the architecture or methodology, but the lack of explicit reference to a section or part of the paper makes it weakly grounded. The comment is specific in pointing out that the paper is incremental with respect to a particular work, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference, 31, and describes the adaptation of the existing architecture for the multiperson case. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is incremental with respect to a specific reference, 31, and describes the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this incremental nature or improve their work. It identifies a potential issue but does not offer actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used for solving the minmin problem, which is mentioned as an alternating direction method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify which specific method is being used, provide more details about the method, or explore alternative methods. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"minmin problem\" and the \"alternating direction method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to solve the minmin problem, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. While it identifies a gap in the paper\"s description, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment highlights potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the effectiveness of their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the effectiveness of lower bound double qlearning and the performance decrease of Clipped DDQN in certain environments. The comment further highlights the potential overestimation of the true maximum value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the effectiveness of their approach. The feedback provides some insight into areas for improvement but does not offer actionable steps or detailed advice, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is 3, as it highlights weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to clarify their results. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation or justification for the observed performance trend. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, and it provides an expectation that the performance should approach that of vanilla methods from above but from below. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation or explain why the performance trend is unexpected. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the reviewer\"s expectation. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify their results. While it identifies a potential area of confusion, it lacks actionable feedback or detailed suggestions for improvement, making it 2. The authors are left with a question but without a clear path to address it, which limits the usefulness of the comment. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with earlier research work from 2020, noting that the authors have explained their reasons in the author response. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons they should make. The comment suggests that the authors have compared their results to earlier systems with worse performances, but it does not offer concrete steps or examples of how to improve the comparison. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with earlier research work from 2020, specifically mentioning that the authors have not compared their results with this work. It also notes that the authors have explained their reasons for not doing so in the author response. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the absence of comparison with earlier research work from 2020 and the authors\" explanation in the author response. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not compare the results with earlier research work from 2020, despite the authors explaining their reasons in the author response. However, the comment does not provide specific examples or references to the earlier work or detailed reasoning about why this comparison is necessary. The lack of specific examples or references makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s comparison, specifically noting that the results are not compared with earlier research work from 2020. It acknowledges the authors\" explanation in the author response but highlights that the comparison is made with earlier systems with worse performances. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what comparisons would be beneficial. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it identifies a gap but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to elaborate on the Hoeffding\"s bound and its application in stochastic algorithms. It explicitly instructs the authors to explain how the Hoeffding inequality holds true for any w, given the independence of samples and the conditioning on the previous iterate. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is elaborating on the Hoeffding\"s bound and its application in stochastic algorithms. The comment provides a clear direction for the authors to improve their draft by offering a specific suggestion for elaboration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Hoeffding\"s bound holds true for any w, given the independence of samples and conditioning on the previous iterate in stochastic algorithms. The reviewer provides a logical explanation, stating that the Hoeffding inequality is always possible to show under these conditions. This reasoning is clear and supports the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by asking the authors to elaborate on the Hoeffding\"s bound and its application in stochastic algorithms. It highlights a potential area of clarification regarding the conditions under which the Hoeffding inequality holds true, particularly in the context of stochastic algorithms. By suggesting that the authors elaborate on this, the comment offers actionable feedback that can help the authors improve the clarity and depth of their discussion. However, the comment could be more helpful if it provided specific examples or references to support the elaboration. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While the comment implies that the authors should consider incorporating these approaches, it does not provide explicit instructions on how to implement them or why they would be beneficial. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the potential benefits of adding these approaches. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of the paper this table is in or provide any context about the table itself. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in suggesting the addition of a particular approach, but without grounding, it is challenging for the authors to understand the context or relevance of this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, the comment does not provide any justification or reasoning for why these approaches should be included or how they would enhance the table. Without specific examples, references, or logical reasoning, the claim lacks verifiability. The authors are left without guidance on how to implement this suggestion or why it would be beneficial, making the comment barely verifiable.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it identifies a potential enhancement to the paper by suggesting a specific method that could be included. However, the comment lacks detail on why this approach would be beneficial or how it could be integrated into the table. To be more helpful, the comment could provide more context or reasoning about the potential benefits of adding this approach. Therefore, the comment is rated as 3, as it offers a suggestion but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from temporal relationships. This feedback is clear and direct, providing a specific action for the authors to take. It gives them a clear understanding of what needs to be addressed and how to correct it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that \"causality is different from temporal relationship,\" providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"causality is different from temporal relationship,\" which is a factual statement rather than a claim or suggestion. It does not require verification or evidence, as it is a clear and accurate statement of fact. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out a potential confusion in terminology regarding \"causal mechanisms\" and \"causality\" on page 1. It instructs the authors to use these terms carefully, emphasizing the distinction between causality and temporal relationships. This feedback is specific and actionable, helping the authors to improve the clarity and accuracy of their terminology. However, it could be more helpful if it included examples or further explanation of why this distinction is important. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the relationship with the referenced work, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for improvement by pointing out a relevant reference that could enhance the paper\"s discussion. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this discussion or what aspects of the results should be highlighted. To be more helpful, the comment could specify which parts of the paper the discussion should address or how it would contribute to the overall understanding of the results. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider how well the assumptions underlying PCA are met. While the comment highlights potential issues, it does not provide explicit guidance or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to evaluate the assumptions of PCA and possibly provide additional context or evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the method and assumptions, it lacks grounding, as it does not clearly identify the part of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions of PCA are met in the context of the paper. While the reference provides a starting point for the authors to consider, the lack of detailed analysis or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the authors should consider how well the assumptions underlying PCA are met, referencing a relevant paper for further exploration. While the comment identifies a potential area for improvement, it lacks specific guidance or actionable suggestions on how the authors might address these concerns or enhance the significance of their results. The feedback is 3 as it points out a potential weakness but does not provide detailed advice on how to strengthen the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the fewshot RC models considered in the paper are not stateoftheart, and it suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of fewshot RC models in the paper and suggests comparing their performance to relation extraction/generation models in fewshot settings. However, it does not specify which part of the paper discusses these models, making it weakly grounded. The comment is specific in suggesting a comparison to stateoftheart models, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart, suggesting a comparison to relation extraction/generation models in fewshot settings. However, the comment does not provide specific examples or references to support the claim that the models are not stateoftheart. The suggestion to compare performance is a logical inference but lacks detailed justification or evidence. Therefore, the claim is 3, as it provides a suggestion but lacks sufficient supporting evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart. It suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. This feedback is 3 as it points out an area for improvement and provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included specific examples or references to stateoftheart models or detailed suggestions on how to conduct the comparison. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. While the comment implies that the authors should include results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide results, but the comment lacks specific guidance on how to present these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the discussion on using sequential MCB vs a single MCT layers for the decision head. It is fully grounded as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it requests additional information about what was observed in this discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head, but it does not contain any claims or opinions that require verification. It is a request for additional information, not a claim or suggestion that requires justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing results for the discussion on using sequential MCB vs a single MCT layers for the decision head. This feedback is clear and actionable, as it directs the authors to include additional information that would enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to present these results or what aspects of the results are particularly important to highlight. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment highlights a potential issue with the experimental setup, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify their experimental setup and consider the impact of the number of distribution sets. However, the comment lacks concrete details on how to implement these clarifications, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this choice is discussed. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in its inquiry about the choice of distribution sets and their impact, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification or the potential impact of the choice of distribution sets. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it relates to the overall quality of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area for clarification, it lacks depth and specificity. It does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental setup. The feedback is 3 as it prompts the authors to consider the impact of their experimental choices, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluative framework is limited in scope, specifically mentioning the consideration of only three QuestionAnswering tasks and two language models. It raises questions about the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies a potential limitation, it does not provide explicit guidance on how the authors should address this issue. The feedback is vague and lacks concrete suggestions for improvement, leaving the authors uncertain about how to expand the scope of their framework. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning the limitations in scope, which is restricted to three QuestionAnswering tasks and two language models. It raises questions about the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. However, the comment does not specify which part of the paper discusses the evaluative framework, making it weakly grounded. The authors can infer that it relates to the methodology section, but this is not explicitly mentioned. The comment is specific in detailing the limitations of the framework, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, specifically mentioning the consideration of only three QuestionAnswering tasks and two language models. The reviewer questions the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment raises a valid concern about the scope of the evaluation, it lacks specific examples or references to support the claim. The reasoning is based on the limited number of tasks and models considered, but without further elaboration, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is 3, as it provides a basis for the claim but requires additional details for full verification.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, specifically noting that it is restricted to only three QuestionAnswering tasks and two language models. The reviewer questions the method\"s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca, suggesting that the potential generalizability of the method is a subject of inquiry. This feedback is 3 as it highlights a potential area for improvement in the paper\"s scope and applicability. However, it lacks specific suggestions or guidance on how the authors might address this limitation, such as proposing additional tasks or models to consider. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models instead of the obsolete ngram HMM and RNN models. This action is clear and concrete, as it provides a specific direction for the authors to improve their draft by aligning it with current NLP trends. The comment offers a clear and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of perplexity experiments with obsolete language models, specifically mentioning ngram HMM and RNN. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the use of perplexity experiments. The comment is also specific because it clearly specifies the need to use transformerbased models to improve alignment with current trends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of perplexity experiments with obsolete language models (ngram HMM and RNN) is outdated and recommends using transformerbased (masked) language models to better align with current NLP trends. The reviewer provides a clear rationale for this suggestion, stating that transformerbased models are more commonly used and aligned with current trends. This reasoning is logical and provides a strong basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the use of perplexity experiments with obsolete language models (ngram HMM and RNN). It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more aligned with current NLP trends. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and currency of their work. By following this suggestion, the authors can significantly improve the alignment of their research with contemporary practices in the field. However, the comment could be more helpful if it included additional context or examples to further support the recommendation. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify the estimation of mu. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the estimation of mu, which is the proportion of missing observations. However, it does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the estimation of mu, but it lacks detailed guidance on how the authors might address this issue or clarify the estimation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any supporting evidence, reasoning, or references to justify why this estimation might be unclear or problematic. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the estimation process. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific action for the authors to take, which is to present the performance as a function of the distance of initialization. It provides a detailed method for doing so, including the steps to vary the distance, sample initial matrices, and report the performance accordingly. The comment also includes an expectation about the expected results, such as the mean error and variance increasing as the quality of initialization decreases. This level of detail and specificity makes the action explicit and concrete, allowing the authors to clearly understand and implement the suggested improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests a specific action for the authors to present the performance as a function of the distance of initialization. It provides a detailed method for doing so, including the steps to vary the distance, sample initial matrices, and report the performance accordingly. This level of detail and specificity allows the authors to accurately identify the part of the paper where this action should be applied, making the comment fully grounded. The comment also specifies what needs to be addressed, namely the presentation of performance as a function of initialization distance. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a method for presenting the performance as a function of the distance of initialization, which is a specific and detailed suggestion. However, it does not provide any evidence, reasoning, or references to support why this method is necessary or how it would improve the paper. The claim lacks context or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of the performance of the proposed method, focusing on the sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization, which is a novel and detailed approach. The comment includes a method for varying the distance and sampling initial matrices, providing a clear and actionable way for the authors to enhance their results. Additionally, it offers an expectation of how the mean error and variance might increase as the quality of initialization decreases, which adds depth to the suggestion. This level of detail and practical guidance makes the comment 5, as it empowers the authors to significantly improve their draft by implementing a specific and effective method for analysis. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds instead of only bounds in expectation. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies these actions, it does not explicitly instruct the authors to make these changes. The suggestion is concrete in terms of what needs to be done, but the action is inferred, making it 3.", "grounding_specificity_rationale": "The comment suggests that only bounds in expectation are provided and questions whether highprobability bounds could be obtained. It also suggests using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific part of the paper, it implies that the authors should consider these suggestions in the context of the experiments. The authors can infer that the comment pertains to the experimental section or results, but they cannot pinpoint the exact part being addressed. The comment is specific in detailing what needs to be addressed, such as obtaining highprobability bounds and adding measures of robustness. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and questions whether highprobability bounds could be obtained. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the potential benefits of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that only bounds in expectation are provided, suggesting that highprobability bounds could be more informative. It provides a specific suggestion to consider using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, offering the authors a concrete way to enhance the robustness and reliability of their results. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these suggestions. Overall, the comment is 4 as it directs the authors to improve their work by addressing a specific limitation and offering a practical solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the author is not an expert in pruning but finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the results and consider additional evaluation aspects, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the author\"s expertise in pruning and finds the motivation to be good, but it raises concerns about the results being less impressive and suggests evaluating them from additional aspects, such as latency, memory consumption, and network size. However, the comment does not specify which part of the paper these concerns relate to, making it weakly grounded. The authors can infer that it pertains to the results section or discussion, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely, the evaluation of results from multiple aspects. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the author\"s expertise in pruning and finds the motivation to be good, but it raises concerns about the results being less impressive. It suggests that the results should be evaluated from more aspects, such as latency, memory consumption, and network size. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the author\"s expertise in pruning and finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these concerns or enhance the evaluation. The feedback is 3 as it points out potential weaknesses but does not provide detailed actionable advice, leaving the authors with a general direction to improve their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their model to enforce diversity. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. However, it does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results sections. The authors might infer that it pertains to the methodology or results, but this is not explicitly stated. The comment is specific in detailing the issue with the lack of explicit diversity enforcement, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s focus on diversity is not reflected in the model, despite the title suggesting otherwise. However, the comment does not provide specific examples or evidence to support this claim, such as detailed comparisons between the title and the content of the paper. Without explicit examples or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s focus on diversity, as indicated by the title, but the lack of explicit enforcement of diversity in the model. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s methodology that needs to be addressed. By pointing out this inconsistency, the reviewer provides a clear direction for the authors to improve their draft, specifically by suggesting that they should explicitly enforce diversity in their model. This constructive feedback is valuable as it guides the authors in enhancing the rigor and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are supposed to be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these missing experiments. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the absence of experiments involving contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these experiments effectively. Overall, the comment is 4 as it highlights a critical gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to include in the comparisons, making it 5. The authors know exactly what changes to make to enhance their work based on the feedback provided.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of FIDs and DinoV2 Frechet Distances, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that FIDs are being widely used for evaluation but have clear flaws, and suggests using DinoV2 Frechet Distances instead. The comment provides a rationale by referencing a specific work C that highlights the flaws in FIDs and the use of Inception networks. This provides some support for the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs (Frechet Inception Distances) as a metric for evaluation, noting that there have been clear flaws associated with them and the simplicity of the Inception network. It suggests using DinoV2 Frechet Distances as an alternative, which is a specific and actionable recommendation. This feedback is valuable as it provides the authors with a clear direction for improving their evaluation metrics, enhancing the robustness and reliability of their results. However, the comment could be more helpful if it included further justification or examples of the flaws in FIDs or detailed guidance on how to implement the suggested metric. Despite this, the feedback is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point questions the novelty of the paper, suggesting that it may be incremental. It asks the authors to clarify how their work differs from a previous publication, specifically mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This comment implicitly suggests that the authors should provide a detailed comparison or explanation of the differences between their work and the referenced publication. However, it does not explicitly instruct the authors to make these comparisons or provide specific details on what aspects need to be addressed. The action is concrete in terms of what needs to be done, but it is inferred rather than explicitly stated. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific reference, https://aclanthology.org/2021.findingsacl.57.pdf, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the novelty of the paper and asks for clarification on how the work differs from the referenced publication. The comment provides a clear direction for the authors to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the novelty of the paper, suggesting that it may be incremental. It asks the authors to clarify how their work differs from a specific publication, implying that the methodology is similar. However, the comment does not provide specific examples or detailed reasoning to support the claim that the work is incremental. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides a basis for questioning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the paper, questioning whether it offers incremental improvements over a previous publication. By asking the authors to clarify the differences between their work and the referenced publication, the comment prompts a detailed comparison or explanation of the unique contributions. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and impact of their draft. However, the comment could be more helpful if it offered specific suggestions or examples of how to highlight the novelty or differentiate the work. Overall, the comment is 4 as it directs the authors to address a critical aspect of their paper\"s originality."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what steps they should consider to resolve it. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and references specific datasets, CUB and SOP, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results of the ablation studies, particularly why the complete loss function performed worse than those with some terms missing. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential inconsistency but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that introducing inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. While the comment identifies a potential area for further exploration, it does not explicitly instruct the authors to conduct these tests or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental scope to include other embedding models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that introducing inverse triples might be applicable to other embedding models besides CP, but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or experiment this comment refers to, making it weakly grounded. The comment is specific in suggesting that the authors should test inverse triples in other embedding models, but it lacks grounding, as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be applicable to other embedding models besides CP, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific references or detailed explanations, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or guidance for the authors to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that introducing inverse triples might be applicable to other embedding models besides CP, but the authors did not test such cases in their experiments. This feedback is 3 as it points out a potential area for further exploration that could enhance the scope and applicability of the study. However, the comment lacks specific guidance or suggestions on how the authors might conduct these tests or what aspects of the other embedding models they should consider. To be more helpful, the comment could provide more detailed advice or examples of how to expand the experimental scope. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the abstract, noting that the statement \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions\" is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. While the comment points out a specific area of confusion, it does not provide explicit guidance on how to clarify the statement or what aspects of the abstract should be made more highlevel. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the abstract without providing detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which is its unclear nature due to the technicalities mentioned. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technicalities are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that the abstract should be more highlevel. The comment provides a rationale by stating that technicalities are not necessary for a highlevel understanding, which supports the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the technicalities that are unclear, which limits the clarity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the abstract, noting that a statement about ensuring a lowrank feature subspace and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. This feedback is clear and actionable, as it provides a specific area for improvement and offers guidance on how to simplify the abstract. By addressing this feedback, the authors can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 4, as it effectively directs the authors to improve the clarity of their abstract without fully addressing all aspects of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left without any actionable steps or concrete advice on what aspects of the algorithm\"s complexity could be enhanced. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the algorithm needs improvement or what aspects of complexity should be addressed. This lack of specificity makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide any guidance on how to improve the complexity of the algorithm, leaving the authors without a clear understanding of what changes to make. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is room to improve the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what aspects of the algorithm\"s complexity could be enhanced or how to make those improvements. This lack of specificity and actionable guidance makes the comment 2, as it does not effectively support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of Gaussian Process (GP) and mentions that dynamical modeling has been widely investigated in the GP community, referencing the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their use of GP or address the critique. The comment lacks actionable advice, leaving the authors without a clear understanding of what changes or additions are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may have an idea of where the critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The comment is specific in its critique of the use of GP and references a specific paper, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is \"kind of straightforward and naive,\" suggesting that it is not innovative or sophisticated. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of dynamical modeling and the reference to a specific paper (NIPS 2005) provides some context, but it does not substantiate the claim. Without additional evidence or explanation, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Process (GP) and suggests that its application is \"kind of straightforward and naive.\" It references the Gaussian Process Dynamical Model in NIPS 2005, implying that the authors should consider more sophisticated approaches. However, the comment lacks specificity and does not provide detailed guidance on how the authors might improve their use of GP or what specific aspects of the dynamical modeling approach are being critiqued. Without actionable advice or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is 2, as it identifies a potential issue but does not offer actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statement in the supplemental section D.4 regarding the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It also questions the author\"s experience, suggesting that the baseline models may not be properly regularized. The reviewer further asks if dropout is applied to the hidden states in addition to the embeddings. While the comment identifies a potential issue and provides a specific question for the authors to consider, it does not explicitly instruct the authors to address this concern or provide guidance on how to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization of their models and possibly clarify the statement in the supplemental section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for LM compared to the GAN model and suggests that the baseline models may not be properly regularized. The comment further asks if dropout is applied to the hidden states in addition to the embeddings, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about a statement in the supplemental section D.4 regarding the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. The reviewer questions this claim by referencing a study by Zaremba et al. 2014, which suggests that the baseline models may not be properly regularized. The comment also asks if dropout is applied to the hidden states in addition to the embeddings. While the reviewer provides a reference to support their claim, the comment lacks detailed reasoning or specific examples to fully substantiate the critique. The mention of Zaremba et al. 2014 provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about a statement in the supplemental section D.4 regarding the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It challenges this claim by referencing a study by Zaremba et al. 2014, which suggests that the baseline models may not be properly regularized. The reviewer also asks if dropout is applied to the hidden states in addition to the embeddings. This feedback is 3 as it prompts the authors to reconsider their claims and provides a specific reference for further investigation. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional context for the authors to consider. Overall, the comment provides a basis for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to find. The action is implicit and vague, as the authors are left to infer that they need to improve the organization and clarity of the ablation sections. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not specify which sections or ablations are problematic, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of specific guidance or examples makes it challenging for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s organization, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback highlights a potential weakness in the paper\"s structure, which could hinder the reader\"s understanding. However, the comment lacks actionable suggestions or guidance on how the authors might improve the organization or make the ablations more accessible. While it points out a problem, it does not provide concrete steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think more clearly about it. It also recommends that the online algorithm and robustness be highlighted as novel and interesting, and that the experimental results in the appendix be moved to the main paper. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need to be revised or how the authors should address the \"halfbaked\" aspect of the differential privacy application. The action is explicit but somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think more clearly about it. It also recommends moving the online algorithm and robustness results from the appendix to the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application or the online algorithm, making it weakly grounded. The feedback is specific in suggesting improvements to the presentation and content of the paper, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think more clearly about it. It also recommends moving the online algorithm and robustness results from the appendix to the main paper. However, the comment does not provide specific examples or detailed reasoning to support the claim that the application is \"halfbaked\" or why it should be moved to the main paper. The suggestion lacks explicit evidence or justification, making it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion regarding the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think more clearly about it. It also recommends moving the online algorithm and robustness results from the appendix to the main paper, which is a valuable suggestion for improving the presentation and accessibility of these findings. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to enhance the differential privacy application or how to present the online algorithm and robustness results more effectively. Overall, the feedback is 4 as it offers clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this comparison or what specific aspects of the multilingual chainofthought could be improved. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not specify which part of the paper this comparison is based on, nor does it provide any details on what aspects of the multilingual chainofthought are incremental or how they compare to the villa chainofthought. Without specific references or detailed feedback, the authors cannot confidently determine which part of the paper this comment pertains to or what specific issues need addressing. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this comparison or improve their work. Without actionable feedback or guidance, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, as it provides a general observation but fails to offer meaningful insights or actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide METEOR results, which are mentioned in recent works. This is a clear and direct action for the authors to take, as it specifies what additional information should be included in their draft. The comment is explicit and provides concrete guidance on how to address the feedback, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"METEOR results,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of METEOR results, which are mentioned in recent works. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide METEOR results, which are reported in recent works. However, it does not provide any specific references or examples of these recent works, making it difficult for the authors to understand the context or relevance of the suggestion. Without detailed references or examples, the claim is not 5, as it lacks the necessary evidence to support the need for METEOR results. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to include METEOR results, which are mentioned in recent works. This feedback is specific and provides a direct suggestion for improvement, helping the authors to enhance their draft by incorporating additional metrics that are relevant to their field. However, the comment could be more helpful if it explained why METEOR results are important or how they should be integrated into the paper. Despite this, the feedback is 4 as it guides the authors toward a specific enhancement that can improve the comprehensiveness and relevance of their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the comparability of results. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the comparability of their findings. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches, which is raised due to studying Geffect of each learning objective in isolation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the results are not comparable. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this concern. This feedback is 3 as it points out a potential weakness in the paper\"s methodology or presentation. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve the comparability of results. The comment could be more helpful if it provided actionable advice or examples of how to enhance the comparability of the findings. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. However, the comment does not explicitly instruct the authors to include this theory or provide specific guidance on how to integrate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for existing linguistic theory and consider incorporating it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue, which is the authors\" consideration of the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain it. The comment suggests that incorporating such theory would strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain it. However, the comment does not provide any specific references, examples, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or examples on how to integrate this theory or what linguistic theory might be relevant. The feedback is 3 as it points out a potential avenue for enhancement, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should spend more time discussing the potential benefits of using AutoML approaches, such as extracting hints that can be reused in the design of new network architectures. It implies that the authors should provide more detailed comments on the findings of the study, particularly regarding the most significant takeaways from the discovered architecture. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed comments on the findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to discuss the biggest takeaways from the found architecture, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, suggesting that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s value and contribution. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what aspects of the findings should be highlighted. To be more helpful, the comment could include examples of how this could be achieved or what specific insights could be discussed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This implies that the authors should clarify or redefine T_a(t) in Section 3.1 to ensure consistency and proper understanding. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides a clear indication of the specific part of the paper being addressed, making the comment fully grounded. However, the comment does not specify what needs to be addressed in terms of clarifying or redefining T_a(t) in Section 3.1. While the authors can infer that they need to address the inconsistency, the comment lacks specificity in detailing the exact steps or changes required. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This observation is factual and does not require any supporting evidence or justification. It is a straightforward statement of a potential inconsistency in the paper, which the authors can verify by reviewing the sections mentioned. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper regarding the usage and definition of T_a(t). It notes that T_a(t) is used in Section 3.1 but only defined in Section 4, which could lead to confusion for readers. This feedback is clear and actionable, as it highlights a potential issue that the authors need to address to ensure clarity and consistency in their work. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency, such as suggesting where to redefine T_a(t) or how to clarify its usage. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise. It also recommends including empirical results. While the comment implies that the authors should make the introduction more concise and incorporate empirical results, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the conciseness and include empirical results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which part of the main part or the introduction is being addressed, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and include empirical results, but without explicit references to sections, it remains challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve this. The authors are left with a general suggestion to make the introduction more concise, but without additional context or examples, it remains unclear how to implement this advice effectively. Therefore, the comment is 3, as it points out a potential issue but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide explicit guidance on what specific evidence or arguments are needed to substantiate the contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence, but they are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in identifying the need for more substantial evidence or arguments to establish this as a significant contribution, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment lacks specificity and does not provide detailed guidance on what specific evidence or arguments are needed to substantiate the contribution. While it highlights an important area for improvement, the feedback is 3 as it points out a potential weakness but does not offer actionable suggestions for addressing it. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not provide specific guidance or suggestions on how the authors might address these concerns or enhance the novelty of their work. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. As a result, the feedback is 1.", "grounding_specificity_rationale": "The comment critiques the improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is not specific about what aspects of the paper\"s novelty or improvements are being questioned. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. While it identifies a potential issue with the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is vague and does not provide actionable steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While the comment points out a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their performance claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not specify which part of the paper this observation is based on, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. This claim is supported by the observation that the improvements are within the error bar range, which implies that the performance differences are not substantial. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide more detailed analysis or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range. This observation suggests that the performance differences between methods may not be significant. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their results. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice on how to enhance the paper\"s claims or methodology. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, and it questions how to select representative images. While the comment identifies a specific area of improvement, it does not provide explicit guidance or suggestions on how to achieve this diversity or representativeness. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of the evaluation set, but the comment lacks concrete steps or examples. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of making the new proposed evaluation set more diverse and representative than the previous method, specifically questioning how to select representative images. However, it does not specify which part of the paper this evaluation set is discussed in, making it weakly grounded. The comment is specific in its request for guidance on how to achieve diversity and representativeness, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the diversity and representativeness of the new proposed evaluation set, specifically asking how to select representative images. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to improve their draft accordingly. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed evaluation set, questioning its diversity and representativeness compared to previous methods. It highlights a lack of clarity on how to select representative images, which is a critical aspect for ensuring the validity and generalizability of the evaluation. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending specific criteria for selecting representative images or methods for enhancing diversity. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it directs the authors\" attention to an important area for improvement but does not offer detailed guidance on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section on the RL framework, specifically mentioning the need to introduce elements such as the MDP, trajectories, and policy. This action is clear and direct, providing the authors with a specific task to improve their draft. Additionally, the comment suggests including a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This further guidance on what needs to be included makes the feedback 5. The authors know exactly what changes are needed to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including a background section on the RL framework and provides specific elements to include, such as the MDP, trajectories, and policy. It also recommends providing an overview of the original DPO algorithm to clarify modifications in the methods section. This level of detail allows the authors to accurately identify the parts of the paper that need revision, making the comment fully grounded. The specificity is clear, as it specifies what needs to be addressed in terms of background information and the original algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section on the RL framework and provide an overview of the original DPO algorithm to clarify the context and distinguish the proposed modifications. The claim is supported by logical reasoning, as it highlights the importance of context for understanding the subsequent sections and the need for clarity in the methods section. However, the comment could be strengthened by providing specific examples or references to illustrate the importance of these additions. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a background section on the RL framework to clarify the context and introduce key concepts like the MDP, trajectories, and policy. This is important for readers who may not be familiar with these concepts, as it helps them follow the subsequent sections more effectively. Additionally, the comment recommends providing an overview of the original DPO algorithm, which is crucial for understanding the modifications proposed in the methods section. This feedback is specific and actionable, offering the authors a clear path to improve their draft by enhancing its clarity and comprehensiveness. Therefore, the comment is 5, as it provides detailed guidance on how to enhance the paper\"s clarity and understanding for readers."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may encounter issues if users continuously add new languages due to the limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggestions for potential solutions. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. However, it does not specify which part of the paper discusses the method or the model capacity, making it weakly grounded. The comment is specific in identifying the issue of limited capacity and its potential impact on the method, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation if users continuously add new languages due to the limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. This is a valid concern that the authors should consider, as it could impact the scalability and applicability of their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or improve the method\"s scalability. Without actionable feedback or specific recommendations, the comment is 3, as it highlights an important area for consideration but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. It suggests that the kernel height/width remaining the same would result in more parameters. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length, but they also emphasize the need for more details regarding parameters. While the comment identifies an area for clarification and improvement, it does not provide explicit guidance on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that more details are needed but are not given a clear path to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters in the S2D structure, questioning why it does not change despite the increase in depth. The comment further elaborates on the potential impact on efficiency and suggests that more details are expected. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length. However, the comment lacks specific reasoning or evidence to support the claim that the number of parameters should change or why it remains constant. The suggestion for more details on parameters is vague and does not provide a clear path for the authors to address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a specific question about the S2D structure, questioning why the number of parameters does not change despite the increase in depth. It points out that if the kernel height/width remains the same, the depth would increase, leading to more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length but emphasizes the need for more details regarding parameters. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or provide the necessary details. The feedback is 3 as it highlights an area for clarification but could be more actionable with additional guidance or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. It questions why 10 cannot use these side information. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so or provide concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment compares the proposed method to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is relevant to, making it weakly grounded. The comment is specific in questioning why 10 cannot use these side information, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is similar in spirit to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, the comment lacks specific reasoning or evidence to support why this is the case, such as detailed comparisons or examples. The claim is based on a comparison to another work, but without further elaboration, it remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. It questions why 10 cannot use these side information, implying that the authors should consider this possibility. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore this idea or address the question. The feedback is 3 as it points out a potential avenue for further development but does not provide detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. It suggests that this makes it difficult to interpret the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, analyze them differently, or provide additional context. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the Atari game results are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Atari game results are limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. This feedback is 3 as it points out a specific area where the paper could be improved. However, the comment lacks depth and does not provide suggestions on how the authors might address this limitation or expand their analysis. Without actionable guidance or additional context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. While the comment explicitly states what needs to be addressed, it does not provide detailed guidance on how to reiterate this point or what specific aspects should be emphasized. The action is clear but somewhat vague, as it lacks concrete steps on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, namely the lack of comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not favorable to the authors because they do not comment on why the GPC (benchmark) performs better than BPC (their method). The reviewer suggests that this is due to the use of bandit feedback and not the form of the cost function. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors\" method is not being effectively explained. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not provide an explanation for why their method (BPC) performs worse than the benchmark (GPC). It suggests that the authors should reiterate that the better performance of GPC is due to bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it directs the authors to clarify their results and provide a more detailed explanation of their findings. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores. It explicitly asks the authors to clarify how perplexity was calculated. This direct request for clarification provides a clear and concrete action for the authors to take, allowing them to address the discrepancy and provide a detailed explanation of their methodology. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the reported perplexities being over 30 and the better BLEU scores, prompting the authors to clarify how perplexity was calculated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the high perplexity reported in Figure 1, which contradicts better BLEU scores. The reviewer asks for clarification on how perplexity was calculated. While the comment highlights a discrepancy, it does not provide specific reasoning or evidence to support the claim that perplexity should be lower or how it relates to the BLEU scores. The request for clarification is logical and reasonable, but without additional context or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the reported perplexities in Figure 1 and the better BLEU scores, suggesting that the perplexity values may be too high. It explicitly asks the authors to clarify how perplexity was calculated, which is a clear and actionable request for additional information. This feedback helps the authors to address a potential issue in their methodology and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to resolve the discrepancy or provided examples of how to calculate perplexity more accurately. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, as it specifies what additional experiments are required to improve the evaluation. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include additional experiments, but without grounding, the authors may struggle to identify the exact sections that need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section, suggesting that experiments on distributed deployment and a larger model are needed. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work. By addressing these suggestions, the authors can strengthen their evaluation and potentially improve the overall quality of their paper. However, the comment could be more helpful if it provided additional context or guidance on how to conduct these experiments or what specific aspects to focus on. Despite this, the feedback is 4 as it directs the authors toward a clear area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be addressed and offers a concrete suggestion on how to implement it, ensuring the authors know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns\" and references the concept of \"orbit counting in GSN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of explanation regarding why rooted patterns are important and how they are chosen. Additionally, it suggests that a brief discussion should be included in the main text or, alternatively, in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. The comment suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a brief discussion on why rooted patterns are important and how they are chosen. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and depth of their work. By addressing this suggestion, the authors can better explain the significance of rooted patterns and improve the comprehensibility of their approach. However, the comment could be more helpful if it provided additional context or examples to illustrate the importance of rooted patterns. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including some failure cases and related discussion would be beneficial. However, it does not provide explicit guidance on which specific failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add failure cases and discuss them, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this feedback pertains to. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in its suggestion to include failure cases and discuss them, but it lacks grounding as it does not specify the exact sections or parts of the paper where this information should be added. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including some failure cases and related discussion, but it does not provide any specific reasoning, examples, or references to support why this would be beneficial. Without additional context or justification, the claim lacks verifiability. The authors may infer that including failure cases could enhance the paper\"s comprehensiveness or robustness, but this inference is not explicitly made in the comment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including some failure cases and related discussion would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific failure cases to include or how to structure the discussion. This limits the usefulness of the feedback for the authors, as it does not offer actionable steps or detailed suggestions for enhancing their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors conduct an ablation study to clarify the necessity of the base layer GNN encoding in their proposed method. This action is clear and concrete, as it provides a specific direction for the authors to follow. The comment also specifies what needs to be done, namely an ablation study, which gives the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the inclusion of a base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to clarify its necessity. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in its suggestion to conduct an ablation study, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is unclear why there is a base layer GNN encoding in the proposed method and recommends conducting an ablation study to clarify its necessity. However, the comment does not provide any specific reasoning or evidence to support why this encoding is unclear or unnecessary. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, questioning the necessity of the base layer GNN encoding in the proposed method. It suggests that an ablation study would be beneficial to clarify this point. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting an ablation study. However, the comment could be more helpful if it offered additional guidance on how to structure the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes.\" This provides a clear and direct action for the authors to take, specifying what needs to be added or elaborated upon. The comment is concrete, as it outlines specific steps for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of computational complexity, suggesting that the authors should add upper bounds and elaborate on empirical runtimes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, despite making brief statements about it. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the current discussion is insufficient. The suggestion to add upper bounds and runtimes provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a more detailed discussion of the computational complexity of counting homomorphisms. It highlights that the current discussion is brief and suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that could be expanded upon to enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided additional context or examples of how this improvement could be achieved. Overall, the comment is 4 as it offers a clear direction for enhancing the paper\"s content, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. This is an explicit action that the authors can take to improve their draft. The comment also provides a rationale by comparing the method to previous topdown and bottomup pose estimation methods, which adds concrete details on how to conduct the comparison. This level of specificity and directness makes the action 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. The authors might infer that it relates to the experimental results or discussion section, but this is not explicitly mentioned. The comment is specific in its suggestion to compare inference speed to previous methods, but it lacks grounding as it does not specify where this information should be integrated into the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. This is a logical suggestion based on the nature of the method and the importance of inference speed in the field of pose estimation. However, the comment does not provide specific references or examples of previous topdown and bottomup pose estimation methods for comparison, which would strengthen the claim. The lack of detailed references or comparisons makes the claim 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. This is a constructive suggestion as it highlights an important aspect that could enhance the paper\"s comprehensiveness and relevance. By comparing the inference speed to previous topdown and bottomup pose estimation methods, the authors can provide a more complete picture of their method\"s performance. This feedback is clear and actionable, offering a specific direction for improvement that can significantly enhance the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim regarding evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicit. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but without explicit grounding, it is challenging for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. The reviewer supports this claim by comparing it to Batch Normalization, which standardizes the variance and centers the activation. This comparison provides a logical basis for the claim, making it 3. However, the comment could be strengthened by providing more detailed examples or references to support the comparison between evolutional dropout and Batch Normalization. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and suggests that it only increases the variance of lowvariance units. It points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. This feedback is 3 as it highlights a potential area for improvement in the paper\"s discussion of internal covariate shift. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects of the discussion should be expanded. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution should be described or how to enhance the description. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the contribution without being given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper, but it does not specify which part of the paper this contribution is discussed in or what aspects of the contribution need more description. This lack of specificity makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment does not provide any specific guidance on what additional details should be included. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution need more description or how to enhance the description. This lack of detail makes it difficult for the authors to understand the exact areas that require improvement and limits the usefulness of the feedback. As a result, the comment is 2, as it provides a general suggestion without actionable advice. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of minor comments and suggestions for improvement. It explicitly suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide specific guidance on how the authors can improve their draft. The comments are explicit and concrete, allowing the authors to directly address each point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sections 2.3 and 2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as describing the main contributions of introducing two types of attention for deep VAEs and organizing the description of the layerwise attention mechanism. The suggestion to reference tricks like normalization or feature scaling in a separate section is also specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, such as recommending the separation of contributions and the description of models, as well as the inclusion of tricks like normalization or feature scaling in a separate section. These suggestions are based on logical reasoning and common practices in academic writing, making them 4. However, the comment lacks specific examples or references to support the suggestions, which could strengthen the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a list of minor suggestions for improving the organization and clarity of the paper. It suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and actionable, offering the authors specific ways to enhance the structure and presentation of their work. While the comment does not delve into detailed analysis or critique, it provides valuable guidance for improving the manuscript. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the minimal performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It also references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly instruct the authors to address these issues or suggest specific actions to improve their work. The feedback is somewhat vague, as it does not provide detailed guidance on how to resolve the identified problems or enhance the paper\"s performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or discussion, but this inference is not precise. The comment is specific in detailing the issue with the performance differences and suggesting a potential solution, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal and suggests that the benchmarks are outdated and likely saturated. The comment provides a logical reasoning by noting that the performance differences are less than 1 percentage point, which could be attributed to random variation. Additionally, it references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. This level of detail and reference to external work supports the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed reasoning about the saturation of the benchmarks, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the performance differences between methods, noting that they are minimal across evaluations. It points out that the performance differences are less than 1 percentage point, which may be attributable to random variation. Additionally, the comment highlights that the benchmarks selected are outdated and likely saturated, suggesting that the results may not be representative of current stateoftheart performance. The reviewer provides a reference to a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which could offer insights or potential solutions to address these issues. This feedback is 4 as it provides clear and actionable suggestions for improvement, such as updating the benchmarks or considering alternative methods. However, it could be more helpful if it included specific recommendations or examples of how to address the identified issues. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics to assess its empirical efficacy. Second, it questions why BEAR is missing from the baselines. While the comment identifies areas for improvement and suggests potential experiments, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should explore different domains and include BEAR in their baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics. Second, it questions why BEAR is missing from the baselines. While the comment does not explicitly mention specific parts of the paper, it is clear that it pertains to the discussion of the method\"s applicability and the choice of baselines. The authors can infer that it relates to the experimental setup and results sections, but the comment lacks explicit grounding. The questions are specific, providing clear guidance on what aspects of the method\"s evaluation and comparison need further exploration. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with nondeterministic dynamics. Second, it asks why BEAR is missing from the baselines. The comment does not contain any claims or opinions that require verification. It is a series of questions seeking clarification or further explanation, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two important questions that could help the authors improve their draft. First, it questions the relevance of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This feedback encourages the authors to expand their experimental setup and consider a broader range of environments. Second, it points out the absence of BEAR in the baselines, which could be relevant for comparison. These questions provide clear and actionable feedback, prompting the authors to consider additional experiments and include relevant baselines. However, the comment could be more helpful if it offered suggestions on how to implement these changes or provided specific examples of nondeterministic domains to evaluate the method. Overall, the comment is 4 as it identifies areas for improvement and encourages further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. While the comment implies that these techniques are important for performance, it does not explicitly instruct the authors to include this justification. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. However, the comment does not provide specific guidance on how to structure this justification or what aspects to focus on. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its request for a theoretical justification, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed explanation or evidence to substantiate the need for a theoretical justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. This is a constructive suggestion as it highlights the importance of understanding the theoretical basis of the methods used in the paper. However, the comment lacks specificity and does not provide detailed guidance on how to develop this justification or what aspects of the theory should be emphasized. While it identifies a potential area for improvement, the feedback could be more helpful if it offered more detailed advice or examples. Therefore, the comment is 3, as it points out a valuable area for enhancement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details should be included, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that more information is needed, but it lacks concrete guidance on how to present this information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for additional information about the method, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these details are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that more details about the proposed method should be presented. It highlights the need for clarification on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides the authors with a specific direction for enhancing the clarity and depth of their method description. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have addressed similar issues. Overall, the comment is 4 as it guides the authors towards improving their draft by providing a clear direction for additional detail."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about the label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to take. It specifies what needs to be verified and where to focus, making the comment 5. The authors know exactly what steps to take to address the feedback, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment addresses the issue of theoretical findings relating to realworld deep learning models, suggesting that the authors verify their conclusions on MNIST and CNN. However, it does not specify which part of the paper this relates to, making it weakly grounded. The comment is specific in its suggestion to verify the conclusions on MNIST and CNN, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the theoretical findings should be verified on realworld deep learning models, specifically on MNIST and CNN. However, the comment does not provide any specific reasoning or evidence to support why this verification is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by questioning the relevance of theoretical findings to realworld deep learning models. It suggests that the authors verify their conclusions about label noise and model size on MNIST and CNN, which is a specific and actionable recommendation. This feedback provides a clear direction for the authors to improve the applicability of their findings, making the comment 4. However, it could be more helpful if it included additional context or suggestions on how to conduct the verification. Overall, the comment is valuable in guiding the authors towards enhancing the practical relevance of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests that qualitative experiments should be conducted to demonstrate the validity of the conditional independence model, specifically by providing illustrative experimental results. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the lack of a correctness test for the proposed new test metric and suggests providing visualization results or schematic diagrams to aid understanding. These actions are clear and concrete, giving the authors a detailed roadmap for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of qualitative experiments to demonstrate the validity of the conditional independence model and the absence of a correctness test and comparative experiments for the proposed new test metric. It provides explicit suggestions for improvement, such as providing illustrative experimental results and using a toy dataset to demonstrate separability, as well as suggesting the inclusion of visualization results or schematic diagrams for better understanding. This level of detail and specificity allows the authors to clearly identify the parts of the paper that need attention and how to address them. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model and that the authors should provide illustrative experimental results. It also suggests using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test for the proposed new test metric and recommends providing visualization results or schematic diagrams. While the comment provides specific suggestions for improvement, it lacks detailed reasoning or references to support the claim that these additions are necessary. The suggestions are logical and reasonable, but without further justification, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting that illustrative experimental results could be provided to support the claim. This feedback is actionable and provides a clear direction for the authors to enhance their work. Second, it notes the absence of a correctness test for the proposed new test metric and recommends providing visualization results or schematic diagrams to aid understanding. These suggestions are detailed and provide the authors with concrete steps to improve their draft, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity with other methods, providing a clear and direct action for the authors to take. The comment also highlights the impracticality of training multiple iterations/epochs with large models and datasets, which adds context to the comparison. This level of specificity and directness makes the comment 5, as it gives the authors a clear path to follow in addressing the issue. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the claim that the proposed method requires much more computation than other methods, suggesting that it is impractical to train multiple iterations/epochs with large models and datasets. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in questioning the computational complexity of the method compared to others, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification or improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It questions whether the method requires much more computation than other methods and suggests comparing the computational complexity with other methods. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the proposed method is computationally more demanding. This lack of detailed evidence or comparison makes the claim 3, as the authors would need to conduct further analysis to address the concern fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the computational complexity of the proposed method compared to other methods, suggesting that it may require much more computation than other methods. It also points out the impracticality of training multiple iterations/epochs with large models and datasets. This feedback is 3 as it identifies a potential weakness in the computational efficiency of the proposed method, which could be important for the authors to address. However, the comment lacks specific suggestions or guidance on how to compare computational complexity or improve efficiency, leaving the authors with a general area for improvement. Therefore, the comment is rated as 3, as it provides a direction for the authors to consider but does not fully support them in making actionable improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach description in Section 3 is difficult to follow and should be revised. It also suggests that the additional page in the cameraready version should be used to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach description is difficult to follow and suggests using the additional page in the cameraready version to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approach description is difficult to follow and suggests that the additional page in the cameraready version should be used to extend the approach description rather than adding more experiments. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is difficult to follow or how extending the description would improve it. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the additional page in the cameraready version be used to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to improve the clarity and depth of their approach description, which is crucial for readers to understand the methodology. However, the comment could be more helpful if it provided specific suggestions on how to revise the approach description or examples of what additional information should be included. Overall, the comment is 4 as it offers clear guidance for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the experiments section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, and the absence of comparison with other stateoftheart methods that might not rely on gyrostructures. While the comment highlights these areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and comparisons, but the comment lacks concrete suggestions on what specific aspects to focus on or how to structure these additions. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issues with the related discussion, such as the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods. Additionally, it highlights the need for comparison with simpler or more commonly used techniques in manifoldbased learning. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights into why the proposed gyrostructures outperform existing methods and that the paper lacks comparison with other stateoftheart methods. The comment provides a logical reasoning by suggesting that the absence of such comparisons makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the comparison that should be made, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the related discussion lacks interpretive insights into why the proposed gyrostructures outperform existing methods, suggesting that more detailed explanations are needed. Second, it notes that the paper lacks comparison with other stateoftheart methods that might not rely on gyrostructures, which could provide a more comprehensive evaluation of the proposed approach. The comment provides clear and actionable feedback, encouraging the authors to enhance the interpretive insights and broaden the scope of their comparisons. However, it could be more helpful if it offered suggestions on how to achieve these improvements or specific examples of what kind of comparisons would be beneficial. Overall, the comment is 4 as it directs the authors to areas that need further development and provides a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 5 is difficult to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and suggests that the authors could extend the CATER dataset to support multiple languages in the future. This feedback is clear and provides specific actions for the authors to take, such as adding more details about the baselines and considering the extension of the CATER dataset to other languages. The comments are concrete and actionable, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is hard to comprehend and suggesting that more details about the two baselines presented should be included. Additionally, it points out the limitation of the study focusing only on Englishcentric datasets and suggests extending the CATER dataset to support multiple languages. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and suggests extending the CATER dataset to support multiple languages. While the comment provides a logical reasoning for the need for more details and suggests an extension, it lacks specific examples or references to support the claim fully. The suggestion to extend the CATER dataset to other languages is a reasonable one, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend. It provides a clear suggestion for improvement by requesting more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study\"s focus on Englishcentric datasets and suggests that the authors could extend the CATER dataset to support multiple languages in the future. This feedback is actionable and provides the authors with concrete steps to enhance their draft, making it 4. However, it could be more helpful if it included specific suggestions on how to present the details or how to extend the dataset. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review in the paper needs improvement, specifically noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and direct, giving the authors a specific action to take: to enhance the clarity and comparative analysis of the literature review. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and specifies the issue with it, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly outlines what needs to be improved, such as providing a more explicit and comparative analysis of related work. This level of detail helps the authors understand what aspects of the literature review need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and lacks clarity on the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issues and how to address them. This lack of detailed justification or evidence makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It provides a clear and actionable suggestion for improvement by recommending that the paper should provide a more explicit and comparative analysis of related work. This feedback is valuable as it directs the authors to enhance the clarity and depth of their literature review, which is crucial for establishing the novelty and significance of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct a comparative analysis. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests eliminating section 3.2, stating that readers are presumed to know about the GumbelSoftmax/Concrete distribution. While the comment implies that the section is redundant, it does not provide explicit guidance on how to eliminate it or what to include instead. The action is implicit and somewhat vague, as the authors need to infer that they should remove the section and possibly restructure the paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests eliminating section 3.2, implying that readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper this section is in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion to eliminate the section, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment does not provide any reasoning or evidence to support why this section is redundant or unnecessary. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential redundancy in the paper, it lacks specificity and does not provide any guidance on how to address this issue or what might be included in the section instead. The comment does not offer actionable advice or suggestions for improvement, leaving the authors without a clear path forward. Therefore, the comment is 2, as it provides a suggestion but lacks depth and actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific actions for the authors to consider. The first action suggests adding performance metrics on word similarity and sentence translation tasks, as seen in the MUSE paper and others, to enhance the credibility of the framework\"s robustness and effectiveness. The second action recommends including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is a minor suggestion. Both actions are explicit and provide clear guidance on what the authors should include in their experiments to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two actionable suggestions: adding performance on word similarity and sentence translation tasks, as in the MUSE paper, and including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages. These suggestions are clear and provide a concrete direction for the authors to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding performance metrics on word similarity and sentence translation tasks, as well as including experiments with morphologically rich and lowresource languages. These suggestions are based on the reviewer\"s knowledge of the field and the potential benefits of including these metrics and languages in the experiments. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim. While the suggestions are logical and could enhance the robustness and effectiveness of the framework, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the paper. First, it recommends adding performance metrics on word similarity and sentence translation tasks, which are commonly used in the field and could enhance the credibility of the framework\"s robustness and effectiveness. Second, it suggests including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which could further validate the framework\"s applicability across diverse linguistic contexts. These suggestions are clear and provide a concrete direction for the authors to enhance their work, making the comment 5. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully implemented these metrics or experiments. Overall, the feedback is 4, as it offers valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. This implies that the authors should clarify this connection in the text or figures. Second, it requests that labels be included for subfigures in Figs 3 and 4, which is a specific and direct action. Both actions are clear and provide concrete guidance on how the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely, the need for labels in the figures and a more explicit explanation of the link between IP and the terms/equations. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. It also requests the inclusion of labels for subfigures in Figs 3 and 4. While the comment provides a clear request for improvement, it lacks specific reasoning or examples to support why these changes are necessary. The suggestion is 3 as it points out a potential area for improvement, but it does not provide detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improvement. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear direction for the authors to enhance the clarity of their work. Second, it requests the inclusion of labels for subfigures in Figs 3 and 4, which is a direct and specific recommendation for improving the presentation of the figures. These suggestions are clear and provide the authors with concrete steps to take to improve their draft, making the comment 4. However, it could be more helpful if it offered additional guidance or examples on how to achieve these improvements. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions are currently hidden in the experimental section and recommends that the paper highlight these observations and conclusions. This feedback provides a clear and explicit action for the authors to take, which is to make these observations and conclusions more prominent in the paper. The suggestion is concrete, as it specifies what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While it does not explicitly mention a specific section, the authors can infer that it pertains to the experimental section. The comment is specific in its suggestion to highlight the observations and conclusions, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim that the observations and conclusions are indeed hidden. This makes the claim 3, as the authors would need to infer the exact observations and conclusions being referred to. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, providing the authors with a specific area to address and improve in their draft. However, it could be more helpful if it offered additional guidance on how to effectively highlight these observations or conclusions. Overall, the comment is 4 as it directs the authors to a critical aspect of their paper that needs attention, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for ablation experiments, but it lacks concrete details on how to execute these experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing ablation experiments to validate the model performance further, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. However, the comment does not provide any specific reasoning or evidence to support why these experiments are necessary or how they would improve the validation of the model. The lack of detailed justification or examples makes it difficult for the authors to understand the rationale behind the suggestion, leaving the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it identifies a specific area where additional experiments could be beneficial. By suggesting ablation experiments, the comment provides a concrete way for the authors to enhance the validation of their model, making it 4. However, it could be more helpful if it offered guidance on which specific modifications to focus on or how to structure the ablation experiments. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It also questions whether it is possible to show a comparison of performance on datasets with a decision space beyond binary. While the comment highlights an issue and suggests a potential comparison, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include such a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it is possible to show a comparison of performance on datasets with a decision space beyond binary, as mentioned in Zhang et al. 44. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It references Zhang et al. 44 as an example of a situation where this is not a problem, suggesting that the authors should consider showing a comparison of performance on datasets with a decision space beyond binary. However, the comment lacks specific details or examples to fully substantiate the claim, making it 3. The authors would need to conduct further research or analysis to address the concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the requirement of more data for the KDE when the classifier space is beyond binary. It references Zhang et al. 44 as an example of a situation where this is not a problem, suggesting that the authors should consider showing a comparison of performance on datasets with a decision space beyond binary. This feedback is 3 as it identifies a potential issue and provides a reference for comparison. However, it could be more helpful if it included specific suggestions on how to conduct the comparison or what aspects of the performance should be compared. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While the questions are clear, they do not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to investigate these aspects and possibly provide additional analysis or discussion. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions regarding the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. These questions are factual inquiries seeking clarification or explanation, rather than claims or opinions. Therefore, they do not contain claims that require verification, aligning with a classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While these questions are relevant and could lead to valuable insights, the comment lacks specific guidance or suggestions on how the authors might address these issues or what additional analysis or discussion might be needed. The feedback is 3 as it identifies areas for further exploration but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include content in Appendix A and clarify the purpose of Proposition B.1, but without detailed instructions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues by questioning the purpose of Proposition B.1 and noting the absence of a proof, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition may only illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. However, the comment lacks specific examples or references to support the claim that the \"proof\" is missing. While the comment identifies potential issues, it does not provide detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to investigate further to address the concerns raised in the comment.", "helpfulness_rationale": "The review comment identifies two specific issues with the appendices of the paper. It points out that Appendix A is left blank, which is a significant oversight, and that the purpose of Proposition B.1 in Appendix B is unclear. The comment also questions whether the proposition is merely illustrative of a wellknown concept in machine learning, the classic partitioning principle of Kmeans, and notes that the authors\" \"proof\" is missing. This feedback is clear and actionable, as it directs the authors to address the content gaps in the appendices and provide a more detailed explanation of Proposition B.1. However, the comment could be more helpful if it offered suggestions on how to improve the appendices or provided examples of how to clarify the purpose of Proposition B.1. Overall, the comment is 4, as it provides valuable insights for the authors to consider in revising their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, as they are explicitly told what types of experiments are needed to improve the draft. The comment is specific in identifying the types of experiments that should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the types of experiments that are missing, but without grounding, the authors may struggle to pinpoint where these experiments should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples or reasoning to support why these experiments are necessary or how they would improve the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly informs the authors of specific areas where their work could be strengthened. By addressing these points, the authors can enhance the robustness and comprehensiveness of their study. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific comparisons or analyses would be beneficial. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to conduct a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed model on various benchmarks, specifically mentioning that it demonstrates impressive performance. However, it does not specify which benchmarks are being referred to or which part of the paper discusses these results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in suggesting that more careful analysis is needed, particularly for \"old\" benchmarks, and that more details about the evaluation procedures would be helpful. However, without full grounding, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model\"s impressive performance on benchmarks might be due to the data curation process, implying that the data might have been indirectly seen by the model. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks, suggesting that the data might have been indirectly seen by the model through the \"data curation\" process. It recommends that the authors conduct a more careful analysis of these benchmarks and provide more details about the evaluation procedures. This feedback is 3 as it points out a potential weakness in the evaluation process and suggests a specific area for improvement. However, it could be more helpful if it provided additional guidance or examples on how to address this issue. Overall, the comment offers a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. While the comment implies that the authors should consider including collaborative games in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include collaborative games. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not mention specific sections or experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning or evidence to support why collaborative games are important or how they would enhance the paper. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting the absence of collaborative games in the experiments. It suggests that including collaborative games would be interesting and could provide valuable insights into how the evaluated methods behave in different settings. This feedback is clear and actionable, as it directs the authors to consider expanding their experimental scope to include collaborative games. However, the comment could be more helpful if it provided specific suggestions on how to incorporate collaborative games or examples of how this could enhance the paper. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. This provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is explicit and concrete, giving the authors a straightforward task to improve the clarity and verifiability of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by noting that the experimental settings are missing, which makes the figures difficult to be convincing. This level of detail is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing. This is a critical point as it affects the verifiability and credibility of the results presented in the figures. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors improve the clarity and robustness of their experimental setup. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of what kind of experimental settings should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment does not provide explicit guidance on how the authors should address this ambiguity or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed clarification on the proposed method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the rationale behind the work and the suggestion of pathway protection based on sparsity in activation channels. It highlights an ambiguity regarding how the proposed method avoids impeding the learning of new task knowledge, which is a critical aspect of the work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the ambiguity and suggesting a need for clarification, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the rationale behind the work, specifically regarding the suggestion of pathway protection based on sparsity in activation channels. It questions whether this approach avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage this sparsity. The comment provides a logical reasoning by pointing out the potential ambiguity in the rationale and suggests that the authors clarify how their proposed method addresses this issue. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale of the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It highlights a comparison with parameter isolation methods that leverage sparsity in activation channels, suggesting that the authors need to clarify their approach. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this ambiguity. The feedback is 3 as it directs the authors\" attention to a specific area that requires clarification, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by suggesting the integration of benchmark comparisons against stateoftheart fairness algorithms. This feedback is specific and actionable, as it outlines exactly what needs to be done to improve the paper\"s presentation and positioning within the field. The authors are given a direct path to enhance their draft by incorporating these comparisons, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparisons with existing fairness algorithms. The comment suggests integrating benchmark comparisons against stateoftheart fairness algorithms to enhance the paper\"s presentation and positioning within the existing FairML research landscape. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance its credibility and positioning within the field. The claim is supported by logical reasoning, as it highlights the importance of benchmark comparisons in evaluating the performance of the proposed method. However, the comment could be strengthened by providing specific examples of existing fairness algorithms or references to relevant literature that could be used for comparison. This would make the claim more verifiable. Therefore, the comment is rated as 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s credibility and positioning within the existing FairML research landscape. By offering a specific and constructive suggestion, the comment empowers the authors to make a meaningful improvement to their draft. This feedback is clear, actionable, and provides a clear direction for enhancing the paper, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they should also discuss the iteration cost of all related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what aspects of the iteration cost they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and recommends including a discussion of the iteration cost of all related methods, including baseline methods. While it does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the discussion or results sections where computational aspects are typically addressed. The comment is specific in its suggestion to discuss the iteration cost of related methods, providing a clear direction for improvement. However, the lack of explicit mention of a section makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and recommends including a discussion of the iteration cost of all related methods, including baseline methods. This is a logical suggestion that aligns with common practices in the field, as it highlights the importance of computational efficiency in evaluating methods. However, the comment does not provide specific examples or references to support the claim that discussing iteration cost is crucial or how it might impact the evaluation of related methods. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to discuss the iteration cost (computational budget) of their proposed method. It also recommends including a discussion of the iteration cost of all related methods, including baseline methods. This feedback is valuable as it highlights an important aspect of computational efficiency that should be addressed in the paper. By following this advice, the authors can enhance the comprehensiveness and relevance of their work, making it more impactful and informative for the readers. However, the comment could be more helpful if it provided specific examples or references to related methods for comparison, which would further guide the authors in their discussion. Overall, the comment is 4, as it offers clear guidance for improvement but could be expanded with more detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. While the comment implies that the authors should provide an explanation or justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 8082\" and \"Figure 4 A&B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating otherwise in lines 8082. The comment clearly specifies what needs to be addressed, namely, the rationale behind using the metric in this context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. While the comment raises a valid concern, it lacks specific reasoning or evidence to support the claim that the metric is not insightful elsewhere. The authors may need to provide additional context or justification to fully address the reviewer\"s question. Therefore, the comment is 3, as it requires more detailed explanation or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. This feedback is 3 as it prompts the authors to clarify their reasoning or provide an explanation for their choice. However, the comment could be more helpful if it suggested how the authors might address this inconsistency or provided additional guidance on how to improve the clarity of their statements. Overall, the comment offers some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented. It questions the validity of this term, noting that it implies a total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment does not provide specific guidance on how the authors should address this issue or suggest alternative terminology. The action is implicit and vague, as the authors are left to infer that they should consider revising the terminology but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used to describe the phenomenon of distributional generalization. It points out that the term might be too strong to capture the empirical phenomenon presented, questioning the validity of the claim that the total variation between the test and train distributions of the network\"s outputs vanishes to zero. However, the comment does not specify which part of the paper this terminology is used in, making it weakly grounded. The feedback is specific in identifying the issue with the terminology, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the empirical phenomenon presented. It suggests that the term implies a total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case based on the few test functions on which the outputs match. The comment provides a logical reasoning for questioning the term\"s validity, but it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a basis for the critique but requires further elaboration for full clarity.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used to describe the phenomenon of distributional generalization. It questions the appropriateness of the term, suggesting that it might be too strong to capture the empirical phenomenon presented. The comment provides a logical reasoning by pointing out that the term implies a total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case based on the few test functions on which the outputs match. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the terminology. While it highlights an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers an \"explanation\" for how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the scientific insight or provide additional explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model and formalism, questioning whether it provides a scientific insight beyond prior taskoptimized approaches. The comment highlights the lack of explanation regarding the model\"s approximation to nonlinear RNN models and its emergent behavior, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers an \"explanation\" for how these nonlinear models attain solutions through optimization. The comment provides a logical reasoning by comparing the model to prior approaches and questioning its novelty or scientific contribution. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 offers a novel or explanatory advantage over existing methods. The comment highlights a specific gap in the paper, namely the lack of demonstration that the model is a prototype approximation to nonlinear RNN models with emergent behavior. This feedback is clear and actionable, as it directs the authors to clarify the scientific contribution of their work and provide a more detailed explanation of the model\"s novelty. However, the comment could be more helpful if it suggested specific ways to address these concerns or provided examples of how to demonstrate the model\"s explanatory power. Overall, the comment is 4 as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental results, suggesting that the placement of adaptive convolutions is important but lacks analysis or comments. It explicitly points out a specific observation from Table3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This feedback implies that the authors should consider analyzing the impact of adaptive convolutions\" placement on the performance of their technique. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, leaving the authors with a general direction but without detailed instructions. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks concrete guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the experimental results, specifically the observation that replacing normal convolutions with adaptive convolutions is not always beneficial, as demonstrated by the performance of ACNNv3 compared to ACNNv2. The comment clearly specifies what needs to be addressed, which is an analysis or comments on the importance of the placement of adaptive convolutions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, based on the observation that ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This claim is 3 as it provides a specific example from the experimental results to support the assertion. However, the comment lacks detailed reasoning or analysis to explain why this observation is significant or how it relates to the broader implications of the study. Additionally, the comment does not provide references or further context to substantiate the claim. Therefore, the comment is rated as 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It highlights a specific observation from Table3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This feedback suggests that the placement of adaptive convolutions is important and lacks analysis or comments in the paper. The comment is clear and actionable, as it points out a specific area for improvement and provides a concrete example to guide the authors in addressing this issue. However, it could be more helpful if it offered suggestions on how to analyze the impact of adaptive convolutions\" placement or what aspects of the technique could be further explored. Overall, the comment is 4, as it effectively directs the authors to a critical area for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what needs to be added to the discussion section, making it 5.", "grounding_specificity_rationale": "The comment suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is fully grounded as it explicitly mentions the discussion section and provides specific details on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. This feedback is based on logical reasoning and specific examples, making it 4. However, it could be strengthened by providing references or further justification for the importance of this discussion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, offering the authors a specific direction for enhancing the discussion section. By addressing this suggestion, the authors can provide a more comprehensive and insightful analysis of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their presentation. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance the experimental design. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not specify which parts of the paper are unclear or lack intuition, nor does it provide specific suggestions for improvement. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not provide enough detail to guide the authors in addressing the issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is difficult to follow due to a lack of clear intuition and insufficient experiments. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the clarity and coherence of their work. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending ways to improve the intuition or structure of the presentation or suggesting additional experiments that could provide more context. While it points out a problem, it does not offer actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically whether scaling the vector before applying attention weight could be beneficial. While the comment suggests an action by asking a question, it does not provide explicit guidance on how to implement this suggestion or what specific changes might be necessary. The authors are left to infer that they should explore the idea of scaling the vector before attention weight, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scaling of the refined region vector and suggests whether a scaling variable before attention weight could be beneficial. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector, specifically whether scaling the vector before applying attention weight could be beneficial. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scaling of the refined region vector, specifically whether scaling the vector before applying attention weight could be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made. The feedback is 3 as it prompts the authors to consider an alternative approach, but it does not provide detailed or actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ALFRED benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of goal misspecification, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable suggestions. The authors are informed of a potential weakness in their work but are not provided with guidance on how to address it or improve their approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. While the comment provides specific suggestions for analysis and questions, it does not explicitly instruct the authors on how to conduct these analyses or what specific improvements to make. The actions are implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. However, the comment does not specify which part of the paper these concerns relate to, such as the results section or the discussion. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific suggestions for analysis, it lacks grounding, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This claim is 3 as it provides a logical reasoning for the authors to investigate the distribution of disparities. However, it lacks specific examples or references to support the claim fully. The second concern about the difficulty of SamplingGaussian to improve frameworks similar to IGEV is not substantiated with evidence or reasoning, making it difficult to verify. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment raises two concerns regarding the improvement of the method over SOTA methods like IGEV and the difficulty of SamplingGaussian to improve frameworks similar to IGEV. It suggests that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This feedback is 3 as it provides a specific suggestion for analysis, which could help the authors identify areas for improvement. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct the analysis or what specific aspects to focus on. Overall, the comment provides some actionable feedback but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus the pretrained language models. It provides a clear and concrete suggestion for the authors to include results using the GCPG model without pretrained initializations. This feedback is explicit and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results\" and \"task formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the lack of ablation studies to clarify the contribution of the task formulation versus pretrained language models. The comment is specific in suggesting that the paper should include results using the GCPG model without pretrained initializations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus pretrained language models. The comment suggests including results using the GCPG model without pretrained initializations. While the suggestion is clear, it lacks specific examples or references to support the claim that ablation studies are necessary. The reasoning is logical, but the comment could be strengthened with more detailed justification or references to similar studies. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of ablation studies. It highlights the importance of understanding the contribution of the task formulation versus the pretrained language models by suggesting that the paper should include results using the GCPG model without pretrained initializations. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. By addressing this issue, the authors can better demonstrate the impact of their proposed method and enhance the comprehensiveness of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting a way to clarify the axes or providing examples of how to improve the figure. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding what the axes represent in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty in understanding the axes in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it highlights a potential area of confusion for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the axes or improve the figure. Overall, the comment is 3 as it directs the authors to an area that needs attention but lacks depth in terms of actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any explicit guidance on how to achieve this or what specific aspects of the results should be emphasized. The action is implicit and vague, as the authors are left to infer that they should include ImageNet results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. Without explicit references or detailed guidance, the authors may find it challenging to determine exactly what needs to be addressed. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific reasoning, examples, or references to support why ImageNet results would be particularly relevant or how they would enhance the method\"s credibility. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific guidance on how to achieve this or what aspects of the results should be emphasized. The feedback is vague and lacks actionable advice, leaving the authors with a general idea of what could be improved but without concrete steps to take. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing, and it highlights the importance of including these comparisons to demonstrate the efficiency of the proposed approach. The comment provides a clear and concrete action for the authors to take, which is to include direct runtime comparisons. This guidance is explicit and provides a specific direction for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Direct runtime comparisons with existing methods are missing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the absence of direct runtime comparisons, which is crucial for demonstrating the efficiency of the proposed approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which usually requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are essential for evaluating the efficiency of the proposed method. However, the comment could be strengthened by providing specific examples or references to similar studies that have included such comparisons. Therefore, the claim is 4, as it is wellsupported but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons in demonstrating the efficiency of the proposed approach, which is based on implicit differentiation. By suggesting that direct runtime comparisons are necessary, the comment provides a clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or which existing methods to compare against. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed framework is a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the technical contribution or what specific aspects need to be improved. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the proposed framework, specifically mentioning that it is a simple combination of metalearning and federated learning. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of technical contribution, but without clear grounding, it is challenging for the authors to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed framework, suggesting that it is a simple combination of metalearning and federated learning without any significant technical contribution. This feedback is 3 as it points out a potential weakness in the paper\"s originality or innovation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. It suggests that the paper could be more insightful or provide possible solutions. While the comment identifies a gap in the study, it does not explicitly instruct the authors on how to address this issue or what specific aspects to focus on. The feedback is somewhat vague, as it provides a general direction but lacks concrete guidance on how to enhance the contribution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the insufficiency of the contribution, particularly regarding the lack of exploration into leveraging the connection between complementary and model robustness to improve model robustness. It highlights that while the paper could be the first to study this connection, the conclusion is easily and intuitively obtained. The comment is fully grounded as it explicitly mentions the \"complementary and robustness\" connection and the need for more insightful findings or solutions. However, it lacks specificity in terms of suggesting how the authors might address this issue or what specific areas to explore. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, implying that the study lacks depth or originality. However, the comment lacks specific examples or references to support the claim that the conclusion is easily obtained, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. This feedback is 3 as it highlights a gap in the study and suggests that the conclusion is easily and intuitively obtained. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional insights or solutions could be explored. While it points out a critical area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide explicit guidance on how the authors should reframe their focus or what specific aspects of the differences in representation should be explored. The action is implicit and somewhat vague, as the authors can infer the need for a shift in focus but lack concrete instructions on how to implement this change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the focus, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide specific reasoning or examples to support why this shift is necessary or how it aligns with the paper\"s motivation. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. This feedback is 3 as it identifies a potential area for improvement in the paper\"s focus and methodology. However, it lacks specific guidance on how the authors might reframe their analysis or what aspects of the differences in representation should be explored. To be more helpful, the comment could provide examples or suggestions on how to address this critique, such as recommending specific metrics or methods for evaluating the differences in representation. Overall, the comment provides a direction for improvement but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment does not provide specific guidance on how to address these issues or suggest concrete steps for improvement. The authors are left with a general understanding of what needs to be fixed but without detailed instructions on how to implement the changes. Therefore, the comment is 3, as it provides a direction but lacks explicit and concrete guidance.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some level of specificity in detailing the issues, it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not well organized and identifies specific issues with the layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks detailed reasoning or examples to support these claims, making it difficult for the authors to understand the extent of the issues or how to address them. The lack of specific evidence or references to justify the claims renders the comment barely verifiable, as it provides a general critique without actionable guidance for improvement.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks actionable guidance on how to address these issues or suggestions for improvement. While it points out areas that need attention, it does not provide detailed advice or examples of how to correct these problems, leaving the authors with a general understanding of what needs to be fixed but without specific steps to take. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a clear and explicit action for the authors to take, as it instructs them to define the notation \"cal P\" with a subscript in the same section where it is first used. The comment provides specific guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the notation \"cal P\" with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of definition for the notation \"cal P\" with a subscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward statement of a potential issue in the paper, but it lacks depth or context, making it difficult for the authors to fully understand the significance of the claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"cal P\" with a subscript being used without being defined in the same section. This is a clear and actionable feedback that highlights a potential confusion for readers who might not be familiar with the notation. By pointing out this issue, the comment provides the authors with a specific area to address, which could improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested how the authors might define the notation or provided an example of how to do so. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and issues that require clarification and explanation. It asks for a definition of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \u201cp\u201d is not explicitly defined and has been used extensively throughout the paper, which is problematic. The reviewer suggests moving the definition of \u201cp\u201d to a more appropriate location. While the comments imply actions, such as providing definitions and explanations, they are not explicitly stated. The authors can infer the need for these actions, but the lack of concrete guidance makes the comments 3.", "grounding_specificity_rationale": "The comment raises several specific issues related to the paper, including the definition of \"upper faces\" of the convex hull, the explanation of dual subdivision and projection \u03c0, and the definition of the variable \u201cp\u201d. It provides clear guidance on what needs to be addressed, making the comment 5. The authors can accurately identify the parts of the paper being addressed and understand what needs to be clarified or improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and observations regarding the paper\"s content and presentation. It seeks clarification on specific terms and concepts, such as \"upper faces\" of the convex hull and the variable \u201cp\u201d, without making any subjective claims or judgments. The comment does not express an opinion, suggestion, or request for change, making it a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several specific questions and points out areas where the paper could be improved. It asks for clarification on the term \"upper faces\" of the convex hull and the explanation of dual subdivision and projection \u03c0. Additionally, it points out that the variable \u201cp\u201d is not explicitly defined and has been used extensively throughout the paper, which is problematic. The comment provides clear and actionable feedback, suggesting that the authors need to clarify these concepts and definitions to improve the clarity and comprehensiveness of their work. This feedback is valuable as it guides the authors in addressing potential confusion or gaps in their paper, making the comment 4. However, it could be more helpful if it offered suggestions on how to improve the explanations or definitions. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern about the idea that images and their augmentations should be treated separately, suggesting that they might be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what changes they might need to make to their draft. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment questions the idea that images and their augmentations should be treated separately, suggesting they might be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on why the author is not convinced or what specific aspects of the paper support this concern. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the idea that images and their augmentations should be treated separately, suggesting they might be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the idea that images and their augmentations should be treated separately, suggesting they might be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim, nor does it offer suggestions on how the authors might address this concern or improve their approach. Without actionable feedback or detailed guidance, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. It suggests that the authors should provide more clarity by checking the original paper. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the presentation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the presentation of existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"pieces using existing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of existing methods in the paper, particularly referring to equation (12). It points out that the presentation is vague and requires checking the original paper for clarity. While the comment highlights a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how to enhance the clarity of the presentation. This limits its helpfulness, as the authors may find it challenging to address the issue without additional context or direction. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the writing or presentation being jumbled at times, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the writing or presentation, nor are there suggestions for specific sections or areas that need clarification. Without actionable advice or specific feedback, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"writing\" and \"presentation,\" but it does not specify which parts of the paper are jumbled or unclear. This lack of grounding makes it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its critique of the writing and presentation being jumbled, but without explicit references to sections, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the writing and presentation being jumbled, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to specific sections, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the writing and presentation being jumbled at times, but it does not provide any specific examples or suggestions for improvement. This lack of detail and actionable feedback makes it difficult for the authors to understand where the issues lie or how to address them. Without actionable guidance, the comment does not contribute significantly to the authors\" efforts to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should investigate the computational complexity and power demand of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and power demand, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support the claim about computational complexity or power demand. The reasoning is based on the reviewer\"s imagination and speculation, which makes the claim 3. The authors would need to conduct further analysis to address this concern, making the comment 3.", "helpfulness_rationale": "The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device, which is a relevant consideration for practical applications. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a critical aspect of the work, the feedback lacks depth and actionable advice, making it 3. The authors would need to conduct further analysis to address the computational complexity and power demand, but the comment provides a starting point for consideration. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific error in the authors\" claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. However, the comment does not provide explicit guidance on how the authors should correct this error or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should revise their claim based on the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of their paper being addressed. It is also specific because it clearly specifies the error in the authors\" claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. The comment provides a clear reference to a previous work and details the specific issue with the claim, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit is incorrect, referencing a specific section of a previous work, Wang et al., 2023. This provides a clear and specific reference to support the claim, making it 5. The reviewer has provided a logical basis for the claim by referencing a previous work that contradicts the authors\" assertion, ensuring that the authors can effectively address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" claim about the attention patterns of certain heads in the base IOI circuit. It references a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. This feedback is valuable as it directs the authors to a specific area where their understanding or presentation needs clarification. By pointing out the discrepancy and providing a reference, the comment offers a clear and actionable suggestion for improvement. However, it could be more helpful if it included additional context or guidance on how the authors should address this issue in their draft. Overall, the comment is 4, as it provides a clear direction for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible for a single instance to hold all the training data from realworld datasets. However, it does not provide explicit guidance on how the authors should address this issue or whether they should develop a distributed version of the method. The comment lacks concrete suggestions or actions for the authors to take, making it 3. The authors can infer that they might need to explore scalability options, but the lack of specific guidance limits the actionability.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, specifically questioning whether a single instance can hold all the training data from realworld datasets. However, it does not specify which part of the paper discusses the method\"s scalability, making it weakly grounded. The comment is specific in its critique, as it points out a potential limitation of the method and suggests that a distributed version might be necessary. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable, suggesting that a distributed version might be necessary. However, the comment lacks specific reasoning or evidence to support why the method is not scalable or how a distributed version would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential scalability issue with the method, suggesting that a single instance may not be able to hold all the training data from realworld datasets. This is a valid concern that could impact the practical applicability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as exploring distributed versions of the method or alternative approaches to scalability. While it highlights an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the tuplelike structure of triples denoted as $(e_1, r, e_2)$ in line 122. This feedback is clear and direct, providing a specific action for the authors to take. It specifies what needs to be done to improve the clarity of the presentation, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of the tuplelike structure of triples denoted as $(e_1, r, e_2)$. This provides clear guidance on how to improve the presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures instead of sets. This is a logical suggestion based on the typical representation of triples in graph structures. However, the comment does not provide specific examples or references to support why this change would be beneficial or how it would improve the clarity of the presentation. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the potential benefits of this change themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to improve the clarity of the presentation by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuplelike structures instead of sets. This feedback is clear and directly addresses a potential issue in the paper, offering a concrete way for the authors to enhance the readability and understanding of their work. By following this advice, the authors can make their presentation more accessible and easier to follow for readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this problem or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to find a way to mitigate the scalability issue without being given concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the comment does not explicitly mention specific sections, it is clear that it relates to the scalability of optimal quantization, which is a critical aspect of the paper. The authors can infer that it pertains to the sections discussing quantization and its implications for scalability. However, the comment lacks specificity in terms of what aspects of the quantization process need improvement or how to address the scalability issue. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It further explains that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M). The comment also notes that the paper aims to speed up variational inference (VI) for big data and big model settings, but quantization is a bottleneck, making the method lose its point. While the claim is based on the paper\"s own acknowledgment of scalability issues and the authors\" stated goal of speeding up VI, it lacks specific examples or references to support the claim fully. The reasoning is logical and consistent with the paper\"s content, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the cost is high in terms of both the number of data points (N) and the dimension (M), making it a bottleneck for the paper\"s aim of speeding up variational inference (VI) for big data and big model settings. This feedback is valuable as it highlights a significant limitation of the proposed method and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address the scalability issue or alternative approaches to consider. Overall, the comment is 4 as it provides a clear insight into a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address these issues. While the comment provides a clear direction for improvement, it does not specify which existing methods should be compared or how the issues should be addressed. The action is explicit but somewhat vague, as the authors need to infer the details of the comparison and the specific issues to address. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address these issues. However, the comment does not specify which part of the paper discusses the core methodology or the issues mentioned above, making it weakly grounded. The comment is specific in suggesting comparisons and addressing issues, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address these issues. However, the comment does not provide specific references or examples of existing methods or issues to support the claim. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also implies that the paper should aim for a more applicationoriented venue if it does not address these issues. While the comment identifies areas for improvement, it lacks specific guidance on how to conduct the comparisons or address the issues. The suggestion to aim for a more applicationoriented venue is 3 but could be more detailed. Overall, the comment provides some actionable feedback but could be more comprehensive, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed. The reviewer also expects the authors to further elucidate the technical contribution. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes are needed. The actions are implicit and somewhat vague, leaving the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the algorithm\"s effectiveness, problem, and validation experiments. It points out that the algorithm requires access to the entire training dataset and suggests considering how it operates when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not analyzed. The comment is fully grounded as it explicitly mentions the algorithm\"s effectiveness and problem, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific in detailing what needs to be addressed, such as the need for comprehensive validation experiments and analysis of time complexity and efficiency. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment provides a logical reasoning for the concerns raised, such as the need for comprehensive validation and analysis of efficiency. However, it lacks specific references or examples to fully substantiate the claims, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the algorithm requires access to the entire training dataset, suggesting that the authors should consider how the algorithm operates effectively when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution. While the feedback highlights important areas for improvement, it could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it provides clear directions for enhancing the paper\"s comprehensiveness and technical depth, but it could be more detailed to fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that every kernel can be described by a feature space parameterized by a neural network, noting that this is not true for infinitedimensional RKHSs, such as those associated with RBF kernels. The reviewer suggests that the limitation of NNs in representing such kernels should be made clearer. While the comment identifies a specific issue and provides a clear suggestion for improvement, it does not offer explicit guidance on how to address this limitation or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to clarify the limitation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, particularly noting the limitation for infinitedimensional RKHSs, such as those associated with RBF kernels. The comment suggests that the limitation should be made clearer, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper, specifically regarding the ability of neural networks to represent kernel functions. It provides a specific example, the RBF kernel, to illustrate that the claim is not true in practice due to the infinitedimensional RKHS associated with it. The reviewer suggests that the paper should clarify this limitation. While the comment includes a specific example to support its claim, it lacks detailed reasoning or references to further substantiate the argument. This makes the claim 3, as the authors would need to delve deeper into the literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example, the RBF kernel, to illustrate that this claim is not true in practice due to the infinitedimensional RKHS associated with it. The reviewer suggests that the paper should clarify this limitation, which is a valuable and actionable piece of feedback. By pointing out this oversight, the comment helps the authors improve the accuracy and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provide additional context. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding during inference. It points out that while the network can be trained with a batch of inputs with long token dimensions, during generation, only a limited number of tokens are used to generate the next token. The reviewer asks if this limitation affects the benefits of the linear attention during inference. While the comment raises a valid concern, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the implications of this limitation and potentially provide a response or explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the concern of limited tokens used during inference. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the discussion of the linear attention mechanism, but without explicit references, the comment is weakly grounded. The question is specific in its inquiry about the limitations of the linear attention during inference, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically in terms of the limited tokens used during inference. The comment acknowledges that the network can be trained with a batch of inputs with long token dimensions but questions whether this benefit is maintained during the generation phase. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the concern or suggest how the authors might address it. Without additional context or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the handling of autoregressive decoding with the linear attention mechanism, specifically questioning how the network can maintain benefits during inference when only a limited number of tokens are used to generate the next token. This is a relevant point that could impact the effectiveness of the proposed approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are left to infer that they need to consider this limitation and potentially provide a response or explanation, but without specific guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests the need for additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the possibility of GPI with noise reproducing data similarly well and suggests additional measures to demonstrate this. The comment further specifies the need for a discussion on the suitability of the approach for modeling pattern separation tasks, which is relevant to the paper\"s focus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate this. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims or suggestions. The lack of detailed evidence or justification makes it difficult for the authors to fully understand and address the points raised. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment raises a question about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also points out the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment identifies areas for improvement and provides some guidance, it lacks specific suggestions or detailed feedback on how to address these points. The authors are given a direction to consider, but the comment could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the compared methods using the same settings as the proposed method, specifically mentioning the use of AdamW with cosine lr for training. This action is clear and concrete, as it provides a specific step for the authors to take to ensure a fair comparison. The comment also highlights the importance of using the same settings as the compared methods, which is a logical and actionable suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the comparison between the proposed method and other methods, specifically mentioning the use of AdamW with cosine lr for training and the comparison with methods using adam with fixed lr. It suggests that the direct comparison is unfair and recommends reproducing the results of the compared methods using the same settings as the proposed method. This provides a clear and specific direction for the authors to improve their draft by ensuring a fair comparison. The comment is fully grounded as it explicitly mentions the methods being compared and the specific issue with the current comparison. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the direct comparison between the proposed method and other methods is unfair because the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests reproducing the results of the compared methods using the same settings as the proposed method to ensure fairness. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action to address it. However, it lacks detailed examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests that this difference in training settings could make the comparison unfair. The comment is constructive as it provides a clear and actionable suggestion for the authors to reproduce the results of the compared methods using the same settings as the proposed method, ensuring a fair comparison. This feedback is valuable as it helps the authors improve the validity and fairness of their comparison, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the corrected phrase and the type of mistake. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific experiments to perform. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the performance of the feedback network, specifically regarding the corrected phrase and the type of mistake. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in its inquiry about the performance with and without these types of information, providing a clear direction for the authors to explore. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network, asking for a comparison between the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is crucial or how it might affect the network\"s performance. Without such support, the claim is difficult for the authors to address effectively, making it 1.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the corrected phrase and the type of mistake. This feedback is 3 as it prompts the authors to conduct a specific analysis that could enhance the understanding of their model\"s performance. However, the comment lacks detailed guidance on how to conduct these comparisons or what specific metrics to consider, which limits its usefulness. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. It provides a clear action for the authors to take, which is to include standard deviations in Table 1 and conduct more extensive experiments. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. This includes conducting more extensive experiments. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks specific examples or references to support the claim that the inclusion of standard deviations would enhance the submission. The suggestion to conduct more extensive experiments is vague and does not provide a clear rationale or evidence for why this would improve the paper. Without detailed reasoning or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also provides a clear suggestion for improvement by indicating that the submission would be stronger if the experiments were more extensive, including the inclusion of standard deviations. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct more extensive experiments or suggested specific areas where the additional data could be collected. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit suggestions for improving the paper\"s structure, specifically recommending a clearer organization of sections (introduction, method, experiments) and more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests improving the visualization of Figures 7 and 8. These actions are clear and provide concrete guidance on how the authors can enhance their draft. The feedback is specific and actionable, allowing the authors to make direct improvements to their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests improvements to the paper\"s structure, specifically recommending a clearer organization of sections and more focus on the IEM in Figure 3. It also mentions the need to improve the visualization of Figures 7 and 8. While the comment does not explicitly mention specific sections or figures, it provides enough context for the authors to understand the areas needing attention. The suggestion to improve the structure and focus on the IEM is specific, allowing the authors to identify the main points for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to follow and recommends improvements to the structure and visualization of certain figures. However, it does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the suggestions. The lack of detailed justification or references leaves the authors without a clear understanding of how to address the issues, making the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that some sections are difficult to follow and require multiple readings. It provides actionable suggestions for improving the structure of the paper, recommending a clearer organization of sections (introduction, method, experiments) and more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests enhancing the visualization of Figures 7 and 8. These specific and detailed suggestions empower the authors to make significant improvements to their draft, making the feedback 5. However, the comment could be more helpful if it provided additional guidance on how to achieve these improvements or examples of how to enhance the figures. Overall, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It also raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. While the comment provides a clear action for the authors to take, it does not specify how to determine the optimal learning rate or how to address the potential issue. The request for information is explicit, but the suggestion for addressing the concern is vague. Therefore, the comment is 4, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the final used learning rates and the concern about the optimal learning rate being outside the tested interval. This provides clear guidance on what information is required and why it is important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a factual request for additional information and does not contain any claims or opinions, making it a normal statement. The second part raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. This part is a claim, as it suggests a potential issue that could impact the results. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the overall classification is 3.", "helpfulness_rationale": "The review comment is 4 as it provides clear and actionable feedback. It explicitly requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a specific and relevant piece of information that could significantly impact the results and understanding of the study. Additionally, the comment raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. While the comment does not provide detailed guidance on how to address this concern, it highlights an important aspect that the authors should consider. Overall, the comment offers valuable insights and suggestions for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need to clarify the impact of the mitigation strategies on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and questions whether these strategies significantly impair the model\"s utility. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of the mitigation strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these strategies or how they are implemented, making it weakly grounded. The comment is specific in its concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the implications of the mitigation strategies on performance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies discussed in the paper, specifically questioning their impact on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is a critical consideration for the authors to address. The comment suggests that if these strategies significantly impair the model\"s utility, it might deter their adoption, providing a valuable insight for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue or provide additional context to support the claim. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of understanding regarding the reason for using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is necessary for their problem. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the crossvalidation method should be explained. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the use of 6fold crossvalidation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper and questions the necessity of this method, given that other papers in the comparison did not use it. However, it does not specify which part of the paper discusses the crossvalidation or where the comparison to other papers is made. This lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in questioning the reason for using 6fold crossvalidation, but it is not fully grounded as it does not provide a clear reference to the relevant sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. The reviewer provides a logical reasoning by pointing out the absence of crossvalidation in other papers, which raises a question about the justification for its use in the current study. However, the comment lacks specific references or examples to support the claim that other papers did not use crossvalidation, making it 3. The authors would need to provide additional context or references to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is required for their problem. This feedback is 3 as it points out a gap in the paper\"s justification and encourages the authors to provide a rationale for their choice of crossvalidation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other papers justify their use of crossvalidation. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two issues with the results presented in Table 2: the lack of consistent performance improvement over baselines and the unclear superiority of the proposed methods. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide specific guidance on which experiments to conduct or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the results, such as the lack of consistent performance improvement and the unclear superiority of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods due to the lack of consistent performance improvement and the unclear superiority of the proposed methods. The reviewer provides a logical reasoning by pointing out that the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a strong logical basis but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three. It also points out the lack of a consistent trend in the results, making it unclear which proposed method is better. This feedback is clear and actionable, as it highlights a critical weakness in the paper\"s experimental validation. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims made in the paper. This constructive feedback provides the authors with a clear direction for improving their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the presence of combinatorial and heuristic aspects in the proposed framework, particularly in the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information on the impact of these components, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should clarify the impact of the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed framework for ReC, specifically mentioning the NonAmbiguous Query Generation procedure. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights the heuristic components and suggests clarifying their impact. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC, but it also notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the nature of the heuristic components and their impact, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the presence of combinatorial and heuristic aspects, particularly in the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer the nature of the heuristic components and their impact, which limits the comment\"s helpfulness. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that a detailed comparison is needed, it does not provide explicit instructions on how to conduct this comparison or which specific aspects should be compared. The action is somewhat implicit, as the authors can infer that they need to include a more detailed comparison, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to include a detailed comparison of time complexity and competitiveness, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is 3 as it identifies a specific area for improvement that could enhance the paper\"s comprehensiveness and relevance. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or which aspects of related work should be compared. To be more helpful, the comment could include examples of relevant works or suggest specific metrics to consider. Therefore, the comment is rated as 3, as it points out a potential area for improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests two actions for the authors to take: conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method, and conducting experiments on the full dataset instead of the lowresource regime. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is 5 because it offers concrete steps for the authors to follow, ensuring they know exactly what changes to make to enhance their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lack of experimental results on more datasets\" and provides specific suggestions for improvement, such as conducting experiments on more datasets and evaluating the method on the full dataset instead of the lowresource regime. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also recommends evaluating the method on the full dataset rather than the lowresource regime. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more datasets would be beneficial or that the current evaluation is insufficient. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of experimental results on more datasets. It provides a clear and actionable suggestion for the authors to conduct additional experiments on more datasets to provide a more comprehensive evaluation of their proposed method. Additionally, the comment suggests evaluating the method on the full dataset instead of the lowresource regime, which could further enhance the evaluation. This feedback is clear and provides the authors with specific steps to take to improve their draft, making it 4. However, it could be more helpful if it included examples of other datasets that could be used or further guidance on how to conduct these additional experiments. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment identifies areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback lacks concrete steps or examples of what changes could be made to improve clarity and coherence. As a result, the authors are left without a clear understanding of how to enhance their draft based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the clarity of the generic argument task and the random argument task, as well as the dataset transformation and experimental setup. However, it does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of clarity and the cumbersome nature of the dataset transformation and experimental setup, but it does not provide detailed guidance on how to improve these aspects. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task do not clearly support the authors\" claims, and the dataset transformation and experimental setup are cumbersome. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment highlights areas of concern, it does not provide specific suggestions or actionable steps for the authors to improve the clarity and coherence of their work. Without detailed guidance or examples, the authors may find it challenging to address these issues effectively. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to compare the PL condition used in their work with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is explicit and provides a clear action for the authors to take, which is to compare their PL condition with the one in the referenced paper. The comment also specifies the source where the comparison should be made, making it 5. The authors know exactly what action to take and how to implement it, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment asks about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This question is fully grounded as it explicitly mentions the reference and the specific aspect being addressed, allowing the authors to accurately identify the part of the paper being discussed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the PL condition used in the paper with the one proposed in the referenced work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks for a comparison between the PL condition used in the paper and the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is logical and seeks clarification on the differences between the conditions, but it does not provide any specific reasoning or evidence to support why such a comparison is necessary or how it might impact the paper. The request is clear in its scope but lacks detailed justification or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This question is clear and actionable, as it prompts the authors to consider the relevance and differences between their PL condition and the one proposed in the referenced work. By addressing this question, the authors can potentially strengthen their work by demonstrating the novelty or superiority of their approach compared to existing literature. However, the comment could be more helpful if it provided additional context or guidance on why such a comparison is important or how it might impact the paper. Overall, the comment is 4 as it directs the authors to an important area for further exploration and comparison, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or what steps they should take to mitigate the potential issues. The questions posed are more of an inquiry than a direct action, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the potential information leakage in AutoAugment\"s policy and questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim 3, as it provides a basis for inquiry but requires further elaboration to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. The comment provides a logical inquiry that challenges the authors\" assumptions and suggests a potential area for further investigation. However, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their analysis. While it prompts the authors to consider important aspects of their work, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to take: \"add more analysis about the multilingual alignment of entity representations\" and suggests that \"it would be better to have visualizations or case studies for different types of languages such as language family.\" Additionally, it raises a specific question about the alignment of entities from lowresourced languages with highresourced ones. The comment is concrete, as it specifies what additional analysis and visualizations are needed, and it provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the analysis of entity representations, specifically the alignment of entity representations across different languages. It suggests that the paper lacks a thorough analysis of this aspect and recommends adding more analysis, particularly focusing on multilingual alignment. The comment also suggests including visualizations or case studies for different types of languages, such as language families. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the analysis or discussion sections where entity representations are discussed. The suggestion to include visualizations or case studies provides a clear direction for improvement, making the comment somewhat specific. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper has weak analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests that the authors should add more analysis and provides specific recommendations, such as including visualizations or case studies for different types of languages. While the comment provides a clear suggestion for improvement, it lacks detailed reasoning or evidence to fully substantiate the claim about the weak analysis. The suggestion to include visualizations or case studies is a logical step but could be strengthened with examples or references to support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of the alignment of entity representations across different languages. It suggests that the paper lacks a thorough analysis of this aspect and recommends adding more analysis, particularly focusing on multilingual alignment. The comment also suggests including visualizations or case studies for different types of languages, such as language families, which could enhance the paper\"s comprehensiveness. Additionally, it raises a question about whether entities from lowresourced languages are well aligned with highresourced ones, which is a relevant consideration for the study. This feedback is clear and actionable, providing the authors with specific directions for enhancing their analysis and improving the presentation of their results. Therefore, the comment is 5, as it offers detailed guidance on how to strengthen the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out two issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This provides clear and direct actions for the authors to take, such as removing duplicates and ensuring that all publications include their respective venues and years. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment identifies specific issues with the references list, such as duplicates and missing publication venues and years. However, it does not specify which references are duplicates or which papers lack publication details, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the authors can infer that the references section is being addressed, the comment lacks full grounding due to the lack of specific references or details. It is specific in identifying the issues but not fully grounded, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This feedback is clear and actionable, providing the authors with a straightforward task to address. By correcting these issues, the authors can improve the accuracy and completeness of their reference list, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it offered suggestions on how to avoid duplicates or provided examples of how to include publication venues and years. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear what the error bound means. It also suggests that the authors should analyze and compare their theoretical results to other comparable methods. While the comment explicitly states the need for clarification and comparison, it does not provide detailed guidance on how to achieve this. The authors are left with a clear direction but without specific instructions on how to implement the suggested actions. Therefore, the comment is 4, as it provides a clear action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, particularly the unclear meaning of the error bound and the need for comparison with other methods. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear what the error bound means. It provides a clear direction for improvement by suggesting that the authors should analyze and compare their theoretical results to other comparable methods. This feedback is actionable and provides a concrete path for the authors to enhance the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it offered specific suggestions or examples of how to compare their results with other methods. Overall, the comment is 4 as it guides the authors towards improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudocode of the proposed method is missing. The first part of the comment suggests that the authors should provide an explanation for the observed performance difference, but it does not specify how or what kind of explanation is needed. The second part of the comment is explicit in stating that the pseudocode is missing, but it does not provide guidance on how to include it or what specific details should be included. While the comment identifies areas for improvement, it lacks concrete instructions on how to address these issues, making it 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in detailing the issues, as it provides references to relevant literature and suggests that the authors should include pseudocode. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises two issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. The first part of the comment questions the performance difference, but it does not provide any specific reasoning or evidence to support this claim. The second part of the comment is more verifiable, as it references external works (S\u00f8ren Asmussen and Peter W Glynn, and P. Florence, C. Lynch, A. Zeng, O. A. Ramirez, A. Wahid, L. Downs, A. Wong, J. Lee, I. Mordatch, and J. Tompson) to provide context and references for the discussion. However, the first part of the comment lacks detailed justification, making it 2. Therefore, the overall score is 2.", "helpfulness_rationale": "The review comment raises two important points. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a critical aspect of the paper\"s methodology and results. This question prompts the authors to provide a detailed explanation or analysis of this observation, which could enhance the paper\"s understanding and contribution. Second, the comment points out that the pseudocode of the proposed method is missing, which is essential for replicating and verifying the results. This feedback is valuable as it highlights a critical gap in the paper that needs to be addressed for reproducibility and clarity. However, the comment could be more helpful if it provided suggestions on how to include the pseudocode or what specific details should be included. Overall, the comment is 4 as it identifies important areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of lowresource language pairs and suggests using the method like R3F to maintain the generalization ability of the model. It also mentions a missing reference, Aghajanyan, Armen, et al., which is relevant to the discussion. However, the comment does not provide explicit guidance on how to implement this suggestion or how to address the missing reference. The action is implicit and somewhat vague, as the authors need to infer that they should consider using R3F and include the reference. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs and suggests using the method like R3F to maintain the generalization ability of the multilingual model. It also mentions a missing reference, Aghajanyan, Armen, et al., which is relevant to the discussion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section or methodology, but this is not explicitly stated. The comment is specific in detailing the issue with the lowresource language pairs and the need for a reference, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs further finetune the multilingual model and suggests using the method like R3F to maintain the generalization ability of the model. It also mentions a missing reference, Aghajanyan, Armen, et al., which is relevant to the discussion. However, the comment lacks specific examples or detailed reasoning to support the claim about the significance of the improvement or the need for the reference. While the mention of a reference provides some context, the overall justification is not fully developed, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs in the multilingual model and suggests using the method like R3F to maintain the generalization ability. It also points out a missing reference, which is relevant to the discussion. However, the comment lacks specific guidance on how to implement the suggested method or how to address the missing reference. While it highlights an area for improvement, the feedback could be more actionable and comprehensive to be considered 5. Therefore, the comment is rated as 3, as it provides some insight but does not fully empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. While the comment implies that this visualization would be beneficial, it does not explicitly instruct the authors to perform this task or provide guidance on how to create the visualization. The action is implicit and somewhat vague, as the authors need to infer that they should include a visualization and how to create it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The authors can infer that it pertains to the motivation or discussion section, but this inference is not explicit. The comment is specific in suggesting a visualization to support the claim, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not provide any specific reasoning, examples, or references to support why this visualization would be beneficial or how it would enhance the paper. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. This is a constructive suggestion that could enhance the paper by providing a clearer understanding of the research motivation. However, the comment lacks specific guidance on how to create the visualization or what aspects should be included. While it identifies a potential improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a convoluted description of results and suggests that the authors need to simplify their presentation. It also provides specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication. The comment includes links to external references, which can guide the authors in addressing the issue. However, while the suggestions are concrete, they do not explicitly instruct the authors to make these changes themselves. The authors are left with a clear direction but without direct instructions on how to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the convoluted description of results, specifically mentioning the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This provides some grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or figure this description is found in. The comment is specific in suggesting that the authors simplify their presentation and provides references to related work. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the convoluted description of results, suggesting that it could be simplified. It provides specific examples and references to related work, such as 1 and 2, which can help the authors understand the context and potential improvements. The comment also questions the differences in figures and suggests checking for useful communication, which adds depth to the critique. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Overall, the feedback is 4 due to the references and suggestions, but it could be more robust with additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted description of results, providing a clear example of the problem. It suggests simplifying the presentation and offers a related idea from the literature, which can guide the authors in improving their communication. The comment also references external works, such as 1 and 2, which can provide additional context and support for the critique. However, while the feedback is specific and actionable, it could be more helpful if it included detailed guidance on how to simplify the presentation or if it pointed out specific areas where the convoluted description is most problematic. Overall, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions that the longtext input could restrict the scalability of the framework. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or formats for text descriptions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenges and potential limitations, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the implications of these statements, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the current approach, specifically the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also points out that this could restrict the scalability of the framework. While the comment highlights an important issue, it lacks specific suggestions or actionable steps for the authors to address this limitation. The feedback is 3 as it provides a direction for improvement but could be more comprehensive with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of ~0.02 in the bank dataset. It suggests using tables to present the key improvements more intuitively and in detail. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3\" and \"table,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the performance improvement of the proposed methods seems insignificant and suggests using tables to present the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of ~0.02 in the bank dataset. It also suggests using tables to present the key improvements more intuitively and in detail. However, the comment lacks specific examples or detailed reasoning to support the claim about the significance of the performance improvement. The suggestion to use tables is a logical response to the issue but does not provide evidence or examples to substantiate the claim. Therefore, the comment is 3, as it provides a suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the improvement is not significant, as indicated by the largest improvement of ~0.02 in the bank dataset. It provides a constructive suggestion by recommending the use of tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and impact of their results. However, the comment could be more helpful if it provided additional context or examples of how to effectively use tables to present the data. Overall, the comment is 4 as it guides the authors towards improving their draft by addressing a specific area of concern."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out several issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the positioning of the work with respect to related works. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental setup to include deeper networks and provide more details about the optimization strategy. The suggestion about layer redundancy is specific but does not offer detailed guidance on how to incorporate this into the paper. Therefore, the comment is 3, as it provides some direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses several specific issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, referencing a specific paper on layer redundancy. This provides clear guidance on what needs to be addressed in the paper, making the comment fully grounded. However, the comment could be more specific about how to improve the experimental validation or provide more detailed feedback on the optimization strategy. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the experimental validation, specifically noting that only shallow networks (2 or 3 layers) are considered and that the optimization strategy, including the grid search strategy for hyperparameters selection, is not described. The comment also highlights a minor issue regarding the positioning of the work with respect to related works, mentioning a specific paper on layer redundancy. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claims. The references to related works are helpful but do not fully address the concerns about the experimental validation. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several specific issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also points out a minor issue regarding the positioning of the work with respect to related works, mentioning a specific paper on layer redundancy. While the comment provides clear and actionable feedback on areas that need improvement, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to enhance the experimental validation. Overall, the comment is 4 as it directs the authors to specific areas that require attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or what new theoretical results they could explore. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not specify which part of the paper this claim pertains to, such as the theoretical section or the results section. The authors may have to infer that it relates to the theoretical contributions or the discussion of results. While the comment is specific in its critique, it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s theoretical contributions, noting that the use of a novel type of loss in a specific setting does not result in any new theoretical results. This observation is important as it highlights a gap in the paper\"s contribution. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what new theoretical results they could explore. While it identifies a weakness, it does not provide the authors with a clear path forward for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment implies that the authors should investigate and provide evidence for their hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to support or refute the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. However, the comment does not specify which part of the paper this hypothesis relates to, such as a particular section or analysis. This makes it difficult for the authors to identify the exact area needing attention. While the comment is specific in terms of the hypothesis, it lacks grounding, as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point presents a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, suggesting that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion to provide evidence is a request for further analysis, which is not inherently verifiable. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully substantiated.", "helpfulness_rationale": "The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment identifies a potential area for exploration and suggests a hypothesis, it lacks specific guidance or actionable steps for the authors to follow. The feedback is 3 as it prompts the authors to consider additional evidence or analysis, but it could be more comprehensive and detailed to be fully beneficial. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the authors improve it by providing more illustrations and examples. While the action is explicit, the comment does not specify which parts of the section are particularly confusing or how the illustrations and examples should be incorporated. This lack of detail makes the action somewhat vague, as the authors know they need to improve the section but may not know exactly how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the section is difficult to follow and recommending the inclusion of more illustrations and examples. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is difficult to follow and recommends improvements by providing more illustrations and examples. However, the comment does not provide any specific examples or reasoning to support why the section is unclear or how the suggested improvements would enhance understanding. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending the inclusion of more illustrations and examples to enhance understanding. This feedback is actionable and provides a concrete direction for the authors to improve the clarity of their work. However, the comment could be more helpful if it offered specific examples of what types of illustrations or examples would be beneficial. Overall, the comment is 4 as it guides the authors towards a clear area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. While the action is explicit, it does not provide specific guidance on how to implement this addition or what specific metrics or results should be included. The authors are aware of the need to include these baselines but may need more detailed instructions on how to execute this suggestion. Therefore, the comment is 4, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. While the comment provides a clear idea of what needs to be addressed, it lacks grounding as it does not explicitly mention the table or section number. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it would enhance the understanding of the gap. Without specific justification or evidence, the claim remains 1, as it lacks the necessary details for the authors to understand and address the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. This feedback is clear and actionable, as it provides a specific recommendation for improving the analysis and understanding of the results. By including fullysupervised baselines, the authors can gain insights into the performance differences between supervised and semisupervised approaches, which is valuable for enhancing the comprehensiveness of their study. However, the comment could be more helpful if it provided additional guidance on how to interpret or present these results. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear suggestion for enhancing their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be timeconsuming, especially for problems with many objectives. The reviewer suggests that this could make LaMOO impractical for such problems. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should analyze and possibly optimize the time complexity of the algorithm. However, the comment lacks concrete details on how to implement this analysis or optimization, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the time complexity of the proposed algorithm, particularly the calculation of the hypervolume in each step of LaMOO, and raises a concern about its practicality for problems with many objectives. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. The reviewer questions whether this could make LaMOO impractical for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the calculation of the hypervolume is timeconsuming or impractical. The reasoning is based on general observations about the complexity of the calculation, but without detailed evidence or analysis, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically focusing on the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be timeconsuming, especially for problems with many objectives, and questions whether LaMOO would become impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm that the authors should address. However, the comment could be more helpful if it provided suggestions on how to analyze and potentially optimize the time complexity of the algorithm. Overall, the comment is 4 as it identifies a significant area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues regarding the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The feedback is 3 as it points out areas for improvement but lacks concrete suggestions on how to implement them. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the limitations section or the title, but this is not explicit. The comment is specific in its critique of the title and the concept of \"brittle convergence properties,\" but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the limitations of evolutionary methods and suggests that the title is too generic and vague. It questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment lacks specific examples or references to support the claim about the limitations of evolutionary methods or the meaning of \"brittle convergence properties.\" The suggestion to be more precise and honest is a general observation without detailed evidence or reasoning, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s discussion of evolutionary methods, suggesting that there are deeper aspects of leveraging state, reactiveness, and learning during an episode that should be explored. It also critiques the title as being too generic and vague, recommending that the authors be more precise and honest in their critique. The comment provides a clear direction for improvement by highlighting specific areas that need further exploration and clarification. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it guides the authors towards enhancing the depth and clarity of their work, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. While the comment does not explicitly instruct the authors to provide this information, it clearly indicates what needs to be addressed. The authors can infer that they need to include details on these aspects in their paper. However, the comment lacks specific guidance on how to present this information, such as suggesting the inclusion of a detailed explanation or example. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the synthesis process and edge handling, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the paper, such as the synthesis of the focal stack and the handling of edges with depth discontinuities. These questions are not claims but rather requests for information or clarification. Therefore, they do not fit the criteria for a claim and are classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. These are critical aspects that need to be addressed for a comprehensive understanding of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional references, methodologies, or examples. While it identifies areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out important areas for clarification but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and identical to BRPNAS. The comment further states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies specific issues with the approach, it does not provide explicit guidance on how the authors should address these concerns or improve their work. The feedback lacks actionable steps or suggestions for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment addresses specific components of the approach, such as the weak predictors used (MLP, Regression Tree, and Random Forest) and the sampling strategy (epsilongreedy and similar to BRPNAS). It also references Table 2 in Appendix C to show the similarity in results between the proposed WeakNAS and BRPNAS. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific in detailing what is not novel and how the results compare to existing work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and identical to BRPNAS. The comment provides references to specific works (2, 3, 7) and cites BRPNAS 5 to support its claim. This level of detail and evidence makes the claim 4, as it provides a clear basis for the assertion. However, it could be strengthened by more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the novelty of the approach, noting that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before for NAS performance prediction. It also points out that the sampling strategy is similar to epsilongreedy and identical to BRPNAS, suggesting that the results of the proposed WeakNAS are almost the same as BRPNAS. The comment provides references to specific works (2, 3, 7 and BRPNAS 5) to support its claims. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their approach. While it highlights areas for improvement, it does not offer concrete steps or recommendations, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the discussion of KG handling continuous tasks and the lack of experiments with continuous tasks. It also questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The comment implies that the authors should include these experiments to provide a more comprehensive evaluation of their methods. However, it does not explicitly instruct the authors to include these experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should include these experiments and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of experiments with continuous tasks despite discussing KG\"s handling of continuous tasks, and the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The authors can identify the relevant sections of the paper, as the comment explicitly mentions \"Section 7 in the appendix,\" providing full grounding. The comment is also specific because it clearly outlines what needs to be addressed: the inclusion of experiments with continuous tasks and the comparison of empirical performance to ConBO. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims. First, it questions why there are no experiments with continuous tasks despite discussing KG\"s handling of continuous tasks. Second, it asks why entropy methods for conditional optimization, which are derived in Section 7 of the appendix, are not included in the experiments. The reviewer provides a logical reasoning for the first claim by pointing out the inconsistency between the discussion and the lack of experiments. However, the second claim lacks specific examples or references to support the comparison with ConBO, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss how KG handles continuous tasks, there are no experiments conducted to validate this claim. This is a critical oversight that the authors should address to provide empirical evidence for their claims. Second, the comment questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. It suggests that the authors should include these experiments to compare their empirical performance with ConBO. The feedback is clear and actionable, providing the authors with specific areas to focus on for improvement. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what specific results to expect. Overall, the comment is 4, as it guides the authors toward necessary enhancements to strengthen their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it implies that the authors should provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between these concepts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the introduction of the importance of unsupervised feature selection from a diffusion perspective. It also raises a question about the difference between similarity and exit times in nature. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in its request for a detailed explanation of the difference between similarity and exit times, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. It does not contain any subjective opinions, claims, or suggestions that require verification. Instead, it is a request for clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it provides some insight but does not offer detailed or constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It first asks for clarification on how the precision, recall, and F1score were calculated for the 4class classification of breast density. This is a direct request for additional information. Additionally, it suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection. The comment further recommends providing AUC results for comparisons, which is another explicit action. These actions are clear and concrete, giving the authors a specific path to follow for improving their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision, recall, and F1score for the 4class classification of breast density, and it also refers to the comparison of model performance with AUC, sensitivity, and specificity for breast cancer detection. This provides clear guidance on which parts of the paper need attention. The comment is specific because it details the need for additional information on the calculation methods and suggests a more informative way to report results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for clarification on the calculation of precision, recall, and F1score for the 4class classification of breast density, and a suggestion to report AUC with sensitivity and specificity for breast cancer detection. The first part is a request for additional information, which does not require verification. The second part suggests a more informative way to report results, which is a logical and reasonable suggestion. However, it lacks specific examples or references to support the claim that AUC with sensitivity and specificity is more informative. Therefore, the comment is 4, as it provides a clear suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the methodology and reporting of results. It questions the calculation of precision, recall, and F1score for the 4class classification of breast density, suggesting that the authors clarify their methodology. Additionally, it recommends reporting AUC with sensitivity and specificity for breast cancer detection, which is a common practice in the field. This feedback is clear and provides the authors with a concrete way to improve their draft by offering more detailed and informative results. The comment is 5 as it guides the authors in enhancing the clarity and comprehensiveness of their report, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also critiques the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the critique of the crosslayer modification and the limited improvement observed, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment lacks specific examples or references to support the claim that the crosslayer modification does not bring much insight or that the improvements are negligible. The reasoning is based on general observations and lacks detailed evidence or analysis, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel and questioning the significance of the crosslayer modification. It also points out that the ablation study results show limited improvement, suggesting that the main improvements come from using a na\u00efve transformer rather than the proposed modification. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies areas for improvement, it does not provide actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, the comment is 3, as it highlights potential issues but does not fully support the authors in addressing them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and provides a specific direction for the authors to improve their experiments. The action is explicit and concrete, as it outlines exactly what additional experiments need to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments\" and \"sentence similarity tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the limitation of the current experiments, suggesting that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what additional experiments are needed to enhance the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, without mentioning other tasks involving sentence pairs. The reviewer suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This claim is 3 as it provides a logical reasoning for the claim that the experiments are limited, but it lacks specific examples or references to support the suggestion of additional tasks. The authors would need to conduct further research or experimentation to fully address this feedback, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental evaluation, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness and relevance of their experimental results. By addressing this suggestion, the authors can improve the scope and impact of their work. Therefore, the comment is 4, as it offers valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, which is an explicit action. However, it does not specify why this is important or provide guidance on how to include it. The comment also mentions minor issues with the abstract and Figure 2, but these are not actionable suggestions. Therefore, the comment is 3 as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment about the prompt being included in the appendix or supplement is somewhat specific as it suggests a particular section where the prompt should be placed. However, it does not specify which part of the paper this prompt is currently located in, making it weakly grounded. The comment is specific in its suggestion to include the prompt in the appendix or supplement, but without explicit references to sections, it is challenging for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, but it does not provide any reasoning or evidence to support why this is important or necessary. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or explanation, the authors may find it challenging to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 4 as it provides a clear and actionable suggestion regarding the inclusion of the prompt in the appendix or supplement. This feedback is specific and directly addresses a potential issue with the paper\"s organization, guiding the authors on how to improve the accessibility and organization of their work. However, the comment could be more helpful if it explained why the prompt should be included in the appendix or supplement, or if it provided additional context on the importance of this inclusion. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, noting that the theoretical proof appears straightforward due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It suggests that the convergence proof lacks substantial novelty and rigor. However, the comment does not provide specific guidance on how the authors might address this issue or improve the proof. The feedback is explicit in identifying the problem but lacks concrete suggestions on how to enhance the draft. As a result, the authors are left with a clear understanding of what needs improvement but without detailed instructions on how to implement those changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Theoretical proof for convergence\" and references \"Assumption 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the convergence proof, noting that the proof appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The comment further explains how the convergence proof lacks novelty and rigor, providing a clear basis for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, based on the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a logical reasoning by referencing Assumption 4.1 and Modification 1 in Appendix C, which suggests that the convergence proof lacks novelty and rigor. This is supported by the reviewer\"s explanation of how the covariance matrix is derived and how it relates to the i.i.d. assumption. However, the comment could be strengthened by providing specific examples or references to similar works that highlight the lack of novelty in the proof. Overall, the claim is 4 due to the logical reasoning and references provided, but it could be further strengthened with additional examples or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a clear explanation of how the proof lacks novelty and rigor, based on the assumptions and modifications mentioned. This feedback is valuable as it highlights a critical area for improvement in the paper\"s theoretical foundations. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the proof\"s novelty and rigor. Despite this, the comment provides a clear direction for the authors to consider, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"mention clearly\" that the experimental setup borrowed from 2 is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and direct, providing a specific action for the authors to take. It also specifies what needs to be addressed, ensuring that the authors know exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the experimental setup, referencing a borrowed setup from 2 and noting that it is only semireal due to the creation of multinode seed cascades by merging singlenode seed cascades. This provides full grounding as it explicitly mentions the borrowed setup from 2 and specifies the issue with the experimental design. However, it does not specify which part of the paper this issue is discussed in, such as a specific section or table. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup is not fully realistic. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it provides a specific point for the authors to address in their draft. By mentioning this issue, the authors can improve the realism and validity of their experimental setup, which is crucial for the credibility of their findings. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context on why this distinction is important. Overall, the comment is 4 as it directs the authors\" attention to a specific area needing clarification or improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a contradiction in the paper\"s statements regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly requests clarification on this apparent contradiction. However, the comment does not provide specific guidance on how the authors should address this issue or what additional information or analysis is needed to resolve the contradiction. While the action is clear, the lack of detailed instructions on how to implement the clarification makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the statements about the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly mentions these two statements, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies the contradiction and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a logical inconsistency by noting that the paper simultaneously claims both a performance loss for the multienv model and its outperformance due to knowledge sharing. This is a clear claim that requires clarification. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the specific statements being referred to, which adds to the complexity of addressing the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a logical inconsistency in the paper\"s claims regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. By pointing out this contradiction, the comment provides a clear and actionable suggestion for the authors to clarify their statements. This feedback is valuable as it helps the authors address a potential confusion in their paper, ensuring that their claims are consistent and wellsupported. However, the comment could be more helpful if it offered specific guidance on how to resolve the contradiction or suggested ways to clarify the statements. Overall, the comment is 4, as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing them. While the comment implies that the authors should include more information about the metrics, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide more details or citations, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of the metrics used in the paper, suggesting that it is limited and recommending either an explanation or a citation. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its suggestion to provide more information about the metrics, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation or citing the metrics. However, the comment does not provide specific examples or references to support the claim that the metrics are not adequately explained. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that either an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the metrics used. However, the comment could be more helpful if it offered additional guidance on how to explain the metrics or suggested specific references for the authors to consider. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify or address this issue, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. This makes it difficult for the authors to identify the exact part of the paper that needs clarification. Additionally, the comment lacks specificity as it does not provide details on what aspect of the embedding is unclear or how it should be explained. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to clarify the issue or suggest how the authors might address it. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue. The comment lacks depth and actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it highlights a potential area of concern but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they should consider to make their results more original. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, it does not specify which part of the paper these results are reported in or which specific results are being discussed. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in pointing out the issue of derivative results, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. However, the comment does not provide specific examples or references to the literature that supports this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks the results already presented in the literature for standard networks. This feedback identifies a potential issue with originality and innovation in the paper. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this concern or improve the originality of their work. Without actionable suggestions or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, suggesting that it is underspecified. It implies that the work focuses on injecting a CoTbased approach to smallscale Language Models, and if that is not the case, it questions the absence of additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) in Tables 2 and 3. The comment also includes a clarification question, \"See Question A,\" which further guides the authors on what needs to be addressed. While the action is implicit, it is clear and specific, providing the authors with a concrete path to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the underspecification of the study\"s scope and suggesting the inclusion of additional relevant CoT baselines for incontext learning of Large Language Models. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified, suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. The reviewer implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. However, the comment does not provide specific examples or references to support the claim that the study is underspecified or that the missing baselines are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. It questions whether this is the only focus and, if not, highlights the absence of additional relevant CoT baselines for incontext learning of Large Language Models in Tables 2 and 3. The comment also includes a clarification question, \"See Question A,\" which further guides the authors on what needs to be addressed. While the comment provides a clear direction for improvement, it could be more helpful if it offered suggestions on how to incorporate these additional baselines or clarified the scope of the study. Overall, the comment is 4 as it directs the authors to a specific area for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point states that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the figure\"s readability, such as suggesting changes in font size, color contrast, or layout. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the figure is \"very hard to read anything on the figure,\" which is a clear and specific description of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty of reading Figure 3, which is a claim that can be verified by the authors themselves. However, the comment does not provide any reasoning, examples, or references to support why the figure is hard to read or how it could be improved. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or evidence to fully support it.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it does not provide any suggestions or guidance on how the authors might improve the figure\"s readability or what specific elements are causing the difficulty. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, as it highlights a problem but does not offer constructive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment implies that the authors should clarify or discuss this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this connection in their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the mention of tensor decomposition being harder in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This question prompts the authors to clarify or discuss this connection, which could be an important aspect to address in their draft. However, the comment does not provide specific guidance or suggestions on how to improve the connection or what aspects to focus on. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to replace `n^2/(2*s^2)` with an arbitrary parameter `lambda` and to clarify the justification for using a SGD learning rate of ~0.1. These actions are clear and concrete, as they specify what needs to be changed and why. The authors know exactly how to address these issues, making the comments 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` (lines 119121) and the use of SGD learning rate ~0.1 (line 164). These references provide full grounding, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in each case. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two claims: the first claims that replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` is arbitrary, and the second claims that the justification for using a SGD learning rate of ~0.1 is unclear. The first claim is 3 as it suggests that the replacement is arbitrary, but it lacks specific reasoning or examples to support this claim. The second claim is more verifiable, as it questions the justification for the SGD learning rate, but it could be strengthened with additional context or references. Overall, the comments are 3 due to the need for more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas for improvement in the manuscript. It suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a clear and direct recommendation for enhancing the clarity and flexibility of the mathematical expressions. Additionally, it questions the justification for using a SGD learning rate of ~0.1, pointing out that unlike the Adam default value, this choice lacks explanation. This feedback is valuable as it guides the authors in making their work more transparent and understandable. However, the comment could be more helpful if it provided additional context or suggestions on how to justify the choice of SGD learning rate. Overall, the comment is 4, as it offers clear guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the authors\" claim that there is no research on joint error for UDA, suggesting that this problem has been studied in previous works, such as \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019. The reviewer explicitly instructs the authors to discuss this work and illustrate the relationship between it and the proposed method, as well as why the proposed method is better. This feedback provides a clear and specific action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the authors\" claim about the lack of research on joint error for UDA and suggests discussing this work to clarify the relationship between it and the proposed method. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in previous works, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019. The reviewer provides a specific reference to support their claim, making it 5. This level of detail and evidence allows the authors to understand and address the critique effectively. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" claim about the lack of research on joint error for UDA, pointing out that this problem has been studied in previous works, such as \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML 2019. The reviewer suggests that the authors discuss this work and illustrate the relationship between it and the proposed method, as well as why their proposed method is better. This feedback is 5 as it provides a clear and actionable suggestion for the authors to address a potential oversight in their paper and improve its comprehensiveness. By correcting this oversight, the authors can enhance the clarity and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the need for a new curriculum learning method for text graphs, suggesting that existing methods could be applied. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the existing methods should be considered. The comment implies that the authors should explore why existing methods are not applicable, but it lacks concrete suggestions or steps for the authors to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the need for a new curriculum learning method for text graphs and questions why existing methods cannot be applied. The comment provides a clear direction for the authors to consider, namely, to discuss the research gap and why existing methods are not applicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified, as existing methods could be applied. However, the comment does not provide specific examples or references to existing methods that could be applied or why they are not suitable for text graphs. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion of curriculum learning methods, specifically questioning the need for a new method for text graphs. It points out that existing methods could be applied, suggesting that the authors should discuss the research gap and why existing methods are not applicable. This feedback is 3 as it highlights an area for improvement and provides a direction for the authors to consider. However, it lacks specific suggestions or examples on how to address the issue, which would make the comment more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This is an explicit suggestion that provides a clear action for the authors to take, which is to incorporate these models as the base encoder and compare their transfer parts. The comment also offers concrete guidance on what specific changes to make, making it 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to use pretrained models and compare transfer parts, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This claim is based on the observation that pretrained models can overcome domainshift problems in the NLP field. However, the comment lacks specific references or examples to support the claim that these models are indeed effective in this context. While the suggestion is logical, it would be strengthened with more detailed evidence or references to substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be improved with additional supporting information.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of powerful pretrained language models like BERT and XLNet as the base encoder for all methods. This suggestion is based on the observation that these models can overcome domainshift problems in the NLP field. By comparing the efficacy of the transfer parts instead of the simplest ngram features, the authors can potentially enhance the performance and robustness of their methods. The comment is specific and provides a concrete direction for improvement, making it 5 for the authors to enhance their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more thorough ablation study to clarify the contributions of each module and parameters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to the increased number of parameters. However, it does not specify which part of the paper this concern relates to, such as the methodology section or the results section. The authors can infer that it pertains to the method description or the ablation study, but this inference is not explicit. The comment is specific in detailing the issue with the current ablation study, but it lacks full grounding as it does not pinpoint the exact section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. The authors are left to infer that the study needs to be more comprehensive, but without explicit guidance, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically the complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to the increased number of parameters. This is a valid concern that the authors should address to ensure the clarity and robustness of their findings. The comment highlights the need for a more thorough ablation study to provide definitive answers to these questions. While the feedback is clear in identifying the issue, it could be more helpful if it suggested specific steps or methods for conducting a more comprehensive ablation study. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the explanation provided in line 1967 regarding the difference between two quantities and how it captures the difference in learning settings. It suggests that more explanation is needed. However, the comment does not provide explicit guidance on what additional explanation is required or how to address the issue. The authors are left to infer that they need to provide a clearer explanation, but the comment lacks concrete details on what specific aspects need clarification. Therefore, the comment is 3, as it identifies a need for more explanation but does not provide clear instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for more explanation regarding why the two quantities are different and how they capture the difference in learning settings. The reviewer\"s stance on acceptance is also included, providing additional context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification on the explanation provided in the paper regarding the difference between two quantities and how it captures the difference in learning settings. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the explanation provided in the paper regarding the difference between two quantities and how it captures the difference in learning settings. It seeks clarification on why these quantities are different and how they relate to the learning settings. While the comment identifies a gap in the paper\"s explanation, it does not provide actionable feedback or suggestions on how the authors might address this issue. The comment lacks depth and does not offer guidance on how to improve the draft, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request provides a clear and direct action for the authors to take, as it specifies what aspect of the model they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the discussion of the sensitivity of any fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should focus on in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to discuss the sensitivity of fixed tuning parameters in their model, both in terms of strengths and weaknesses. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement, namely the discussion of the sensitivity of fixed tuning parameters in the model. It suggests that the authors should address both the strengths and weaknesses of these parameters, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific guidance on how to conduct this analysis or what aspects of sensitivity should be emphasized. To be more helpful, the comment could include examples of how sensitivity analysis is typically conducted or what specific parameters should be considered. Overall, the feedback is 3 as it points out an area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. However, it does not provide explicit instructions on how to conduct these experiments or what specific policy gradient approaches to consider. The request for \"experiment results\" is somewhat vague, as it does not specify which experiments are being referred to or what additional information is needed. The comment lacks concrete details on how to implement the suggested exploration, making it 3. The authors can infer that they need to conduct additional experiments, but the lack of specific guidance on what to include in these experiments limits the actionability.", "grounding_specificity_rationale": "The comment suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional information about the experimental setup, particularly regarding the number of random seeds used. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies. However, it does not provide any reasoning, evidence, or references to support why this exploration is necessary or how it would impact the framework. The request for \"experiment results\" is vague and lacks specific guidance on what aspects of the experiments should be detailed. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. This feedback is 3 as it provides a potential avenue for further research and improvement. However, the comment lacks specificity regarding which policy gradient approaches to consider or how the exploration could be structured. Additionally, it does not provide guidance on how this exploration could enhance the paper\"s contribution or what specific insights might be gained from such an investigation. While it offers a direction for future work, the feedback could be more actionable and comprehensive to be rated as 5. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. While the comment implies that the authors should expand their evaluation to include additional datasets and tasks, it does not provide explicit instructions on how to do so or which specific datasets and tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to strengthen their results and conclusions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this evaluation is based on, nor does it provide details on which datasets or tasks should be considered. The authors might infer that the comment relates to the experimental section, but without explicit references or specific suggestions, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion to expand the evaluation, but it lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This claim is 3 as it provides a logical reasoning for the suggestion, implying that broader evaluation would enhance the robustness and generalizability of the results. However, the comment lacks specific examples or references to other studies that have successfully expanded their evaluations, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, specifically noting that the analysis is currently limited to one dataset and one task. It suggests that the results and conclusions would be stronger if the evaluation were expanded to include more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. By suggesting a broader evaluation, the comment offers a concrete way for the authors to improve their draft, making it 4. However, it could be more helpful if it provided examples of additional datasets or tasks that could be considered. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing could be improved in some places, specifically mentioning an issue with the definition of \"relevant\" auxiliary model weights in definition 2.1. While it identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what changes should be made. The authors are left to infer that they need to clarify the definition of \"relevant\" auxiliary model weights, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it provides a direction but lacks specific instructions for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition, namely the difficulty in interpreting the term \"relevant\" auxiliary model weights. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning an issue with the definition of \"relevant\" auxiliary model weights in definition 2.1. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the definition is difficult to interpret. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the writing, specifically mentioning the difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their work. However, the comment could be more helpful if it provided suggestions on how to improve the definition or offered examples of clearer phrasing. Overall, the comment is 4 as it highlights a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA 1 as an alternative. While the comment identifies a potential issue and suggests a solution, it does not provide explicit instructions on how to address the concern or integrate ULiRA into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider using ULiRA and understand how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA 1 as an alternative. However, the comment does not specify which part of the paper discusses MIA testing or unlearning effectiveness, making it weakly grounded. The comment is specific in identifying the issue with MIA testing and suggesting an alternative, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not robust for privacy guarantees and suggests using ULiRA 1 as an alternative. However, the comment does not provide specific evidence or reasoning to support why MIA testing is not robust or why ULiRA is a better choice. The lack of detailed justification or references makes the claim 3, as the authors would need to independently verify the claim or seek additional information to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness, noting that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also suggests using ULiRA 1 as an alternative, providing a specific recommendation for improvement. However, the comment lacks detailed guidance on how to integrate ULiRA into the paper or address the limitations of MIA testing. While it highlights an important area for consideration, the feedback could be more helpful with additional context or suggestions for implementation. Therefore, the comment is 3, as it points out a critical issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit guidance on how the authors should incorporate these suggestions into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these connections and present them in a different context. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore connections with kernel regression and smoothing, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" This feedback is 3 as it points out a potential connection that the authors might explore, which could expand the scope of their work. However, the comment lacks specific guidance on how to make this connection or what aspects of the paper could be rephrased in this context. Without detailed suggestions or examples, the authors may find it challenging to fully utilize this feedback. Therefore, the comment is rated as 3, as it provides a direction for potential improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including qualitative explanations, minimal description of procedures in simulations or experiments, confusing figures, and the lack of statistical inferences with error bars or pvalues. It suggests adding more details to the paper or supplementary information to clarify the procedures and results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what additional details should be included. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the explanations being qualitative and the procedures being described minimally, as well as the confusion regarding the term \"sample count\" in the figure. The comment further suggests adding more details to the paper or supplementary information to clarify the procedures and results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanations are qualitative and that the procedures in simulations or experiments are described minimally or not at all. It also notes that some figures are confusing, such as the unclear term \"sample count\" in Figure 2. The reviewer suggests adding more details to the paper or supplementary information to clarify the procedures and results. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include error bars and pvalues for statistical inferences is a logical extension but is not explicitly supported by the comment. Therefore, the claim is 3, as it provides some guidance but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the qualitative nature of explanations, the minimal description of procedures in simulations or experiments, and confusing figures. It provides specific examples, such as the unclear term \"sample count\" in Figure 2, which helps the authors pinpoint where additional details are needed. The comment also suggests adding error bars and pvalues to statistical inferences, which is a constructive suggestion for enhancing the paper\"s rigor and clarity. However, the comment could be more helpful if it provided specific guidance on how to improve the explanations or suggested additional details to include. Overall, the feedback is 4 as it offers clear directions for enhancing the paper, but it could be more comprehensive with more detailed suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that the authors should include references to support their claims. While the comment explicitly states the action of adding references, it does not provide detailed guidance on which specific studies to include or how to integrate them into the text. The action is concrete but could be more detailed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to add supportive references for claims that may be inspired from existing studies. The comment provides a specific example of the lines in question and highlights that most of the factors discussed have been discussed in existing studies, suggesting that references should be added. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example by mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that references should be added to support the claims. While the comment provides a logical basis for the claim, it lacks specific references or detailed examples to fully substantiate the suggestion. This makes the claim 3, as it provides a general direction but requires more detailed support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims, suggesting that some may be inspired from existing studies. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment highlights that most of these factors have been discussed in existing studies, implying that the authors should include supportive references. This feedback is clear and actionable, as it directs the authors to add references to strengthen their claims. However, the comment could be more helpful if it provided specific examples of existing studies or detailed guidance on how to integrate these references into the paper. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their draft. The suggestion is concrete, as it specifies what needs to be added to the paper to enhance its comprehensiveness and utility for the community. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. While it does not specify which part of the paper this suggestion pertains to, it implies that it should be addressed in the methodology or results sections where these settings are typically discussed. The comment is specific in its suggestion to include these settings, which would help the community by providing a comprehensive review of the algorithm\"s advances. However, the lack of explicit mention of a specific section makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback is based on the idea that providing these settings would help the community by offering a comprehensive review of the algorithm\"s advances. However, the comment lacks specific examples or references to prior work that would support the need for this information. While the suggestion is logical, it requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback is clear and actionable, as it provides a specific way for the authors to enhance the comprehensiveness and utility of their work. By including these settings, the paper would better align with prior work and provide a more detailed review of the algorithm\"s advances. This suggestion is valuable as it offers a concrete step for the authors to take to improve their draft, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide specific guidance on which datasets would be most useful or how they should be incorporated into the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks detailed instructions on how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not specify which datasets would be most relevant or how they should be incorporated into the study. The authors cannot confidently determine which part of the paper this comment addresses, as it lacks explicit references to specific sections, tables, or figures. The comment is specific in its suggestion to include more datasets for crosstask transferability, but it is 1 because it does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide specific examples or references to support the claim that additional datasets would be necessary or how they would enhance the study. The comment lacks detailed reasoning or evidence to substantiate the need for more datasets, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. While this feedback highlights an area for improvement, it lacks specificity and does not provide detailed guidance on which datasets would be most relevant or how they should be incorporated into the study. The authors are left with a general suggestion but without actionable steps to enhance their draft. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making the necessary enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. While the comment implies that the authors should explore these unique tasks, it does not explicitly instruct them to do so. The action is somewhat implicit and concrete, as the authors can infer the need to explore additional tasks but are not given a direct instruction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment does not specify which part of the paper discusses the tasks or the dataset, making it weakly grounded. The authors can infer that it relates to the tasks or dataset sections, but this inference is not explicit. The comment is specific in suggesting unique tasks that could be explored, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment lacks detailed reasoning or evidence to support why these tasks are considered standard or why introducing unique tasks would be beneficial. The suggestion is somewhat vague and lacks specific examples or references to other works that might support the claim. Therefore, the comment is considered 2, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential limitation in the tasks presented in the paper, suggesting that they are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. This feedback is 3 as it offers a clear direction for the authors to explore more diverse tasks that could enhance the utility and novelty of their work. However, the comment could be more helpful if it provided additional suggestions or examples of other unique tasks that could be explored. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the tractability of MMD DRO compared to phidivergence or Wasserstein uncertainty sets. It also critiques the upper bound provided in Theorem 3.1, noting that it is crude due to the loss function belonging to the RKHS. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, including the tractability of MMD DRO compared to other uncertainty sets, the upper bound provided in Theorem 3.1, and the assumption of the loss function belonging to the RKHS. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the tractability and the upper bound, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a severe drawback. It also critiques the upper bound provided in Theorem 3.1, noting that it is crude and restrictive, as it assumes the loss function belongs to the RKHS. The reviewer provides specific examples, such as the loss function belonging to the RKHS and the need for further approximation, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or references to substantiate the critique of the upper bound. Overall, the comment is 4, as it provides some justification but lacks comprehensive evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the tractability of MMD DRO compared to other uncertainty sets, such as phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, particularly because it drops the nonnegative constraint on the distribution, and further approximation is still needed. Additionally, the comment highlights the restrictive assumption that the loss function belongs to the RKHS. While the comment effectively identifies weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these issues or improve their approach. The feedback is 3 as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It also inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment raises important questions, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific aspects of the framework should be clarified or expanded upon. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.3, binary classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues regarding the relevance of the framework to nonconvex losses and nonnorm type defenses, as well as questions about the impact of the duality gap and the difficulty of maximization over nonnorm type constraints. Additionally, it inquires about the algorithm\"s relevance and whether it provides intuitions on the risk upperbound, and it asks about the use of the true mean to design a better defense. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or whether it still provides intuitions on the risk upperbound. The comment also questions whether the true mean being known through an oracle can be used to design a better defense. While the questions are logical and could prompt the authors to consider these aspects, the comment does not provide specific examples, references, or detailed reasoning to support the claims. This makes the claim 3, as it requires the authors to explore and address these questions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment identifies areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these questions or enhance their draft. The feedback is 3 as it prompts the authors to consider important aspects of their work but does not provide detailed actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is an explicit suggestion that provides a clear direction for the authors to explore. However, the comment does not specify how to implement this action or what specific aspects of the sparsification process to focus on. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014sparsifying the trained models and comparing their accuracy to the proposed model. This provides clear guidance on what needs to be done to improve the analysis or presentation in Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. However, the comment does not provide any reasoning, evidence, or justification for why this action might be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This feedback is 3 as it provides a specific direction for the authors to explore, potentially leading to improvements in the analysis or presentation of their results. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of sparsification to focus on. To be more helpful, the comment could include additional context or reasoning about why this action might be beneficial or how it could enhance the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized, but it does not provide any specific guidance on how to reorganize it or what changes should be made. The action is implicit, as the authors can infer that they need to reorganize the section, but it lacks concrete details on how to do so. This makes the comment 3, as the authors know they need to address the issue but are left without clear instructions on how to proceed.", "grounding_specificity_rationale": "The comment suggests reorganizing the Appendix H section, but it does not specify which part of the paper this section is located in or what specific issues make it difficult to follow. Without this information, the authors cannot confidently determine which part of the paper the comment refers to, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the section are difficult to follow or how they might be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the Appendix H section should be reorganized because it is difficult to follow, but it does not provide any specific reasoning, examples, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance on what aspects of the section are unclear or how they might be improved. Without detailed feedback or suggestions, the authors are left without actionable steps to enhance the clarity and organization of the section. This makes the comment 3, as it identifies a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the paper\"s reproducibility, noting that while the pseudocode is provided in the supplementary material, it does not feel like the paper is written to be reproduced. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback implies that the authors should include these missing details to enhance the reproducibility of their work. However, the comment does not explicitly instruct the authors to add these details, leaving the action somewhat implicit. The authors are left to infer that they need to provide additional implementation details, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of reproducibility, specifically mentioning the lack of details about the RNN implementation, such as the number of units. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional details to enhance reproducibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, despite the presence of pseudocode in the supplementary material. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This claim is 3 as it points out a specific issue with the paper\"s reproducibility, but it lacks detailed examples or references to support the claim fully. The authors would need to infer the exact details that are missing, making the comment 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s reproducibility, noting that while pseudocode is provided in the supplementary material, the paper does not feel written to be reproduced. The reviewer highlights the need for additional details, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback is clear and actionable, as it directs the authors to include these missing details to enhance the reproducibility of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to include these details. Overall, the comment is 4 as it effectively identifies a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to clarify the model\"s capabilities. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the model\"s capabilities, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. This is an important point that the authors should consider, as it questions the potential impact and utility of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the model\"s capabilities. While it identifies a critical area for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking what the \"keypoint mask averaged feature vector\" is and whether it is obtained by multiplying each feature map elementwise by H_psi. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this aspect in their draft. However, the comment is 3 because it directs the authors to a specific area that needs clarification, but it lacks concrete details on how to implement this clarification. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the nature of the \"keypoint mask averaged feature vector\" and asks whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific aspect of the paper, namely the calculation of the \"keypoint mask averaged feature vector.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the calculation of the \"keypoint mask averaged feature vector\" in the KeyQN section. It asks whether this vector is obtained by multiplying each feature map elementwise by H_psi. This question is clear and directly addresses a potential area of confusion in the paper. However, the comment does not provide any additional guidance or suggestions on how the authors might clarify or improve this aspect. While it identifies a specific point for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or analysis to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the central contribution of modeling weight evolution using ODEs, particularly the problem of neural ODEs exhibiting inaccuracy while recomputing activations. It references a previous paper that first reported this issue and questions the current paper\"s analytical argument and empirical evidence. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the issue and the need for evidence, but the lack of grounding makes it challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide specific references or detailed reasoning to substantiate the claim, making it difficult for the authors to address the concern effectively. The lack of supporting evidence or examples makes the claim 3, as it requires the authors to investigate and provide additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the central contribution of the paper, which is the modeling of weight evolution using ODEs. It questions the issue of neural ODEs exhibiting inaccuracy while recomputing activations, suggesting that a previous paper first reported this issue. The reviewer expresses doubt about the current paper\"s analytical argument and empirical evidence regarding this problem. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this concern or provide more convincing evidence. The feedback is 3 as it points out a potential weakness in the paper\"s contribution, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the paper\"s approach to proving lower bounds for round complexity, suggesting that the results follow easily from a reduction to collaborative ranking. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the approach to proving lower bounds for round complexity in the context of batched ranking problems. It mentions the exploitation of an easy reduction from the problem of collaborative ranking, which implies that the authors are using a known result from collaborative ranking to derive their lower bound results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of an easy reduction and the resulting corollary nature of the lower bound results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a major part of the work involved in proving results for batched ranking problems. It further suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which implies that the lower bound results follow as a corollary of these collaborative ranking results. However, the comment lacks specific examples or references to support the claim that the reduction is easy or that the results are a corollary. This makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach to proving lower bounds for round complexity in the context of batched ranking problems. It points out that the paper exploits an easy reduction from the problem of collaborative ranking, which implies that the lower bound results follow as a corollary of these collaborative ranking results. This feedback highlights a potential weakness in the paper\"s methodology and suggests that the authors may need to address this issue to strengthen their claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. While it points out a potential area for improvement, it lacks actionable details, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to fully utilize the potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment implies that the authors should consider using more sophisticated prompting techniques, it does not provide specific guidance on how to implement this suggestion or what constitutes a \"carefully curated\" prompt. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their prompting technique. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of a basic prompting technique in the study, suggesting that it fails to leverage the full potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or how it could be improved. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to use carefully curated prompts, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of large language models (LLMs). However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with other studies or detailed explanations of how the current technique limits the potential of LLMs. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by noting that the prompting technique used is basic and does not fully leverage the capabilities of large language models (LLMs). It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to implement the suggested changes. The authors are left with a general idea of what could be improved but without detailed steps or examples to follow. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the performance of the models in Table 4, noting that the performance on REC and RES is behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT. However, the comment does not explicitly instruct the authors to make any changes or improvements to their models or results. The action is implicit, as the authors can infer that they need to address the performance gap, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT. The comment provides specific examples of the performance achieved by these models, which helps the authors understand the scope of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES is behind more recent models, providing specific examples of other models that achieve better results. This claim is supported by references to GLaMM and UNINEXT, which provide concrete examples of the performance gap. The inclusion of specific references and examples makes the claim 4, as it offers a clear basis for the authors to understand and address the issue. However, the comment could be strengthened by providing more detailed comparisons or analysis of the performance differences, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that the results on REC and RES are behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT, which helps the authors understand the scope of the problem. However, the comment does not offer actionable suggestions or guidance on how to improve the performance of the models or address the identified gap. While it highlights a critical area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the phrase \"evidence\" in the comment might be too strong and proposes a more moderate statement, such as \"Fig.\" This feedback provides a specific suggestion for revising the language used in the comment, which is explicit and concrete. The authors know exactly what action to take to improve the clarity of their statement, making this comment 5.", "grounding_specificity_rationale": "The comment addresses a specific part of the paper, specifically mentioning \"Fig. 5,\" which allows the authors to accurately identify the section being discussed. This provides full grounding. The comment also suggests a revision to the language used, indicating that the authors should use a more moderate term like \"Fig.\" instead of \"evidence.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the phrase \"evidence\" in the comment might be too strong and proposes a more moderate statement, such as \"Fig.\" This feedback is based on a subjective judgment about the strength of the claim, but it does not provide any supporting evidence or reasoning to justify why \"evidence\" is too strong. Without additional context or explanation, the comment lacks verifiability, as it does not offer a clear rationale or examples to support the claim. Therefore, it is classified as 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for revising the language used in the comment, suggesting that \"evidence\" may be too strong and proposing a more moderate statement like \"Fig.\" This feedback is clear and actionable, offering the authors a concrete way to improve the clarity and precision of their language. By following this suggestion, the authors can enhance the effectiveness of their communication and ensure that their message is more accurate and understandable. Therefore, the comment is rated as 5, as it provides a clear and actionable improvement to the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the limited novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, similar to ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a potential issue with the novelty of the approach, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The feedback lacks actionable steps or concrete advice on how to enhance the novelty or differentiate the approach from existing work. As a result, the authors are left without a clear understanding of what changes or additions would be necessary to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the video storyboarding approach, specifically noting that it relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of crossattention. However, the comment does not specify which part of the paper discusses the video storyboarding approach or where the comparison with ConsiStory is made. This lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment does not provide specific guidance on how to enhance the novelty or differentiate the approach. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, as it relies on framewise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of crossattention. However, the comment does not provide specific examples or detailed reasoning to support the claim that the approach is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of crossattention. While the comment highlights a potential issue with the novelty of the approach, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it points out a concern but lacks actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the weakness of the method might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not specify which part of the paper this observation pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method or comparison are being suggested. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the method\"s weakness would be more pronounced in these scenarios. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, suggesting that its weakness might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. This feedback is 3 as it points out a specific area where the method might struggle and suggests a potential direction for further investigation. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could provide more detailed suggestions or examples of how to approach this comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to test the method on larger backbones. The action is implicit and vague, as the authors are left to infer that they should explore the method\"s performance on larger models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not specify which part of the paper discusses the experimental results or the proposed methods, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issue with the relative gains and suggesting a potential area for further exploration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed methods are not very strong, particularly on a small backbone ResNet50, where only a 1% gain is achieved. The reviewer suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to the smaller receptive field of ResNet50. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method would perform better on larger backbones. The suggestion is based on a plausible assumption but lacks concrete evidence or references to substantiate it. Therefore, the claim is 3, as it provides a logical basis but requires further elaboration to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to the smaller receptive field of ResNet50. This feedback is 3 as it points out a potential limitation in the current experimental setup and suggests an area for further exploration. However, the comment could be more helpful if it provided specific guidance on how to test the method on larger backbones or what additional experiments could be conducted to validate the claim. Overall, the comment offers some insight but lacks detailed actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of neural networks contributes less and suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies an issue with the analysis, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analysis of neural networks, specifically mentioning \"Section 3.2, 3.3,\" which provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies the issue by pointing out that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of neural networks, specifically noting that the analysis contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it points out a specific area where the paper could be improved. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance their analysis. Without additional context or detailed advice, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a confusing aspect in the paper regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting a rephrasing or clarification. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, referencing a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights a confusing aspect regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. This allows the authors to understand what needs to be clarified or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing in the abstract and introduction, respectively. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. It references a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context, which is helpful for the authors to consider. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative phrasing or clarifications. While it points out a potential area for improvement, the feedback is 3 as it provides a starting point for the authors to consider but does not fully guide them in making the necessary changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly instruct the authors to make a change, it does highlight a potential issue that needs to be addressed. The authors can infer that they should clarify this aspect in their paper to ensure a fair comparison. However, the comment lacks specific guidance on how to address this issue, such as suggesting how to present this information or what additional details to include. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or experimental setup. The authors can infer that it relates to the dataset section or the experimental setup, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, namely the clarity of dataset usage and fairness of comparison. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. The comment does not contain any subjective claims or opinions but rather seeks clarification on a specific aspect of the methodology. It does not make any claims that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the clarity of dataset usage in the paper, specifically regarding the AH36M dataset. It points out that it is not clear whether this dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. This feedback is valuable as it highlights a potential issue that could affect the validity of the experimental results. However, the comment could be more helpful if it provided suggestions on how to clarify this aspect or offered guidance on how to address the issue. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and mentions specific examples of previous works that have been evaluated on this set. Additionally, it recommends comparing the paper to other approaches where corresponding publications are available. These suggestions are clear and provide specific guidance on how the authors can improve their draft by expanding their comparison to include more relevant and uptodate works. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as comparing the results on the official COOC leader board and the blind test set, and suggesting that the paper should at least compare to other approaches where corresponding publications are available. This provides detailed feedback on how the authors can enhance their work. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. The comment provides a specific reference to the COOC leader board and mentions previous works that have won the challenge and been evaluated on the blind challenge set. This provides some justification for the claim, but it could be strengthened by including more detailed reasoning or examples of why these comparisons are important. Therefore, the comment is 3, as it offers a basis for the claim but lacks full detail and specific references to support the suggestion fully.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s comparison to related work. It highlights that the paper should compare its results on the official COOC leader board, specifically on the blind test set, which is a more rigorous and standardized evaluation method. The comment also references specific previous works that have won the challenge and been evaluated on the blind challenge set, providing a benchmark for the authors to follow. Additionally, it suggests that the paper should at least compare to other approaches where corresponding publications are available, which is a valuable piece of advice for expanding the scope of the comparison. This feedback is detailed and actionable, offering the authors a clear path to enhance the robustness and relevance of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises questions about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the reliability of the results or what steps to take to ensure their validity. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the concern about the reliability of the results due to the MSE being significantly smaller than the MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, such as specific examples, references to similar studies, or detailed reasoning about why the MSE should be smaller than the MAE. Without additional context or justification, the claim remains 1, as it lacks the necessary details to substantiate the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a problem but lacks actionable insights or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their methodology or what specific aspects of the existing methods could be improved upon. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or specific sections where the novelty is discussed. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the existing methods are being extended or how the proposed meta algorithm could be more novel. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. While it identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. Without actionable feedback or detailed insights, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. While the comment identifies a potential area of confusion, it does not explicitly instruct the authors to make this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms, but they are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the meaning of \"good,\" \"bad,\" or \"wrong\" explanations before using these concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"wrong\" used in the paper, suggesting that it lacks clarity. The comment implies that the authors should clarify what is meant by \"good,\" \"bad,\" or \"wrong\" explanations before using these concepts. However, the comment does not provide specific examples or references to support the need for clarification, making it 3. The authors would need to infer the importance of this clarification, which limits the comment\"s verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. This feedback is valuable as it points out a potential area of confusion for the reader and provides a clear direction for improvement. By addressing this issue, the authors can enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to clarify these terms or provided examples of what constitutes a good or bad explanation. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of state, specifically questioning whether the \"elements\" mentioned in lines 186187 are equivalent to \"states\" or \"actions.\" It suggests that more elaboration is needed to clarify this. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address the issue or what specific details should be added. The action is implicit and somewhat vague, as the authors can infer that more explanation is needed but may not know exactly how to provide it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the concept of state, questioning whether \"elements\" are equivalent to \"states\" or \"actions\" and suggesting that more elaboration is needed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the concept of state, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of state in the paper, particularly in lines 186187. It questions whether \"elements\" are equivalent to \"states\" or \"actions,\" suggesting that more elaboration is needed to clarify this. This feedback is clear and actionable, as it points out a potential source of confusion for readers and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to clarify the concept or provided examples of how to elaborate on it. Overall, the comment is 4 as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue in Section 5.3, where a generator with a standard RGCN discriminator tends to collapse, while the proposed module does not. The reviewer suggests that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. However, the comment does not provide explicit instructions on how the authors should address this issue or what specific aspects of the proposed module prevent collapse. The action is implicit and somewhat vague, as the authors need to infer that they should explain the mechanism of the proposed module in more detail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of a generator equipped with a standard RGCN discriminator collapsing and suggests that this observation is crucial for demonstrating the mechanism of the proposed method. The comment clearly specifies what needs to be addressed, namely, understanding why the proposed module can prevent collapse. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN discriminator tends to collapse, while the proposed module does not, and suggests that this observation is crucial for demonstrating the mechanism of the proposed method. However, the comment lacks specific evidence, examples, or references to support this claim. The authors are left to infer the significance of this observation without detailed guidance on how to address it. Therefore, the claim is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 5.3, where a generator with a standard RGCN discriminator tends to collapse, while the proposed module does not. It suggests that this observation is crucial for demonstrating the mechanism of the proposed method and differentiating it from previous approaches. However, the comment does not provide detailed guidance on how the authors should address this issue or what specific aspects of the proposed module prevent collapse. While it highlights an important area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors are given a direction to explore but need more detailed guidance to effectively improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit actions for the authors to take to improve this aspect. There is no guidance on how to clarify these comparisons or what specific elements need to be addressed. Without actionable steps or suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the theoretical comparisons to adaptive learning of GPRGNN are not clear, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper the comment addresses, making it weakly grounded. The comment is specific in pointing out the lack of clarity in theoretical comparisons, but without grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the theoretical comparisons to adaptive learning of GPRGNN. However, it lacks detail and does not provide any suggestions or guidance on how the authors might clarify or improve these comparisons. Without actionable feedback or specific examples, the authors are left without a clear understanding of what needs to be addressed or how to enhance their draft. Therefore, the comment is 2, as it points out a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what alternative measures they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion about object hallucination. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the sufficiency of the measurement method, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. This feedback highlights a potential limitation in the evaluation methodology, prompting the authors to consider alternative measures or metrics for assessing object hallucination. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative methods might be more appropriate. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also questions the impact of having only one type of query. This feedback is clear and direct, providing a concrete action for the authors to take. The comment specifies what needs to be added or explained, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This provides clear guidance on what the authors need to include to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the completeness of the experiments section, specifically regarding the ablation study. It suggests that there should be experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This is a logical suggestion based on the reviewer\"s understanding of the paper\"s focus and the need for comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that these components are missing, making it 3. The authors would need to infer the exact details of what is missing, which limits the clarity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the ablation experiments. It points out that the paper lacks experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This is a critical aspect of the paper, as it differentiates the work from other related studies like VideoChatGPT. The comment also raises a hypothetical scenario about the impact of having only one type of query, which encourages the authors to consider the full scope of their experiments. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the completeness and depth of their experimental analysis. However, it could be more helpful if it included suggestions on how to conduct these experiments or what specific results to expect. Overall, the comment is 4, as it guides the authors toward improving their draft by addressing a significant gap in the current experimental setup."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific action to improve the redundancy between Section 3 and Section 4 by rearranging the content. It provides a concrete suggestion to move the first paragraph of Section 4 to Section 3 and the remainder of Section 4 before Section 3. This explicit guidance gives the authors a clear idea of how to address the redundancy issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a rearrangement of content to reduce redundancy, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a rearrangement of content to reduce redundancy between Section 3 and Section 4. It provides a specific suggestion by recommending the movement of certain content from one section to another. However, the comment lacks detailed reasoning or evidence to support why this rearrangement would be beneficial or how it would improve the flow of the paper. The suggestion is based on a subjective judgment of redundancy, which could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides a logical suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a redundancy issue between Section 3 and Section 4 and provides a specific suggestion for rearranging the content to address this redundancy. By suggesting the movement of certain content from one section to another, the comment offers a clear and actionable way for the authors to improve the organization and flow of their paper. This feedback is valuable as it helps the authors enhance the clarity and coherence of their manuscript, making the comment 4. However, it could be more helpful if it included additional guidance on how the rearrangement might impact the overall structure or if it provided examples of how the content could be reorganized. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of connection between the concepts of improved variance control of prediction y^ and the smoothness of the loss landscape, and the effectiveness of zeroshot learning. It suggests that the connection is unclear due to poor clarity. However, the comment does not provide specific guidance or suggestions on how the authors might clarify this connection or improve the clarity of their paper. The action is implicit and vague, as the authors are left to infer that they need to clarify the connection between these concepts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in detailing the issue of poor clarity and the need for a clearer connection between these concepts and zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" suggesting poor clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting a lack of connection between the concepts of improved variance control of prediction y^ and the smoothness of the loss landscape, and their relationship to zeroshot learning effectiveness. It highlights a potential gap in the paper\"s clarity and suggests that this could be due to poor clarity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their paper. While it points out a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to provide a citation for where the kmax problem was discussed elsewhere in the paper. This is a clear and direct request, giving the authors a specific action to take: identify and cite the relevant sections. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kmax problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a citation for where the kmax problem was discussed elsewhere in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for a citation, which is a factual statement rather than a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide a citation for where the kmax problem was discussed elsewhere in the paper. This is a specific and direct request that helps the authors identify and address a potential oversight in their draft. By following this feedback, the authors can ensure that their work is more comprehensive and that all relevant discussions are properly referenced. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the citation or integrate the discussion of the kmax problem. Overall, the comment is 4 as it guides the authors towards a specific improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. It explicitly asks for clarification on these aspects, providing a clear and direct action for the authors to take. The comment specifies what needs to be addressed, namely the estimation process and the reliability of the model, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of information regarding the estimation of the function for the optimal sequence length and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support why this information is crucial or how its absence affects the paper. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by questioning the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide more details on the estimation process and the model\"s reliability. By addressing this issue, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it suggested specific methods or references for estimating the function or assessing model reliability. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to modify the statement \"thousands\" in the text to \"on the subword level.\" This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and how to implement the correction. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the phrase \"thousands\" is not accurate and recommending the addition of \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a correction to the text, specifically recommending the change from \"thousands\" to \"on the subword level.\" This is a factual statement that does not contain subjective opinions or claims, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the text, suggesting that the phrase \"thousands\" is not accurate and recommending the addition of \"on the subword level.\" This feedback is clear and actionable, providing the authors with a direct correction to make in their draft. By specifying the exact change needed, the comment helps the authors improve the accuracy and clarity of their text. However, it could be more helpful if it explained why the change is necessary or provided additional context. Overall, the comment is 4 as it guides the authors in making a specific and impactful revision to their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is explicit, as it directly instructs the authors to provide the missing hyperparameters. The second issue is more implicit, as it suggests that the authors clarify the y value at x=0 in the figures. While the comment does not provide specific guidance on how to clarify this, the authors can infer that they need to address this aspect in their description. Overall, the comment is 4, as it provides clear guidance on what needs to be addressed but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses two specific issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. It provides explicit references to \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be clarified or addressed, such as providing the missing hyperparameters and explaining the y value at x=0. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is a factual observation that requires clarification, while the second is a suggestion for further analysis. The comment does not contain subjective opinions or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues that need attention: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. It provides clear and actionable feedback by explicitly instructing the authors to provide the missing hyperparameters and clarifying the y value in the figures. Additionally, it suggests further analysis using interpolations, which could enhance the paper\"s depth and impact. This feedback is detailed and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deeprag algorithm or discussion on high concurrency. While the comment highlights specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the contributions in the Introduction and ensure that supporting material is appropriately integrated into the main sections. The action is implicit and somewhat vague, as it does not offer detailed guidance on implementation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies issues with forward referencing in the paper, specifically mentioning the need for clearer explanation of contributions in the Introduction and the placement of supporting material in the appendix. However, it does not specify which sections or parts of the paper are affected by these issues, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for clearer explanations and the proper integration of supporting material. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix, not the main sections. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction, which is a valuable piece of feedback for the authors to consider. Additionally, the comment points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deeprag algorithm or discussion on high concurrency. This observation is helpful as it directs the authors to ensure that their contributions are clearly presented and accessible to the reader. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity of the contributions or how to integrate the supporting material into the main sections. Overall, the comment is 4 as it highlights areas for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the presentation of test settings in the visual dialog domain. It highlights that while there are two test settings, only one is shown in Table 1, specifically the discriminative setting. The reviewer questions why the generative setting is not included and asks for the results on this setting. This feedback is explicit and concrete, as it directly instructs the authors to provide results for the generative setting, which is a clear and actionable suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the presentation of test settings in visual dialog, specifically questioning why only the discriminative setting is shown in Table 1 and asking for results on the generative setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the completeness of the results presented in Table 1, specifically regarding the absence of results for the generative setting in visual dialog. The reviewer points out that the discriminative setting is not applicable to realworld applications and asks for results on the generative setting. While the comment raises a valid concern about the completeness of the results, it lacks specific examples or references to support the claim that the discriminative setting is not applicable. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only shows results for the discriminative setting in visual dialog, while there are two test settings in total. The reviewer points out that the discriminative setting is not applicable to realworld applications and asks for results on the generative setting. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive presentation of their results. By addressing this gap, the authors can enhance the completeness and relevance of their findings. Therefore, the comment is rated as 5, as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to test the approach in other language families. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section, table, or figure this comment pertains to, making it weakly grounded. The comment is specific in that it highlights a potential limitation of the approach, but without explicit references or detailed guidance, the authors may struggle to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to similar work, the authors are left without guidance on how to address this concern. The lack of detailed justification makes the claim 1, as it does not provide the authors with a clear path to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, specifically questioning its effectiveness for other language families. This is a valid concern that the authors should consider, as it highlights an area where the current work may be lacking. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or explore the effectiveness of their approach in other language families. Without actionable advice or specific recommendations, the feedback is limited in its usefulness. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the named works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about providing this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the named works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not specify which specific works are being referred to or what aspects of the differences need to be described. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment is weakly grounded because it does not provide explicit references to sections or specific works, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works are being referred to or what aspects need further clarification. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to substantiate the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, suggesting that more detailed descriptions of the differences between named works are needed. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and specificity. The authors are given a direction to improve their draft, but the comment could be more helpful if it provided examples of how to enhance the descriptions or suggested specific works to focus on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. While the comment implies that the authors should provide this explanation, it does not specify how to do so or what aspects of the explanation are needed. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but may not know exactly how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific point about the importance of reliable PPP metrics and the lack of explicit explanation in the article. It explicitly mentions the importance of understanding PPP effects in different tasks, which grounds the comment well. However, it does not specify which part of the article lacks this explanation, making it weakly grounded. The comment is specific in its request for an explicit explanation of what type of understanding one can gain by looking at PPP maps. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of explicit explanation regarding the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should provide a more detailed explanation. While the comment identifies a gap in the article, it does not provide specific examples or references to support the claim that the explanation is missing. The reasoning is based on the authors\" statement about the importance of PPP metrics, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the article by noting that while the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, this explanation is not explicitly provided in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the concept, which could significantly enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to structure this explanation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include for comparison. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional comparisons to enhance the credibility of their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a lack of comparison with stateoftheart methods for spanrelated tasks, specifically mentioning SpanBERT. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for comparison with other methods, which is a clear direction for improvement. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. However, the comment does not provide specific examples or references to support the claim that SpanBERT or other methods are the only relevant ones. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with stateoftheart methods for spanrelated tasks, such as SpanBERT. This feedback is important as it highlights a potential weakness in the credibility and comprehensiveness of the work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which methods to include for comparison or how to structure these comparisons. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for enhancement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic of the forward prediction model. Additionally, it points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and provides specific actions for the authors to take, such as revising the figure and improving the connection between the text and the figure. The authors know exactly what needs to be done to address the issues raised, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figure does not effectively represent the schematic of the forward prediction model and that it is difficult to connect the text, figure, and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, and specifically mentions that Figure 2(b) does not effectively represent the schematic of the forward prediction model. The reviewer suggests that the figure should be redrawn to improve clarity. However, the comment lacks specific examples or detailed reasoning to support why the current representation is inadequate or how the suggested changes would enhance understanding. This makes the claim 3, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, noting that Figure 2(b) does not effectively represent the schematic of the model. It also points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and actionable, as it provides specific suggestions for improvement, such as redrawing the figure to better illustrate the model. By addressing this issue, the authors can enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the connection between the text, figure, and equations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their baseline. The action is implicit and vague, as the authors are left to infer that they need to provide a stronger baseline or address the issue of rewardless actions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This feedback is fully grounded as it explicitly mentions the training process for RBI, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the training process and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI compared to RBI alone. However, the comment lacks specific examples or detailed reasoning to support the claim that ignoring rewardless actions is a significant factor. The suggestion to provide a stronger baseline is a logical response to the concern, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This observation could be significant in understanding the performance of FP + RBI compared to RBI alone. The reviewer suggests that the authors should provide a stronger baseline to prove the usefulness of FP, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided specific examples or detailed reasoning to support the claim about the impact of rewardless actions. Overall, the comment is 4 as it identifies a potential area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the baseline methods are weak and not presenting stateoftheart results, and suggests that there is no discussion of limitations. It also raises questions about the difference between the work and reinforcement learning. The comment implies that the authors should address these issues by discussing the limitations and providing a comparison with reinforcement learning. While the action is implicit, it is concrete as it specifies the areas that need attention and suggests a direction for improvement in the conclusion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the baseline methods, suggesting they are weak and not presenting stateoftheart results, and lacks discussion of limitations. It also raises questions about the difference between the work and reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for a discussion of limitations and the difference between the work and reinforcement learning, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not presenting stateoftheart results, and suggests that there is no discussion of limitations. It also raises questions about the difference between the work and reinforcement learning. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to discuss the similarity and difference in the conclusion is a general direction but does not provide detailed guidance on how to address these issues. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not presenting stateoftheart results, suggesting that there is no discussion of limitations. Additionally, it raises questions about the difference between the work and reinforcement learning, indicating that the authors should address these issues in the conclusion. The comment provides a clear direction for improvement by suggesting that the authors discuss the limitations and provide a comparison with reinforcement learning. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it highlights important areas for the authors to consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should clarify the distinction between the decision maker\"s interest in the true objective function and the noise, which is typically assumed to be noise. The comment provides a clear action for the authors to take, which is to make this distinction more explicit in the formulation. This guidance is concrete and provides a direct path for the authors to improve their draft by addressing the specific issue of clarity. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formulation, which is the distinction between the decision maker\"s interest in the true objective function and the noise, which is assumed to be noise. The comment suggests that this distinction should be clarified upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the typical use of expected performance under observation noise for evaluation is misleading because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. The reviewer suggests that the formulation in the paper should clarify this distinction. While the comment provides a logical argument, it lacks specific examples or references to support the claim that the typical use of expected performance is misleading. This makes the claim 3, as the authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formulation of the paper, noting that the decision maker\"s interest is in the true objective function, not the noise, which is typically assumed to be noise. The comment suggests that this distinction should be clarified upfront to avoid potential confusion. This feedback is clear and actionable, as it provides a specific area for improvement that can enhance the clarity and accuracy of the paper. By addressing this issue, the authors can better align their work with the intended focus of the decisionmaking process. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method performs well, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty and contribution of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, which provides a clear reference for the authors to identify the part of the paper being discussed. It also critiques the novelty and contribution of the method, suggesting that the main contribution is a new network design inspired by prior work for the sound source localization task. This feedback is specific in its critique and provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. While the comment provides a logical reasoning for the critique, it lacks specific examples or references to prior work that could be used to substantiate the claim. This makes the claim 3, as the authors would need to further explore the literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for the sound source localization task. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might enhance the novelty or contribution of their work. The feedback is 3 as it points out a critical aspect for consideration but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. While the comment implies that the authors should provide evidence or results to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional results or demonstrations to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the demonstration or results related to the model collapsing less than other methods, and it references a specific point in the text where gradients become 0 and collapse. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the demonstration or results related to the model collapsing less than other methods. It references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. However, the comment does not provide any evidence, reasoning, or references to support the claim or question. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods, referencing a specific point in the text where gradients become 0 and collapse. While the comment identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors might address this issue or what additional information should be included. The feedback is 3 as it prompts the authors to consider demonstrating or explaining their model\"s performance in this regard, but it does not offer detailed suggestions or actionable steps. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment notes that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the problem. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the problem formulation is unclear, the comment lacks full grounding as it does not provide specific guidance on what aspects need clarification. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any further details or suggestions on how the authors might clarify this issue. Without additional guidance or examples, the authors are left without a clear path to address the problem. The feedback is vague and lacks actionable advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and direct action for the authors to take, which is to include these experiments to enhance the paper\"s applicability and generalizability. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or methodology. This makes it difficult for the authors to identify the exact section that needs attention. While the comment is specific in suggesting what experiments to conduct, it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical suggestion for improving the paper\"s applicability and generalizability. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the lack of experiments on different LLM families. It provides a clear and actionable suggestion by recommending that the authors conduct trials with models like OPT, BLOOM, or other alternatives. This feedback is valuable as it guides the authors on how to enhance the applicability and generalizability of their method. However, the comment could be more helpful if it included specific guidance on how to design and execute these experiments or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or whether they should consider expanding the scope of their method to other types of generative models. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper discusses this limitation or provides examples of generative models that can be finetuned. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its claim about the method\"s limitations, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, specifically that it only works for generative models that can be finetuned as an in/outpainting model. This observation is relevant and could prompt the authors to consider the applicability of their method to a broader range of generative models. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their method. Without actionable feedback or additional insights, the comment is 3, as it highlights an area for potential improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not provide specific guidance or suggestions on how the authors might strengthen these connections or improve the clarity of their presentation. The comment lacks actionable details, leaving the authors without a clear path to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not specify which sections or parts of the paper are being discussed, making it weakly grounded. The comment is specific in its critique, as it highlights a potential disconnect between the title and the actual content of the paper, noting that the process of finding weights and learning curves is not as described in the title. However, without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to sections or parts of the paper that need clarification, making it difficult for the authors to address the issue effectively. As a result, the claim is considered 2, as it provides some insight but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It provides a specific example of what the author might have expected based on the title and the first part of the paper, but notes that it was not as described. This feedback is 3 as it highlights a potential disconnect in the paper\"s structure or presentation, prompting the authors to clarify or reframe their approach. However, the comment could be more helpful if it offered suggestions on how to strengthen the connections or improve the clarity of the paper\"s structure. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include results for linear scalarization + Concorde for a better comparison, given that the obtained Pareto front is not highly nonconvex. This action is clear and concrete, as it specifies exactly what additional results need to be included to improve the comparison. The comment provides a direct and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the results for linear scalarization + Concorde should be included for a better comparison, given the nature of the Pareto front. This provides clear guidance on what additional information is required to enhance the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are much better than the heuristicbased solvers, but it does not provide specific evidence or reasoning to support this claim. The suggestion to include results for linear scalarization + Concorde for a better comparison is based on the observation that the Pareto front is not highly nonconvex. However, the comment lacks detailed justification or examples to substantiate the claim that Concorde would be a better choice. Therefore, the claim is 3, as it provides a logical basis but lacks comprehensive evidence or references to fully support the suggestion.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of competitive baselines in the paper. It points out that while the learningbased solvers perform better overall, the SOTA heuristicsolver (Concorde) is typically the best for singleobjective TSP. The comment suggests including results for linear scalarization + Concorde to provide a more comprehensive comparison, especially since the Pareto front is not highly nonconvex. This feedback is clear and actionable, as it directs the authors to make a specific improvement to their experimental setup to enhance the validity of their results. However, the comment could be more helpful if it provided additional context or guidance on how to integrate these results into the paper. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some details from the appendix back into the main text and moving some background information from Section 2 to the appendix. This provides explicit actions for the authors to take, such as identifying which details should be moved back and which background information should be moved to the appendix. The suggestion is concrete, as it outlines specific steps for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of moving experimental details and tasks to the appendix, which makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. This provides a clear and specific suggestion for the authors to consider, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim fully. The authors might find it challenging to understand the exact details that need to be moved back or why the background information should be moved to the appendix. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s organization, noting that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret. It provides a clear suggestion to move some of these details back into the main text and to move some background information from Section 2 to the appendix. This feedback is actionable and provides a concrete way for the authors to improve the clarity and accessibility of their work. However, the comment could be more helpful if it specified which details should be moved back and which background information should be moved to the appendix, as this would give the authors a clearer idea of what changes to make. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide glosses in Figure 2, which is a clear and explicit action. It does not require the authors to infer the action, as it is directly stated. The suggestion is also concrete, as it specifies what needs to be added to the figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the provision of glosses in the figure. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide glosses in Figure 2, which is a request for clarification or improvement. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment suggests that the authors provide glosses in Figure 2, which is a clear and actionable suggestion. It identifies a specific area where the paper could be improved, offering a direct way for the authors to enhance the clarity and accessibility of their work. However, the comment does not provide additional context or suggestions on how to implement the glosses, which could further enhance its helpfulness. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This implies that the authors should include a reference to the stateoftheart work, \"Memb,\" to provide context and support for their claim. However, the comment does not explicitly instruct the authors to include a reference or specify which reference to use. The action is implicit and somewhat vague, as the authors need to infer that they should add a reference but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This implies that the authors should include a reference to support this claim. However, the comment does not specify which part of the paper this issue is related to, such as a section or a particular discussion. The authors can infer that it pertains to the stateoftheart section or a related discussion, but this inference is not explicit. Therefore, the comment is weakly grounded as it does not provide a clear reference to the specific part of the paper being addressed, and it is specific in pointing out the need for a reference. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that \"Memb is apparently the previous stateoftheart,\" but it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or references, the authors are left without guidance on how to address the issue or improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This feedback highlights a gap in the paper\"s documentation, suggesting that the authors should include a reference to support their claim about Memb being the stateoftheart. However, the comment does not provide specific guidance on which reference to include or how to integrate it into the paper. While it points out a critical omission, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a gap but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a suggestion for improvement or a point that needs clarification. Without any actionable advice or direction, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in questioning the choice of quantization granularity, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of pertensor and perchannel. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be beneficial or why the current approach is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the question and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of pertensor and perchannel. While it identifies a potential area for improvement, the comment lacks depth and does not provide any suggestions or reasoning to support the need for finer grouping. Without additional context or guidance, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it points out a potential area for consideration but does not offer actionable advice or insights."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples. This feedback is explicit, as it directly instructs the authors to conduct a study on the impact of the ratio of unseen classes. The comment also provides a concrete example of what aspect to investigate, making it 5. The authors know exactly what action to take and how to implement it, aligning with a score of 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes, specifically how the performance varies with different ratios of unseen classes unlabeled examples. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental design or results, but this inference is not explicit. The comment is specific in its suggestion to study the impact of the ratio of unseen classes, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any specific reasoning, examples, or references to support why this is important or how it could be studied. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the significance of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples, which is a relevant and actionable suggestion. This feedback encourages the authors to explore a potential area of improvement that could enhance the depth and applicability of their work. However, the comment could be more helpful if it included specific guidance on how to conduct this study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to an important area for further investigation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While the comment implies that the authors should justify their choice of architectures, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for their architectural choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, it does not specify which part of the paper discusses these architectures or where the improvements are mentioned. The authors can infer that it relates to the methodology section, but the comment lacks explicit grounding. It is specific in questioning the choice of architectures and their impact on performance, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this combination might be beneficial or why it could lead to improvements. Without additional context or explanation, the claim remains 1, as the authors may not understand the basis for the question. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While it identifies a potential area for improvement or explanation, it lacks specific guidance or suggestions on how the authors might address this issue or justify their architectural choices. The comment provides a starting point for the authors to consider, but it does not offer detailed feedback or actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in line 135, where the author mentions that the network initially has a few active vertices due to sparsity. However, the comment does not provide any explicit or implicit action for the authors to take. It simply asks for clarification on the definition of \"active vertices.\" As a result, the authors are left without guidance on how to address this issue or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the definition of \"active vertices,\" providing a clear direction for the authors to address this issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the definition of \"active vertices\" in line 135. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the definition of \"active vertices\" in line 135, which is relevant to understanding the context and methodology of the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback or constructive advice, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s limitations, specifically mentioning that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide specific guidance on what kind of elaboration is needed. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the paper, specifically mentioning that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment does not explicitly mention a specific section, it is clear that it pertains to the limitations section or the discussion of the theoretical framework. The authors can infer that it relates to these parts of the paper, but the comment lacks explicit grounding. The specificity is clear as it identifies the issue of theoretical limitations and suggests areas for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theory presented in the paper does not seem to be applicable to the used model, and that unspecified structural assumptions are only given in the appendix, making it hard to find. The reviewer also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific issues with the paper, it lacks detailed reasoning or evidence to fully substantiate the claims. The suggestion to elaborate on potential negative societal impacts is a general recommendation rather than a specific critique. Therefore, the comment is 3, as it provides some support but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s limitations, specifically noting that the theory does not seem to be applicable to the used model and that unspecified structural assumptions are only given in the appendix. It also suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention but does not provide detailed actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the meaning. As a result, the authors are left without a clear understanding of what action to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...,\" providing a clear indication of what needs to be clarified or addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" without providing any claim or suggestion for improvement. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify this point or address any potential issues. The feedback lacks actionable advice or detailed explanations, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. It implies that the authors should consider whether this combination offers any novel contributions or if it is merely a direct combination of existing techniques. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or what specific aspects of the method could be improved. The action is implicit and vague, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the proposed method, suggesting it is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the technical aspects of the method, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. The reviewer implies that this combination may not offer any novel contributions. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the originality of their work. While it points out a potential weakness, it does not provide actionable feedback or constructive suggestions for enhancing the draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue regarding the projection head and classification head in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the projection head and classification head in the paper, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or experimental setup, but they cannot confidently determine the exact section being addressed. The comment is specific in identifying the issue with the classification head, but it lacks grounding as it does not specify the exact part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) is affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue regarding the distinction between the projection head (CNN layers) and the classification head (FCN layer) in the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their work. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analogy between HOI analysis and Harmonic analysis is weak, as there are only two \"basis\" (human and object) in the problem contexts. It also notes that the decomposition and integration steps introduced in the paper do not have a close connection with Fourier analysis as claimed. While the comment identifies specific issues with the analogy and the connection to Fourier analysis, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. However, it does not specify which part of the paper this analogy is discussed in, making it weakly grounded. The comment is specific in identifying the issues with the analogy and the connection to Fourier analysis, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The absence of detailed evidence or references leaves the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition and integration steps do not have a close connection with Fourier analysis as claimed. This feedback is 3 as it points out a specific area where the paper may be lacking in coherence or accuracy. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the analogy. Without additional context or specific recommendations, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. It implies that the proposed methodology might have limited implications. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors could address this issue or explore alternative implications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning that it might only show meaningful performance gains on bitserial accelerators. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in identifying the potential limitations and suggesting that the proposed methodology might have limited implications due to the common use of bitparallel fixedpoint numbers in existing ML accelerators. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This claim is 3 as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This observation is relevant and provides a critical perspective on the applicability of the proposed methodology. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or explore alternative implications. While it highlights an important consideration, it does not offer specific steps or insights for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalization of the focusing distance beyond the 1m and 5m distances shown in Figure 8. It suggests that the authors should consider focusing distances that are not present in the training data to assess generalization. While the comment implies that the authors should explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the generalization of focusing distances beyond the training data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalization of the focusing distance beyond the 1m and 5m distances shown in the figure, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalization of the focusing distance beyond the 1m and 5m distances shown in Figure 8. It suggests that the authors should consider focusing distances not present in the training data to assess generalization. While the comment is a request for further exploration, it does not contain a claim or an opinion that requires verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a question about the generalization of the focusing distance in Figure 8, which only shows distances of 1m and 5m. It suggests that the authors should consider focusing distances not present in the training data to assess generalization. This feedback is 3 as it identifies a potential area for improvement in the paper\"s generalizability. However, it lacks specific guidance on how to address this issue or what focusing distances should be considered. The comment could be more helpful with additional suggestions or examples, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness in the work, which is the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It also points out that the proposed Xtransformation is similar to STN but applied locally, and that PointNet uses a variant of STN. The comment suggests that the technical novelty is limited and that there should be empirical or conceptual comparisons to STN. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or analyses should be conducted. The action is implicit and somewhat vague, as the authors can infer the need for comparisons and novelty enhancements but lack detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the technical novelty of the work, specifically regarding the use of spatial transformer networks (STN) and the proposed Xtransformation. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture. However, the comment does not specify which part of the paper discusses STN or the proposed Xtransformation, making it weakly grounded. The comment is specific in detailing the issues with technical novelty and the lack of comparisons, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty with respect to spatial transformer networks (STN) and does not provide comparisons to existing works that use STN. It also notes that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture. The comment provides a logical reasoning by comparing the proposed Xtransformation to STN and existing works, which supports the claim. However, it could be strengthened by providing specific references or examples of the existing works mentioned, which would enhance the verifiability. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed references or examples.", "helpfulness_rationale": "The review comment identifies a main weakness in the work, specifically regarding the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty of the work is limited. The comment also highlights the importance of empirical or conceptual comparisons to STN. While the feedback is clear in identifying areas for improvement, it could be more helpful if it provided specific suggestions on how to enhance the technical novelty or how to conduct the necessary comparisons. Overall, the comment is 4 as it provides actionable insights for the authors to consider in improving their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests correcting a labeling error in the supplementary material (Row 821, \"Fig.7\" should be \"Fig.12\") and recommends attaching proof links to each theorem and corollary in the main paper for easier reader navigation. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion. While the comment does not specify how to address these concerns, it provides clear and actionable steps for the authors to take. The feedback is 4 because it outlines specific actions that the authors can take to improve their draft, but it could be more detailed in terms of how to address the concerns about motivation, methodology, and experiment persuasion. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue with the labeling error and provides a suggestion for attaching proof links to theorems and corollaries. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a mix of factual statements and suggestions. The factual statements, such as the correction of a labeling error, are clear and verifiable. However, the suggestion to attach proof links to theorems and corollaries is not fully supported by evidence or reasoning. While it is a logical suggestion, it lacks specific examples or references to justify why this is necessary. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues: a labeling error in the supplementary material and the need to attach proof links to theorems and corollaries in the main paper. This feedback is clear and directly addresses the authors\" need to correct the labeling error and improve the reader\"s navigation through the paper. Additionally, the comment highlights concerns about motivation, methodology soundness, and experiment persuasion, which are important aspects for the authors to consider in enhancing the paper\"s overall quality. While the comment does not delve into detailed suggestions for addressing these concerns, it provides a strong foundation for the authors to improve their draft. Therefore, the comment is rated as 4, as it offers clear guidance on specific improvements and raises important areas for consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions that seek clarification on specific aspects of the paper. The first question asks about the missing determiner in the definition, while the second question inquires about the selection of 50 classes and their explicit tagging as action verbs by Levin. The third question asks about the concept of \"action frames\" and how they are chosen. These questions provide explicit actions for the authors to take, such as clarifying the missing determiner and explaining the selection of action verbs and frames. However, the comment lacks concrete guidance on how to address these issues, such as suggesting specific changes or providing examples. The actions are clear, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the definitions and selection of action verbs and frames, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the missing determiner, the selection of 50 classes, and the concept of \"action frames.\" These questions are not claims but rather requests for clarification or information. Therefore, they do not require verification as they are not claims or opinions that need to be substantiated. The comment is classified as \"No\" because it does not contain claims or opinions that require verification.", "helpfulness_rationale": "The review comment consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"above,\" the selection of 50 classes, and the concept of \"action frames.\" While the questions provide valuable insights into areas that need clarification, they do not offer actionable feedback or suggestions on how to improve the draft. The authors are left with a list of questions but without guidance on how to address these issues or enhance the clarity and coherence of their work. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify or provide more information on the design of rewards, but it does not offer concrete steps or examples of what should be included. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area where details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft lacks detail, specifically mentioning the lack of understanding of how to design rewards. This feedback is 3 as it points out a gap in the paper that needs attention. However, it does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of reward design should be clarified. To be more helpful, the comment could include examples or references to similar works that might provide insight into designing rewards. As it stands, the comment offers a starting point for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about generalizing a model to different numbers of entities, specifically referencing Figure 3 from INs. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific steps to generalize the model. The comment implies that the authors need to clarify or modify their approach, but it lacks concrete details or actionable advice on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the model can be generalized to different numbers of entities, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the model to different numbers of entities, referencing Figure 3 from INs. However, it does not provide specific examples or detailed reasoning to support why this is a concern or how it affects the model\"s applicability. The mention of INs provides some context, but without further elaboration, the claim remains 3. The authors would need to infer the exact issue and how it impacts the model, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s generalizability to different numbers of entities, referencing Figure 3 from INs. This feedback is 3 as it points out a potential limitation in the current approach, which could be addressed by the authors. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might overcome this limitation or improve the model\"s generalizability. Without additional context or actionable advice, the feedback is incomplete, leaving the authors with a basic understanding of the issue but no clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions that the experimental design is good. However, the comment raises a concern about the novelty of the work, suggesting that it is a \"nitpicking\" issue. The reviewer implies that the authors should consider the tradeoff between novelty and execution effort, but does not provide explicit guidance on how to address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should evaluate the tradeoff between novelty and execution effort. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the incremental nature of the work compared to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions the good experimental design. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in its critique of the novelty and execution effort, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, lacking significant novelty but requiring substantial engineering and execution effort. It also notes that the experimental design is good. However, the comment raises a concern about the novelty of the work, suggesting that it is a \"nitpicking\" issue. The reviewer implies that the tradeoff between novelty and execution effort should be considered, but does not provide specific examples or detailed reasoning to support this claim. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also highlights the good experimental design. However, the comment raises a concern about the novelty of the work, suggesting that it is a \"nitpicking\" issue. The reviewer implies that the tradeoff between novelty and execution effort should be considered, but does not provide specific guidance or suggestions on how to address this concern. While the comment identifies a potential weakness, it lacks actionable feedback or detailed advice, making it 3. The authors may find it challenging to fully understand and address the critique without additional context or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. It implies that the authors should include a discussion on the computational efficiency of Prithvi WxC as a limitation for MLbased emulators of climate model parametrizations. While the comment implies an action, it does not provide explicit instructions on how to discuss the runtime or what specific aspects of the runtime should be addressed. The action is somewhat vague, as the authors need to infer the details of the discussion required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the runtime of Prithvi WxC, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime as a limitation, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. This claim is 3 as it provides a logical reasoning based on the computational cheapness of MLbased emulators, which is a common expectation for such models. However, the comment lacks specific examples or references to support the claim fully. Therefore, it is classified as 3.", "helpfulness_rationale": "The review comment suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as a limitation for MLbased emulators of climate model parametrizations. This feedback is 3 as it identifies a potential area for improvement in terms of computational efficiency, which is an important consideration for the application of MLbased emulators. However, the comment lacks specific guidance on how to discuss the runtime or what aspects of the runtime should be highlighted. To be more helpful, the comment could provide examples or references to similar discussions or suggest specific metrics to consider. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contribution. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the framing are problematic or how they contribute to the paper\"s clarity. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed feedback on how the framing could be improved or what aspects of the method are being oversold. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to address the issue. This lack of detail and specificity makes the comment 2, as it provides a general observation but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding. It also recommends using a notation table to clarify the use of symbols. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or explain how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of a notation table to clarify the use of symbols. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or subsection. This makes it difficult for the authors to identify the exact area needing improvement. While the comment provides specific suggestions for improvement, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to clarify the use of symbols. While the comment provides specific suggestions for improvement, it does not include any supporting evidence, reasoning, or references to justify why these changes are necessary. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that presenting the generative process in separate steps would enhance understanding. It also recommends using a notation table to clarify the use of symbols, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided examples of how to structure the generative process or detailed guidance on creating an effective notation table. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not provide specific suggestions or guidance on how the authors might improve the writing. The comment lacks actionable details, such as identifying specific sections that need clarification or offering tips on how to enhance the clarity of the text. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly difficult to follow or suggest specific areas for improvement. This lack of grounding and specificity makes it challenging for the authors to identify the exact parts of the paper that need attention. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to address the issue effectively. Without additional context or evidence, the authors may find it challenging to understand the exact areas of the paper that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not provide specific suggestions or guidance on how the authors might improve the clarity or structure of their writing. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes are needed to enhance the draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment explicitly identifies a specific sentence in the abstract as cumbersome and suggests that it can be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made. The authors are left with a clear understanding of what needs to be improved but are not given concrete steps on how to implement the suggested changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 1217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, which is its cumbersome nature and suggests that it can be made clearer. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning, examples, or references to support why the sentence is cumbersome or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the abstract, noting that the sentence in lines 1217 is cumbersome and suggesting that it can be made clearer. While the comment points out a potential problem, it does not provide any guidance on how to improve the clarity or what specific changes should be made. This lack of actionable feedback limits the usefulness of the comment for the authors, as it does not offer concrete steps or suggestions for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the fairness of the comparisons made between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zeroshot singleimage 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the comparison of the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, particularly in relation to the fairness of comparisons to zeroshot singleimage 3D reconstruction models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the unfairness of the comparisons, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D are unfair, particularly when compared to zeroshot singleimage 3D reconstruction models. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are unfair. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparisons made in the paper, specifically noting that the domainspecific model is trained and tested on the same dataset (Pix3D), which could lead to an unfair comparison with zeroshot singleimage 3D reconstruction models. This feedback is 3 as it points out a potential weakness in the experimental setup that could affect the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable advice, the feedback is limited in its usefulness for the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include more scenarios, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the reliance on 4 OCR QA datasets and the need for more scenarios like the LLaVA benchmark. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue with the limited evaluation and suggests including more scenarios for ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included. The claim is 3 as it points out a specific limitation in the evaluation, but it lacks detailed reasoning or examples to fully substantiate the claim. The mention of the LLaVA benchmark provides some context, but additional justification or references would be needed to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, specifically noting that it relies heavily on 4 OCR QA datasets and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for expanding the evaluation to enhance its reliability and comprehensiveness. By highlighting this area for improvement, the comment offers valuable guidance to the authors on how to strengthen their work. However, it could be more helpful if it provided additional context or examples of how the inclusion of more scenarios could impact the results or analysis. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical aspect of their evaluation that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, noting that they are unintuitive and difficult to solve. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not specify which part of the paper these tasks are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the tasks are problematic or how they could be simplified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment lacks specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. The comment also seeks clarification on whether the current formulation is the best approach. While it identifies potential issues, it lacks specific suggestions or actionable advice on how the authors might address these concerns or improve their approach. The feedback is 3 as it points out areas for improvement but does not provide detailed guidance or concrete steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide concrete steps to enhance the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the evaluation of weak supervision and provides examples of unrealistic elements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" While the comment offers detailed examples, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors are left to infer the significance of these examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, suggesting that the evaluation could be enhanced by considering the realism of the evaluated tweets. It provides detailed examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" This feedback is clear and actionable, offering the authors a concrete direction to improve the evaluation of weak supervision. However, the comment could be more helpful if it suggested specific ways to assess the realism of the tweets or provided examples of more realistic prompts. Overall, the comment is 4 as it provides valuable insights for enhancing the evaluation process."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the keypoint detection results should be included in the experiments section. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and concrete, giving the authors a clear path forward in improving their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the keypoint detection results should be included in the experiments section. However, it does not specify which part of the paper this section is currently located in, making it weakly grounded. The comment is specific in its suggestion to include the keypoint detection results in the experiments section, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the keypoint detection results should be included in the experiments section. This is a clear and actionable suggestion that provides the authors with a specific area to address in their draft. By including these results, the authors can enhance the transparency and completeness of their experimental section, allowing readers to better understand and evaluate the findings. However, the comment could be more helpful if it provided additional context or guidance on how to present these results effectively. Overall, the feedback is 4 as it directs the authors to an important aspect of their draft that needs attention, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the methodology used in the grid search for learning rate, specifically whether it is conducted on the validation set. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the grid search for learning rate is conducted on the validation set. While it identifies a potential issue or area for clarification, it does not provide any additional context, suggestions, or guidance on how the authors might address this concern. The comment lacks depth and specificity, leaving the authors without actionable feedback to improve their draft. Therefore, it is rated as 2, as it provides a starting point for the authors but does not fully support their efforts to enhance the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a potential issue with the classification of discourse relations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether they should consider revising their classification criteria. As a result, the authors are left without a clear understanding of what steps to take in response to the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a large number of discourse relations in the treebank and suggests that this might be an artifact of colloquial language or a potential issue with the classification of discourse relations. The comment provides a clear direction for the authors to consider revising their classification criteria or explaining the nature of the discourse relations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a potential issue with the classification of discourse relations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a potential issue with the classification of discourse relations. This feedback is 3 as it prompts the authors to consider whether their classification criteria are consistent with other languages in the Universal Dependencies (UD) project. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or clarify their classification. To be more helpful, the comment could provide additional context or examples to support the claim or offer potential solutions for addressing the identified problem. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalizability of the results to different groups, specifically marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the generalizability of their results. The action is implicit and somewhat vague, as the authors need to infer that they should explore the diversity of their sample and consider its implications for generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generalizability of the results to different groups, particularly marginalized groups, and prompts consideration of the diversity of the sample, including racial and economic diversity. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the results to different groups, specifically marginalized groups, and the diversity of the sample, including racial and economic diversity. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external studies that might address the issue of generalizability, making it difficult for the authors to understand the basis of the concern. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the generalizability of the results to different groups, particularly marginalized groups. It prompts the authors to consider the diversity of their sample, including racial and economic diversity, and its implications for the broader applicability of their findings. This feedback is valuable as it encourages the authors to reflect on the representativeness of their dataset and its potential limitations. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending additional analyses or data collection to enhance diversity. Overall, the comment is 3 as it identifies an important area for consideration but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the output quality is reasonable but still far from realistic, referencing recent GAN works for comparison. It suggests that there is room for improvement in result quality and mentions the limited novelty, low resolution output, and high hardware requirement as reasons for rejection. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the paper. The action is implicit and vague, as the authors are left to infer that they need to enhance the result quality and consider alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality, suggesting that it is reasonable but still far from realistic. It references recent GAN works for comparison and implies that the paper\"s results are not up to the current standard. However, the comment does not specify which part of the paper discusses the output quality or results, making it weakly grounded. The feedback is specific in identifying the need for improvement in result quality and referencing recent GAN works, but it lacks detailed guidance on how to achieve this improvement. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works for comparison. It suggests that the paper\"s results are not up to the current standard and implies that there is room for improvement. However, the comment lacks specific examples or detailed reasoning to support the claim that the output quality is not realistic. The mention of recent GAN works provides some context, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3, as it provides some support but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment acknowledges that the output quality is reasonable but still far from realistic, referencing recent GAN works for comparison. It suggests that there is room for improvement in result quality and mentions the limited novelty, low resolution output, and high hardware requirement as reasons for rejection. While the comment identifies weaknesses and provides a rationale for potential rejection, it lacks specific suggestions or actionable feedback on how the authors might address these issues or improve the paper. The feedback is 3 as it highlights areas for improvement but does not offer detailed guidance or constructive advice, leaving the authors with a general sense of what needs to be addressed but without clear steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are potentially due to subpar hyperparameters. It also questions why the authors did not extend the curve further. While the comment highlights areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly adjust their hyperparameters or extend the curve. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific results and hyperparameters, particularly mentioning the use of soft labels in the context of CRM and Cross entropy. It also questions the authors\" choice of hyperparameters and suggests that the results may be impressive due to subpar settings. However, the comment does not explicitly mention which part of the paper this discussion is related to, such as specific figures or sections. While the authors can infer that it pertains to the results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the concerns about hyperparameters and the potential need for further analysis, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive due to subpar hyperparameters. However, the comment lacks specific examples or detailed reasoning to support the claim that the hyperparameters are subpar. The mention of \"iNaturalist19\" and the suggestion that a higher beta value would be more effective provides some context, but the lack of detailed evidence or references makes the claim 3. The authors would need to investigate further to fully understand and address the concerns raised in the comment.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive due to subpar hyperparameters. It also questions why the authors did not extend the curve further. While the comment identifies potential issues with the results, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their analysis. The feedback is 3 as it points out areas for potential improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should provide more evaluation in this direction, specifically on classifying unseen words. The reviewer suggests adding translations to Figure 6 to help nonChinese speakers understand the results. While the comment implies that more evaluation is needed, it does not explicitly instruct the authors to add translations to Figure 6. The action is somewhat implicit and vague, as the authors need to infer that they should enhance the evaluation and provide translations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the addition of translations to help nonChinese speakers understand the results. This provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that more evaluation is needed, particularly on classifying unseen words. The reviewer suggests adding translations to Figure 6 to aid nonChinese speakers in understanding the results. While the comment provides a logical suggestion for enhancing the evaluation, it lacks specific examples or references to support the claim that more evaluation is necessary. The suggestion is 3, as it points out a potential area for improvement but does not fully substantiate the claim with detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the simple/traditional experiment for unseen characters is presented as an afterthought. It implies that more evaluation is needed, particularly on classifying unseen words, and suggests adding translations to Figure 6 to aid nonChinese speakers in understanding the results. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their evaluation and improving the accessibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to implement these changes effectively. Overall, the comment is 4 as it guides the authors in improving their draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the number of images in the VioT dataset, suggesting that it may be insufficient to validate the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting additional data collection or analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the number of images in the dataset is small, which could affect the validity of the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which could affect the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a potential issue with the VioT dataset, noting that it consists of only 20 images in each of the four categories. This observation is relevant as it questions the sufficiency of the dataset for validating the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern, such as recommending additional data collection or analysis. While it highlights an important aspect to consider, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, it is rated as 3, as it provides a starting point for the authors but does not fully address their needs for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and that figure captions should include additional explanations and legends, such as explaining the colors in Figure 2. However, the comment does not provide specific guidance on how to improve the explanations or what additional information should be included. While the authors can infer that they need to enhance the clarity of their derivations and figure captions, the lack of detailed instructions makes the feedback 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the difficulty in following the mathematical derivations and the lack of explanations in figure captions. It specifically mentions Figure 1 and 2, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, such as providing more intuitive explanations and additional explanations and legends for the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests that more intuitive explanations are needed. It also points out the lack of explanations in figure captions, such as the colors in Figure 2. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references limits the verifiability of the claim. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that the mathematical derivations are difficult to follow and suggesting that more intuitive explanations are needed. It also points out the lack of explanations in figure captions, such as the colors in Figure 2, and notes that Figures 1 and 2 did not contribute much to the understanding of the paper. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to enhance the clarity and comprehensiveness of the mathematical derivations and figure captions. This makes the feedback 3, as it provides a direction for improvement but does not fully empower the authors to make the necessary changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate comments. The first comment explicitly states that the text in Table 1 is too small and hard to read, providing a clear and direct action for the authors to take. The second comment mentions a missing gradient symbol in Algorithm 1, which is also an explicit action. Additionally, the comment provides references to external works, which can guide the authors in understanding the context or potential improvements. Both actions are concrete and provide specific guidance on what needs to be addressed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the small text in Table 1 and the missing gradient symbol in Algorithm 1. The references to external works are specific, providing the authors with concrete examples to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment is a factual observation about the readability of text in Table 1, which is a descriptive statement and does not contain a claim or suggestion that requires verification. The second comment mentions a missing gradient symbol in Algorithm 1, which is also a factual observation. Therefore, the overall comment is composed of factual statements, making it \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the draft: the small text in Table 1, which makes it difficult to read, and the missing gradient symbol in Algorithm 1. These are clear and actionable points that provide the authors with specific areas to address, such as improving the legibility of the table or ensuring all necessary symbols are included in the algorithm. However, the comment could be more helpful if it offered suggestions on how to improve the readability of the table or how to incorporate the missing symbol. Overall, the feedback is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific error in the equation on Line 502, suggesting that the \"+\" sign after \nu_j should be a \"\" sign. It also points out other errors in the definition of B and Line 504, specifying the necessary corrections. The comment provides clear and actionable feedback, guiding the authors on how to correct these errors. The explicit nature of the suggestions and the detailed guidance on what needs to be changed make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 502,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the exact errors in the equation, such as the incorrect signs in the definition of B and Line 504. The comment provides clear guidance on what needs to be corrected, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of observations and suggestions regarding the mathematical notation in the paper. It identifies specific errors in the equations, such as the incorrect signs in the definition of B and Line 504. These observations are based on logical reasoning and are supported by the specific notation and symbols used in the equations. However, the comment does not provide references or detailed explanations for why these corrections are necessary, which could enhance its verifiability. Therefore, the comment is 4, as it provides a clear basis for the claims but lacks full justification.", "helpfulness_rationale": "The review comment identifies specific errors in the mathematical notation of the paper, providing clear and actionable feedback. It points out the incorrect signs in the equation on Line 502 and suggests the necessary corrections in the definition of B and Line 504. This feedback is valuable as it helps the authors correct minor but important errors in their draft, ensuring the accuracy and clarity of their work. However, the comment could be more helpful if it explained the significance of these corrections or provided additional guidance on how to avoid similar errors in the future. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It also suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison, as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this alternative baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the ResNet in the experiments shares parameters between residual blocks and suggests an alternative baseline by comparing to a deeper ResNet with parameter sharing. This comparison is relevant to the discussion of ODE nets with a fixed timestep Euler integrator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison, as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment does not provide explicit evidence or references to support the claim that parameter sharing would make the ResNet equivalent to an ODE net, it does offer a logical suggestion for further exploration. The authors might need to conduct additional research or experimentation to fully verify this claim. Therefore, the comment is 3, as it provides a suggestion but lacks detailed justification or references.", "helpfulness_rationale": "The review comment raises a question about the parameter sharing in the ResNet used in the experiments, suggesting that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison. This comparison would be relevant as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might conduct this comparison or what aspects to focus on. The feedback is 3 as it points out a potential avenue for improvement but lacks depth and actionable advice, leaving the authors with a general idea but no clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the motivation are unclear or need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point challenges the claim that the crossencoder architecture \"ignores crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. It provides a counterpoint by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support the claim that the architecture is not as finegrained as implied. This makes the claim 3, as it provides a logical argument but requires more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores, which is a significant point of clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their motivation or clarify their claims. While it identifies a potential area for improvement, it does not offer actionable feedback or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work uses an antiquated GNN model and method, which impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or methods, nor are there suggestions for alternative approaches or references to more recent work. As a result, the authors are left without any actionable steps to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an antiquated GNN model and method, as well as the antiquated baseline algorithms/methods. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what specific aspects of the model or methods are outdated or how they impact the performance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an antiquated GNN model and method, which impacts the performance of the framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to more recent and effective models, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is 1, as it lacks the necessary justification to be actionable for the authors.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which is likely to impact the performance of the framework. It also points out that the baseline algorithms/methods are antiquated, which could be a concern for the authors. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations for improvement, the authors are left without a clear path forward. Therefore, the comment is 2, as it highlights a potential problem but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary modifications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the explanation provided in Figure 1, questioning the clarity of how the proposed method produces the explanation and suggesting the need for additional adhoc postanalysis to extract shared motifs. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. While the comment provides a logical reasoning for the need for additional analysis, it lacks specific examples or references to support the claim fully. The suggestion is 3, as it highlights a potential issue but does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, questioning the clarity of the explanation provided. It points out that the explanation \"mutagens contain the NO2 group\" seems to require additional adhoc postanalysis to extract shared motifs for explaining a set of instances. This feedback is 3 as it highlights a potential area of confusion and suggests that the authors might need to clarify or enhance the explanation. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or if it offered alternative ways to present the information. Overall, the comment provides some guidance but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the paper, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific instructions or suggestions makes it difficult for the authors to know exactly what changes to make. The feedback is vague and does not offer concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. It provides explicit references to specific lines and sections, such as \"Line 99, section 3.1\" and \"Line 165, section 3.4,\" which allows the authors to accurately identify the parts of the paper that need attention. Additionally, the comment highlights the need for citations and references, which is a clear and specific issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several observations and requests for clarification. It does not contain subjective opinions, judgments, or suggestions that require verification. Instead, it points out factual issues such as the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. These are straightforward observations that do not require justification beyond the information provided. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. These are important points that can help the authors improve the clarity and completeness of their work. However, the comment does not provide detailed guidance on how to address these issues or offer suggestions for improvement. While it highlights areas that need attention, it lacks actionable advice, making it 3. The authors are aware of the issues but may need additional support to effectively address them. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide explicit guidance on how to conduct such an analysis or what specific aspects should be addressed. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details or actionable steps, making it vague and 3. The authors can infer that they need to enhance their analysis, but the lack of specific guidance makes it difficult to implement the suggested improvement. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what specific aspects of the analysis could be expanded. This lack of grounding and specificity makes it difficult for the authors to identify the exact areas needing improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for a more extensive analysis, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance or examples on what aspects of the analysis could be expanded or how this could be achieved. The comment acknowledges that the paper is short, which limits the scope of the analysis, but it does not offer actionable steps or suggestions for improvement. As a result, the feedback is vague and lacks depth, making it 2 to the authors. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should include a deeper connection to metalearning and cite relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. While the comment implies that the authors should take these actions, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. However, the comment does not specify which part of the paper should include these connections or how they should be integrated. The authors can infer that it pertains to the sections discussing related work or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact sections. The comment is specific in suggesting what needs to be addressed but lacks full grounding, as it does not explicitly mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. The comment provides a logical reasoning by suggesting that these connections would enhance the paper\"s depth and relevance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to explore the suggested connections themselves to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that there is a deeper connection to metalearning, which has several approaches. It recommends citing relevant works that do not directly target continual learning but are still relevant, and it suggests linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s depth and relevance. By following this advice, the authors can significantly improve their draft by establishing a stronger connection to existing literature and demonstrating the broader applicability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback. It suggests that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. While the comment implies an action\u2014exploring different types of feedback\u2014it does not provide explicit instructions on how to implement this suggestion. The authors are left to infer that they should consider generating diverse feedback, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it identifies a potential issue but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for diversity in feedback, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. However, the comment does not provide specific examples or evidence to support the claim that the diversity is lacking. It lacks detailed reasoning or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the lack of lexical and syntactic diversity in the teacher feedback, particularly if it is autogenerated. It suggests that the authors might consider manually reviewing or generating different types of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the diversity of feedback. However, it could be more helpful if it included specific examples or guidance on how to generate diverse feedback. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This is a clear and direct action for the authors to take, as it provides specific references to compare with. The comment also specifies that these works involve training adapters on top of a welltrained multilingual pretrained model, which gives the authors a clear idea of what to look for in these comparisons. Therefore, the comment is 5, as it provides explicit and concrete guidance on how to improve the draft by including relevant comparisons.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper this recommendation pertains to, such as a section or a particular experiment. This makes it difficult for the authors to identify the exact area where this comparison should be included. The comment is specific in its suggestion to compare with these works, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the performance of the current work with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any reasoning or evidence to support why these particular works are relevant or how they might influence the current study. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how it could enhance their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation is 5 as it directs the authors to relevant literature that could enhance the comprehensiveness and impact of their study. By including these comparisons, the authors can better position their work within the existing literature and potentially identify areas for improvement or innovation. The comment is specific and provides a clear path for the authors to follow, making it 5 for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that standard deviations are not displayed, which raises uncertainty about whether the best method is truly the best or if other Random Forest (RF) configurations have performances close to it. However, the comment does not provide explicit guidance on how the authors should address this issue. It lacks concrete suggestions, such as recommending the inclusion of standard deviations or suggesting alternative ways to present the data. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises uncertainty about the reliability of the results. However, it does not specify which part of the paper lacks this information, making it weakly grounded. The comment is specific in its concern about the lack of standard deviations and their impact on the perceived reliability of the best method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper makes it difficult to determine the reliability of the best method. However, the comment does not provide any specific examples or references to support this claim, nor does it offer suggestions on how to address the issue. The lack of detailed reasoning or evidence makes it challenging for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the absence of standard deviations in the results. This omission makes it difficult for readers to assess the reliability and robustness of the best method presented. The comment highlights a potential limitation that could impact the interpretation of the results, which is important for the authors to address. However, the comment lacks specific suggestions or guidance on how to include standard deviations or present the data in a more comprehensive manner. While it points out a significant issue, the feedback could be more helpful with actionable advice. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests that the authors consider extending their approach to more general settings. While the comment implies that the authors should explore broader applicability, it does not provide explicit guidance on how to achieve this extension or what specific aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the extent of the extension required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. However, the comment does not specify which part of the paper discusses the current setting or how it could be extended. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in terms of the limitations it identifies, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point identifies specific limitations of the current setting, such as the need for knowledge of the model or access to a generative model, and the requirement for episodic problems with rewards given at the end of a task. It then suggests extending the approach to more general settings. While the comment provides a clear rationale for the limitations, it lacks specific examples or references to support the claim that these limitations are unique or restrictive. The suggestion to extend the approach is logical, but without detailed guidance on how to achieve this, the comment remains 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. This feedback is 3 as it points out a potential area for improvement and provides a clear direction for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to achieve this extension or provided examples of how to address the limitations. Overall, the comment provides a good starting point for the authors to explore broader applicability, but it lacks depth and specificity to be fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add these details but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper lacks these details or where they should be included. This makes it difficult for the authors to identify the exact sections that need revision. The comment is 1 because it does not reference specific parts of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not provide any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While this feedback is 3, it lacks specificity and does not offer detailed guidance on which parts of the paper could benefit from these details or how they should be presented. The authors are left with a general idea of what could be improved but without actionable steps to take. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to explain how they chose the value p < 0.4 in Algorithm 1. This is a direct request for clarification, providing the authors with a clear and explicit action to take. The comment does not require any inference or interpretation, making it 5. The authors know exactly what information they need to provide to address the comment, ensuring a straightforward path to improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on how the value p < 0.4 was chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a direct request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not provide any feedback or suggestions on how this choice might impact the results or the overall methodology. While it identifies a specific area that needs further explanation, it lacks depth and actionable guidance for the authors to improve their draft. Therefore, the comment is 3, as it points out a gap in the paper but does not offer comprehensive feedback or suggestions for improvement. This aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify why there are negative numbers in Figure 1 and to provide explanations or analysis for Figures 2 and 3. This feedback is clear and direct, giving the authors a specific action to take: to include explanations or analysis for the figures. The comment also specifies what needs to be addressed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" \"Figure 1,\" \"Figure 2,\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing explanations or analysis for the figures and clarifying the presence of negative numbers in Figure 1. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors need to clarify why there are negative numbers in Figure 1 and provide explanations or analysis for Figures 2 and 3. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these clarifications are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, namely, the lack of explanations or analysis for Figures 1, 2, and 3 in Section 5. It highlights a critical issue by pointing out the presence of negative numbers in Figure 1 and the need for clarification regarding the implications of Figures 2 and 3. This feedback is actionable as it provides clear guidance for the authors to address these gaps in their draft. However, the comment could be more helpful if it offered suggestions on how to provide the necessary explanations or analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It also suggests references for further reading. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to conduct the analysis or compare methods. The authors are aware of what needs to be done but may require additional information to fully implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"data augmentation method\" and \"paraphrasing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as the lack of analysis and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment further provides references for the authors to consider, making it specific and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to support the claim, such as 1 and 2, which are relevant to the topic of language models and their effectiveness. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would clarify the unique advantages of the method. While the references are a good start, the lack of specific examples or detailed analysis makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would provide clarity on the unique advantages of the method. Additionally, the comment provides references to relevant literature, which can guide the authors in expanding their analysis and understanding of the topic. This feedback is clear and actionable, offering specific suggestions for improvement that can enhance the paper\"s depth and contribution. However, it could be more helpful if it included more detailed guidance on how to conduct the analysis or compare methods. Overall, the comment is 4, as it provides valuable insights and suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an ablation study is necessary to understand the net effect of each component in the proposed model. It provides specific examples of what could be included in the ablation study, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This guidance is explicit and concrete, as it clearly outlines the actions the authors should take to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests an ablation study to understand the net effect of each component in the proposed model, specifically mentioning the use of MMD. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an ablation study to evaluate the effect of each component, but without grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study is necessary to understand the net effect of each component in the proposed model, specifically mentioning the use of MMD. However, the comment does not provide specific examples or detailed reasoning to support why an ablation study is needed or how it would improve the understanding of the model. The suggestion is vague and lacks detailed justification, making it difficult for the authors to fully grasp the need for an ablation study. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that an ablation study is necessary to understand the net effect of each component, specifically mentioning the use of MMD. It provides specific examples of what could be included in the ablation study, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is clear and actionable, offering the authors a concrete path to improve their understanding of the model\"s components and their contributions. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the ablation study effectively. Overall, the comment is 4 as it guides the authors towards a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what implications it might have for the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario in their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context where this discussion is relevant. Without specific grounding, the authors cannot confidently determine where to address this question within their draft. Additionally, the comment lacks specificity as it does not provide any guidance on why this question is important or what implications it might have for the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how this question might impact the paper or what implications it could have. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it identifies a potential area for exploration but does not offer actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the scalability of RLCD compared to RLAIF, as the advantage of RLCD diminishes when moving from 7B to 30B language models. It suggests that the authors should explore whether RLCD or RLCDRescore can scale to even larger language models. However, the comment does not provide specific guidance on how to address this issue or what aspects of scalability should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore scalability in more detail. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison between RLCD and RLAIF, specifically mentioning Tab. 2, which indicates full grounding as the authors can accurately identify the part of the paper being discussed. The comment also specifies the issue by noting that the advantage of RLCD over RLAIF diminishes as the language model size increases, and it questions whether RLCD can scale to even larger models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the language model size increases, specifically from 7B to 30B, as shown in Table 2. However, the comment does not provide any supporting evidence, such as specific data or analysis, to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this observation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of RLCD compared to RLAIF, noting that the advantage of RLCD diminishes as the language model size increases from 7B to 30B, as shown in Table 2. It raises a question about whether RLCD or RLCDRescore can scale to even larger language models, which are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential limitation in the scalability of the proposed method, prompting the authors to consider its applicability to larger models. However, the comment could be more helpful if it provided suggestions on how to address this scalability issue or explored the implications of this finding. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time. This provides a clear and direct action for the authors to take, which is to include such quantitative analysis to substantiate the claimed computational benefits. The comment is explicit and concrete, guiding the authors on exactly what needs to be added to strengthen their claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the claim of computational benefits from replacing the MAE model with a CNNbased data augmentation strategy. It also specifies what is missing, namely, the need for measurements like GPU hours, memory usage, or training time to substantiate these claims. This provides clear guidance on where the paper lacks detail and what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the claimed efficiency improvements. The comment provides a clear rationale for why such measurements are important, as they would provide concrete evidence of the computational benefits. However, the comment could be strengthened by including specific examples or references to similar studies that have used such metrics. Overall, the claim is 4 as it offers a logical reasoning and a suggestion for improvement, but it could be more robust with additional supporting evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the lack of quantitative analysis on computational gains. It highlights the importance of providing measurements such as GPU hours, memory usage, or training time to substantiate the claimed efficiency improvements in the DQ V2 model. This feedback is clear and actionable, as it guides the authors to include specific metrics that would strengthen their claims. By addressing this gap, the authors can provide a more robust evaluation of their model\"s computational efficiency. However, the comment could be more helpful if it suggested how to incorporate these measurements or provided examples of similar studies that have done so. Overall, the comment is 4, as it effectively directs the authors to improve their draft by adding quantitative analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, implying that the method is less efficient for these scenes. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the time factor in their comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of methods, specifically mentioning COLMAP and scenebyscene finetuning. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the time taken for these processes should be considered when comparing methods, indicating what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, suggesting that the method is less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, specifically mentioning the time taken for COLMAP and scenebyscene finetuning. It suggests that this time factor should be considered when comparing methods, implying that the method may be less efficient for these scenes. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it points out a relevant aspect, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should investigate the individual contributions of noise and the exponential moving average to the proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\"s performance. The comment provides a clear and explicit action for the authors to take, which is to conduct specific experiments to assess the contributions of each factor. This guidance is concrete, as it outlines a specific direction for the authors to follow to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\"s performance. However, the comment does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a method for further analysis, but without explicit grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It implies that the authors should investigate the individual contributions of each factor to the model\"s performance. However, the comment does not provide specific evidence, examples, or references to support the claim that these factors are beneficial or how they contribute to the model. Without detailed reasoning or references, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It provides a clear and actionable suggestion for further analysis, which could enhance the understanding of the model\"s performance. However, the comment could be more helpful if it included specific guidance on how to conduct these experiments or what metrics to use for evaluation. Overall, the feedback is 4 as it directs the authors towards a meaningful direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as the authors are left to infer that they should consider reporting results during learning or exploring the impact of early training. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the reporting of results and the potential impact of early training, but it lacks grounding as it does not reference specific sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The authors are left to infer the relevance of this concern, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. This feedback is 3 as it points out a potential limitation in the current reporting and encourages the authors to consider reporting results during learning. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending the inclusion of results during the learning process or exploring the impact of early training. While it prompts the authors to think about their results\" presentation, it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether they consider documents as entire sentences in the context of the DocRED dataset. It also inquires about how the authors handle concepts with multiple entity mentions referring to the same entity. These questions provide clear and direct actions for the authors to take, namely, to include this information in their manuscript. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors consider documents as entire sentences and how they handle concepts with multiple entity mentions referring to the same entity. This provides clear guidance on what information is missing from the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how the authors handle concepts with multiple entity mentions referring to the same entity in the context of the DocRED dataset. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the handling of concepts with multiple entity mentions referring to the same entity in the context of the DocRED dataset. It prompts the authors to clarify whether they consider documents as entire sentences and how they deal with such concepts. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and completeness of their manuscript. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how other studies have handled similar concepts. Overall, the comment is 4 as it identifies a gap in the manuscript and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of supervised contrastive learning. It suggests that the authors should provide additional motivations for PBSD beyond improving the discriminative power of the learned representation for tail classes. While the comment implies that the authors should clarify the motivation for PBSD, it does not provide explicit guidance on how to address this issue or what specific motivations should be discussed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their contribution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of supervised contrastive learning. It highlights the performance gain from PBSD and suggests that the paper is mostly motivated by supervised contrastive learning, questioning the need for PBSD beyond improving discriminative power for tail classes. However, the comment does not specify which part of the paper this discussion should be addressed in, making it weakly grounded. The feedback is specific in its critique of the main contribution and the need for additional motivation for PBSD, but it lacks explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of supervised contrastive learning. The reviewer notes that the performance gain is mostly from PBSD, which is motivated by supervised contrastive learning. However, the comment lacks specific examples or detailed reasoning to support the claim that the main contribution is unclear. It provides a general observation but does not offer a comprehensive explanation or evidence to substantiate the claim. As a result, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of supervised contrastive learning. It highlights that while the ablation study shows a performance gain from PBSD, the paper is mostly motivated by supervised contrastive learning. The comment suggests that the authors should provide additional motivations for PBSD beyond improving the discriminative power of the learned representation for tail classes. This feedback is 3 as it identifies a potential area for clarification and improvement, prompting the authors to revisit and possibly expand their discussion on the motivations behind PBSD. However, the comment could be more helpful if it provided specific suggestions or examples of what additional motivations might be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It specifically asks how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, and it provides a specific example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It asks if the tester immediately yields an (\u03b5, \u03b4)identity tester and provides a specific example of how it might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment does not contain an explicit claim, it poses a logical question that requires the authors to clarify their approach or provide additional details. The comment is 3 as it prompts the authors to address a specific issue but lacks detailed reasoning or examples to fully substantiate the question. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a specific question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It highlights a potential gap in the paper\"s explanation by asking how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This question prompts the authors to clarify their approach or provide additional details to address this issue. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how to resolve the issue. The feedback is 3 as it points out a potential weakness in the paper\"s methodology but does not fully support the authors in addressing it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should clarify this distribution or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the detailed distribution of the proposed dataset, indicating that it is unclear. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the problem, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed dataset, noting that the detailed distribution is unclear. However, it does not provide any suggestions or guidance on how the authors might clarify this distribution or improve the dataset\"s description. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, as it highlights a problem but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method\"s reliance on annotated labels for learning semantic tokens limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to implement this change or provide detailed guidance on how to transition to a selfsupervised approach. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for annotated labels in the proposed method, suggesting that a selfsupervised pretraining approach without annotations could be more appealing. However, it does not specify which part of the paper discusses the use of annotated labels or the proposed method, making it weakly grounded. The comment is specific in suggesting a potential improvement, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to make the change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method\"s reliance on annotated labels limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which is its reliance on annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is clear and actionable, as it points out a potential area for improvement and provides a specific direction for the authors to consider. By suggesting a selfsupervised approach, the comment offers a concrete way to enhance the applicability and versatility of the method. However, it could be more helpful if it included specific examples or guidance on how to implement a selfsupervised approach. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should expand their experimental scope to include these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on scalability. The authors can infer that it relates to the experimental results or the conclusion, but this inference is not explicit. The comment is specific in its suggestion to include more challenging tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why the authors should expand their experimental scope to include more challenging tasks. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s demonstration of the scalability of the proposed method, LFF. It suggests that the authors should expand their experimental scope to include more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids, to fully demonstrate the method\"s capabilities. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their work. However, the comment could be more helpful if it included suggestions on how to approach these more challenging tasks or what specific metrics to use for evaluation. Overall, the comment is 4 as it guides the authors towards a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the abstract should include a more detailed statement about the expressivity of the model, referencing a specific citation. Additionally, it recommends including learning curves for all experiments, at least in an appendix. These suggestions are clear and provide specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract\" part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for improvement by recommending a more detailed statement about the expressivity of the model and the inclusion of learning curves for all experiments, at least in an appendix. This provides the authors with a clear understanding of what needs to be addressed in the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific change to the abstract, recommending that it should include a more detailed statement about the expressivity of the model, referencing a specific citation. This is a clear and specific suggestion that provides a logical basis for the claim. However, the comment does not provide additional context or examples to fully substantiate the claim, such as explaining why the change in linear regions is important or how it relates to the model\"s expressivity. While the suggestion is 4, it lacks comprehensive justification, making it a 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting a more detailed statement about the model\"s expressivity and referencing a specific citation. It also recommends including learning curves for all experiments, at least in an appendix, which is a valuable suggestion for enhancing the transparency and completeness of the paper. This feedback is clear and actionable, offering the authors a straightforward way to improve their draft. However, it could be more helpful if it provided additional context or examples to further explain the importance of these changes. Overall, the comment is 4, as it guides the authors in making significant improvements to their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any explicit or implicit actions for the authors to take regarding these references. There is no guidance on how the authors should incorporate these references into their paper or what specific aspects of their work should be compared or discussed with these references. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific references, such as MISA, M2FNet, and MMDFN, which are relevant to the field of multimodal sentiment analysis. However, it does not specify which part of the paper these references are relevant to, making it difficult for the authors to identify the exact section that needs attention. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline for crosssensory interaction, but it does not provide specific feedback on how this baseline could be improved or integrated into the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered out of fashion. However, the comment does not provide specific evidence or reasoning to support the claim that MULT is outdated or why it is considered the only relevant baseline. Without detailed justification or references, the claim remains 1, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a list of references to other works in the field of multimodal sentiment analysis, including MISA, M2FNet, and MMDFN. However, it does not offer any specific feedback or suggestions on how these references could be integrated into the paper or what aspects of the work should be compared or discussed with these references. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline for crosssensory interaction, but it does not provide further explanation or guidance on why this is the case or how the authors might address this issue. Without actionable feedback or detailed suggestions, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a major issue with the comparison against other models in the experiments, specifically noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It explicitly instructs the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. The comment provides a clear and concrete action for the authors to take, which is to include the ranks for all models and compare them with the same number of parameters. This guidance is explicit and detailed, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the number of model parameters,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. The comment also provides a concrete suggestion for improvement, instructing the authors to compare the tensor completion results for all models while ensuring they have the same number of parameters. This detailed guidance helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all models. This makes it impossible to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models while ensuring they have the same number of model parameters. The comment provides a logical reasoning for the claim, suggesting that having the same number of parameters is crucial for a fair comparison. However, it lacks specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a clear rationale but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the comparison against other models in the experiments, noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It provides a clear and actionable suggestion for improvement, instructing the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. This feedback is detailed and provides a specific direction for the authors to enhance the clarity and fairness of their experimental comparisons. However, the comment could be more helpful if it included additional guidance on how to compute the number of model parameters or provided examples of how to implement this suggestion. Overall, the comment is 4 as it offers clear and actionable advice for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module and suggests that it appears different in the two versions, despite the text implying otherwise. It also notes that Figure 4 is confusing in the 0/50 latency range due to overlapping symbols. Additionally, it mentions minor issues with the text, such as a problem on page 4 after equation. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the normalization module, suggesting that it appears different in the two versions, but the text implies otherwise. It also mentions specific issues with Figure 4, particularly the confusing symbols in the 0/50 latency range. Additionally, it points out minor problems with the text, such as a concern on page 4 after equation. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the normalization module and Figure 4. The comment is specific in detailing the issues with the normalization module and Figure 4, but it lacks explicit references to sections, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the normalization module and its apparent differences between two versions, suggesting that the text implies otherwise. It also notes that Figure 4 is confusing due to overlapping symbols in the specified latency range. The comment provides specific examples of issues with the text and figure, which makes the claims 3. However, the comment lacks detailed reasoning or references to support the claim about the normalization module\"s differences, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including concerns about the normalization module and its apparent differences between two versions. It also points out a confusing aspect in Figure 4, particularly in the 0/50 latency range where the chosen symbols overlap. Additionally, it mentions minor problems with the text, such as an issue on page 4 after equation. While the comment provides clear and actionable feedback on these specific areas, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the normalization module or figure. Overall, the comment is 4 as it directs the authors\" attention to critical areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide explicit guidance on how the authors should address this issue or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"observation\" and the \"theoretical part\" of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the lack of detail on how the proposed algorithm removes subdivision splines and whether it incurs extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific examples or references to support the claim that the algorithm lacks detail or incurs extra computation cost. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional details are needed. The feedback is 3 as it highlights an area that requires further clarification, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that W1 and W2 are not defined in the paper, suggesting that they might denote the Encoder and the Decoder network. It also mentions that W and V are not defined in Eq. 3, which is similar to the issue with W1 and W2. However, the comment does not provide explicit instructions on how the authors should define these terms or where they should be defined. The actions are implicit and somewhat vague, as the authors need to infer that they should define these terms in the appropriate sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides explicit references to page 3, line A4, and Eq. 3, allowing the authors to accurately identify the parts of the paper being addressed. This level of detail ensures full grounding. Additionally, the comment specifies what needs to be addressed, namely the need to define these terms, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that W1 and W2 are not defined in the paper, and it suggests that they might denote the Encoder and the Decoder network. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides clear and actionable feedback by suggesting that these terms might denote the Encoder and the Decoder network, which could help the authors clarify their notation. However, the comment could be more helpful if it offered suggestions on how to define these terms or where they should be defined in the paper. Overall, the comment is 4 as it directs the authors to address a critical issue in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore the impact of this process on performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the process and its potential impact on performance, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance and asks for clarification. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to enhance their draft. The feedback is 3 as it prompts the authors to consider the impact of their current approach, but it does not provide detailed or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed approach on new patients and old patients separately, given the possibility of patients being firsttime visitors without historical reports. This feedback is explicit and provides a clear action for the authors to take, which is to conduct separate evaluations for new and old patients. The comment is concrete, as it specifies the exact action needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the proposed approach on new patients and old patients separately, particularly in cases where patients are firsttime visitors without historical reports. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, table, or figure. The authors might infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in its suggestion to evaluate the approach on new and old patients, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the proposed approach on new patients and old patients separately, particularly in cases where patients are firsttime visitors without historical reports. However, the comment does not provide any reasoning, examples, or references to support why this evaluation is necessary or how it would impact the study. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on new patients and old patients separately, particularly in cases where patients are firsttime visitors without historical reports. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their evaluation. By addressing this suggestion, the authors can gain a better understanding of how their approach performs across different patient demographics, which is crucial for the robustness and generalizability of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct these evaluations or what specific metrics to consider. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis of this training dynamics would strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis would strengthen the paper. However, the comment does not provide specific reasoning or evidence to support why this analysis is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of indepth analysis in the paper, specifically questioning why inverse scaling occurs over compute. It suggests that providing an analysis of this training dynamics would significantly strengthen the paper. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects should be included. The feedback is 3 as it points out a critical gap in the paper\"s analysis but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multihead attention. It also asks for clarification on the split arrow in Figure 2 and whether the same vectors are used for keys and values. While the comment does not explicitly instruct the authors to provide these definitions, it clearly indicates what information is missing and how it could be improved. The authors can infer that they need to clarify these details to enhance the readers\" understanding. However, the comment lacks explicit instructions on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the split arrow in the figure and the lack of mathematical definition for multihead attention. The comment is specific in detailing what needs to be addressed, such as clarifying the use of the same vectors for keys and values. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multihead attention. It also asks for clarification on the split arrow in Figure 2. While the comment identifies areas where the paper could be improved, it does not provide specific examples or references to support the claim that the lack of mathematical definition is problematic. The questions are logical and seek clarification, but without additional context or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the lack of mathematical definition in the architectural details, particularly regarding multihead attention. It provides a clear and actionable suggestion by asking for clarification on the split arrow in Figure 2 and whether the same vectors are used for keys and values. This feedback is valuable as it guides the authors to enhance the clarity and understanding of their work for readers. However, the comment could be more helpful if it offered additional suggestions or examples of how to provide this mathematical definition. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider a more complex setting where the policy is not fixed, which would allow them to compare with a reinforcement learning algorithm baseline. While the comment implies that the authors should explore a more challenging scenario, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for a more complex setting, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring a more complex setting where the policy is not fixed, which would allow the authors to compare with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider a more complex setting, but without grounding, the authors may struggle to identify the exact section where this suggestion is relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. However, the comment does not provide specific examples or references to support the claim that a more complex setting would be beneficial or how it would improve the comparison with reinforcement learning algorithms. The suggestion lacks detailed reasoning or evidence to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. This suggestion could be valuable as it encourages the authors to explore a more challenging scenario that would allow them to compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the policy should be varied to achieve a more complex setting. While it provides a direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might expand the scope of their work or what specific areas they should explore to enhance applicability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this critique pertains to, such as a particular section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s focus on explaining multitask models limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on explaining multitask models, suggesting that this focus may limit the applicability of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA for online problems from 1 and DASHAMVR from 2. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the literature review. The action is implicit and vague, as the authors are left to infer that they need to include these papers in the literature review. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the literature review, mentioning that it ignores several papers that are relevant and suggesting that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment also includes a question, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA for online problems from 1 and DASHAMVR from 2. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide specific examples or detailed reasoning to support why these papers should be included or why they are relevant. The mention of \"See Question\" implies that further explanation is needed, but it is not provided in the comment itself. This lack of detailed justification makes the claim 3, as the authors would need to seek additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It provides examples of papers, VRMARINA from 1 and DASHAMVR from 2, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment also includes a question, suggesting that the authors should consider including these papers in their literature review. However, the comment lacks detailed guidance on how to integrate these papers or what specific aspects of the literature review should be revised. While it highlights an important oversight, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, while the second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions provide clear guidance for the authors to consider, as they are asking for specific information or analyses that could enhance the paper. However, the questions do not explicitly instruct the authors on how to address these points, such as by conducting additional experiments or providing detailed explanations. The actions are implicit but concrete, as the authors know what information is needed to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment consists of two questions, one about additional insights into modest performance gains on the Clothing1M dataset and the other about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. While the questions are specific in their inquiries, they do not provide explicit references to specific sections of the paper where these issues might be discussed. The authors can infer that the questions relate to the results or discussion sections, but they cannot pinpoint exact parts. Therefore, the comment is weakly grounded as it does not specify the exact sections being addressed, but it is specific in its requests for additional insights and performance evaluations. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of two questions seeking additional insights and performance evaluations. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, which could help the authors better understand and explain their results. The second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix, which could provide a broader context for the algorithm\"s capabilities. While the questions are clear and provide areas for further exploration, they do not offer specific guidance or suggestions on how to address these points. The feedback is 3 as it prompts the authors to consider additional analyses or comparisons, but it lacks depth and actionable advice, leaving the authors with a general direction to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. While the comment implies that these experiments are necessary to provide a more comprehensive benchmark, it does not explicitly instruct the authors to perform these additional experiments or provide guidance on how to integrate them into the study. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack specific instructions on how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. However, it does not specify which part of the paper discusses the current experiments on T5, PaLM, and GPT series LLMs, making it weakly grounded. The comment is specific in suggesting additional experiments to include, but without explicit references to the current experiments, the authors may find it challenging to pinpoint the exact sections that need further exploration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. However, the comment does not provide any reasoning, examples, or references to support why these specific LLMs are more appropriate or why they should be included. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the current experimental setup, specifically suggesting that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, which are not included in the current set of experiments. This feedback is 3 as it points out a gap in the study that could enhance the comprehensiveness of the results. However, the comment lacks specific guidance on how to integrate these additional experiments or what specific aspects of the experiments should be expanded upon. To be more helpful, the comment could provide more detailed suggestions or examples of how these additional experiments could be conducted or what specific insights they might yield. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper does not describe the hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the lack of description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the hyperparameters and evaluation, providing clear guidance on how to improve the paper. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not describe the hyperparameters used by each defense nor how they are derived. It suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. While the comment identifies a potential issue with the paper, it lacks specific examples or references to support the claim that the hyperparameters are not described or how the evaluation could be improved. This makes the claim 3, as the authors would need to infer the extent of the issue and how to address it based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not describe the hyperparameters used by each defense nor how they are derived. This is a critical aspect of the evaluation process, as hyperparameters can significantly impact the performance of the defenses. The comment also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific area to address and a method to improve their evaluation. However, the comment could be more helpful if it offered additional guidance on how to optimize hyperparameters or what specific aspects of the evaluation should be considered. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers a constructive suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate different pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling and suggests considering other pooling strategies. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of mean pooling and suggests considering other pooling strategies. It does not contain any subjective opinions, claims, or suggestions that require verification. Instead, it is a request for clarification or further explanation, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how they might be implemented. The comment lacks depth and actionable advice, leaving the authors with a general idea of what to consider but without concrete steps to take. Therefore, it is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is an explicit suggestion that provides a clear action for the authors to take, as it specifies what additional information should be included in the table. The comment is concrete, as it gives a specific direction on how to enhance the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular enhancement, namely comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries. This provides clear guidance on what needs to be added to improve the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is a logical suggestion that aligns with the goal of providing a comprehensive comparison. However, the comment does not provide specific examples or references to support why this comparison is necessary or how it would enhance the table. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of data in Table 3. It suggests that in addition to the number of queries, the authors should also compare the real search cost, such as the number of GPU days. This feedback is actionable and provides a clear direction for enhancing the table\"s content and analysis. By following this suggestion, the authors can make their results more comprehensive and meaningful. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the interpretation of the results. Overall, the comment is 4 as it offers a clear and actionable improvement to the draft, but it could be more comprehensive with additional context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This request provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"training details\" and specifically asks about the pretraining of the VQGAN and its training on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what part of the paper needs clarification. The comment is specific because it identifies the exact details that are missing, allowing the authors to address the issue directly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on specific training details, specifically whether the VQGAN is pretrained or trained on a particular dataset. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on a specific dataset. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or emphasized its importance. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods (DualIS and DualDIS) regarding their performance on crossmodel retrieval tasks, particularly in the MSVD dataset (Table 3). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the performance of their methods. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed methods (DualIS and DualDIS) on crossmodel retrieval tasks, specifically mentioning the MSVD dataset (Table 3). This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights a particular issue with the methods\" performance, namely the minor improvements observed in the MSVD dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods (DualIS and DualDIS) are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements observed in the MSVD dataset (Table 3). However, the comment lacks specific examples or detailed reasoning to support this claim. The mention of \"minor improvements\" is not quantified or contextualized, making it difficult for the authors to understand the extent of the issue or how to address it. Without additional evidence or analysis, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods (DualIS and DualDIS) by noting that they are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements observed in the MSVD dataset (Table 3). This feedback is 3 as it highlights a potential limitation of the methods, which could guide the authors in revising or expanding their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the performance of their methods. To be more helpful, the comment could include additional context, examples, or recommendations for enhancing the methods\" generality. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors should investigate or establish this relationship, nor are there suggestions for additional experiments or analyses that could be conducted. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the study, specifically mentioning that the relationship between the top selected patches and the disease is not yet established. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the missing relationship, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, specifically pointing out that the relationship between the top selected patches and the disease is not yet established. This feedback is clear and actionable, as it highlights a critical area that needs further investigation or clarification. However, the comment could be more helpful if it provided suggestions on how the authors might explore or establish this relationship, such as through additional experiments or analyses. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide explicit guidance on how the authors should address this issue or improve the performance of FedSP. The comment lacks concrete suggestions or actions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of FedSP in Tables 1 and 2, suggesting that the theme of the paper is mainly about FedSP. However, it does not specify which part of the paper this theme is discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue with the performance of FedSP, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper might be mainly about FedSP. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or improve the performance of FedSP. Without actionable feedback or suggestions, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is 2, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify what Omega is and to be more explicit about the link function and the theorem in 32 that provides the regret guarantee. These requests are direct and specific, providing clear actions for the authors to take. The comment also suggests that the OMD family of algorithms is mentioned, which adds context to the request. Therefore, the comment is 5, as it provides explicit and concrete guidance on how the authors can improve their draft by addressing these specific points.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying what Omega is, being more explicit about the link function, and specifying the theorem in 32 for the regret guarantee. This provides clear guidance on how the authors can improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions asking for clarification on specific aspects of the paper, such as what Omega is, the link function, and the theorem in 32 that provides the regret guarantee. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the authors can improve their draft. It points out the need to clarify what Omega is and provides additional details about the OMD family of algorithms, suggesting that the authors be more explicit. Additionally, it asks about the link function and references a specific theorem in 32 for the regret guarantee, which helps the authors understand where they might need to provide more information or context. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how to address them. Overall, the feedback is clear and actionable, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their models. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the absence of a Markovian state in the learning process, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the models being learned directly from pixels without a Markovian state. This is a critical observation that could impact the validity and effectiveness of the models. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without additional context or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed feedback or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a question about a specific practice mentioned in Example 2. The reviewer is surprised by the mention of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF). They request the authors to provide references to support this approach. While the comment identifies a specific point of confusion and suggests a need for references, it does not explicitly instruct the authors to include these references or explain the reasoning behind the approach. The action is implicit and somewhat vague, as the authors need to infer that they should provide references to clarify the approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular practice mentioned in the example, namely the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF. The reviewer questions the commonality of this approach and requests references to support it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about a specific practice mentioned in Example 2, questioning the commonality of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF). The reviewer acknowledges the usefulness of the sequence example but expresses surprise at the mention of this particular approach. However, the comment does not provide any supporting evidence, references, or logical reasoning to substantiate the claim or question. Without additional context or references, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a specific question about a particular practice mentioned in Example 2. The reviewer is surprised by the mention of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of Conditional Random Fields (CRF). They request the authors to provide references to support this approach. This feedback is 3 as it identifies a potential area of confusion and suggests a need for additional references or clarification. However, it could be more helpful if it included specific suggestions on how to address the confusion or provide references. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two actions: changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections while briefly mentioning the metrics in the captions of the tables. These suggestions are explicit and provide clear guidance on how the authors can improve their draft. The first action is concrete, as it specifies what needs to be changed, and the second action is also concrete, as it outlines how the metrics should be integrated into the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, which implies that the authors should consider renaming the section and possibly revising the content. However, it does not specify which sections or parts of the paper are being addressed, making it weakly grounded. The comment is specific in suggesting changes to the terminology and structure of the paper, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, suggesting that the metrics are wellknown and standard practice. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the metrics are indeed wellknown and standard. The authors would need to verify this themselves or seek additional information to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting a change in terminology and the removal of sections, which could improve the clarity and organization of the paper. It also offers a specific suggestion to briefly mention the metrics in the captions of the tables, aligning with common practices. This feedback is clear and provides concrete steps for the authors to enhance their draft, making it 4. However, it could be more helpful if it included additional context or examples to fully support the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that realizing efficiency gains on GPU is a common challenge in pruning work, but it does not provide any specific guidance or suggestions for addressing this issue. It lacks explicit or implicit actions for the authors to take, such as recommending alternative approaches or providing examples of successful implementations. Without actionable advice or direction, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. However, it does not specify which part of the paper this observation pertains to, nor does it provide any specific suggestions or guidance on how the authors might address this issue. Without explicit references to sections or specific areas of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what the authors should do to overcome this challenge. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. While it identifies a relevant issue, it lacks actionable feedback or suggestions for the authors to address this challenge. Without specific guidance or examples of how the authors might overcome this limitation, the comment provides minimal value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights a concern but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. While the comment identifies a potential issue with the evaluation, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for improvement, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem addressed by 5. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the evaluation and the potential unfairness of the comparison, but it lacks grounding as it does not reference a specific section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the evaluation being conducted only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate why the evaluation is not convincing or why the comparison with 5 is unfair. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. This feedback highlights an important aspect that the authors should consider when evaluating their method, specifically the need for more comprehensive evaluation on realworld data to ensure the robustness of their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional evaluation on realworld datasets or suggesting ways to adapt the comparison to a fairer basis. While it points out a critical area for improvement, the feedback could be more helpful with actionable advice. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment implies that conducting this experiment could strengthen the paper, but it does not explicitly instruct the authors to perform the experiment. The action is implicit and somewhat vague, as the authors need to infer that they should consider conducting the experiment to enhance the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in questioning the impact of the number of bits in logits on robustness, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external works that could validate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment provides a potential area for further exploration that could strengthen the paper, but it lacks specific guidance or suggestions on how to conduct the experiment or what results to expect. While it identifies a potential avenue for improvement, the feedback is 3 as it prompts the authors to consider additional experiments but does not offer detailed advice on how to implement them. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which gives the authors a clear direction on how to address the issue. This level of specificity and directness makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the concept of meta solvers and their relationship to centralized RL, specifically mentioning the need for clarification. It provides a reference to a specific paper, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which helps the authors identify the part of the paper where this clarification is needed. This makes the comment fully grounded, as the authors can accurately pinpoint the section being addressed. The comment is also specific because it clearly specifies what needs to be clarified, namely the difference between meta solvers and centralized RL, where agents share weights. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which supports the claim by offering a comparison with a related work. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by elaborating on the specific aspects of the meta solvers that are centralized and how they differ from centralized RL with shared weights. Despite this, the reference to a relevant paper and the logical reasoning provided make the claim 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which helps the authors clarify the concept and understand the context better. This feedback is clear and actionable, as it guides the authors to clarify a potentially confusing aspect of their work. However, the comment could be more helpful if it offered suggestions on how to present this distinction more clearly in the paper. Overall, the comment is 4 as it provides a specific direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. While the action is explicit, it is somewhat vague because it does not specify which part of the paper this definition appears in or how the examples should be structured. The authors know they need to provide examples, but the comment lacks detailed guidance on how to do so effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. However, the comment does not provide specific examples or detailed reasoning to support why the notation is unclear or how examples could improve understanding. This lack of detailed justification makes the claim 3, as the authors would need to infer the nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used to define M_T, specifically noting that it seems to be defined over the probabilities of atomic events. The reviewer suggests that the notation is not clear and proposes providing examples to clarify this concept. This feedback is clear and actionable, as it directs the authors to improve the clarity of their notation and provides a specific suggestion for enhancing the draft. However, the comment could be more helpful if it offered additional guidance on how to structure the examples or what aspects of the notation are particularly unclear. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference between detecting \"just\" the long one. While the comment raises a valid point about the purpose of detecting both entities, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the purpose of detecting both entities or provide a rationale for including both in the example. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks about the difference to \"just\" knowing the long one. This provides clear guidance on what aspect of the example needs further explanation or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks about the difference between detecting \"just\" the long one. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with a general question that does not offer a clear path for improvement. Therefore, it is rated as 2, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any explicit or implicit action for the authors to take. It lacks guidance on how the authors should address this issue or what changes might be necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the theorem, particularly regarding the assumption of a separate node with 0 neighbors. The reviewer points out that the upper bound in this case would be 0, which is not true, and asks for an explanation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. The reviewer points out that the upper bound in this case would be 0, which is not true, and asks for an explanation. While the comment identifies a potential issue, it lacks specific reasoning or evidence to fully substantiate the claim. The authors are left to infer the nature of the exception and how to address it, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about Theorem 1, pointing out a potential issue with the assumption of a separate node with 0 neighbors. It highlights that the upper bound in this case would be 0, which is not true, and asks for an explanation. This feedback is clear and actionable, as it directs the authors to address a specific weakness in their theoretical framework. By identifying this issue, the comment provides valuable guidance for improving the draft, making it 4. However, it could be more helpful if it offered suggestions on how to resolve the issue or further context to support the explanation. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a gap in the analysis regarding the handling of rumors generated by GPT and suggests that further analysis or solutions should be proposed. It questions why GPTgenerated Rumor is closer to Natural Rumor in terms of detectability, despite being written by humans. However, the comment does not provide specific guidance or suggestions on how to address this issue or what kind of analysis should be conducted. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is 3, as it identifies a gap but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why GPTgenerated Rumor is closer to Natural Rumor in terms of detectability, despite being written by humans. The comment provides a clear direction for further analysis or solutions, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting rumors generated by GPT compared to natural rumors. It suggests that since artificial rumors are written by humans, they should be about the same difficulty as natural rumors, but the experimental results show otherwise. The comment questions the logic behind this discrepancy and implies that further analysis or solutions should be proposed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to conduct additional analysis or provide more detailed reasoning to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the analysis regarding the handling of rumors generated by GPT, specifically questioning why GPTgenerated Rumor is closer to Natural Rumor in terms of detectability. It points out that artificial rumors are written by humans and should be about the same difficulty as natural rumors, but the experimental results suggest otherwise. This feedback is 3 as it highlights an area for further exploration and analysis, prompting the authors to consider additional factors or methodologies that could explain the observed results. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue or what kind of analysis should be conducted. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. While it identifies a potential issue with the technical contribution, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details or actionable steps for the authors to take, such as recommending specific changes or improvements to the content. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This feedback is 3 as it points out a potential area for improvement in the paper\"s technical contribution. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and improve upon this aspect of their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. It implies that using various probability mass functions would add depth to the experimental setting. However, the comment does not provide explicit guidance or concrete steps on how the authors should implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the probability mass function in MixBoost, specifically mentioning that it is set to a quasiuniform distribution with only one parameter. It suggests that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is not wellsuited or that using various probability mass functions would be beneficial. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the probability mass function should be considered individually for each learner class, even in the case of BDT of different depths. This feedback implies that using various probability mass functions could add depth to the experimental setting. However, the comment lacks specificity and does not provide detailed guidance on how the authors might implement this suggestion or what specific probability mass functions could be explored. While it points out a potential area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or whether they should consider abstention rates when comparing model accuracies. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, it does not specify which part of the paper this question pertains to, such as a specific section or result. The authors may infer that it relates to the comparison of model accuracies or results, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the comparison are unfair or how the authors should address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, due to its high percentage of abstention. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or improve their analysis. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss connections with a specific reference, a, which is relevant to their topic. It provides a clear action by suggesting that the authors should address the connections with a, which uses supervised learning in QBF solving. This guidance is concrete and provides a direct path for the authors to improve their draft by incorporating relevant references and discussions. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting a discussion of connections with reference a, which uses supervised learning in QBF solving. This provides clear guidance on what the authors should include in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references provided are relevant to the topic and suggests discussing connections with a specific reference, a. However, the comment does not provide detailed reasoning or evidence to support why these connections are important or how they relate to the authors\" work. The mention of a provides some context, but without further elaboration, the claim remains 3. The authors would need to investigate the reference a to fully understand the relevance and potential connections. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a missing reference that is relevant to the topic, specifically mentioning a as a potential connection. It suggests that the authors discuss the connections with this reference, which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to a specific area for improvement by highlighting a relevant reference and suggesting a potential connection. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this reference into the paper. Overall, the comment is 4 as it provides a clear direction for enhancing the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment implies that the authors should consider exploring alternative relationships and provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and explain alternative relationships. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the exploration of alternative relationships and the explanation of the mono tonic relationship. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. The comment provides a reference to a previous work, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with HypernetworksC//International Conference on Learning Representations. 2020,\" which could be used to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The addition of the reference provides some support, but the lack of detailed explanation or examples limits the thoroughness of the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to explore alternative relationships or explain the mono tonic relationship. The reference provided is relevant, but the comment could be more helpful if it included detailed reasoning or examples to support the suggestion. Overall, the comment is 3 as it points out an area for further exploration but does not fully guide the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or evidence regarding privacy preservation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the privacypreserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. It suggests that one traffic signal knowing the color of the next one could be a bad example of an application of federated learning. However, the comment does not specify which part of the paper this discussion pertains to, making it weakly grounded. The authors might infer that it relates to the privacy discussion or the application of federated learning in traffic signal control, but this is not explicit. The comment is specific in its questions about privacy and the application of federated learning, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. It suggests that one traffic signal knowing the color of the next one could be a bad example of an application of federated learning. However, the comment does not provide specific evidence, examples, or references to support these claims. The reasoning is based on general observations and assumptions, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises important questions about the privacypreserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example of an application of federated learning. This feedback is 3 as it prompts the authors to consider and address potential privacy concerns in their approach. However, the comment lacks specific suggestions or guidance on how to improve the privacy aspect or address the concerns raised. While it highlights an important area for consideration, it does not provide detailed actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions that the hyperlinks for footnotes 3 and 4 do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and correct the hyperlinks. The comment is explicit and concrete, giving the authors a specific task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is specific because it clearly identifies the issue with the hyperlinks not working, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the nonfunctioning of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a straightforward statement of a technical issue, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable feedback that directly impacts the usability and accessibility of the paper. By pointing out this technical issue, the authors are given a straightforward task to address, which is to verify and correct the hyperlinks. This feedback is helpful as it provides a concrete step for improvement, making it 4. However, it could be more helpful if it included suggestions on how to resolve the issue or provided examples of how to fix it. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It specifically mentions the need for a better formalization of the architecture in section 2 and points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to revise the discussion or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer the need for clarification but lack detailed guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, indicating that it is currently unclear. It specifies that a better formalization of the architecture in section 2 would be beneficial, and it points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. This provides some level of grounding as it mentions specific sections and elements of the paper, but it does not explicitly name them, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the architecture and the figure, which helps the authors understand the issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific example by mentioning section 2 and the need for a better formalization of the architecture. The comment also points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. This feedback is 3 as it provides a specific example of an unclear section and highlights a potential issue with the figure. However, it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific example by mentioning section 2 and the need for a better formalization of the architecture. Additionally, it points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. This feedback is clear and actionable, as it directs the authors to improve the clarity of their discussion and provides a specific area for revision. However, the comment could be more helpful if it offered suggestions on how to clarify the architecture or the figure. Overall, the comment is 4 as it provides valuable insights for improving the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to start the section with the final paragraph, which is said to clarify the description of the neural network. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is specific and concrete, guiding the authors on how to improve the clarity of their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the description of the neural network is hard to understand and suggests starting the section with the final paragraph for clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand, but it does not provide any specific examples, reasoning, or references to support this claim. The suggestion to start the section with the final paragraph implies that the later part of the section clarifies the description, but without further explanation, the authors may not fully understand the basis of the critique. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the neural network, noting that it is hard to understand. It provides a clear suggestion to start the section with the final paragraph, which is said to clarify the description. This feedback is actionable and provides a direct way for the authors to improve the clarity of their draft. However, the comment could be more helpful if it offered additional guidance on how to clarify the description or what aspects of the neural network are particularly confusing. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and offers a concrete suggestion. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of training the model with attentionbased encdec training instead of CTC loss. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not specify which part of the paper discusses the model\"s limitations or the training process, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to the relevant sections, the authors may struggle to pinpoint where to address this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this alternative might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on why this alternative might be beneficial or how it could be implemented. The comment is 3 as it prompts the authors to consider an alternative training method, but it does not offer actionable advice or detailed reasoning, leaving the authors with limited guidance on how to address this suggestion. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment does not explicitly instruct the authors to include these methods or how to integrate them into their work. While the suggestion is clear, it lacks concrete guidance on how to implement the changes, making it 3.", "grounding_specificity_rationale": "The comment addresses the use of naive attack methods and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, it does not specify which part of the paper discusses the attack methods, making it weakly grounded. The comment is specific in suggesting alternative attack methods and references, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment lacks detailed reasoning or evidence to support why the current attack methods are naive or why other methods should be considered. The suggestion to check specific papers is a step towards justification but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for the authors to explore but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the attack methods used are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration, which is a valuable suggestion for the authors to enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it offered more detailed guidance on how to integrate these methods or what specific aspects of the current methods are considered naive. Despite this, the feedback is 4 as it directs the authors towards potential improvements in their methodology."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider to improve the image quality. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the impact of mitigation methods on the image generation capabilities of diffusion models, specifically mentioning that it can lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the effect of the mitigation methods on image quality, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the mitigation methods used in the paper, specifically noting that they affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the image quality. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential problem but does not offer meaningful assistance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what aspects of the paper could be revised in response. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, which is a clear issue for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or context to explain why this might be surprising or how it relates to the paper\"s content. Without any justification or references, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as depicted in Figure 1. However, it does not provide any context, explanation, or suggestions for why this might be surprising or how it relates to the paper\"s content. Without additional information or guidance, the authors are left without a clear understanding of what aspects of the paper need improvement or clarification. As a result, the comment is not helpful, as it lacks actionable feedback or insights that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that using the minimal kmeans objective over multiple seeds might be more reasonable than the average of kmeans objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. While the suggestion is clear, the lack of explicit action and detailed instructions makes it 3. The authors can infer that they should consider using the minimal kmeans objective, but the comment does not specify how to do so or why it is more reasonable. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests a minor change in the methodology, specifically recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It provides references to support this suggestion, which is a valuable addition. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines the change that could be made to improve the methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a minor change in methodology, recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. These references provide a logical basis for the suggestion, as they discuss the properties of kmeans objectives and their implications. However, the comment could be strengthened by including specific examples or further explanation of why the minimal kmeans objective is more reasonable. Overall, the claim is 4 due to the references provided, but it could be more robust with additional details or examples.", "helpfulness_rationale": "The review comment provides a minor suggestion for improving the methodology by recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It supports this suggestion with references to relevant literature, specifically Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja, which provide a logical basis for the claim. This feedback is actionable as it offers a specific change that could enhance the robustness and reliability of the methodology. However, the comment could be more helpful if it included a detailed explanation of why the minimal kmeans objective is more reasonable or how it could impact the results. Overall, the comment is 4 as it provides a clear suggestion for improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises two concerns: (1) the apparent contradiction between the independence of temperature calibration and uncertainty calibration, and (2) the confusion regarding the role of the training regularization term (H) and its relation to temperature calibration. The reviewer explicitly asks the authors to clarify this point and questions the motivation for reducing entropy, which is against the paper\"s goal of calibrating the networks. These comments provide clear and specific actions for the authors to take, such as clarifying the relationship between temperature calibration and uncertainty calibration, and addressing the contradiction in the paper\"s motivation. The feedback is concrete and actionable, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) where the confusion arises, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the apparent contradiction between temperature calibration and uncertainty calibration, as well as the confusion regarding the role of the training regularization term (H) and its relation to temperature calibration. The comment is specific in detailing what needs to be clarified or addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the apparent contradiction between the independence of temperature calibration and uncertainty calibration, as well as the role of the training regularization term (H) and its relation to temperature calibration. The reviewer provides a logical reasoning by pointing out the confusion in lines 155160, where it appears that both are required for uncertainty calibration. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a confusing aspect of the paper regarding the relationship between temperature calibration and uncertainty calibration. It points out a contradiction in the text, where it appears that temperature calibration is independent of uncertainty calibration but is required for calibration in another part of the paper. The reviewer also questions the motivation for reducing entropy, which is against the paper\"s goal of calibrating the networks. By raising these points and asking for clarification, the comment provides clear and actionable feedback that can help the authors improve the clarity and coherence of their draft. The feedback is specific and constructive, offering a path for the authors to enhance their paper\"s clarity and address potential inconsistencies. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss the relationship, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the reference and discuss the context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not specify which part of the paper should include this reference or discuss the context, making it weakly grounded. The authors can infer that it relates to the introduction or related work section, but this is not explicitly mentioned. The comment is specific in suggesting the need for context and the importance of including the reference, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is closely related to the idea of unrolling, as proposed in \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" However, the comment does not provide specific examples or detailed reasoning to support why this reference is important or how it relates to the paper. The claim is 3 as it highlights a potential gap in the paper\"s context, but it lacks the depth and specificity needed for a 5 comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context and situate the paper within the relevant literature. This feedback is clear and actionable, as it directs the authors to include a crucial reference and encourages them to discuss the context of their work. However, the comment could be more helpful if it provided specific guidance on how to discuss the similarities and differences or suggested additional references to consider. Overall, the comment is 4 as it highlights a significant omission and offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain the linear program in Theorem 3 intuitively, specifically asking for clarification on the objective and constraints. This feedback is clear and direct, providing a specific action for the authors to take. The comment also highlights the importance of this explanation, noting that it is a main theorem. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for an intuitive explanation of the linear program, including the objective and constraints. This provides clear guidance on what the authors should focus on improving. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained intuitively, specifically asking for clarification on the objective and constraints. This is a request for clarification rather than a claim or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for an intuitive explanation of the linear program in Theorem 3. It highlights the importance of this theorem by noting that it is a main result, and it provides a clear and actionable suggestion for the authors to include a more accessible explanation of the objective and constraints. This feedback is valuable as it guides the authors in enhancing the clarity and understanding of their work for the reader. However, the comment could be more helpful if it offered additional suggestions or examples of how to achieve this intuitive explanation. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about Algorithm 2, specifically questioning whether it is possible to update one node based on results from multiple connected nodes. It also notes that \"avg\" is computed but not used, and asks for clarification on the variables \"j\" and i\"\". The authors\" response addresses some concerns but does not fully address the initial questions. The comment provides explicit actions for the authors to clarify their algorithm and explain the variables, but it lacks concrete details on how to implement these actions. The authors are given a direction but not fully guided on how to execute it, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the algorithm, such as the unclear update process for nodes and the use of \"avg,\" as well as questions about the variables \"j\" and i\".\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the update process for nodes based on results from multiple connected nodes. It also questions the use of \"avg\" and the meaning of \"j\" and i\".\" While the comment identifies areas of confusion, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors\" response addresses some concerns but does not provide additional context or evidence to fully verify the claims. Therefore, the comment is 3, as it provides some support but requires more detailed explanation or references to be fully substantiated.", "helpfulness_rationale": "The review comment raises several concerns about Algorithm 2, specifically questioning the update process for nodes based on results from multiple connected nodes. It also notes that \"avg\" is computed but not used, and asks for clarification on the variables \"j\" and \"i\"\". While the comment identifies areas of confusion and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The response from the authors indicates that some concerns have been addressed, but the initial feedback remains incomplete. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed guidance or actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to \"Clarity, Quality, Novelty And Reproducibility\" for more information, but it does not provide specific guidance or examples of what needs to be addressed or improved. The comment lacks explicit instructions or concrete details on how the authors should enhance the paper, leaving the authors uncertain about the exact steps to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which sections or parts of the paper are missing details, making it difficult for the authors to identify the exact areas needing attention. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests a reference or resource for improvement, but it does not provide specific guidance on what aspects need to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing, without providing specific examples or references to support these claims. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests a source for further guidance but does not substantiate the claim. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient justification.", "helpfulness_rationale": "The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to \"Clarity, Quality, Novelty And Reproducibility\" for more information, but it does not provide specific guidance or examples of what needs to be addressed or improved. While the comment identifies areas for improvement, it lacks actionable feedback, leaving the authors with a general sense of what needs to be done but without clear direction. Therefore, the comment is 3, as it points out weaknesses but does not fully support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order of around 45. While the comment implies that the authors should consider overfitting as a potential cause, it does not explicitly instruct the authors to investigate this further or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of overfitting and potentially provide additional analysis or discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason behind the accuracy drop after a certain order, specifically asking if it is due to overfitting. This provides clear guidance on what aspect of the figure needs further explanation or analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5, specifically asking why it starts to drop after a certain order of around 45. This question prompts the authors to consider potential causes, such as overfitting, which could be relevant to the analysis and interpretation of their results. However, the comment does not provide any guidance or suggestions on how to address this issue or further explore the phenomenon. While it identifies an area for potential improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is an explicit action for the authors to take, as it clearly indicates a specific area that requires attention. The comment also raises a minor comment or question, but it does not provide detailed guidance on how to address these points. Therefore, the comment is 4, as it provides a clear direction for the authors to follow but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a specific suggestion for the authors to consider, providing clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, which is the inclusion of a specific baseline. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a logical suggestion based on the context of the paper, as it highlights a potential gap in the experimental setup. However, the comment does not provide specific examples or references to support the claim that this baseline is crucial or how it would impact the results. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of this baseline themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of certain natural ablation studies, such as the need to include a baseline where scratchGAN is pretrained. This feedback is clear and actionable, as it provides a direct suggestion for the authors to consider in their work. By addressing this point, the authors can strengthen their experimental setup and provide a more comprehensive analysis. However, the comment could be more helpful if it included additional context or reasoning about why this baseline is crucial or how it could impact the results. Overall, the comment is 4 as it guides the authors towards a specific enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention in SI 6.5 that the preprocessing is identical to that in Mnih et al. 7, but the evaluation is slightly different due to the absence of human starts. This provides a clear and direct action for the authors to take, specifying exactly what needs to be included in the supplementary information. The comment is explicit and concrete, allowing the authors to know exactly how to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to mention that the preprocessing is identical to that in Mnih et al. 7 but the evaluation is slightly different due to the absence of human starts. This provides clear guidance on what the authors should include in their supplementary information. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is slightly different from Mnih et al. 7 because no human starts are used. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples that would help the authors understand the basis of the claim or how it affects the evaluation. Without additional context or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or evidence to fully support it.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include in their supplementary information. It highlights a discrepancy between the preprocessing method mentioned in Mnih et al. 7 and the evaluation process in the current work, noting that no human starts are used in the evaluation. This feedback is clear and direct, offering a concrete way for the authors to enhance the transparency and completeness of their work. By addressing this point, the authors can better align their evaluation with the established methods in the field, potentially strengthening the credibility and reproducibility of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors in improving their draft by highlighting a specific area for clarification."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. It explicitly states that the paper does not report any metrics for efficiency, which is a clear and direct action for the authors to take. However, the comment does not provide specific guidance on which metrics to report or how to measure efficiency, leaving some ambiguity in terms of how to implement the suggested action. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metrics that demonstrate the efficiency of the proposed method compared to previous work. This is a factual statement that does not require verification, as it is based on the absence of specific information in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that it does not report any metrics demonstrating the efficiency of the proposed method compared to previous work. This is a clear and actionable feedback that highlights an important area for improvement. However, the comment could be more helpful if it provided suggestions on which metrics to report or how to measure efficiency. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests the authors to provide more details about the statespace, whether it is finite or continuous, and to specify the space in which theta lies. The reviewer also suggests that the actions should be precise, implying that the authors should give clear and detailed information. This feedback is explicit and concrete, as it directly instructs the authors on what specific information needs to be clarified and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more details about the statespace, whether it is finite or continuous, and the space in which theta lies. The comment also suggests that the authors should be precise in their answers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement asking for more details about the statespace and actions, which is a logical request for the authors to provide additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors need to provide more details, namely, the statespace and the space in which theta lies. It suggests that the authors should be precise in their answers, which is a valid point. However, the comment lacks depth and does not offer specific guidance on how to improve the clarity or provide additional details. While it prompts the authors to address an important aspect of their work, it does not fully support the authors in making the necessary improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point states that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method or what specific aspects need to be addressed. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the method on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper discusses the method or the results that are being evaluated. The authors may have an idea of where this discussion is located, but the comment lacks explicit references, making it weakly grounded. The comment is specific in pointing out a potential issue with the method\"s performance, but without grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve the method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task and provides a rationale for this belief. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this belief or incorporate it into their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the choice of using object detection as the downstream task and expresses a personal belief that LiDARbased segmentation is the best choice. It also mentions that colorizationbased pretraining learns semantics and that object detection requires accurate locations and poses, particularly in benchmarks like KITTI and Waymo. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the choice of downstream task and the importance of accurate locations and poses, but it lacks grounding as it does not reference specific parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a personal opinion rather than logical reasoning or external references, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose, particularly in benchmarks like KITTI and Waymo. While the comment provides a perspective on the choice of downstream task, it lacks actionable feedback or suggestions for the authors to consider or address. It does not offer specific guidance on how the authors might improve their work or incorporate this perspective, leaving the authors without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide explicit guidance on how the authors should address this contradiction or what changes they should make to resolve it. The comment lacks specific suggestions or detailed instructions on how to align the objective with the theory proof. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (12)\" and \"IPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the objective of Equation (12) and the theory proof. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a contradiction between the objective of Equation (12) and the theory proof provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting a contradiction between the objective of Equation (12) and the theory proof provided. This feedback is 3 as it points out a potential inconsistency that the authors should address. However, the comment lacks depth and does not provide specific guidance or suggestions on how to resolve the contradiction or improve the draft. To be more helpful, the comment could include additional context, examples, or suggestions for addressing the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they need to explore or address this concern, but without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It mentions the use of DINO representations, which are known for containing rich geometric information, and questions whether the adaptation capacity still holds for such concepts. However, the comment does not specify which part of the paper discusses the adaptation capacity or the proposed visual memory, making it weakly grounded. The comment is specific in detailing the concern about the adaptation capacity for concepts with semantic correlations, but it lacks explicit references to the paper\"s sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is based on general observations about the nature of concepts and the limitations of the image encoder, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It questions whether the image encoder can produce meaningful embeddings for such concepts, which could be a concern for the proposed method. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the adaptation capacity. The feedback is 3 as it points out a potential limitation, but it could be more actionable with additional insights or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. While the comment points out a potential issue, it does not provide explicit guidance on how to address this confusion. The authors are left to infer that they should clarify the notation or reword the description to avoid ambiguity, but the comment lacks concrete suggestions or examples of how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out potential confusion regarding the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their notation or reword the description to avoid ambiguity. However, the comment could be more helpful if it provided suggestions on how to address the confusion, such as proposing alternative notation or explaining the purpose of the dummy variable. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests that a more detailed mathematical formulation should be included in the appendix to complement the highlevel description. Additionally, it recommends reworking the figure to better align with the main contribution of the paper, which is improvements on the WiC task. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as the need for a more detailed mathematical formulation and the suggestion to rework the figure to better align with the main contribution of the paper. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that a more detailed mathematical formulation would be helpful, particularly in the appendix, to complement the highlevel description. It also critiques the figure, noting that it is confusing due to its abstraction and lack of alignment with the main contribution of the paper, which is improvements on the WiC task. The reviewer provides specific suggestions for improvement, such as adding more text labels and reworking the figure to better depict the WiC task. These suggestions are clear and provide actionable feedback, making the comment 4. However, the reviewer could further enhance the verifiability by providing specific examples or references to support the suggestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting that a more detailed mathematical formulation should be included in the appendix to complement the highlevel description. It also identifies specific issues with the figure, such as its abstraction and lack of alignment with the main contribution of the paper, which is improvements on the WiC task. The reviewer offers constructive suggestions for improvement, such as adding more text labels and reworking the figure to better depict the WiC task. These suggestions are clear and provide the authors with a roadmap for enhancing their draft. However, the comment could be more helpful if it included specific examples or detailed guidance on how to rework the figure. Overall, the feedback is 4, as it offers actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide specific guidance on which tasks to include or how they would enhance the paper. The action is implicit, as the authors need to infer that they should expand the benchmarking tasks, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies a potential improvement but does not provide explicit instructions on how to achieve it.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this recommendation pertains to, such as the experimental section or the results. This makes it difficult for the authors to identify the exact area where the suggestion should be applied. Additionally, the comment lacks specificity regarding which benchmarking tasks should be included or why they would be beneficial. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide any specific examples or reasoning to support why these additional tasks would be beneficial or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks should be added or how they would enhance the paper. The feedback is 3 as it points out a potential weakness but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the requirement mentioned in the abstract and the clarification provided in the text. It explicitly states that the requirement is not true, as the authors themselves clarify elsewhere. However, the comment does not provide any guidance or suggestions on how the authors should address this discrepancy or clarify the abstract. The action is implicit and vague, as the authors are left to infer that they need to correct the abstract based on the clarification provided in the text. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the requirement mentioned in the abstract, which is not true as the authors clarify in the text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the requirement mentioned in the abstract is not true, as the authors clarify elsewhere in the text. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the requirement mentioned in the abstract and the clarification provided elsewhere in the text. It points out that the requirement is not true, as the authors themselves clarify in the text. This feedback is clear and actionable, as it highlights a specific inconsistency that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to resolve this discrepancy or offered additional guidance on how to improve the clarity of the abstract. Despite this, the comment is 4 as it directs the authors to a critical area for revision, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This raises a concern that needs clarification. The second part points out a minor issue with the line \"but also on learning  on is unnecessary.\" These comments provide explicit actions for the authors to take, such as clarifying the policy gradient\"s optimality and removing unnecessary text. The feedback is concrete and actionable, guiding the authors on what specific aspects of their draft need attention. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 6\" and \"Line 78,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, such as whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. Additionally, it points out a minor issue with the line \"but also on learning  on is unnecessary.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the optimality of the policy gradient in Equation 6, suggesting that it might be better to clarify this. The second part points out a minor issue with the line \"but also on learning  on is unnecessary.\" These comments are factual observations and requests for clarification, rather than claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific points for improvement. It questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This feedback is actionable as it prompts the authors to clarify their methodology and results. Additionally, it points out a minor issue with the line \"but also on learning  on is unnecessary,\" suggesting a correction. While the comment is 4, it could be more comprehensive by providing additional guidance on how to address these issues. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, as it makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to include a discussion on the limitations of this choice. The comment is explicit and concrete, guiding the authors on exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment suggests that the authors should discuss the limitations of this choice, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that the authors should discuss the limitations of this choice. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that this choice is risky or assumptions are being made. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable piece of feedback. By pointing out this limitation, the comment encourages the authors to consider the implications of their decision and potentially address it in their paper. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be included in the discussion. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It also mentions that the paper delves into technical details without providing a clear overview of the approach. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The feedback is 3 as it points out the need for clarification but lacks detailed guidance on how to achieve it. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment highlights the need for clarification regarding the approach and specifically mentions the issue of how the approach allows for the interaction of knowledge about objects and verbs to overcome reporting bias. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification and the particular aspect of the approach that is unclear. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the interaction of knowledge about objects and verbs to overcome reporting bias. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks explicit evidence or detailed explanations, making it difficult for the authors to understand and address the issues effectively. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the clarity of the approach and the interaction of knowledge about objects and verbs to overcome reporting bias. It highlights that the paper delves into technical details without providing a clear explanation of the overall approach. This feedback is 3 as it points out a specific area where the paper needs improvement, but it lacks detailed guidance or suggestions on how the authors might address this issue. The comment could be more helpful if it provided concrete examples or steps for clarification, making it align with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This feedback provides a clear and direct action for the authors to take, which is to justify their choice of using link prediction accuracy for early stopping. The comment is explicit and concrete, as it specifies what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use link prediction accuracy for early stopping, suggesting that it might be more appropriate to use average accuracy with type accuracy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this might be the case. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the decision to use link prediction accuracy for early stopping, rather than considering average accuracy with type accuracy. This feedback is clear and actionable, as it prompts the authors to justify their choice and potentially reconsider their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to explain how to set a reasonable classimbalanced task in the fewshot learning setting, providing a clear and direct action for the authors to take. The request for \"concrete details\" indicates that the authors should provide specific examples or methods to support their explanation. This level of specificity and directness makes the comment 5, as it gives the authors a clear path to follow in improving their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, \"sampling classimbalanced tasks.\" This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue, which is the need for a reasonable explanation on how to set a classimbalanced task in the fewshot learning setting. The authors are directed to provide concrete details, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the setting of classimbalanced tasks in the context of fewshot learning, asking for a reasonable explanation. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the setting of classimbalanced tasks in the context of fewshot learning, which is a relevant and important aspect of the paper. It prompts the authors to provide a detailed explanation or justification for their approach, which can help clarify the methodology and improve the paper\"s clarity. However, the comment does not offer suggestions or guidance on how to address the issue or improve the explanation, leaving the authors with a clear question but without actionable feedback. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It suggests including discourse relation information in prompts, possibly using a ChainofThought style, which could improve the results. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should enhance their baseline and consider the suggested approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and lacks testing for a fewshot approach. It also recommends including discourse relation information in prompts, possibly using a ChainofThought style, which could improve the results. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its suggestions for improvement, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It also suggests that including discourse relation information in prompts could yield good results, which would enhance the paper\"s evaluation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper\"s baseline, specifically noting that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It also suggests that including discourse relation information in prompts, possibly using a ChainofThought style, could improve the results. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for enhancing the evaluation. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how they might be applied. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It explicitly states that the authors should provide more details on how actual pruning was done. This feedback is clear and direct, giving the authors a specific action to take: to provide additional details on the pruning process. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detail on how the ground truth of sensitivity is achieved and the actual pruning process. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the authors mention estimating a layer\"s sensitivity by pruning, but without providing details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the pruning process to enhance the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it suggested specific details or examples of what kind of information should be included. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs, ideally with error bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations, and suggests that the models are small, making it necessary to provide statistics. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve the presentation of the results. This level of detail and specificity makes the feedback 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results comparing standard vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be improved, such as presenting the results as a mean over many runs with error bars, and points out that the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs with error bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. While the comment provides a logical argument for the need to present results with error bars and statistics, it lacks specific examples or references to support the claim about the models being small. This makes the claim 3, as it provides a basis for the suggestion but could be strengthened with additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific issue with the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs with error bars, which is a common practice to ensure statistical significance and reliability. The comment also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and emphasizes the need to provide statistics for the models. This feedback is detailed and constructive, offering the authors a clear path to improve the presentation and robustness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues: the paragraph from L156166 is difficult to understand, and the figure is unclear due to vague descriptions. The reviewer suggests that there are bandit algorithms that plan to explore, such as the Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain. Additionally, the reviewer points out that the phrase \"Dashed lines indicate that the agent can plan ahead\" is too vague. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what changes should be made. The authors are left to infer that they need to clarify the paragraph and the figure, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, such as the difficulty in understanding it and the vague description of the figure. Additionally, it provides specific suggestions, such as mentioning bandit algorithms like the Gittins strategy and clarifying the figure. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and suggests that the figure is unclear due to vague descriptions. The reviewer provides specific examples, such as the mention of bandit algorithms like the Gittins strategy and the need for clarification in the figure. This provides some support for the claim, as it offers a logical basis for the difficulty in understanding. However, the comment could be strengthened by providing more detailed examples or references to specific parts of the text that are unclear. Therefore, the comment is 3, as it offers a basis for the claim but lacks full detail.", "helpfulness_rationale": "The review comment identifies two specific issues with the text: the paragraph from L156166 is difficult to understand, and the figure is unclear due to vague descriptions. It provides a clear example of a bandit algorithm, the Gittins strategy, which the reviewer suggests could be used to explore the evolution of the posterior for each arm as a Markov chain. Additionally, the comment highlights the need for more concrete explanations in the figure, such as clarifying the meaning of \"Dashed lines indicate that the agent can plan ahead...\". This feedback is actionable and provides the authors with clear directions on how to improve the clarity and understanding of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to rephrase the text or enhance the figure. Overall, the comment is 4, as it effectively guides the authors in addressing the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation metric should be mentioned in lines 078079 and 08 to enhance clarity and comparability of the results. It provides a specific example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020), which the authors can reference. This feedback is explicit and provides concrete guidance on what needs to be added to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078079 and 08, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the evaluation metric to enhance clarity and comparability of the results. The comment provides a reference to a specific work, \"Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020),\" which could be used as a basis for understanding the scale of the improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that mentioning the evaluation metric would enhance clarity and comparability of the results. It provides a specific example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in a referenced work, which could be used as a basis for understanding the scale of the improvement. This provides a clear and specific reference for the authors to follow, making the claim 4. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting that the evaluation metric should be mentioned in the paper to enhance clarity and comparability of the results. It provides a concrete example of the \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" used in a referenced work, which the authors can use as a basis for understanding the scale of the improvement. This feedback is actionable and provides a clear direction for the authors to improve their draft, making it 4. However, it could be more helpful if it included additional suggestions or examples to further guide the authors in implementing the change. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what aspects of the performance they should focus on. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any details on what aspects of the performance should be considered or how the authors might address this question. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question about the performance of DVP on video with different lengths, which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any context, analysis, or suggestions on how the authors might address this question or what aspects of the performance should be considered. Without actionable feedback or guidance, the comment lacks depth and does not offer the authors a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for curiosity but does not effectively support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This is a clear and direct action that provides specific guidance on how to address the issue in Section 3.3. The comment also mentions \"Experiments,\" which implies that the authors should include this evaluation in their experiments. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). The comment further instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests that the authors should evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This claim is 3 as it identifies a specific oversight in the training objective and provides a suggestion for evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to conduct the suggested evaluation to fully understand the impact of this oversight. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This feedback is valuable as it directs the authors to a specific area of improvement, offering a concrete step to enhance the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or guidance on how to conduct this evaluation or what specific results to expect. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful for, such as mostly for specular areas. While the comment implies that the authors should consider expanding their discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional discussion on the topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations where the losses are particularly helpful, such as mostly for specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the effectiveness of losses in certain situations, particularly for specular areas. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to discuss which situations the losses are particularly helpful for, such as mostly for specular areas. However, it does not provide any specific reasoning, examples, or references to support why this discussion would be valuable or how it could enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful for, such as mostly for specular areas. While the comment identifies a potential area for further exploration, it lacks specificity and does not provide actionable guidance on how the authors might expand their discussion. The suggestion is vague and does not offer concrete steps or examples for the authors to follow, making it 3. The feedback provides a direction for potential improvement but does not fully address the needs of the authors for actionable guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the major contributions of the paper and suggests that analyzing previous work does not constitute a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or what specific contributions they should highlight. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the paper\"s contributions and suggests that analyzing previous work does not constitute a contribution. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in terms of what aspects of the contributions are unclear or how they should be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that analyzing previous work does not constitute a contribution, which is a subjective judgment. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity regarding its contributions. It points out that analyzing previous work does not constitute a contribution, which is a critical observation that could help the authors refine their paper\"s focus and structure. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a critical area but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not provide specific guidance or suggestions on how the authors could strengthen their evidence or improve their claims. The comment lacks actionable details, such as recommending additional experiments or data analysis that could support the claim. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the experiments are insufficient or how the evidence could be improved. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the claim about the \"mixing time\" is not sufficiently supported by experiments, suggesting that the evidence provided is limited. However, the comment does not provide specific examples or detailed reasoning to substantiate this claim. It lacks detailed evidence or references to support the assertion that the experiments are insufficient. As a result, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. This feedback highlights a potential weakness in the paper\"s evidence and suggests that the evidence provided to practitioners is limited. However, the comment does not offer specific suggestions or guidance on how the authors could strengthen their evidence or improve their claims. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This is an explicit suggestion that provides a clear direction for the authors to consider. However, it does not specify how this extension should be implemented or what specific attributes should be included in the vector form. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where this extension is needed. Additionally, the comment lacks specificity regarding what attributes should be included in the vector form or how this extension would be beneficial. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it could be implemented. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This feedback is 3 as it provides a specific suggestion for improving the paper by suggesting a potential extension of the protected feature. However, the comment lacks detailed guidance on how to implement this extension or what specific attributes should be included in the vector form. To be more helpful, the comment could include examples or detailed reasoning on why this extension would be beneficial. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests denoting the vector representations of words in the equation and following ones, and it asks for clarification on whether the vectors are L2normalized before the process and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. These actions are clear and provide specific guidance on what information needs to be added or clarified in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as denoting the vector representations of words, checking if the vectors are L2normalized, and clarifying the metric used for computing \u201cnearest neighbor\u201d examples. This provides clear guidance on what information is missing or needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the notation used for vectors, whether they are L2normalized, and the metric used for computing \u201cnearest neighbor\u201d examples. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the clarity and completeness of the paper. It identifies a potential area of confusion regarding the notation used for vectors in the equation and suggests denoting them appropriately. Additionally, it raises questions about whether the vectors are L2normalized and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. This feedback is clear and provides detailed guidance on how the authors can improve the clarity and accuracy of their presentation. By addressing these points, the authors can enhance the comprehensibility and rigor of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the novelty of their method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed transductive method, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not specify which part of the paper discusses the transductive method or how it is related to selftraining methods in semisupervised learning. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the method\"s novelty but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. While it identifies a potential issue with the novelty of the method, it lacks specific details or examples to support this claim. The comment does not provide actionable feedback or suggestions for how the authors might address this concern or improve the novelty of their approach. Without actionable guidance, the comment is not helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should include these missing papers in their comparison, but it does not specify how to integrate them or what specific aspects should be covered. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the feature comparison, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is in or where the missing papers should be included. This lack of explicit reference to a specific section or table makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in identifying the issue of missing papers, it is not fully grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, the comment does not provide specific examples or references to these papers, nor does it explain why their inclusion would be beneficial. This lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing papers to enhance the depth and comprehensiveness of their comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate these papers or what specific aspects of the comparison should be expanded upon. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific guidance on how to modify the usage of this word or what alternative terms might be more appropriate. The action is implicit, as the authors can infer that they should be more cautious with the use of \"equivalent,\" but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the use of the word \"equivalent,\" suggesting a more cautious approach, especially when the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific examples or reasoning to support why this is a concern or how it might impact the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, particularly when the equivalence is not verified. It suggests a more cautious approach to using this term, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific guidance on how to address the issue or alternative terms that could be used. While it highlights an important area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors should provide a more detailed explanation of the architecture within the paper itself, rather than relying solely on external references. However, the comment does not explicitly instruct the authors to include this information or how to do so, leaving the action somewhat implicit. The authors can infer that they need to provide a clearer explanation of the architecture, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This provides some grounding as it mentions a specific reference, but it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of the architecture, which is a significant issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, and the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The claim is supported by the observation that the authors do not provide a detailed explanation of the architecture within the paper itself, relying instead on an external reference. However, the comment could be strengthened by providing specific examples or details of what aspects of the architecture are unclear or missing. The lack of detailed reasoning or references to specific sections of the paper limits the thoroughness of the justification. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks full support.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the architecture used for the experiments is not clearly explained and is instead referred to an external source. This feedback highlights a lack of selfcontainment in the paper, which is an important consideration for readers. However, the comment does not provide any suggestions or guidance on how the authors might improve the clarity of their explanation or what specific aspects of the architecture need to be addressed. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests maintaining consistency in the typesetting of BertScore and BLEURT throughout the paper, recommending the use of either \"Bertscore\" or \"Bleurt\" consistently. This provides a clear and direct action for the authors to take, ensuring that the typesetting is uniform throughout the document. The comment is explicit and concrete, offering a specific and actionable suggestion for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the typesetting of BertScore and BLEURT throughout the paper, suggesting that consistency should be maintained. However, it does not specify which parts of the paper are affected by this inconsistency, making it weakly grounded. The comment is specific in its suggestion to maintain consistency, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that BertScore and BLEURT are inconsistently typeset throughout the paper, recommending consistency in the typesetting. However, the comment does not provide any specific examples or reasoning to support why this inconsistency is problematic or how it might affect the paper\"s clarity or professionalism. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a minor but noticeable inconsistency in the typesetting of BertScore and BLEURT throughout the paper, suggesting that maintaining consistency would improve the paper\"s professionalism and readability. While the comment points out a specific issue, it does not provide detailed guidance on how to achieve consistency or why it is important. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with a general idea of what needs to be addressed but without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several specific aspects of the paper\"s presentation quality that are considered weaknesses, such as the formatting of figures, tables, and the management of certain elements like the \"Dataset\" columns and the use of asterisks. However, it does not provide explicit guidance on how to address these issues or suggest specific changes. The authors are left to infer that they need to improve the presentation quality, but the comment lacks concrete steps or examples of how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment provides a list of specific issues related to the presentation quality of the paper, such as the formatting of figures, tables, and the management of certain elements like the \"Dataset\" columns and the use of asterisks. However, it does not explicitly mention which sections or figures are being discussed, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without explicit references, the authors may find it challenging to pinpoint the exact parts of the paper that require improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the paper\"s presentation quality are a weakness, citing specific examples such as the formatting of figures, tables, and the management of certain elements. However, the comment lacks detailed reasoning or evidence to support why these aspects are considered weaknesses. It does not provide specific examples of how the presentation could be improved or what standards are being compared against. As a result, the claim is 3, as it provides some basis for the critique but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several specific areas where the presentation quality of the paper is considered a weakness, such as the formatting of figures, tables, and the management of certain elements like the \"Dataset\" columns and the use of asterisks. However, the comment does not provide detailed guidance or suggestions on how to improve these aspects, leaving the authors with a general understanding of what needs to be addressed but without actionable steps. While it highlights important areas for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include related experiments to demonstrate how the information axis tool can be applied. While the comment implies that such experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to design them. The action is implicit and somewhat vague, as the authors can infer the need for experiments but lack specific instructions on how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"conclusion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is related experiments that demonstrate the application of the information axis tool. This provides clear guidance on what needs to be added to the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support the claim that such experiments are necessary. The comment lacks detailed reasoning or evidence to justify why these experiments are crucial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s contribution and provide more evidence for the effectiveness of the tool. However, the comment lacks depth and does not offer detailed guidance on how to design or conduct these experiments, which would be beneficial for the authors. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the text in lines 293295, stating that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should address this issue by providing a clearer explanation or justification. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors know they need to clarify the text but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement. Without detailed justification or evidence, the claim remains 1, as it lacks the necessary support to help the authors understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text in lines 293295, noting that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification to address this issue. While the comment highlights a potential area of improvement, it lacks detailed guidance or specific suggestions on how to enhance clarity. The feedback is 3 as it points out a specific area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should consider using realworld datasets, it does not provide specific guidance on how to implement this change or which realworld datasets would be most appropriate. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the use of synthetic datasets or the outofdistribution setting, making it weakly grounded. The comment is specific in its suggestion to use realworld datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any reasoning or evidence to support why realworld datasets are more appropriate or why synthetic datasets are insufficient for the outofdistribution setting. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential limitation in the current experimental setup and provides a direction for improvement. However, the comment lacks specific guidance on which realworld datasets would be most suitable or how to incorporate them into the study. To be more helpful, the comment could include examples of realworld datasets or suggest specific criteria for selecting them. Overall, the feedback is 3 as it points out an area for enhancement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the novelty of their approach or what specific aspects of the pretraining strategy could be improved. Without actionable suggestions or explicit directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not specify which part of the paper discusses the pretraining approach or how it is similar to or different from the strategies used in ELECTRA. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential lack of novelty in the proposed approach to pretraining, suggesting that it follows strategies used in the ELECTRA model. While it points out a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their approach. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for using the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function. The reviewer points out that even a basic bisecting line search would converge linearly, questioning the impact on runtime. The comment implies that conducting experiments to explore this would help justify the need for the analysis/algorithm. While the action is implicit, it is clear that the authors should consider conducting experiments to support the motivation for using the Newton algorithm. The suggestion is concrete, as it provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the motivation for using the Newton algorithm, questioning its necessity and suggesting that experiments could help justify its use. The comment provides a clear direction for improvement by suggesting experiments to explore the impact on runtime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the motivation for using the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on the runtime of the algorithm, implying that a basic bisecting line search would suffice. While the comment provides a logical argument, it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as it provides a basis for questioning the necessity of the algorithm but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation for using the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer questions the necessity of the algorithm, noting that even a basic bisecting line search would converge linearly. The comment implies that conducting experiments to explore the impact on runtime could help justify the use of the algorithm. This feedback is 4 as it provides a clear direction for the authors to strengthen their motivation and justification for using the Newton algorithm. However, it could be more helpful if it suggested specific experiments or analyses that could be conducted to support the need for the algorithm. Overall, the comment offers valuable insights and actionable advice, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. It suggests that the results imply that better NMT systems are also better at idiomatic translations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methods. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the impact of the proposed upweighing and KNN methods on idiomatic vs random data, providing a clear indication of what needs to be addressed. The comment specifies that the results imply that better NMT systems are also better at idiomatic translations, which is a specific issue that the authors should consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the impact of the proposed upweighing and KNN methods on idiomatic vs random data is similar for most language and score combinations, suggesting that the methods are not idiomspecific. This claim is 3 as it provides a logical reasoning based on the observation of similar impacts in Figure 3. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it 3. The authors would need to further explore the data or provide additional context to fully understand and address the critique.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. This observation suggests that the methods may not be as idiomspecific as initially claimed. The comment implies that the results imply that better NMT systems are also better at idiomatic translations, which could be a significant insight for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methods. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not provide explicit guidance on how to address this issue. The comment implies that the authors should clarify or correct the number of biases mentioned in the paper, but it lacks concrete steps or suggestions on how to implement these changes. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the number of biases in the paper, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not specify why this is a concern or what implications it might have for the paper. The comment is fully grounded as it references a specific section of the paper, allowing the authors to accurately identify the part being addressed. However, it is underspecific because it lacks detailed explanation or suggestions for addressing the issue. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper, particularly regarding the resulting volume and the bias being a scalar. It suggests that the authors should clarify this issue, as it is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the number of biases is inconsistent or confusing. The authors are left to infer the nature of the inconsistency and the need for clarification, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the number of biases in the paper, particularly regarding the resulting volume and the bias being a scalar. It suggests that the authors should clarify this issue, as it is confusing. However, the comment lacks detailed guidance on how to address this concern or what specific changes should be made. While it points out a potential area for improvement, it does not provide actionable steps or suggestions for the authors to follow. Therefore, the comment is 3, as it highlights an important area for clarification but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This explicit suggestion provides clear guidance on what needs to be done to improve the paper. The authors are given a direct action to enhance the clarity of the reconstruction quality, making the comment 5.", "grounding_specificity_rationale": "The comment suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include smoothed GT shapes, but without explicit references to the figures, the authors may struggle to pinpoint the exact sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The lack of justification or evidence makes the claim 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This feedback is clear and actionable, as it provides a direct way for the authors to enhance the clarity of their reconstruction quality. By following this suggestion, the authors can improve the readers\" understanding of their work. However, the comment could be more helpful if it explained why showing these smoothed shapes is important or how it would benefit the readers. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and detailing the coverage. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the method to other domains and questions the selection of event types from Freebase. It asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about generalizability. The request for clarification on the selection process and coverage provides some guidance but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to address but requires additional detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the selection process and coverage, which is crucial for understanding the applicability of their method. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it suggested specific ways to improve the generalizability or provided examples of how the method could be applied to other domains. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"cite and discuss\" certain references related to domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, specifying what needs to be added to improve the draft. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment highlights a lack of important references for domain adaptation, suggesting that the authors should cite and discuss these references in the revised manuscript. However, it does not specify which references are missing or what specific domain adaptationrelated topics are underrepresented. This makes it difficult for the authors to pinpoint the exact areas needing attention, as they cannot confidently determine which parts of the paper are affected. The comment is weakly grounded because it does not provide specific references or details about the missing content, and it is not specific in terms of what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are important. This lack of detail makes it difficult for the authors to understand the scope of the issue and how to address it effectively. As a result, the claim is considered 1, as it lacks sufficient evidence or justification to support the assertion.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include and discuss these references in the revised manuscript. This feedback is valuable as it directs the authors to a critical aspect of their work that needs improvement, offering a concrete step for enhancing the draft. However, the comment could be more helpful if it provided specific examples of the missing references or discussed why they are important for the field. Overall, the comment is 4 as it highlights a significant gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether EMAweighting is used for other baseline models in Table 3. It suggests that knowing whether all models being compared utilize the EMA benefits would ensure a fair comparison. While the comment does not explicitly instruct the authors to make this clarification, it is clear that the authors should address this issue to provide a more accurate comparison. The action is implicit but concrete, as the authors can directly infer that they need to clarify this aspect in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether EMAweighting is used for other baseline models, such as \"Supervised,\" and suggests that knowing this would ensure a fair comparison. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of EMAweighting in other baseline models, specifically in Table 3. It suggests that knowing whether all models use EMA benefits would ensure a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how it impacts the fairness of the comparison. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the use of EMAweighting in other baseline models, such as \"Supervised,\" in Table 3. It suggests that knowing whether all models utilize the EMA benefits would ensure a fair comparison. This feedback is clear and actionable, as it directs the authors to clarify a potential issue in their comparison methodology. By addressing this concern, the authors can improve the transparency and fairness of their results. However, the comment could be more helpful if it provided additional context or suggested how to implement this clarification. Overall, the comment is 4, as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. The comment also provides a presentation suggestion. While the action of questioning the hyperparameters and suggesting a presentation improvement is explicit, the comment lacks concrete guidance on how to address the issue of hyperparameters or how to present the results effectively. The authors know they need to investigate the hyperparameters and consider presentation suggestions, but the comment does not provide detailed steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion for presentation is specific, but the lack of grounding makes it challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. However, the comment lacks specific evidence or detailed reasoning to support the claim that the SCNN is \"lucky\" or to explain why the distance to the next best model is suspiciously large. Without additional context or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. While the comment identifies a potential issue with the model\"s performance, it lacks specific guidance on how to address the concern about the hyperparameters or how to present the results effectively. The suggestion for presentation is a positive addition, but the overall feedback could be more actionable if it included detailed steps or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what aspects need clarification or how to improve the motivation. The comment lacks concrete details or suggestions on how the authors should address these issues, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies specific areas of the experimental setup that are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the clarity and motivation of the experimental setup, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. However, it lacks detail and does not provide specific suggestions or examples of what aspects are unclear or how they could be improved. This makes it difficult for the authors to address the feedback effectively. While it highlights an important area for improvement, the comment is incomplete and lacks actionable guidance, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This comment implies that the authors should provide more detailed information about the model\"s size to facilitate a comparison with competing approaches. While the action is implicit, it is clear and concrete, as the authors know exactly what information needs to be added to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This provides some grounding as it refers to the model\"s architecture, but it does not specify which part of the paper this information is missing. The comment is specific in asking for clarification on the size of the hourglass modules, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This is a factual observation that does not require verification or evidence. It is a request for clarification rather than a claim or suggestion that requires justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This feedback is 3 as it identifies a gap in the information provided, which could be addressed by the authors to provide a more comprehensive understanding of their model. However, the comment lacks specific guidance or suggestions on how the authors might improve this aspect of their draft, such as by providing detailed information about the size of the hourglass modules. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim that the proposed PACE treats climate emulation as a diagnostictype prediction, which is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the distinction between their work and existing approaches. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about PACE treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of misrepresentation by not clarifying that prior work already addresses this aspect. The comment provides a clear direction for the authors to address the claim, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about PACE treating climate emulation as a diagnostictype prediction is misleading without providing clear evidence or references to prior work (such as ClimateBench or ClimateSet) that already addresses this aspect. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that the proposed PACE treats climate emulation as a diagnostictype prediction, suggesting that this claim is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already addresses this aspect. This feedback is 3 as it points out a potential confusion or lack of clarity in the paper. However, it does not provide specific guidance on how the authors might address this issue or improve the clarity of their claims. The comment could be more helpful with additional suggestions or examples to help the authors enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests moving some visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also provides a concrete suggestion to condense the existing figures on the network architecture to make room for additional visual results. This feedback is clear and provides specific guidance on how the authors can improve their draft by enhancing the visual representation of their work. The action is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also suggests condensing the existing figures on the network architecture to make room for additional visual results. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the main paper and the supplementary material. The suggestion is specific, as it provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also suggests condensing existing figures to make room for additional visual results. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current visual results are insufficient or that condensing figures would be beneficial. This makes the claim 3, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to move visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is the main experiment of the paper. It also offers a concrete suggestion to condense existing figures on the network architecture to make room for additional visual results. This feedback is valuable as it guides the authors on how to enhance the visual representation of their work, which can significantly improve the clarity and impact of the paper. The comment is specific and actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to incorporate the corpus residual value into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of corpus residual value to detect such differences. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. The comment suggests that this issue could be detected using the corpus residual value, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the corpus residual value could be used for this purpose. Without additional justification or references, the claim remains 1, as it lacks the necessary details to help the authors understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value, which is a constructive and insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or incorporate the corpus residual value into their analysis. While it identifies a potential weakness, the feedback could be more helpful with additional details or actionable steps. Therefore, the comment is 3, as it provides a valuable insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. However, the reasoning provided gives the authors a clear understanding of the benefits of using WebQuestions, making the action somewhat explicit. The authors know what needs to be done but may need to infer the exact steps to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of dataset used in the study, specifically mentioning \"WebQuestionsSP\" and suggesting the use of \"WebQuestions (Berant et al., 2013) benchmark set.\" This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the choice of dataset. The comment is also specific because it suggests a more intuitive and straightforward choice of dataset and explains how it could facilitate direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It offers a rationale for this choice, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors towards a more appropriate choice of dataset, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it included specific details on how the use of WebQuestions could improve the study or what aspects of the research would benefit from this change. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It provides a clear and concrete action for the authors to take, which is to verify the effectiveness of the framework on ImageNet1k or ImageNet100 and present these results in the main paper. This guidance is explicit and provides a direct path for the authors to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s improvements on CIFAR derivatives and suggests that the authors should include analysis or results on other datasets, specifically ImageNet derivatives. This provides clear guidance on where the paper lacks analysis and what specific results should be included. The comment is also specific because it clearly specifies the datasets that need to be addressed and the importance of verifying the framework\"s effectiveness on them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives, and recommends including these results in the main paper. The claim is 3 as it provides a logical reasoning for the importance of including results on ImageNet derivatives, which could enhance the paper\"s comprehensiveness and impact. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to infer the significance of including these results on their own, which could be challenging without additional context or evidence.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by pointing out that while it shows improvements on CIFAR derivatives, it lacks analysis or results on other datasets, such as ImageNet derivatives. This is a critical observation as it highlights an area where the paper\"s findings may not be fully validated or demonstrated. The comment provides a clear and actionable suggestion for the authors to include analysis or results on ImageNet1k or ImageNet100, which would enhance the paper\"s comprehensiveness and credibility. By addressing this feedback, the authors can significantly improve the robustness and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to present these results or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for addressing them as models. This feedback provides a clear and explicit action for the authors to take, which is to ensure consistency in the terminology throughout the paper. The suggestion is concrete, as it specifies the action needed to resolve the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the inconsistency in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The authors can identify the sections where this inconsistency occurs, such as the Abstract and Introduction, as well as the Experiments section. This provides full grounding, allowing the authors to accurately pinpoint the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the inconsistent use of these terms and suggests a more consistent approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for addressing them as models. This claim is 3 as it points out a logical inconsistency in the paper\"s terminology. However, it lacks specific examples or references to support the suggestion, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets in the experiments. The reviewer suggests that it would be more consistent to refer to them as datasets unless there is a specific reason for addressing them as models. This feedback is clear and actionable, as it provides a straightforward suggestion for improving the consistency and clarity of the paper\"s terminology. By addressing this issue, the authors can enhance the coherence and professionalism of their draft. Therefore, the comment is rated as 5, as it offers a specific and actionable way to improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization to specific TSP instances in the paper, particularly in the context of the finetuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a clear direction for improvement, it does not specify how to achieve these clarifications or comparisons. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take to address the suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the generalization to specific TSP instances, specifically mentioning the finetuning step in DIMES. It suggests clarifying the generalization gaps and provides a specific recommendation to compare DIMES with other methods on TSP100. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the generalization gaps and comparing with other methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the generalization to specific TSP instances should be clarified, particularly in the context of the finetuning step in DIMES. It acknowledges that DIMES has advantages in direct RL training for largescale problems and meta finetuning, but it questions the clarity of these advantages. The reviewer also suggests comparing DIMES with other methods on TSP100 to provide a more comprehensive evaluation. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the generalization gaps. The suggestion to compare with other methods is a logical extension but does not provide detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for improvement but requires more detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the generalization to specific TSP instances, particularly in the context of the finetuning step in DIMES. It acknowledges the advantages of DIMES but suggests that the paper should clarify these advantages and provide a more detailed comparison with other methods. The comment also recommends testing DIMES on TSP100 with and without metalearning, which could enhance the paper\"s evaluation. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions on how to clarify the generalization gaps or how to conduct the recommended comparisons. Overall, the comment is 4 as it guides the authors towards improving the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to provide the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility. This request is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what information needs to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"final thresholds\" and \"hyperparameters,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests the authors to provide the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two requests for information: the final thresholds used for the results and the sharing of the full set of hyperparameters for reproducibility. These are factual requests for additional information that do not require any justification or evidence. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, addressing a specific issue related to the reproducibility of the results. It explicitly asks for the final thresholds used for the results and suggests sharing the full set of hyperparameters, which is crucial for others to reproduce the findings. This feedback is valuable as it provides a direct way for the authors to enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important for reproducibility. Overall, the comment is 4 as it guides the authors in improving their draft by addressing a critical aspect of reproducibility. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the authors\" claim that the readability of RC datasets does not directly affect question difficulty, but it points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment highlights a potential limitation of the claim, it does not provide explicit guidance or suggestions on how the authors might address this issue or further explore the impact of different features on question difficulty. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of various features on their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and their effect on question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this inference is not explicit. The comment is specific in detailing the dependency on features for answer detection, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges a claim made by the authors about the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or detailed reasoning to support the claim that the method or features are indeed responsible for the observed impact. The lack of detailed evidence or examples makes the claim 3, as the authors would need to further explore the impact of different features to fully understand the reasoning behind the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges a claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it highlights a potential limitation of the authors\" claim and suggests that the authors should consider the impact of different features on their analysis. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might address this issue or further explore the impact of features on their results. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically mentioning the need to address the repetition of explaining basic memory networks and the forward model. It also points out that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific guidance on how to improve the writing quality or what aspects of the related work should be expanded. The authors are left with a general understanding of what needs to be addressed but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not specify which sections of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing quality is being evaluated in general, but the lack of specific references to sections or elements makes it difficult to pinpoint the exact areas needing improvement. The comment is specific in identifying the need for improvement in writing quality and the gaps in the related work section, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement in the paper: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, suggesting that this repetition could be addressed. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. While the comment highlights specific areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the paper, suggesting that the first column of Qo is replaced by vo to form P\"o, which results in the first state being unreachability. It implies that either Assumption 1 (finite length of an option) or Assumption 2 (termination) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly modify their assumptions or analysis to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo with vo to form P\"o, which results in the first state being unreachability. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, resulting in the first state being unreachability. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide detailed explanations or examples of how this replacement affects the reachability of the first state. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, pointing out that the first column of Qo is replaced by vo to form P\"o, which results in the first state being unreachability. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (termination) is violated. This feedback is 3 as it highlights a potential weakness in the paper\"s assumptions and provides a clear direction for the authors to investigate and potentially address. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided additional context on the implications of this finding. Overall, the comment is 3, as it directs the authors\" attention to a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this assumption should be tested or how to address it. The comment lacks specificity and does not offer any concrete steps for the authors to follow, making it 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not specify which part of the paper this assumption is made in. The authors cannot confidently determine the exact section or part of the paper being addressed, making the comment weakly grounded. However, it is specific in questioning the validity of the assumption, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the assumption that d_e are good replacements for entity embeddings, questioning whether this assumption has been tested. This feedback is valuable as it prompts the authors to consider the validity of their approach and potentially conduct further testing or analysis. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that presenting factors in a table does not convey more information than pure text, implying that the authors should consider alternative ways to present the information. However, the comment does not provide specific guidance on what those alternative ways might be or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different presentation methods but are not given concrete suggestions on what those methods might be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique, as it clearly identifies the problem with the current presentation method. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that presenting factors in a table does not convey more information than pure text, suggesting that there is no additional information provided. However, the comment lacks specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might improve the presentation or convey more information. Without actionable feedback or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it points out a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of their work might be affected by this inquiry. The comment lacks any explicit or implicit actions for the authors to take, leaving them without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or guidance on how the authors should address this question. Without clear grounding and specificity, the authors cannot effectively respond to the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of their work might be affected by this inquiry. Without actionable feedback or context, the comment lacks depth and does not offer the authors a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for consideration but does not fully support the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to pruning and its impact on large networks trained in distributed settings. It highlights the potential necessity of finding global top Q values of the metric over the average of gradients, which could affect acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion on pruning or related techniques, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue and its implications, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors do not mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is 3 as it points out a potential oversight in the paper, but it lacks specific examples or references to support the assertion that this is a significant issue. The comment implies that this oversight could impact the effectiveness of acceleration techniques like quantization and sparsification, but without further elaboration, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could impact the effectiveness of acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a critical area for consideration, the feedback is 3 as it provides a direction for potential improvement but does not offer detailed actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting they check the figures or providing specific steps to correct any mistakes. Without actionable guidance, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. This provides full grounding as it explicitly mentions the figures being addressed, allowing the authors to accurately identify the parts of the paper being discussed. The comment is also specific because it clearly specifies the issue of potential figure swapping, giving the authors a clear direction for addressing the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the figures in Figs 1 and 2, suggesting that some subfigures may have been swapped by mistake. While this observation is relevant and could potentially impact the clarity and accuracy of the figures, the comment lacks actionable guidance or suggestions for the authors to address this issue. It does not provide any context, reasoning, or specific steps on how the authors might verify or correct the figures. As a result, the comment is 2, as it identifies a potential issue but does not offer actionable feedback for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. While it acknowledges the benefits, it suggests that this should be a substantial part of the discussion. However, the comment does not provide explicit guidance on how to address this concern or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the dropout probe and its impact on sensitivity and the discovery of causal roles for syntactic representations. It acknowledges the benefits but raises a concern about the potential increase in false positives. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion section, but the lack of explicit mention of a section or specific elements makes it difficult to pinpoint. The comment is specific in detailing the concern about false positives, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. The reviewer acknowledges the benefits but suggests that this should be a substantial part of the discussion. However, the comment lacks specific examples or references to support the claim about false positives, making it difficult for the authors to fully understand and address the concern. The reasoning is logical but lacks detailed evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the benefits of the dropout probe in improving sensitivity and finding causal roles for syntactic representations. However, it raises a concern about the potential increase in false positives, which is a valid point to consider. The comment suggests that this aspect should be a substantial part of the discussion, providing a clear direction for the authors to address. While the comment identifies a potential issue, it could be more helpful if it offered specific suggestions on how to discuss and mitigate the risk of false positives. Overall, the comment is 4 as it highlights an important consideration for the authors to address in their discussion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a significant issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on which specific exploration methods should be discussed or compared, or how these comparisons could be made. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing what is missing, namely the discussion and comparison of these exploration methods, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support the claim that these methods are essential or relevant to the paper\"s focus. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of related work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which exploration methods should be discussed or how they could be compared. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 should be enlarged for better visibility. This is an explicit action that the authors can take to improve the figure. However, the comment does not provide specific guidance on how much enlargement is necessary or how to achieve it. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the enlargement of annotations for better visibility. This provides clear guidance on what the authors need to do to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 should be enlarged for better visibility. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the figure. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 4, suggesting that the annotations should be enlarged for better visibility. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it lacks depth and does not offer additional guidance on how to achieve the enlargement or what specific changes might be necessary. While it points out a clear area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a general observation about the existence of multiple entities in sentences and documents, including the case of relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should be addressed or incorporated into the paper. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a general observation about the existence of multiple entities in sentences and documents, including relation classification. This provides clear guidance on what the authors need to consider in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a general observation about the existence of multiple entities in sentences and documents, including relation classification. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The comment identifies a general observation about the presence of multiple entities in sentences and documents, including relation classification. However, it does not provide specific guidance or suggestions on how this observation might impact the paper or what changes the authors should consider. Without actionable feedback or detailed insights, the comment lacks the depth and specificity needed to be helpful. As a result, it is rated as 2, as it provides some insight but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the inference process, provide the coefficient value, and ensure welltuned baselines and confident ablation studies. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the inference process, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. It provides detailed feedback on what needs to be addressed, such as clarifying the inference process, explaining the coefficient value, and ensuring welltuned baselines and confident ablation studies. However, the comment does not explicitly mention the specific section or line number where these issues are discussed, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies these issues, it does not provide specific examples or references to support the claim that inference is slowed down drastically or that the coefficient is 1. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several critical issues in the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. It raises important questions about the methodology and provides specific suggestions for improvement, such as clarifying the inference process and ensuring welltuned baselines. However, the comment could be more helpful if it offered more detailed guidance on how to address these issues or provided examples of how to improve the writing. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify why this change is necessary or how it would improve the paper. While the action is clear, the lack of detailed reasoning or explanation makes it somewhat vague. Therefore, the comment is 4, as it provides a direct action but lacks full guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" However, it does not provide any reasoning or evidence to support why this model is no longer stateoftheart or why it should be replaced. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This feedback is 3 as it identifies a potential issue with the description of the model\"s status, which could be misleading or outdated. However, the comment lacks depth and does not provide specific guidance on why this change is necessary or how it would improve the clarity of the paper. To be more helpful, the comment could include an explanation of why the model is no longer stateoftheart or why the change is important. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some subjective statements in the paper are inappropriate and recommends providing proofs and references to support the statements. It also points out that the image recovery performance is sensitive to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific proofs or references to include. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses subjective statements in the paper, suggesting that they are inappropriate and should be supported with proofs and references. It also points out the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. However, the comment does not specify which parts of the paper contain these subjective statements or where the proofs and references should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections needing revision. The comment is specific in detailing what needs to be addressed, such as providing proofs and references, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some subjective statements in the paper are inappropriate and suggests that proofs and references are needed to support them. The comment also highlights the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. However, the comment lacks specific examples or references to substantiate the claims, making it difficult for the authors to fully understand and address the issues. While the general points are valid, the lack of detailed evidence or examples makes the claim 3, as it provides a basis for improvement but requires further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding subjective statements, proofs, and references. It suggests that some statements are inappropriate and recommends providing proofs and references to support them. Additionally, it points out the sensitivity of image recovery performance to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment also mentions the use of skip connections as an implicit way of using multiscale information, which could be relevant to the paper. However, the comment lacks detailed guidance on how to incorporate these suggestions or provide the necessary proofs and references. While it provides some insight into potential improvements, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method compares with prior art. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the comparison should be addressed or how the authors should approach this comparison. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method compares with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the discussion section or the conclusion, but this inference is not explicit. The comment is specific in asking for a comparison with prior art, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question asking for a comparison with prior art, which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art. While it identifies a gap in the paper\"s discussion, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the comparison should be emphasized. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area for enhancement but does not offer concrete steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that the authors should consider comparing biases towards different languages/nationalities. While the comment suggests an area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the inclusion of various languages and suggests an interesting observation to compare biases towards different languages/nationalities. This provides clear guidance on what the authors should consider in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that there might be interesting observations comparing biases towards different languages/nationalities. However, the comment does not provide specific examples or detailed reasoning to support the claim that these comparisons would be interesting or necessary. The suggestion lacks concrete evidence or examples to substantiate the claim, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It points out that biases towards different languages/nationalities might be different and suggests that comparing them could lead to interesting observations. This feedback is 3 as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, it could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific observations might be interesting. Overall, the comment offers a direction for enhancing the analysis but lacks comprehensive guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests exploring additional properties of features beyond the norm, which is a logical extension of the current approach. However, it does not provide explicit guidance on which specific properties to consider or how to incorporate them into the approach design. The action is implicit and somewhat vague, as the authors need to infer that they should explore other properties and how to integrate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring additional properties of features beyond the norm, which is a logical extension of the current approach. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore other properties, but without grounding, the authors may struggle to identify the exact section where this suggestion is relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring additional properties of features beyond the norm, which is a logical extension of the current approach. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or helpful for the approach design. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests exploring additional properties of features beyond the norm, which is a logical extension of the current approach. This feedback is 3 as it identifies a potential area for improvement or expansion in the approach design. However, it lacks specificity and does not provide guidance on which specific properties to consider or how they might be incorporated into the approach. To be more helpful, the comment could include examples of other properties or suggest how they might enhance the approach. Therefore, the comment is 3, as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this topic numerically. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of learning F^dagger, but without explicit references, it remains unclear. The comment is specific in detailing what needs to be addressed, namely the conservation properties of learning F^dagger. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that learning F^dagger should conserve these properties. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises an important question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. This feedback is valuable as it prompts the authors to consider an important aspect of their work that may impact its applicability and accuracy. However, the comment could be more helpful if it included specific suggestions or guidance on how to investigate and address this issue. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness in the paper, specifically noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. While the comment points out a potential issue, it does not explicitly instruct the authors to make changes or provide specific guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the network for d. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific weakness in the paper, noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or figure. While the authors can infer that it relates to the method or experimental setup, the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the method being mostly constructed on top of previous methods without significant network changes or losses. It questions the use of two SIRENs for f and d, suggesting that d should be a simpler network. However, the comment lacks specific reasoning or evidence to support why this is a weakness or how it affects the paper\"s contribution. The claim is 3 as it points out a potential issue but requires more detailed explanation or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper, specifically noting that the method is mostly constructed on top of previous methods without significant network changes or losses. It highlights the contribution of the signed distance function and the pipeline for transferable implicit displacement fields. The reviewer raises a question about the use of two SIRENs for f and d, suggesting that d should be a simpler network. This feedback is 3 as it points out a potential area for improvement in the paper\"s methodology. However, the comment could be more helpful if it provided specific suggestions or examples on how to simplify the network for d or how to address the issue of relying heavily on previous methods. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. This suggestion is explicit and provides a clear direction for the authors to consider in their analysis. However, it does not specify how to incorporate this analysis into the paper or which sections to address. The action is concrete, as it outlines a specific area for improvement, but it could be more detailed in terms of implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the RQ1 is redundant and proposes an alternative analysis that could be more informative, such as examining the effect of explicit hate information on implicit hate speech detection performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance. The comment provides a reference to support the suggestion, which is a step towards verifiability. However, the claim could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is 4, as it offers a logical basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a redundancy in the RQ1 mentioned in the paper, suggesting that it does not provide additional information for the audience. It proposes an alternative analysis that could be more informative, such as examining how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. This suggestion is clear and actionable, as it provides a specific direction for the authors to improve their analysis. By offering a constructive critique and a potential enhancement, the comment is 4, as it guides the authors in refining their research questions and analysis. However, it could be more helpful if it included specific examples or detailed guidance on how to implement this analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of the authors\" work with other papers focusing on semantic face editing, specifically mentioning the ability to achieve continuous control over attributes. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in identifying the need for elaboration on the differences between the authors\" work and these papers, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are other works in the field of semantic face editing that achieve continuous control over attributes, and it suggests that the authors should elaborate on the differences between their work and these papers. However, the comment does not provide specific examples or references to these other works, making it difficult for the authors to understand the context or basis of the claim. Without detailed examples or references, the claim remains vague and lacks sufficient support, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. This feedback is 3 as it highlights a potential area for improvement by encouraging the authors to differentiate their approach from existing works. However, the comment lacks specific guidance on how to elaborate on these differences or what aspects should be emphasized. To be more helpful, the comment could provide examples of the other works or suggest specific aspects of the differences that should be highlighted. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. However, the comment does not provide explicit instructions or guidance on how to compute the effective receptive field or what specific improvements should be expected. The action is implicit and somewhat vague, as the authors need to infer that they should compute the effective receptive field and compare it before and after applying the GS module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field, referencing a specific source 2 for guidance. However, the comment does not explicitly mention which part of the paper discusses the GS module or the effective receptive field, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this inference is not precise. The comment is specific in its request for computation and comparison of the effective receptive field, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field, referencing a specific source 2 for guidance. However, the comment does not provide any additional context, reasoning, or evidence to support why this computation is necessary or how it would improve the paper. The reference to 2 is not sufficient to fully substantiate the claim, as it lacks detailed explanation or examples. Therefore, the comment is considered 2, as it provides some support but lacks the depth needed for a 5 claim.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field and provides a reference to a specific source, 2, for guidance. This feedback is 3 as it prompts the authors to consider a specific aspect of their methodology and provides a direction for further investigation. However, the comment could be more helpful if it included more detailed guidance on how to compute the effective receptive field or what specific improvements to expect. Overall, the comment offers a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This comment provides a clear and explicit action for the authors to take, which is to modify their approach by adding another head for value function computation in the finetuning stage. The suggestion is concrete, as it specifies what needs to be done and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the LSTM part, but this inference is not explicit. The comment is specific in suggesting a change to the finetuning stage, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This feedback is clear and actionable, providing a specific suggestion for improvement that could enhance the paper. By adding this additional functionality, the authors could potentially improve the performance or utility of their model. However, the comment could be more helpful if it included further details or examples to illustrate the implementation of this suggestion. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation for this combination, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the combination. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the rationale behind the combination, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not provide any supporting evidence, reasoning, or references to justify this inquiry. The comment lacks specific examples or references to HRAC or G4RL, making it difficult for the authors to understand the basis of the question or how to address it. Without additional context or explanation, the claim is not verifiable, as it does not provide enough information for the authors to effectively respond or improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This inquiry prompts the authors to provide a clear explanation of their methodology, which is crucial for understanding the basis of their approach. By asking for clarification on the rationale behind the combination, the comment encourages the authors to justify their choices and potentially reveal insights that could enhance the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it suggested specific areas where additional explanation or justification might be needed. Overall, the feedback is 3 as it directs the authors to clarify a key aspect of their methodology, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, implying that the current list is incomplete. However, it does not specify which older works should be included or how they should be integrated into the existing list. The action is implicit and somewhat vague, as the authors need to infer which specific older works to acknowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, implying that the current list is incomplete. However, the comment does not provide specific examples or references to older works that should be acknowledged, nor does it explain why these older works are relevant or important. This lack of detail makes it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, implying that the current list is incomplete. While this feedback is 3, it lacks specificity and does not provide examples or references of specific older works that should be included. This limits the authors\" ability to effectively address the feedback. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not offer detailed guidance or actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that the authors\" claim about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming architectures. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their results or analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or adjust their results and analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling, and questions the authors\" claim about the predictor being accurate on the good subregion. The comment provides a clear rationale for why the results might be confusing and suggests a potential explanation for the observed performance differences. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" claim that the predictor is accurate on the good subregion, suggesting that increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. However, the comment lacks specific examples or detailed reasoning to support the claim that the predictor is accurate or to explain why the sampling probabilities should be adjusted. This makes the claim 3, as it provides a logical basis for questioning the results but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" claim that the predictor is accurate on the good subregion, suggesting that increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This feedback is 3 as it identifies a potential issue with the results and provides a rationale for questioning the authors\" claim. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this concern or clarify their results. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues contributing to the high time complexity of the proposed method. It points out the use of an itemoriented autoencoder, which may involve many users associated with a typical item, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for reducing the time complexity. The authors are left to infer that they need to optimize the model or explore alternative approaches, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of high time complexity in the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues related to time complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment lacks specific examples or detailed reasoning to support these claims. While the authors may infer that these factors contribute to the complexity, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several factors contributing to the high time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback is 3 as it points out areas where the authors might need to focus on to improve the efficiency of their approach. However, the comment lacks specific suggestions or guidance on how to address these issues, such as proposing alternative methods or optimizations. While it highlights potential areas for improvement, it does not provide detailed actionable advice, leaving the authors with a general understanding of the problem but without clear steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This feedback provides a clear and explicit action for the authors to take, as it directly instructs them to clarify the types of autoencoders used in the figures. The suggestion is concrete, as it specifies what needs to be changed and how to make the figures more clear. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This feedback is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed in terms of clarifying the types of autoencoders used in the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This feedback is based on a logical reasoning that the use of more specific terms could enhance clarity. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact impact of this suggestion on the clarity of the figures, which adds to the ambiguity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. It suggests that specifying \"pretrained solution encoders & solution decoders\" instead of \"autoencoders\" would enhance the understanding of the figures. This feedback is clear and actionable, as it directly addresses a potential source of confusion and offers a concrete way to improve the draft. However, the comment could be more helpful if it explained why this clarification is important or how it might affect the interpretation of the results. Despite this, the feedback is 4 as it guides the authors in making a specific and beneficial change to their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide information about the computation required to implement the experiments, including the duration of the experiments and the hardware used. This request is clear and direct, giving the authors a specific action to take in terms of providing additional details about the computational aspects of their work. The comment is explicit and concrete, as it directly instructs the authors on what information to include, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the computation required to implement the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the duration of the experiments and the hardware used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements of the experiments, specifically asking for details on the duration and hardware used. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide additional information about the computational requirements of their experiments. This includes details on the duration of the experiments and the hardware used. By addressing this request, the authors can provide more context and transparency about their experimental setup, which is valuable for readers and reviewers. However, the comment could be more helpful if it suggested specific ways to present this information or highlighted the importance of this information for the readers. Overall, the comment is 4 as it directs the authors to a specific area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The comment implies that the authors should provide more discussion on this aspect and specify when the meta sampler is applied (i.e., at which epoch). While the action is implicit, it is clear and concrete, as it specifies what additional information the authors need to include. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a specific part of the paper where this information should be addressed. However, the comment does not explicitly mention which section of the paper this relates to, making it weakly grounded. The question is specific in its inquiry about the decoupled application and the timing of the meta sampler\"s use. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The reviewer asks for more discussion on this and when the meta sampler is applied. However, the comment does not provide any evidence, reasoning, or references to support the claim that the meta sampler is only used in a decoupled way. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the authors\" approach to applying the meta sampler, particularly whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a need for more discussion on this aspect. While the comment identifies a potential area for clarification, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests that the authors use related fairnessaware metrics like Equality Odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. The comment also provides a specific reference, the AAAI paper cited, which guides the authors on how to proceed with their experiments. This level of detail and directness makes the actions concrete and actionable, allowing the authors to clearly understand what changes are needed and how to implement them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the use of a \"vanilla metric\" defined by the authors and suggests the inclusion of \"related fairnessaware metrics like Equality Odds (EO)\". It also recommends conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology and experimental setup. The authors can infer that it relates to the sections discussing metrics and experiments, but the comment lacks explicit grounding. However, it is specific in detailing what needs to be addressed, such as the inclusion of fairnessaware metrics and the need for additional experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors lack related fairnessaware metrics like Equality Odds (EO) and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are important or why the authors should include them. The mention of a specific AAAI paper provides some context, but it does not fully substantiate the claim. Without additional justification or evidence, the claim remains 3, as it lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper by noting the lack of fairnessaware metrics, such as Equality Odds (EO), which are crucial for evaluating fairness in algorithmic models. It provides a clear suggestion for improvement by recommending the use of these metrics and conducting more experiments on datasets like COMPAS and Drug Consumption. Additionally, the comment references a specific AAAI paper that the authors have cited, offering a direct path for the authors to follow. This feedback is actionable and provides detailed guidance on how to enhance the paper, making it 5 for the authors to improve their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines to validate their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. The authors might infer that it pertains to the discussion of the proposed changes or the results section, but this is not explicitly mentioned. The comment is specific in its suggestion to include additional baselines for verification, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, the comment does not provide any specific reasoning or evidence to support why these baselines are relevant or how they would improve the verification process. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider using baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. This feedback is 3 as it provides a specific suggestion for additional experiments that could enhance the validation of the proposed changes. However, the comment lacks depth and does not offer detailed guidance on how to implement these baselines or what specific aspects of the performance improvement should be compared. To be more helpful, the comment could include more detailed reasoning or examples of how these baselines would contribute to the analysis. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and direct, giving the authors a specific action to take: conduct an analysis of the neighborhood size h and its influence, and provide insights into performance variations with a constant set of parameters. The suggestion is concrete, as it outlines the exact steps needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the value of neighborhood size h\" and \"an analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing insights into the value of h and the robustness of the method with respect to larger or smaller neighborhoods. Additionally, it points out the use of different hyperparameter sets per dataset, which is not ideal, and suggests that the authors provide insights into performance variations with a constant set of parameters. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the value of h. The suggestion to provide insights into performance variations with a constant set of parameters is a logical extension of the critique but could benefit from more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies two critical areas for improvement in the paper: the lack of analysis of the neighborhood size h and its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It highlights the importance of providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to larger or smaller neighborhoods. Additionally, it points out the issue of using different hyperparameter sets per dataset, which is not ideal, and suggests that the authors provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, offering specific suggestions for improvement that can significantly enhance the paper. By addressing these points, the authors can improve the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of missing data on the model and its ability to leverage additional modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area needing attention. While the comment is specific in its inquiry about the impact of missing data, it lacks grounding, as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or examples, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It prompts the authors to consider whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. This question is relevant and could lead to valuable insights into the robustness and generalizability of the model. However, the comment does not provide specific guidance or suggestions on how the authors might explore or address this issue, such as through additional experiments or analyses. While it identifies a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is explicit and concrete, as it clearly outlines what information should be included and how it should be presented. The authors are given a direct action to take, which is to include these statistics in their analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely, to show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This provides a clear direction for the authors to enhance their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This is a logical suggestion based on the observation that the SST dataset has phraselevel annotations. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this suggestion based on the context of the paper, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. By including these statistics, the authors can better demonstrate the effectiveness of their approach and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is 4 as it offers a clear and actionable improvement to the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of verification of the stability of the OGEAug on OOD benchmarks, specifically on the DrugOOD dataset, where SPE is validated. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to verify the stability. The comment implies that the authors should conduct additional experiments or analyses to assess the stability of their method, but it does not offer concrete instructions or examples of how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of verification of the stability of the OGEAug on OOD benchmarks, particularly on the DrugOOD dataset. It specifies that the authors should address this by validating their method on this dataset, where SPE is already validated. This provides full grounding as it explicitly mentions the DrugOOD dataset and the need for verification. The comment is also specific because it clearly identifies the issue and suggests a solution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of their method, OGEAug, on OOD benchmarks such as DrugOOD, where another method, SPE, is validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their work by verifying the stability of their method, OGEAug, on OOD benchmarks such as DrugOOD. It highlights that another method, SPE, is already validated on this dataset, providing a clear direction for the authors to enhance their study. However, the comment lacks depth and does not offer specific suggestions or guidance on how to conduct this verification or what aspects to focus on. While it points out a potential area for improvement, it does not provide detailed actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their approach to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, specifying what needs to be added or improved in the related work section. The comment is explicit and concrete, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not provide any specific examples or references to support the claim that such comparisons are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient support or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the approach to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for improvement, helping the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it provided examples of strong baselines or detailed guidance on how to conduct the comparison. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments in the paper should be expanded to include multiple seed experiments, which would provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The suggestion is concrete, as it specifies what additional experiments should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Single Seed Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, which are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests a solution by recommending multiple seed experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. While the claim is logical and makes sense, it lacks specific examples or references to support the assertion that multiple seed experiments would indeed provide a more robust evaluation. This makes the claim 3, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it points out a potential weakness in the current experimental setup and offers a straightforward solution to improve the study\"s reliability and validity. By addressing this issue, the authors can enhance the quality and credibility of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggestions for alternative approaches that could make the method more accessible. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the accessibility issue but lacks grounding, as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts the accessibility of the method. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential accessibility issue with the proposed method, noting that it requires an entire multiGPU setup for optimizations. This observation is relevant and could be helpful for the authors to consider when discussing the practical implications of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. While the comment provides explicit suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions or what specific aspects to focus on when comparing the systems. The authors are given a clear direction but may need to infer the exact steps to take, making the comment 4.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to compare with another system and use Ref2 as a baseline, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The suggestion to use Ref2 as a baseline is not elaborated upon, leaving the authors without a clear understanding of the rationale behind the recommendation. Therefore, the comment is considered 2, as it provides some guidance but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. This feedback is clear and actionable, providing the authors with specific steps to enhance their work by including additional comparisons and baselines. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these comparisons or what specific aspects to focus on when evaluating the performance. Overall, the comment is 4 as it directs the authors towards meaningful improvements but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the user decoder\"s information usage, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The lack of context or explanation makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. This question highlights a potential gap in the paper\"s explanation or methodology, prompting the authors to clarify or justify their approach. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies a gap, it lacks actionable feedback, making it 3. The authors are left with a question but without clear direction on how to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement this suggestion or specify how to design the controlled baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of different locations (layers) of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting ICL performance when ablating these heads. It implies that a controlled baseline should be established to ablate heads at different locations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for a controlled baseline to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that location is a confounding factor. The suggestion for a controlled baseline is clear, but the claim itself is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the model\"s performance, specifically the location of induction heads and FV heads within the model. It suggests that a controlled baseline should be established to ablate heads at different locations, which could help clarify the impact of these factors on ICL performance. This feedback is clear and actionable, providing the authors with a specific direction for improving their analysis and experimental design. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or discussed the potential implications of this approach. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under the similarity measurement section, specifying that it should describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, namely to include a section on synonym identification that explains the approach to the multiplechoice task. The comment is explicit and concrete, offering a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"a section on synonym identification\" and specifies that it is missing under the \"similarity measurement\" section. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a section on synonym identification that explains the approach to the multiplechoice task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, specifically regarding the multiplechoice task. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence affects the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the significance of the missing section. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of a section on synonym identification under the similarity measurement section. It specifies that this section should describe how the multiplechoice task is approached, providing a clear and actionable suggestion for improvement. By highlighting this omission, the comment helps the authors understand where their draft needs to be strengthened, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to structure this section. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the comment implies that such an overview would be beneficial, it does not explicitly instruct the authors to include it or provide specific guidance on how to structure this overview. The action is implicit and somewhat vague, as the authors can infer the need for an overview but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, making it weakly grounded. The comment is specific in its suggestion that an overview would be beneficial, but without explicit references to sections or parts of the paper, the authors may struggle to identify where to incorporate this overview. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to structure or present this overview. The authors are left with a general idea of what is needed but without actionable steps to take. Therefore, the comment is 3, as it points out a potential enhancement but does not fully support the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The reviewer suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as the authors need to infer that they should discuss this issue in the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its potential impact, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It argues that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it lacks specific examples or references to support the claim that this issue is not addressed in the paper. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing process, specifically noting the need to know the statistical dimension d_lambda of the design matrix A. It points out that accurately computing this dimension would require the same runtime as solving the ridge regression problem, which could introduce bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment highlights a critical aspect of the methodology, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is 3 as it points out a potential weakness, but it could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3, stating that the expected quantities are scalars but are currently shown as a vector. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are currently shown as a vector. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 should be redefined because the expected quantities are scalars but are currently shown as a vector. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the redefinition of Figure 3. It identifies a particular issue with the figure, noting that the expected quantities are scalars but are currently shown as a vector. This feedback is clear and directly addresses a potential confusion or misrepresentation in the figure, offering a straightforward way for the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided additional context or guidance on how to redefine the figure to better align with the expected quantities. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment implies that the authors should provide empirical evidence and clarify their explanation, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know what needs to be done to address the feedback. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific claim about the usefulness of the proposed models for learning representations for lowfrequency words. It points out the lack of empirical evidence to support this claim and suggests that the authors should provide such evidence. Additionally, it questions the explanation of improvements, particularly regarding the word similarity data sets. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion of the models and their applications. The authors can infer that it relates to the sections where these claims are made, but the comment does not provide explicit references. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have made a reasonable argument about the usefulness of their models for learning representations for lowfrequency words, but they lack empirical evidence to support this claim. The reviewer suggests that the authors should provide empirical evidence to test the hypothesis. Additionally, the comment questions the explanation of improvements, particularly regarding the word similarity data sets. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the explanation is unclear. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis, which is a clear and actionable suggestion. Additionally, the comment questions the explanation of improvements, particularly regarding the word similarity data sets, noting that the explanation does not seem to fully explain the improvements. This feedback is 4 as it provides clear directions for the authors to strengthen their paper by offering empirical evidence and clarifying their explanation. However, it could be more helpful if it offered specific suggestions on how to gather and present this evidence. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the use of global features in the study and suggests that the authors should compare the importance of global features with different resolutions of voxel features. It provides a specific action by recommending that the authors study the importance of global features in Section 4.2 and compare it with different resolutions of voxel features. The comment also suggests that when the resolution is reduced to 1x1x1, it is essentially using a single global feature. This feedback is explicit and provides concrete guidance on how the authors can improve their study by conducting a specific comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to study the importance of global features by comparing them with different resolutions of voxel features. The comment further specifies that when the resolution is reduced to 1x1x1, it is essentially using a single global feature. This level of detail provides clear guidance on what the authors need to address in their study. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of global features in the study, specifically questioning the necessity of using voxellike features due to their high computational and memory cost. The reviewer suggests that the authors should study the importance of global features by comparing them with different resolutions of voxel features. This claim is 3 as it provides a logical reasoning based on the computational and memory costs associated with voxel features. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of global features in the study, specifically questioning the necessity of using voxellike features due to their high computational and memory cost. It suggests that the authors should study the importance of global features by comparing them with different resolutions of voxel features. The comment provides a specific action for the authors to take, which is to conduct a comparison in Section 4.2. This feedback is clear and actionable, offering a concrete way for the authors to improve their study by addressing the computational and memory efficiency of their approach. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment implies that the authors should investigate and present these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and present these trends. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in discerning trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment identifies a potential issue with the table, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to explore trends in the development set provides a direction for improvement but does not offer a comprehensive explanation or evidence to support the need for this exploration. Therefore, the comment is 3, as it provides a suggestion but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This feedback is 3 as it points out a potential weakness in the presentation of results and offers a suggestion for improvement. However, it could be more helpful if it provided specific guidance on how to present these trends or what aspects of the trends are particularly important to highlight. Overall, the comment provides a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the difficulty in understanding Figure 5 due to the clutter of lines. It suggests that the authors could report additional metrics like flops or model size to make the figure more concrete and easier to interpret. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the clarity of their figure and the report, ensuring a direct path to enhancing the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the difficulty in understanding the figure due to the clutter of lines and suggests reporting additional metrics like flops or model size to make the figure more concrete. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to understand due to the clutter of lines and suggests reporting additional metrics like flops or model size to make it more concrete. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to report additional metrics is a logical step to improve clarity, but without further elaboration, the comment remains 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the clutter of lines. It provides a clear suggestion for improvement by recommending that the authors report additional metrics such as flops or model size to make the figure more concrete and easier to interpret. This feedback is actionable and provides a direct path for the authors to enhance the clarity and comprehensiveness of their figure. However, the comment could be more helpful if it included specific examples of how these additional metrics could be incorporated or how they might improve the figure. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that some details of the proposed method are missing, but it does not provide specific guidance on what these details are or how they should be addressed. The comment mentions \"questions section below,\" which implies that the authors should refer to that section for more information, but it does not explicitly instruct the authors to do so. The lack of specific details or actionable steps makes it difficult for the authors to know exactly what needs to be added or clarified. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some details of the proposed method are missing,\" but it does not specify which part of the paper these details are missing from. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in suggesting that details are missing, but without explicit references, it is weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, but it does not provide any specific examples or reasoning to support this claim. Without detailed information or references, the authors may find it challenging to understand what specific details are missing and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting that some details of the proposed method are missing. However, it does not provide any further context, examples, or suggestions on what these details might be or how they could be addressed. This lack of specificity and actionable guidance makes it difficult for the authors to understand the nature of the missing details and how to improve their draft. As a result, the comment is 2, as it provides a general observation but does not offer meaningful feedback or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate the EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that address oversmoothing, like the setting used in GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this evaluation in their study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the EIGNN with respect to oversmoothing under standard settings on realworld datasets, comparing it with variants that address oversmoothing, such as the setting used in GCNII. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate oversmoothing and compare with existing methods, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation of oversmoothing should be conducted under standard settings on realworld datasets, comparing the EIGNN with variants that address oversmoothing, such as the setting used in GCNII. While the comment provides a logical suggestion for further evaluation, it lacks specific references or examples to support the claim that this comparison is necessary or would be beneficial. The suggestion is 3 as it points out a potential area for improvement, but it could be strengthened with more detailed reasoning or references to existing literature. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an interesting direction for evaluating the EIGNN by comparing it with variants that address oversmoothing, such as the setting used in GCNII. This feedback provides a clear and actionable suggestion for the authors to consider, as it highlights a potential area of improvement or differentiation for their work. By evaluating the EIGNN under standard settings on realworld datasets, the authors could gain valuable insights into its performance and contributions. However, the comment could be more helpful if it included specific guidance on how to conduct this evaluation or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for enhancing the study\"s depth and relevance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 is confusing and lacks clarity regarding the meaning of the columns. It specifies that the issue is not addressed in either the text or the caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in Figure 4. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by noting that the meaning of the columns is not clear and is not explained in the text or caption. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, and this is not explained in the text or caption. This is a factual observation rather than a subjective claim or suggestion, as it does not express an opinion or require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing because the meaning of the columns is not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the content of the figure, which is essential for improving the clarity and understanding of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify the figure, such as adding a detailed caption or explaining the columns in the text. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of an ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this lack. The action is implicit, as the authors need to infer that they should include an ablation analysis to better understand the performance gains. However, the comment lacks concrete details on how to conduct the analysis or what specific components should be analyzed. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper should include this analysis or where it should be placed. The authors can infer that it relates to the main paper, but the lack of specific guidance makes it weakly grounded. The comment is specific in identifying the issue of missing ablation analysis and its impact on understanding the performance gain, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of an ablation analysis, which makes it difficult to determine the source of the small performance gain. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to improve the clarity and understanding of their results. By suggesting the inclusion of an ablation analysis, the comment provides a concrete step for the authors to take to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct the analysis or what specific components should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a finding in Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this finding should be addressed or incorporated into the paper. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to Figure 2, providing a specific reference to the part of the paper being addressed, which makes it fully grounded. It also specifies the issue by mentioning the finding that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). This level of detail allows the authors to accurately identify the part of the paper being discussed and understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the findings in Figure 2, which show that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any reasoning, evidence, or references to support the claim that the authors should use \"Th.\" as a result of this finding. Without additional context or justification, the claim remains 1, as it lacks the necessary support to guide the authors in understanding or addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a specific finding from Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions on how this finding should be addressed or incorporated into the paper. Without additional context or guidance, the authors are left without a clear understanding of how to improve their draft based on this observation. Therefore, the comment is 2, as it identifies a potential issue but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a concern with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It suggests that the authors should compare the model trained on the original dataset with that trained on a mixture of the original and adversarial examples to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify their experimental setup to include a comparison with the original dataset. The suggestion is concrete, as it specifies the exact change needed to improve the verifiability of the hypothesis. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental design, suggesting that the authors should compare the model trained on the original dataset with that trained on a mixture of the original and adversarial examples to better highlight the impact of the augmented adversarial examples. This provides clear guidance on how to improve the experiment, making the comment 5.", "verifiability_rationale": "The review point claims that the hypothesis is not wellverified by the designed experiment, specifically noting that the models in conventional methods are trained on the original training set along with generated adversarial examples, while the base model is trained only on the adversarial set. The reviewer suggests that it would be more convincing to compare the model trained on the original dataset with that trained on a mixture of the original and adversarial examples. This claim is 3 as it provides a logical reasoning for the need to improve the experiment, but it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate this suggestion to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It points out a discrepancy in the training of models, where conventional methods are trained on the original training set plus adversarial examples, while the base model is trained only on the adversarial set. The reviewer suggests a more effective comparison by training the model on the original dataset and a mixture of the original and adversarial examples. This feedback is clear and actionable, as it provides a specific and logical suggestion for improving the experiment to better highlight the impact of the augmented adversarial examples. By following this advice, the authors can enhance the verifiability and robustness of their hypothesis. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on what aspects of the experiments are lacking or how they could be improved. Without explicit guidance or concrete steps for the authors to take, the comment lacks actionable information. The authors are left without a clear understanding of what needs to be addressed or how to enhance the convincingness of the experiments. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"CNN experiments,\" but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not precise. The comment is specific in its claim that the CNN experiments are not fully convincing, but it does not provide details on what aspects are lacking or how they could be improved. This lack of specificity makes it difficult for the authors to address the issue effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue or improve the experiments. This lack of justification makes the claim 1, as it does not provide the authors with a basis for understanding or correcting the perceived problem. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a concern with the CNN experiments, stating that they are not fully convincing. However, it does not provide any specific details or examples of what aspects of the experiments are lacking or how they could be improved. Without actionable feedback or suggestions, the authors are left without a clear understanding of what needs to be addressed or how to enhance the convincingness of their experiments. This lack of specificity and guidance makes the comment 2, as it does not effectively guide the authors in improving their draft. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the action is explicit, it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. The authors are given a clear direction to follow but are left to determine the exact steps and details of the comparison. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result section. The authors may infer that it relates to the results or discussion section, but this inference is not explicit. The comment is specific in suggesting a comparison with HateXplain models, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it could enhance the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a specific direction for the authors to enhance their work by comparing their results with established methods. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to structure the comparison or what metrics to use for evaluation. Overall, the feedback is 3 as it points out a potential area for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment implies that the authors should consider using the adaptive method, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method and justify its use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use of freezing, making it weakly grounded. The comment is specific in questioning the rationale behind the use of freezing and suggesting an alternative method, but it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be more appropriate or why freezing is problematic. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on why the adaptive method might be more suitable or how it could be implemented. The feedback is 3 as it prompts the authors to consider alternative methods, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) that examines the robustness of the model by adding negation or changing entities in text. While the comment implies that such an analysis would be beneficial, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should perform a robustness analysis similar to existing work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting a method for evaluating robustness, but without explicit grounding, the authors may struggle to identify the exact section where this analysis should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness. While the comment provides a reference to existing work, it does not offer specific details or examples of how the analysis should be conducted or what aspects of robustness should be evaluated. This lack of detailed guidance makes the claim 3, as the authors would need to infer the exact steps to take based on the reference provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness by adding negation or changing entities in text. This feedback is 3 as it identifies a potential area for improvement and provides a specific reference for the authors to follow. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the analysis or what specific aspects of robustness should be evaluated. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the inconsistency in using p m in the numerator and p c in the denominator in Eq. 3, and the lack of consideration for adding the variance in Alg. 2 for further improvement. It also suggests using \u03bc g instead of \u03bc f for consistency with Eq. However, the comment does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors are left to infer that they need to correct the inconsistency and consider adding the variance, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the use of p m and p c in the equations and suggests adding the variance for further improvement. Additionally, it provides a suggestion to use \u03bc g instead of \u03bc f for consistency with Eq. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims. First, it claims that the use of p m in the numerator and p c in the denominator in Eq. 3 is confusing. This claim is 3 as it points out a potential inconsistency in notation, but it lacks specific reasoning or examples to fully substantiate the claim. Second, the comment suggests that the authors should consider adding the variance in Alg. 2 for further improvement. This suggestion is 3 as it provides a logical reasoning for the addition of variance, but it lacks specific examples or references to support the claim. Overall, the comment is 3 due to the need for more detailed justification and examples.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the inconsistency in notation in Eq. 3 and the lack of variance consideration in Alg. 2. It provides clear and actionable feedback by pointing out the confusion caused by using different symbols for the same variable and suggesting the addition of variance for further improvement. Additionally, it offers a suggestion to use \u03bc g instead of \u03bc f for consistency with Eq, which is a helpful and specific piece of advice. However, the comment could be more helpful if it provided additional context or examples to illustrate the impact of these changes. Overall, the feedback is 4 as it guides the authors in addressing critical issues and improving the clarity and consistency of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for a more comprehensive discussion on the computational complexity of the proposal and questions whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should provide a detailed analysis of the computational cost, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a more thorough discussion of computational complexity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically mentioning the additional cost and its impact on computation. It questions the comprehensiveness of the discussion on computational complexity and raises a concern about the proposal becoming prohibitive in certain settings. However, the comment does not specify which part of the paper discusses computational cost, making it weakly grounded. The authors can infer that it relates to the sections where computational aspects are mentioned, but this inference is not direct. The comment is specific in detailing the need for a more comprehensive discussion and the potential issue of the approach becoming prohibitive. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the comprehensiveness of the discussion on computational complexity, questioning why the additional cost did not lead to \"significant delays in computation.\" It also expresses curiosity about whether the proposed approach becomes prohibitive in some settings. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the discussion is insufficient. The reasoning is based on the reviewer\"s perception of the paper\"s content, which is not fully substantiated with evidence or detailed analysis. Therefore, the claim is 3, as it provides a basis for the concern but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement regarding the discussion of computational cost, noting that the paper does not provide a comprehensive analysis of this aspect. It questions why the additional cost did not lead to significant delays in computation and raises a concern about the proposal becoming prohibitive in certain settings. This feedback is clear and actionable, as it directs the authors to expand their discussion on computational complexity and consider the practical implications of their approach. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these concerns. Overall, the comment is 4 as it highlights a critical area for improvement and offers a direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide more explanation on how novel values in the test set are handled. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the clarity of the paper. The comment does not leave any ambiguity about the action required, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more explanation on how novel values in the test set are handled. This provides clear guidance on what the authors need to do to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more explanation on how novel values in the test set are handled. This is a clear and actionable suggestion that can help the authors clarify their methodology and improve the clarity of their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to handle novel values in the test set. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a missing aspect in the paper, specifically the lack of indepth analysis on experimental results. It questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct a more detailed analysis of the experimental results, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment highlights a missing indepth analysis on experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique, as it identifies a gap in the analysis and provides a clear question for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis on experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an indepth analysis of experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is clear and actionable, as it directs the authors to consider a more detailed analysis of their experimental results to better understand and explain the observed performance differences. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects should be examined. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions for the authors to consider, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. However, the comment does not provide specific guidance on how to implement these suggestions or what constitutes an appropriate number of convolutional layers. While the actions are explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing the actions and improvements needed, but without grounding, it is challenging for the authors to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also questions the effectiveness of the proposed method, citing skepticism about the robustness and domain invariance of similar interventions. However, the comment lacks specific examples or references to support the claim that these actions would be effective or that similar interventions have failed. The suggestion to use modern backbone baselines is somewhat supported by the mention of ResNet50 and DenseNet121, but the overall justification for the claim is weak. Therefore, the comment is considered 2, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. These suggestions are clear and provide specific guidance on how the authors can enhance their work. However, the comment also expresses skepticism about the effectiveness of the proposed method, which is a personal opinion and not directly actionable. Overall, the comment is 4 as it offers valuable insights and actionable steps for improvement, but it could be more comprehensive if it addressed the skepticism aspect. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to achieve this. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of hyperparameters and suggests that the baseline should be fully tuned with the same resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in its suggestion to ensure a fair comparison, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that this is an important consideration, it does not provide specific reasoning or evidence to support why this is necessary. The suggestion is based on common sense and logical reasoning, but without detailed justification or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive use of hyperparameters and the need for a fair comparison. It suggests that the baseline should be fully tuned with the same resources as the proposed method to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the validity of their results. However, the comment could be more helpful if it offered suggestions on how to achieve this tuning or provided examples of similar studies that have addressed this issue. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a discrepancy in the definition of perplexity, stating that it is not what perplexity is and that Eq1 does not resemble perplexity. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should correct this issue or what steps they should follow to address it. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of perplexity and crossentropy, providing clear guidance on what needs to be corrected. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the definitions of perplexity and crossentropy, which are clear and accurate. However, it does not provide any supporting evidence, reasoning, or references to justify why these definitions are incorrect or misleading. Without additional context or examples, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some information but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a discrepancy in the definition of perplexity, pointing out that the explanation provided does not accurately reflect the concept. It also notes that Eq1 does not resemble perplexity, suggesting that it might be a different measure, such as crossentropy. This feedback is specific and actionable, as it highlights a potential error in the paper\"s explanation and provides a clear direction for the authors to correct it. However, the comment could be more helpful if it offered suggestions on how to revise the explanation or provided examples of how to accurately define perplexity. Overall, the comment is 4 as it guides the authors towards improving their draft by addressing a specific issue with the definitions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action that provides specific guidance on what needs to be done to improve the paper. The comment is 5 because it gives the authors a clear path forward in addressing the issue of insufficient baseline comparison in the graph classification task.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and specifies the issue with the lack of sufficient baselines, such as MVGRL4 and gptgnn5. This provides clear guidance on which part of the paper needs attention. The comment is also specific because it suggests adding more baselines of graph contrastive learning and testing them on common datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline comparison in the graph classification task is insufficient, specifically mentioning the absence of MVGRL4 and gptgnn5. The reviewer suggests adding more baselines of graph contrastive learning and testing them on common datasets. While the comment identifies a potential issue with the baseline comparison, it lacks specific examples or references to support the claim that these particular baselines are essential or that their inclusion would significantly improve the study. The suggestion to add more baselines is a logical one, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the baseline comparison in the graph classification task, noting that the current baseline is insufficient. It suggests adding more baselines of graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a specific direction for improving their study by expanding the baseline comparison. By addressing this suggestion, the authors can enhance the robustness and comprehensiveness of their work. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern regarding the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map while still misleading the model. While the comment implies that the authors should conduct this evaluation, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a specific type of adversarial attack. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the evaluation of the proposed strategies, particularly the need to evaluate the defense against an adversarial attack that minimally alters the edge map. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the evaluation against a more realistic adversarial attack scenario. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically regarding the consideration of an adaptive attack against the edge mapbased defense. The reviewer suggests that the evaluation should include an adversarial attack that minimally alters the edge map but still misleads the model. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the current evaluation is insufficient. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map but still misleads the model predictions. This feedback is 5 as it provides a clear direction for improvement, suggesting a more realistic and challenging evaluation scenario. By addressing this concern, the authors can enhance the robustness and effectiveness of their defense mechanisms. The comment is detailed and constructive, offering a specific area for enhancement that can significantly impact the paper\"s quality and relevance. Therefore, it aligns with a score of 5, indicating that the comment is 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to include standard deviations or any other statistical measures to enhance the significance of the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of standard deviations, which makes it difficult to judge the significance of the results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations. This is a critical piece of information as it affects the interpretation and reliability of the results. However, the comment does not provide any guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of standard deviations or other statistical measures to enhance the significance of the results. Without actionable advice, the comment is limited in its usefulness to the authors. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve the quality of the generated images or what specific steps they should consider. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper discusses the generated images or the results, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited realism, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might enhance the realism of their generated images. Without additional context or specific recommendations, the authors may find it challenging to address this issue effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not explicitly instruct the authors to make this correction or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement about Cycle Consistency loss and provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about Cycle Consistency loss is not entirely true, suggesting that it can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This feedback is valuable as it offers a more accurate understanding of the Cycle Consistency loss, which can help the authors improve their explanation or presentation of this concept. However, the comment could be more helpful if it provided additional context or examples to illustrate the correction. Overall, the comment is 4 as it directs the authors to a specific area for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is explicit and provides a concrete action for the authors to take, which is to clarify the terminology or rephrase the text to avoid confusion. The comment is 5 as it directly guides the authors on how to improve their draft by addressing a specific issue with terminology. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used in the paper, specifically the term \"hyperspectral.\" It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is fully grounded as it explicitly mentions the term \"hyperspectral\" and provides a clear explanation of its correct usage. The comment is specific in detailing what is wrong with the current usage of the term, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. The reviewer provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This explanation offers a logical and specific justification for the claim, making it 5. The reviewer\"s reasoning is clear and supported by a detailed explanation, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, pointing out that the term \"hyperspectral\" is confusing. It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is actionable as it guides the authors to clarify their terminology or rephrase the text to avoid confusion. By addressing this issue, the authors can improve the clarity and accuracy of their draft. However, the comment could be more helpful if it suggested alternative terminology or provided examples of how to rephrase the text. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, specifically mentioning the example of combining Linformer and window attention in Big Bird using contrition. While the comment implies that the authors should include such explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for more detailed explanations, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to specific points mentioned in the paper, \"1), 2), and 3) mentioned above,\" which suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. However, it does not explicitly mention which sections or parts of the paper these points are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, providing more detailed explanations of the contributions of each component. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while some ablation studies are provided, it would be beneficial to include more detailed explanations of how each component contributes to the final performance improvements. The comment provides a specific example, \"how the performance of simply combining the Linformer and the window attention in BigBird using contrition,\" which could be used to illustrate the point. However, the comment does not provide detailed reasoning or evidence to support why this additional explanation is necessary, making it 3. The authors would need to infer the importance of this additional information, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that while some ablation studies are provided, it would be beneficial to include more detailed explanations of how each component contributes to the final performance improvements. The comment provides a specific example, \"how the performance of simply combining the Linformer and the window attention in BigBird using contrition,\" which could be used to illustrate the need for additional explanations. This feedback is clear and actionable, as it directs the authors to provide more detailed insights into the contributions of each component. However, the comment could be more helpful if it offered suggestions on how to structure or present these explanations. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the \"w/o perception\" model, and the questionable significance of the improvements based on the sample size. While the comment identifies these issues, it does not provide specific guidance or suggestions on how the authors should address them. The lack of actionable steps or detailed advice makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the \"w/o perception\" model, and the questionable significance of the improvements based on the sample size. It also mentions Table 10, which is a specific part of the paper. This provides full grounding as the authors can accurately identify the sections being addressed. The comment is also specific because it details what needs to be addressed, such as the need for explicit verification and detailed implementation information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several concerns about the paper, including the lack of explicit verification of the effectiveness of the visual information, unclear implementation details, and questionable significance of the improvements based on the sample size. The reviewer provides specific examples, such as mentioning Table 10 and the \"w/o perception\" model, which helps the authors understand the issues. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim about the questionable significance of the improvements. Overall, the comment is 4 due to its specific examples and logical reasoning, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, unclear implementation details, and questionable significance of the improvements based on the sample size. It provides specific examples, such as mentioning Table 10 and the \"w/o perception\" model, which helps the authors understand the areas needing improvement. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as proposing specific experiments or analyses to clarify the effectiveness of the visual information. Overall, the comment is 4 as it highlights important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation used for results, specifically questioning what \"%p\" stands for in the context of the paper\"s claims about the improvement on CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights a specific area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results\" and specifically questions the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This provides clear guidance on where the authors need to clarify their notation. The comment is specific because it identifies the exact part of the paper that needs clarification and what aspect of the notation is unclear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of notation in the paper, specifically regarding the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual observation about the clarity of notation, which is a matter of fact and does not require evidence or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation in the paper, specifically questioning the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This feedback is clear and actionable, as it points out a potential source of confusion for readers. By highlighting this issue, the authors are prompted to clarify their notation, which is an important step in improving the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered alternative ways to express the results. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point critiques a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It explicitly states that the claim is incorrect and provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime or for a finite linear combination of arbitrary random variables. This feedback is explicit and provides concrete details on how the authors can correct their understanding or presentation of the CLT. The authors are given a clear and actionable path to improve their draft by addressing the inaccuracies in their claim. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides detailed reasoning and examples to support the claim that the statement is incorrect, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This critique is supported by logical reasoning and specific references to the limitations of the CLT, making the claim 5. The authors would benefit from this feedback as it provides a clear understanding of the limitations of their claim and how to correct it. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper regarding the Central Limit Theorem (CLT) and provides a detailed critique of its accuracy. It explains that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is 5 as it not only points out a potential error in the paper but also provides a clear and actionable correction. By addressing this issue, the authors can improve the accuracy and clarity of their work. The comment is specific and provides a detailed explanation, making it valuable for enhancing the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for improvement and gives a clear direction on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action required, which is to analyze the time complexity of the proposed policies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to analyze the time complexity of the proposed policies mentioned in Section 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional analysis, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is specific and provides a direct path for the authors to improve their draft by addressing a critical aspect of their work. However, it could be more helpful if it included additional guidance on how to conduct the analysis or what specific aspects of the time complexity should be considered. Despite this, the comment is 4 as it offers a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative metrics they should use. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their choice of metrics. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the human evaluation section. The comment is also specific because it clearly specifies the issue with the use of TSS and suggests that this choice weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation weakens the convincingness of the evaluation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is problematic or how it affects the evaluation\"s credibility. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the human evaluation process, specifically questioning the use of an automatic metric, TSS, instead of a human metric for evaluating style control. This observation is relevant as it could impact the credibility and effectiveness of the evaluation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. Without actionable feedback or detailed recommendations, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. While the comment implies that the authors should expand their experiments to cover a broader range of domains, it does not provide explicit guidance on how to achieve this or which specific domains to include. The action is somewhat implicit and lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. However, the comment does not specify which part of the paper these experiments are in or how they relate to the broader discussion. The authors can infer that it pertains to the experimental section, but the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting that more diverse domains should be explored, but without detailed guidance, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains. However, the comment does not provide any specific reasoning, examples, or references to support the claim that more diverse domains would strengthen the paper. Without additional justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the experiments effectively prove the authors\" point but suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors expand their experiments to cover a broader range of domains. However, the comment lacks specific guidance on how to implement this suggestion or which additional domains might be relevant. To be more helpful, the comment could provide examples of diverse domains or suggest specific areas where the experiments could be expanded. Overall, the feedback is 3 as it points out a potential enhancement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve surprisingly good accuracy, rather than proposing novel techniques. While the comment identifies a potential area of contribution, it does not provide explicit guidance or suggestions on how the authors might enhance their paper to better highlight this contribution or differentiate it from previous work. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to address the critique. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the design of the LUQ and the approaches in Section 5, providing a clear indication of the parts of the paper being discussed. It specifies that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it does not specify what aspects of the design or approaches are unclear or need improvement, nor does it provide detailed feedback on how the authors might enhance their contribution. While the comment is fully grounded in terms of identifying specific sections, it lacks specificity in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve good accuracy, rather than proposing novel techniques. While the comment provides some logical reasoning by pointing out the standard nature of the approaches, it lacks specific references or detailed examples to fully substantiate the claim. This makes the claim 3, as it provides a general idea but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the design of the LUQ is straightforward and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve good accuracy, rather than proposing novel techniques. This feedback provides a clear perspective on the paper\"s contribution and highlights an important aspect of the work that the authors might not have considered. However, the comment could be more helpful if it offered specific suggestions on how the authors might emphasize this contribution or differentiate their work from previous literature. Overall, the comment is 3 as it identifies a potential area of contribution but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. The authors are informed that this might affect the fairness of comparisons with other methods. However, the comment does not provide explicit guidance on how to address this issue or suggest ways to mitigate the impact on the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should consider the impact on running speed and fairness in their comparisons. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. It also mentions that this might affect the fairness of comparisons with other methods. However, the comment does not specify which part of the paper discusses the training process or the comparison with other methods, making it weakly grounded. The comment is specific in identifying the issue with the training speed and its potential impact on fairness, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speeds and an unfair comparison with other methods. The reviewer provides a logical reasoning by stating that the increased sample rate might affect the fairness of the comparison. However, the comment lacks specific examples or references to support the claim about the impact on fairness, making it 3. The authors would need to infer the potential implications of this observation, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speeds. The authors are informed that this might affect the fairness of comparisons with other methods. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the comparison. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This question provides a clear and direct action for the authors to take, namely to explore the assumptions needed for relaxation and the potential outcomes of partial coverage. The comment is explicit and concrete, guiding the authors on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly references a previous remark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration and what would happen if they partially cover them. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification or further exploration of a specific aspect of the paper, rather than a claim or suggestion that requires verification. It does not contain any subjective opinions, judgments, or requests for changes that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a continuation of a previous remark, asking the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This feedback provides a clear and actionable direction for the authors to explore, offering insights into potential improvements or alternative approaches. By prompting the authors to consider specific assumptions and their implications, the comment encourages them to delve deeper into the problem and potentially enhance the robustness of their methodology. However, the comment could be more helpful if it included specific suggestions or examples of assumptions that could be relaxed or how partial coverage might affect the results. Overall, the comment is 4 as it guides the authors towards a direction of improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of the proposed technique across tasks with varying reasoning requirements. While the comment implies that additional datasets should be included, it does not specify which datasets should be used or how they should be integrated into the paper. The action is somewhat explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on generalizability. The authors may infer that it relates to the experimental results or the conclusion, but this inference is not explicit. The comment is specific in its suggestion to include more datasets, but the lack of grounding makes it difficult for the authors to pinpoint the exact section where this feedback should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, the comment does not provide any specific reasoning or evidence to support why these datasets are particularly relevant or why including them would enhance the generalizability of the technique. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it provides a specific direction for enhancing the paper\"s experimental validation. However, it lacks detailed guidance on which datasets to include or how to integrate them into the analysis, which could limit its effectiveness. The comment highlights an important aspect of generalizability that the authors should consider, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It explicitly recommends comparing the methods to existing baselines, such as RefNeRF, which contains appearance decomposition, and MipNerf for larger outdoor scenes. This feedback provides clear and concrete actions for the authors to take, specifying which baselines to consider and why. The comment is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are specific suggestions. However, the comment does not explicitly mention which part of the paper this evaluation should be applied to, making it weakly grounded. The authors can infer that it pertains to the evaluation section or methodology, but this inference is not direct. The comment is specific in suggesting which baselines to consider, making it specific in terms of content. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are specific suggestions. However, the comment does not provide detailed reasoning or evidence to support why these particular baselines are more suitable or why the current choice is inadequate. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting improvements to the choice of baseline methods, particularly for evaluating the appearance decomposition part. It recommends comparing the methods to existing baselines, such as RefNeRF and MipNerf, which are specific suggestions that could enhance the evaluation and validation of the proposed approach. This feedback is clear and provides concrete guidance for the authors to improve their draft, making it 5. However, it could be more helpful if it included additional context or reasoning about why these specific baselines are recommended. Overall, the comment is 4, as it offers valuable insights and suggestions for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide more implementation details of the proposed methods, which is a clear and direct action for the authors to take. It specifies the section where this information should be included, making the action concrete and actionable. The authors know exactly what needs to be done to address the concern, which is to add more details in Section 4.1. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4.1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of implementation details of the proposed methods, which is a clear and specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details in the paper is a significant issue, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples or reasoning to support why this is a concern or how it affects the paper\"s comprehensibility or reproducibility. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for reproducibility and understanding of the work. It provides a clear and actionable suggestion by specifying that the implementation details should be included in Section 4.1. This feedback is valuable as it guides the authors on what needs to be addressed to improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance or examples of what specific implementation details should be included. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the paper, noting that there is no empirical evaluation and no comparison with other methods. It emphasizes the lack of practical value and suggests that the paper is not suitable for publication at NeurIPS without addressing these concerns. While the comment identifies a critical gap in the paper, it does not provide specific guidance on how to address these issues or improve the empirical evaluation. The authors are left with a general understanding of what needs to be done but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it points out a significant problem but lacks detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation and the absence of comparisons with other methods, noting that it is unclear what the practical value of the contribution is. It also critiques the paper for not providing a theoretical argument for its significance, suggesting that it is not suitable for publication at NeurIPS in its current form. However, the comment does not specify which sections of the paper lack empirical evaluation or comparisons, making it weakly grounded. The feedback is specific in identifying the need for empirical evaluation and theoretical justification, but without explicit references to sections, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. The reviewer suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The claim is 3 as it points out a significant gap in the paper\"s evaluation and comparison, but it lacks specific examples or references to other works for comparison. The authors would need to infer the extent of the critique and the potential improvements, making the claim 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that there is no empirical evaluation or comparison with other methods, which makes it difficult to assess the practical value of the contribution. It suggests that even a theoretical paper should attempt to justify its significance, which is not addressed in the current submission. While the comment highlights a significant gap in the paper, it does not provide specific guidance on how to conduct empirical evaluations or comparisons, nor does it offer suggestions on how to improve the theoretical contributions. The feedback is 3 as it points out a critical area for improvement but lacks detailed actionable advice, leaving the authors with a general understanding of what needs to be addressed but without specific steps to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL 1 and asks whether the algorithms can be applied in more general tasks. While the comment implies that the authors should consider expanding the scope of their work, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not specify which part of the paper discusses the limitations to navigation problems or the potential applications in general tasks. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestion to explore broader applications, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is limited to navigation problems or that combining RL and planning has already been discussed in PRMRL. The reference to PRMRL provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. This feedback is 3 as it points out a limitation of the paper\"s scope and suggests a potential direction for future work. However, it lacks specific guidance on how the authors might expand their work to address this limitation or how to integrate the mentioned related work. The comment could be more helpful with additional details or suggestions on how to explore broader applications. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether all feature spaces are wellsuited for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends that if feature dimensions are individually standardized, this issue can be avoided. While the comment implies that the authors should consider these factors, it does not explicitly instruct them to make these considerations or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the need for these considerations and how to address them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether all feature spaces are wellsuited for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment further provides a recommendation to avoid this issue by individually standardizing feature dimensions. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the suitability of feature spaces for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends that individual standardization of feature dimensions could address this issue. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the performance of feature spaces. This makes the claim 3, as the authors would need to explore the reasoning further to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the suitability of feature spaces for 1NN and suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends that individual standardization of feature dimensions could address this issue. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how to implement this recommendation. The feedback is 3 as it highlights an area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional baselines, such as those mentioned in the related work section, would enhance the paper. It also acknowledges that the authors\" response addressed the reviewer\"s concerns and raised the score. However, the comment does not provide explicit instructions on how to include these baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing any remaining unclear parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the reviewer\"s concerns. It also mentions that the unclear parts have been answered and that the authors explained why the chosen baseline makes sense. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and clarify the chosen baseline, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the reviewer\"s concerns. It also mentions that the unclear parts have been answered and that the authors explained why the chosen baseline makes sense. However, the comment does not provide specific examples or detailed reasoning to support the claim that including these additional baselines would be beneficial. The mention of the authors\" response addressing the concerns is a positive aspect, but without further justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including additional baselines in the paper, such as those mentioned in the related work section, which could enhance the comprehensiveness of the study. It acknowledges that the authors\" response addressed the reviewer\"s concerns and raised the score. However, the comment lacks specificity regarding which baselines should be included or how they would improve the paper. Additionally, it does not provide detailed guidance on how to incorporate these suggestions or what specific aspects of the paper need further clarification. While the comment identifies an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280. However, it does not provide any guidance or suggestions on how to address this issue or clarify the meaning of the phrase. The comment lacks explicit or implicit actions for the authors to take, making it 1. Without concrete steps or suggestions, the authors are left without a clear understanding of how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280 is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this particular use of the word is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in a sentence on line 280, noting that it is difficult to understand. While it points out a potential clarity issue, it does not provide any suggestions or guidance on how to address this problem or improve the sentence\"s clarity. Without actionable feedback or examples of alternative phrasing, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it highlights a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this limitation or what specific aspects they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the limitations of the method, but without grounding, it is challenging for the authors to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the limitations of the method, specifically in the context of the graph case where the network was shallow. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any additional context, analysis, or suggestions on how the authors might address this limitation or improve their work. The comment lacks actionable feedback or guidance, leaving the authors without a clear direction for enhancing their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the work would be more convincing if it were also evaluated in machine translation, as this would provide a more comprehensive assessment of the proposed method. However, the comment does not provide specific guidance on how to implement this evaluation or what aspects of machine translation should be considered. The action is implicit and somewhat vague, as the authors can infer the need for additional evaluation but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning the use of answer generation and summarization as conditional generation tasks. However, it does not specify which part of the paper discusses these tasks or how they are evaluated, making it weakly grounded. The comment is specific in suggesting that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work\"s evaluation is limited because it only uses answer generation and summarization, which are more akin to opendomain generation rather than closedomain tasks like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This claim is 3 as it provides a logical reasoning based on the nature of the tasks and their relationship to opendomain and closedomain generation. However, the comment could be strengthened by providing specific examples or references to support the claim that machine translation is a more suitable evaluation metric. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are more akin to opendomain generation rather than closedomain tasks like machine translation. The reviewer suggests that evaluating the method in machine translation would provide a more comprehensive assessment, as machine translation exhibits lower uncertainties per word. This feedback is clear and actionable, as it points out a specific area for improvement in the evaluation of the proposed method. However, the comment could be more helpful if it provided additional guidance on how to conduct the machine translation evaluation or what aspects of machine translation would be most relevant. Overall, the comment is 4 as it directs the authors to a potential enhancement in their evaluation strategy."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dropping rate and the number of masks generated for the dropout technique. While it does not explicitly instruct the authors to provide this information, the question is clear and specific, allowing the authors to understand what additional details are needed. The comment is 3 because it provides a direct question that the authors can address, but it does not offer explicit instructions on how to implement the action. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and references the response letter, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dropout technique, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout technique, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the clarity and completeness of their explanation. By addressing this question, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific aspects of the dropout technique could be further elaborated upon. Overall, the comment is 4 as it directs the authors to a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justifications. It provides a clear action by suggesting that the authors should compare their approach with other singlestage attacks and provide proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This guidance is concrete and provides a direct path for the authors to improve their draft by offering specific comparisons and benchmarks. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the effectiveness of the proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for further justifications and comparisons with other singlestage attacks and SOTA algorithms. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justifications, as only showing the performance drop on fusion models is not sufficient. The reviewer suggests comparing the approach with other singlestage attacks and providing proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This claim is supported by logical reasoning, as it highlights the importance of comprehensive comparisons to validate the effectiveness of the proposed approach. However, the comment could be strengthened by providing specific examples or references to similar studies that have effectively demonstrated the effectiveness of their methods. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justifications of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is not sufficient and suggests comparing the approach with other singlestage attacks and providing proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms. This feedback is clear and actionable, as it provides specific guidance on how the authors can strengthen their paper by offering additional comparisons and justifications. However, the comment could be more helpful if it included specific examples or references to similar studies that have effectively demonstrated the effectiveness of their methods. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusing sentence in the paper and suggests that it is not immediately clear what is meant. The reviewer provides context by mentioning that they understood it after rereading it and subsequent sentences, but this does not offer explicit guidance on how the authors should address the confusion. The comment implies that the authors should clarify the sentence, but it lacks concrete suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, \"9395,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the sentence is confusing and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence is confusing, but it does not provide any specific reasoning, examples, or references to support this claim. The reviewer mentions that they understood it after rereading it and subsequent sentences, but this does not substantiate the claim. Without additional context or evidence, the comment lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence in the paper that is confusing and suggests that it is not immediately clear what is meant. While it acknowledges that the reviewer understood it after rereading, the comment lacks actionable feedback or suggestions on how the authors might clarify the sentence. Providing a clearer explanation or rephrasing could be beneficial for the authors. Therefore, the comment is 3, as it highlights an area of confusion but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Fig 1 and Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This comment implies that the authors should ensure consistency between the figures, but it does not explicitly instruct them to make the necessary changes or provide specific guidance on how to achieve consistency. The action is implicit and somewhat vague, as the authors need to infer that they should correct the inconsistency between the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the inconsistency between the figures, noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between two figures, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This observation is factual and does not require any supporting evidence or reasoning. It is a straightforward comparison of two figures, making it a normal statement without a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy between two figures, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback is clear and actionable, as it points out a specific inconsistency that needs to be addressed. By highlighting this issue, the authors can ensure consistency in their figures and potentially improve the clarity of their presentation. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or if it pointed out the implications of this discrepancy on the overall understanding of the paper. Despite this, the comment is 4 as it directs the authors to a specific area that requires attention, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, as it appears from Equation 2 that only neighboring nodes are attended to based on the description of N_l^(s). However, the comment does not provide any explicit guidance or suggestions for the authors to address this issue. It lacks concrete actions or detailed instructions on how the authors might investigate or modify their approach to address this concern. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in the equation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in Equation 2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the question. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the attention mechanism in the paper, questioning whether each node can attend to its own lowerlevel representation. This is a relevant and detailed inquiry that prompts the authors to clarify or potentially revise their approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It suggests that the authors facilitate the reading by explaining how Lemma 7 is relevant to the current inequality. This request is clear and specific, providing the authors with a direct action to take. The comment also offers a concrete suggestion on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of how the inequality follows from Lemma 7. The comment provides a clear and direct action for the authors to take, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the derivation of an inequality from Lemma 7, suggesting that it may follow from a combination of previous inequalities. The comment requests clarification on how Lemma 7 is relevant to the current inequality. While the comment identifies a potential issue with the logical flow, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is 3, as it provides a logical basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, questioning the derivation of an inequality from Lemma 7. It suggests that the authors clarify how this inequality follows from the lemma, which is a logical step to improve the clarity and coherence of the paper. By pointing out this gap in the logical flow, the comment provides a clear and actionable suggestion for the authors to enhance the readability and understanding of their work. However, it could be more helpful if it offered additional guidance or examples on how to address the issue. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the main contribution of the paper and the proposed method\"s ability to cope with dynamic largescale multitasking. It also questions the applicability of the method and the process of automation. However, the comment does not provide specific guidance or suggestions on how the authors might clarify these points or improve their draft. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically mentioning the proposed method\"s novel properties and the main idea of how it copes with dynamic largescale multitasking. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the main contribution and the proposed method\"s applicability and automation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability and applicability are overstated or not wellsupported. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references to other works or detailed explanations of what aspects are unclear or overstated. This makes the claim 3, as the authors would need to infer the basis of the critique, but it lacks the depth and specificity required for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the proposed method\"s novel properties are either overstated or not wellsupported. It also points out that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear, and the process of automation is not wellexplained. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out critical areas that need clarification, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim of using an \"annotation guideline\" and suggests that it may be an overstatement. It provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve their claim. The action is implicit and vague, as the authors are left to infer that they need to clarify or substantiate their claim about using an annotation guideline. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim and references a specific example from the TACRED slot filling guidelines. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the complexity of annotation guidelines in the IE domain and provides an example to illustrate the depth of true guideline understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim of using an \"annotation guideline\" by pointing out that the paper only considered label name, label description, and fewshot examples, while neglecting the complexity and depth of annotation guidelines in the IE domain. It provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines, such as the rule regarding \"GPEs below the city level.\" This provides a clear and detailed explanation of the claim, making it 5. The authors are given a concrete example and reasoning to support the critique, allowing them to address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper\"s claim of using an \"annotation guideline.\" It points out that the paper only considered label name, label description, and fewshot examples, while neglecting the complexity and depth of annotation guidelines in the IE domain. The comment provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines, such as the rule regarding \"GPEs below the city level.\" This feedback is clear and actionable, as it directs the authors to consider the depth and complexity of annotation guidelines in their work. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provide additional context. Overall, the comment is 4, as it offers valuable insights for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the existing BERTbaseline comparison. This provides a clear and direct action for the authors to take, specifying what additional comparisons are needed to strengthen the experiment section. The feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment comparison,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparing the method to token pruning and token combination baselines, in addition to the existing BERTbaseline comparison. This provides clear guidance on how to enhance the experiment section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. The reviewer suggests that the authors should also compare their method to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need to expand the comparison, but it lacks specific examples or references to support the suggestion. The authors would need to infer the relevance of token pruning and token combination baselines to their work, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section of the paper, noting that the comparison is weak because it only compares the proposed method to the BERTbaseline. It provides a clear and actionable suggestion by recommending that the authors should also compare their method to token pruning and token combination baselines. This feedback is valuable as it guides the authors on how to strengthen their experimental evaluation, making the comment 4. However, it could be more helpful if it included specific guidance on how to conduct these additional comparisons or what aspects to focus on when comparing the methods. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not address the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what specific weaknesses should be considered or how they should be addressed. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of discussion on the weaknesses of the proposed model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing (an exploration of weaknesses), it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their work by addressing the possible weaknesses of the proposed model. However, it lacks detail and does not provide any guidance on what specific weaknesses should be considered or how they might be addressed. This limits the usefulness of the feedback, as it does not offer actionable steps or suggestions for improvement. Therefore, the comment is 2, as it provides a general direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. While the comment highlights a potential issue with the paper\"s lack of context and comparison, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a related work section and compare their system with other extractthengenerate methodologies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It also points out the absence of a related work section and suggests that the paper lacks a comparison with other extractthengenerate approaches. However, the comment does not specify which part of the paper should include a related work section or how the comparison should be made. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific enough to provide clear guidance on what needs to be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. However, the comment does not provide specific examples or references to support the claim that the methodology is not novel or that the paper lacks a related work section. This makes the claim 3, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It questions the lack of a related work section and suggests that the paper does not compare its system with other extractthengenerate approaches. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and encourages the authors to include a related work section and compare their system with existing methodologies. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of related work to include. Overall, the comment offers some guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The suggestion is vague and lacks concrete guidance on how to implement these ideas. The authors are left to infer that they should explore these directions, but without specific instructions, the action remains implicit and somewhat vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, it does not specify which part of the paper this feedback pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestions for alternative approaches but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, the comment does not provide specific evidence, examples, or references to support the claim that training a large number of models is impractical or that the suggested alternatives are more effective. The reasoning is based on a general observation rather than detailed analysis or evidence, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. This feedback is 3 as it identifies a potential issue with the current approach and provides suggestions for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback offers a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. While the comment implies that more work on GLN should be included, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate this information. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, it does not specify which part of the paper the introduction of related work is located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in suggesting that more information on GLN should be included, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, the comment does not provide specific examples or references to support the claim that the introduction is insufficient or how GLN should be discussed. This lack of detailed justification or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommending the inclusion of more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. This feedback is clear and actionable, providing the authors with a specific area to focus on for improvement. By suggesting a more detailed discussion on GLN, the comment offers a concrete direction for enhancing the paper\"s comprehensiveness and depth. However, it could be more helpful if it provided examples or specific references to guide the authors in expanding their discussion. Overall, the comment is 4, as it effectively directs the authors to improve a critical aspect of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a correction in terminology, changing \"hypers\" to \"hyperparameters.\" It also questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. However, the comment does not provide explicit guidance on how the authors should address this issue or why it is important to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or justify the use of different dropout parameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests a correction in terminology and questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the use of different dropout parameters, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a correction in terminology and questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is important or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a correction in terminology, changing \"hypers\" to \"hyperparameters,\" and questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. While the comment identifies a potential inconsistency in terminology and methodology, it lacks specific guidance or suggestions on how the authors should address this issue or why it is important to make this change. The feedback is 3 as it points out a potential area for clarification, but it does not provide detailed or actionable advice, leaving the authors with limited guidance on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This suggestion provides a clear and concrete action for the authors to take, as it specifies the type of experiments that would be beneficial and offers a solution. The feedback is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This provides a clear and specific suggestion for the authors to conduct additional experiments. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as the experimental section or specific results. While the authors can infer that it relates to the experimental results, the comment lacks full grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether this was due to a lack of time or scalability issues. The suggestion to conduct experiments on simple videogame domains provides a specific example of a domain that could be explored. However, the comment lacks detailed reasoning or evidence to support the claim that the method has severe scalability issues. While the suggestion is logical, it could be strengthened with more detailed justification or references to similar studies. Therefore, the comment is 3, as it provides a clear suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s experimental setup by questioning the absence of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. This is a valid concern as it could affect the scalability of the method. The reviewer suggests that conducting experiments on simple videogame domains, which have a lowcardinality discrete state and actionspace, would provide convincing evidence of the method\"s scalability. This feedback is clear and actionable, as it provides a specific suggestion for additional experiments that could significantly enhance the paper\"s credibility and impact. However, the comment could be more helpful if it included specific examples of videogame domains that would be suitable for these experiments. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific metrics or methods to quantify the extent of occupation bias. Without concrete instructions or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement for the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement for the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, as it points out a gap in the analysis that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to quantify this bias or examples of similar studies that have successfully measured it. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what steps to take to improve the clarity of the method. As a result, the authors are left without any actionable steps to follow, making this comment 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the effectiveness of the method but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is simple but unclear why it is effective. However, it does not provide any specific evidence, examples, or references to support this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is simple but unclear why it is effective. However, the comment lacks actionable feedback or suggestions on how the authors might address this issue or improve the clarity of their method. Without specific guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential weakness but does not provide actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speeds between different methods. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is 5 as it offers concrete steps for the authors to take to enhance their work.", "grounding_specificity_rationale": "The comment suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speeds between different methods. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental setup or methodology. The authors can infer that it relates to the data used in the experiments or the comparison of methods. The comment is specific in detailing what needs to be addressed, such as the choice of data and the need for inference speed comparisons. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using real dicom images instead of png images for experiments and recommends the FastMRI challenge dataset for comparison. It also suggests comparing inference speeds between different methods. While the comment provides a logical reasoning for using dicom images and the FastMRI dataset, it lacks specific examples or references to support the claim that dicom images are more suitable or that the FastMRI dataset is a good choice. The suggestion to compare inference speeds is clear, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of real dicom images instead of png images for experiments, which is a relevant and practical improvement. It also recommends the FastMRI challenge dataset for comparison, which can enhance the relevance and applicability of the study. Additionally, the comment suggests comparing inference speeds between different methods, which is a valuable addition to the experimental evaluation. This feedback is clear and provides the authors with concrete steps to improve their draft, making it 4. However, it could be more helpful if it included specific guidance on how to implement these suggestions or examples of how to compare inference speeds. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what implications it might have for their work. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model already associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or details about the implications or potential issues this scenario might introduce. Without clear grounding and specificity, the authors cannot effectively address the question or understand what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving a CAD model associated with spatiallyvarying BRDF maps. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of having a CAD model already associated with spatiallyvarying BRDF maps. While it identifies a potential area for exploration or consideration, it does not provide any guidance or suggestions on how the authors might address this issue or what implications it might have for their work. The comment lacks actionable advice or specific recommendations, making it difficult for the authors to use this feedback to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it implies that additional evaluation is needed, it does not explicitly instruct the authors to conduct these evaluations or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for more evaluation but lack specific instructions on what to evaluate or how to structure the additional analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, nor does it provide detailed guidance on what specific aspects of the evaluation should be expanded upon. The authors can infer that it relates to the evaluation section, but the lack of explicit mention of a section or specific elements makes it weakly grounded. The comment is specific in suggesting additional evaluation scenarios, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, the comment does not provide any specific reasoning, examples, or references to support why these scenarios are particularly important or why additional evaluation would be valuable. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it identifies a specific area where additional analysis could be conducted, it lacks detailed guidance on what specific aspects of the evaluation should be expanded upon or how to structure this additional analysis. The comment provides a general direction for improvement but does not offer actionable steps or detailed suggestions, making it 3. The authors are given a direction to consider but are left to determine the specifics of the additional evaluation themselves. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparison in Table 2, specifically regarding the use of different amounts of data in various comparisons. It suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H, which use less data than H>N+B. However, the comment does not explicitly instruct the authors to make these comparisons or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparisons to ensure they are made on equal footing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in the table, noting that comparisons should be made between using the same amount of data. The reviewer provides examples of comparisons that are not made on equal footing, such as H>N and H>B, or H>N>H and H>N>H, which use less data than H>N+B. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparison in Table 2, specifically questioning the validity of comparing different amounts of data. The reviewer suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H, which use less data than H>N+B. However, the comment lacks specific examples or references to support the claim that these comparisons are not valid. While the reviewer provides a logical reasoning for their concern, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2, questioning the validity of comparisons made between different amounts of data. It suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H, which use less data than H>N+B. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting how the comparisons should be made more consistent. However, the comment could be more helpful if it offered additional guidance on how to adjust the table or what specific changes should be made to ensure the comparisons are valid. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two issues: the counterintuitive placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps in the text. The first comment suggests that the authors should clarify the iterative process, particularly for larger iterations T, which is a concrete suggestion for improvement. However, the second comment about the lack of reference to Laplacian eigenmaps is not explicitly actionable, as it does not provide guidance on how to address this issue. The authors may infer that they need to include a reference to Laplacian eigenmaps, but the comment lacks specific instructions on where or how to incorporate this reference. Therefore, the comment is 4, as it provides a clear action for the first issue but lacks specificity for the second issue.", "grounding_specificity_rationale": "The comment addresses two separate issues: the placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first part of the comment is fully grounded as it explicitly mentions \"Line 224,\" allowing the authors to accurately identify the section being addressed. However, the second part of the comment is 1, as it does not specify which part of the paper lacks a reference to Laplacian eigenmaps. This makes the comment 2, as the authors cannot confidently determine the exact sections needing attention. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point raises two issues: the counterintuitive placement of an addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first claim about the counterintuitive placement is 3 as it suggests that the iterative process should be explained more clearly, particularly for larger iterations T. However, the comment lacks specific examples or references to support this claim, making it 3. The second claim about the lack of reference to Laplacian eigenmaps is not supported by any evidence or reasoning, making it 1. Therefore, the overall verifiability of the comment is 2.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the counterintuitive placement of an addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first point is 3 as it highlights a potential confusion for readers regarding the iterative process, suggesting that the authors should clarify this aspect. However, the comment lacks specific guidance on how to address this issue, such as providing examples or suggesting alternative explanations. The second point about the lack of reference to Laplacian eigenmaps is not addressed, leaving the authors without actionable feedback. Overall, the comment provides some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 2.1 is unnecessary because it discusses Batch Normalization and Conditional Batch Normalization (CBN), which are general techniques. The reviewer also recommends that the description of the proposed methodology should be independent of the choice of model and suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and how they present their methodology, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should restructure their presentation to better motivate the CBN approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of Section 2.1, suggesting that the description of the proposed methodology is independent of the choice of model and recommending that the time spent on describing the ResNet architecture be used to provide greater motivation and intuition for the proposed CBN approach. This feedback is detailed and actionable, providing clear guidance on how the authors might improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2.1 is unnecessary because Batch Normalization and Conditional Batch Normalization are general techniques, and the description of the proposed methodology is independent of the choice of model. The reviewer suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment provides a logical argument for the redundancy of Section 2.1, it lacks specific examples or references to support the claim that the description of the proposed methodology is independent of the choice of model. This makes the claim 3, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Section 2.1, suggesting that the discussion of Batch Normalization and Conditional Batch Normalization is general and does not add significant value to the paper. It also recommends that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by focusing on the proposed methodology rather than general techniques. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition for the CBN approach. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix in equation (1) and how it relates to the expectation of sparsity. While the comment highlights a potential inconsistency, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or correct the assumption regarding sparsity. However, the comment lacks concrete details on how to implement this correction, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying by a dense projection matrix and its implications on the resulting matrix being sparse. The comment clearly specifies what needs to be addressed, namely, the expectation of sparsity and the potential inconsistency with multiplying by a nicelyconditioned matrix. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix and its implications on the resulting matrix being sparse. The reviewer suggests that multiplying by a nicelyconditioned matrix should result in a dense matrix, which contradicts the expectation of sparsity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is logical but requires more detailed justification or evidence to be 5. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises a specific question about the assumption of multiplying by a dense projection matrix in equation (1) and its implications on the resulting matrix being sparse. It points out a potential inconsistency and suggests that the multiplication by a nicelyconditioned matrix should result in a dense matrix, which contradicts the expectation of sparsity. While the comment identifies a potential issue, it does not provide detailed guidance or suggestions on how the authors might address this concern or clarify their assumptions. The feedback is 3 as it highlights a potential area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It also provides a reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should revisit and possibly revise their statement about initialization, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should make a more careful statement and consider the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"initialization\" and references a specific work by Kunstner, Hennig, and Balles (2019), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about initialization should be more carefully stated, referencing a specific work by Kunstner, Hennig, and Balles (2019) as a source of evidence. This provides a clear and specific reference to support the claim, making it 5. The authors can easily understand the basis of the claim and the need for a more careful statement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It provides a specific reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is valuable as it directs the authors to a source of information that can help them better understand and address the issue. However, the comment could be more helpful if it provided additional context or guidance on how to incorporate this reference into the paper or improve the statement about initialization. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. First, it highlights the lack of clarity regarding how named entities were extracted from the datasets, which is an explicit action for the authors to address. Second, it suggests that an Englishproofreading would significantly improve the readability of the paper, providing a concrete and actionable suggestion for improvement. However, the comment does not specify which parts of the paper need Englishproofreading or how it would enhance readability. While the actions are clear, the lack of detailed guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the extraction of named entities from the datasets and the need for Englishproofreading to improve the paper\"s readability. However, it does not specify which part of the paper discusses the extraction of named entities, making it weakly grounded. The comment is specific about the need for clarity in the extraction process and the potential benefits of Englishproofreading, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: the first claims that it is not clear how named entities were extracted from the datasets, and the second suggests that Englishproofreading would significantly improve the readability of the paper. The first claim is 3 as it points out a lack of clarity, but it lacks specific details or examples to substantiate the claim. The second part is more verifiable, as it provides a clear suggestion for improvement, but it does not offer specific guidance on how to address the issue of clarity in the extraction process. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the clarity of how named entities were extracted from the datasets and the need for Englishproofreading to enhance the paper\"s readability. While the comment highlights important issues, it lacks detailed guidance on how to address these concerns. For instance, it does not specify which parts of the paper need clarification or how Englishproofreading could be implemented. This makes the feedback 3, as it points out areas for improvement but does not provide comprehensive guidance for the authors to effectively address these issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part, \"L200: \u201cfor every arm a\u201d implies there is a single optimistic parameter, but of course it depends on a,\" suggests that the authors should clarify the relationship between the optimistic parameter and the arms. However, it does not provide specific guidance on how to address this issue or what changes should be made. The second part, \"L303: Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" offers a suggestion for improving the condition, but it does not provide explicit instructions on how to implement this change. The authors are left to infer that they should consider this suggestion, but without detailed guidance, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L200\" and \"L303,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as clarifying the relationship between the optimistic parameter and the arms, and suggesting a change to the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests a clarification regarding the relationship between the optimistic parameter and the arms, which is a logical observation. The second part offers a suggestion for improving the condition, which is a specific and verifiable claim. However, the comment lacks detailed reasoning or references to support the suggestion for improving the condition. While the suggestion is clear, the lack of supporting evidence makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation and suggests a clarification regarding the optimistic parameter and its relationship to the arms. It also offers a specific suggestion for improving the condition by proposing a different choice for T_0. This feedback is clear and actionable, providing the authors with a concrete way to enhance their draft. However, the comment could be more helpful if it explained why the suggested change is beneficial or provided additional context for the improvement. Overall, the comment is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with additional explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. However, it does not provide specific guidance on how to address this issue, such as recommending a particular section or suggesting a specific format for defining these terms. The action is implicit and somewhat vague, as the authors can infer that they need to address the formatting inconsistency but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296\" and \"Line 302,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point highlights a formatting inconsistency regarding the use of L and E, noting that they are sometimes italicized and sometimes not. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it affects the clarity or professionalism of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a formatting inconsistency regarding the use of L and E, noting that they are sometimes italicized and sometimes not. This feedback is specific and actionable, as it points out a potential issue that could affect the clarity and professionalism of the paper. By highlighting this inconsistency, the authors are given a clear direction to address the formatting to ensure consistency throughout the document. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or offered examples of how to maintain consistency. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental section is weak and requires more experiments. However, it does not provide specific guidance on what additional experiments are needed or how they should be conducted. The authors are left with a general understanding that more experiments are necessary but without concrete steps or suggestions on what those experiments should be. This makes the comment 3, as it identifies a need for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and requires more experiments. However, it does not specify which part of the experimental section is weak or what specific aspects need improvement. This lack of detail makes it difficult for the authors to identify the exact areas that need attention. Without specific guidance, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and requires more experiments. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section of the paper, noting that it is weak and suggesting the need for more experiments. However, the comment lacks detail on what specific aspects of the experimental section are weak or how additional experiments could address these weaknesses. Without actionable guidance or specific suggestions, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it points out a need for enhancement but does not provide sufficient detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct additional comparisons, it does not provide specific guidance on which models or techniques to include or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which part of the manuscript this suggestion pertains to, such as the experimental section or the discussion of related work. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to include more comparisons, but without explicit references to the manuscript, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support the claim that these additional comparisons would be beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement by recommending additional comparisons that could enhance the manuscript\"s comprehensiveness and relevance. However, the comment lacks specific guidance on which models or techniques to include, making it somewhat limited in its usefulness. To be more helpful, the comment could provide examples or references to specific models or techniques that could be compared, offering a clearer path for the authors to follow. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and concrete, providing the authors with clear instructions on how to improve the draft. The reviewer identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity ensures that the authors know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections for grammatical errors and punctuation in the manuscript, such as \"Despite of being compact\u00e2\u0080\u009d > \u00e2\u0080\u009cDespite being compact\u00e2\u0080\u009d,\" \"We refer multiway arrays\u00e2\u0080\u009d > \u00e2\u0080\u009cWe refer to multiway arrays\u00e2\u0080\u009d,\" \"HPFN to a even deeper ConAC\u00e2\u0080\u009d > \u00e2\u0080\u009cHPFN to an even deeper ConAC\u00e2\u0080\u009d,\" and \"Effect of the modelling mixed temporalmodality features.\" > I\"m not sure what this means, it\"s not grammatically correct.\" These corrections are clearly identified and specify what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of corrections for grammatical errors and punctuation, which are factual statements without any claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and actionable, helping the authors to improve the clarity and professionalism of their draft. The feedback is specific and directly addresses the issues, making it 5 for the authors to enhance the quality of their work. However, since it does not offer additional guidance or suggestions for further improvement, it aligns with a score of 4. The authors are given clear instructions on how to correct the grammatical errors, but the comment could be more comprehensive if it included additional feedback on the overall clarity or structure of the manuscript."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what changes are needed. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not specify which part of the paper these equations are located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in questioning the inversion or division, but without clear grounding, it is challenging for the authors to pinpoint the exact issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any context, explanation, or guidance on why this is a concern or how it affects the paper\"s content or analysis. Without additional information or suggestions for improvement, the authors are left without actionable feedback. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived incremental nature of the work or improve the model\"s novelty. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions might be necessary to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the model or approach are considered incremental. Without specific references to sections, figures, or tables, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the model or approach are considered incremental or straightforward. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is somewhat incremental and that the developed model is a straightforward extension of the GAN for static images. While it identifies a potential issue with the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their contribution. Without actionable feedback or detailed insights, the comment lacks the depth and specificity needed to be helpful for the authors. Therefore, it is rated as 2, as it provides some insight but does not offer actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. While it prompts the authors to provide this information, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to include the performance of the baseline in their draft. However, the comment lacks concrete guidance on how to present this information or what specific details should be included. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. This provides clear guidance on what additional information the authors should include in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or additional information, as it seeks to understand the performance of a specific baseline in terms of a particular metric. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance of a baseline, LDA+LSTM, in terms of the topic switch percent metric. This feedback is 3 as it prompts the authors to provide additional information that could enhance the comprehensiveness of their experimental results. However, the comment lacks depth and does not offer suggestions on how to present this information or what specific details should be included. To be more helpful, the comment could have suggested how the authors might analyze and present this data to better understand the performance of their baseline. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It suggests that the authors should clarify the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment implies that the authors should address these aspects, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the introduction or motivation section, but this is not explicitly mentioned. The comment is specific in detailing the issues with the motivation and potential applications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the motivation is unclear. The suggestion to clarify potential applications or benefits is a logical extension of the concern, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a significant area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out a critical aspect that needs clarification, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of mention of TD3GA in the main paper. It also suggests that the comparison to TD3GA should be central to the study, as it is crucial for understanding the synergies between the two methods. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to include more information about TD3GA and its comparison to DQD, but the comment does not offer concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of mention of TD3GA in the main paper and the importance of comparing DQD with TD3GA to understand the synergies. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, particularly due to the absence of mention of TD3GA in the main paper. The reviewer suggests that the comparison to TD3GA is crucial for understanding these synergies. The comment provides a logical reasoning by pointing out the lack of information and the importance of the comparison, which supports the claim. However, it could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is 4, as it offers a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention TD3GA, which is crucial for understanding these synergies. It also highlights a central claim that using onpolicy RL better fits the DQD framework and suggests that the comparison to TD3GA should be central. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of TD3GA in the study. However, the comment could be more helpful if it offered suggestions on how to integrate TD3GA into the analysis or provided additional context on why TD3GA is important. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, prompting the authors to provide an explanation for this observation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. However, it does not provide any supporting evidence, reasoning, or references to justify why this performance is surprising or how it should be explained. The lack of detailed explanation or context makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the surprising performance of the treesliced Wasserstein distance compared to the original optimal transport distance, as mentioned in Sections 6.1 and 6.2. While it identifies an area of interest, it does not provide any guidance or suggestions on how the authors might address this observation or explain the performance difference. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area for exploration but does not offer constructive advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"confident\" in the context of the paper, suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. While the comment explicitly identifies an area for clarification, it does not provide specific guidance on how to rephrase the sentence or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors know they need to clarify the meaning of \"confident\" but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, \"We have found it easier to be confident about applying ceterus paribus convexity,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the word \"confident,\" suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the ambiguity or suggest how the sentence could be rephrased. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential area of confusion, it does not provide specific guidance on how to rephrase the sentence or what aspects need clarification. This feedback is 3 as it highlights a potential issue but lacks depth and actionable suggestions, leaving the authors with a general direction to explore but no clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper\"s empirical findings, including the lack of polishing of figures and empirical results, which impede clarity and confidence in the results. It specifies specific areas for improvement, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. Additionally, it notes that the core findings in section one are conducted on two smallscale datasets and a single architecture type. While the comment provides a clear direction for improvement, it does not offer explicit guidance on how to address these issues, such as suggesting specific changes or improvements to the figures or experiments. The action is implicit and somewhat vague, as the authors can infer the need for improvement but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of polishing in figures and empirical results, which affects the clarity and confidence in the findings. It specifies issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. However, it does not explicitly mention which sections or figures are affected, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for better labeling and more comprehensive experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks confidence in its empirical findings due to issues with figures and empirical results. The reviewer provides specific examples, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and limited dataset and architecture scope. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that these issues impact the confidence in the empirical results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s empirical findings, including the lack of polishing in figures and empirical results, which impede clarity and confidence in the results. It provides detailed examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. This feedback is valuable as it offers actionable insights for the authors to improve the clarity and robustness of their empirical results. However, the comment could be more helpful if it suggested specific ways to address these issues, such as recommending the use of alternative methods or providing additional experiments. Overall, the comment is 4 as it provides clear guidance on how to enhance the paper\"s empirical rigor and clarity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This action is explicit and provides a clear direction for the authors to enhance their analysis. The comment also mentions that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion. However, the comment does not provide specific guidance on how to present or analyze these numbers, leaving some room for interpretation. Overall, the comment is 4 as it provides a clear action but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This provides a clear and specific suggestion for additional analysis, making the comment fully grounded. The authors can accurately identify the part of the paper being addressed, which is the label noise experiment, and the comment specifies what needs to be addressed, namely, reporting the numbers on ImageNet with 1000 classes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper. This is a logical suggestion based on the reviewer\"s understanding of the experiment and its potential impact on the results. However, the comment does not provide specific examples or references to support the claim that this would significantly stresstest the conjecture or that the phenomenon would weaken in this setting. The suggestion is 3 as it offers a clear direction for improvement but lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This is a clear and actionable suggestion that provides a specific way to enhance the robustness of the paper\"s findings. By including these additional results, the authors can further stresstest their conjecture and provide a more comprehensive analysis. The comment also acknowledges that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion for further exploration. Overall, the comment is 4 as it offers a clear direction for improvement and enhances the paper\"s depth and rigor. However, it could be more helpful if it provided specific guidance on how to present or analyze these additional results. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the paper need improvement. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the metric choice but lacks grounding, as it does not reference a particular section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. This question prompts the authors to consider and potentially revise their choice of metrics, which could lead to a more robust analysis. However, the comment does not provide specific guidance or suggestions on how to address this question or what alternative metrics might be more appropriate. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or results sections where the adversarial prediction accuracy is discussed. While the comment is specific in its question, it lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of adversarial prediction accuracy in real scenarios, contrasting it with classical prediction accuracy. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of adversarial prediction accuracy in real scenarios, contrasting it with classical prediction accuracy. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their work. Therefore, it is rated as 2, as it provides some insight but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. It provides specific suggestions for improvement, such as mentioning the number of sets of incontent examples and exploring the effects of varying the number of InContext Examples. These suggestions are explicit and provide clear guidance on how the authors can enhance the comprehensiveness and transparency of their evaluation. The feedback is concrete, as it outlines specific areas for improvement and the actions needed to address them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the evaluation section of the paper, specifically mentioning the lack of transparency regarding the experiment setup and the absence of information about the number of different sets of incontent examples used in the experiments. It also points out the reliance on a single dataset, which may limit the generalizability of the results. While the comment does not explicitly mention specific sections, it is clear that it pertains to the evaluation section, allowing the authors to infer the relevant parts. The comment is specific in detailing what needs to be addressed, such as providing more information about the experiment setup and exploring the effects of varying the number of InContext Examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information about the number of different sets of incontent examples used in the experiments and the reliance on a single dataset, which may limit the generalizability of the results. These points are wellsupported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation section of the paper, including the lack of transparency in the experiment setup and the reliance on a single dataset. It points out specific areas for improvement, such as the need to mention the number of different sets of incontent examples used in the experiments and to explore the effects of varying the number of InContext Examples. This feedback is actionable and provides clear guidance on how the authors can enhance the comprehensiveness and transparency of their evaluation. By addressing these points, the authors can significantly improve the robustness and generalizability of their results. Therefore, the comment is 5, as it offers detailed and constructive suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or whether it requires any changes to the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contrastive learning framework are similar to SimCLR or what implications this similarity has for the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the contrastive learning framework is the same as SimCLR, which is a relevant observation. However, it does not provide any further context, analysis, or suggestions on how this observation might impact the paper or what implications it has for the authors. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors can infer that they need to include more references to related work, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not specify which part of the paper this feedback pertains to, such as the introduction or discussion section, making it difficult for the authors to identify the exact area needing improvement. The comment is specific in suggesting related work to consider, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, the comment does not provide any reasoning, evidence, or justification for why these specific references are relevant or how they would enhance the paper. Without further explanation or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. While this feedback highlights the need for more comprehensive referencing, it lacks specific guidance on how to incorporate these references or what aspects of the related work should be addressed. The comment provides a general direction but does not offer actionable steps or detailed suggestions, making it 3. The authors can use this feedback to identify relevant literature but may need to seek additional guidance to fully implement it. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the absence of a comparison against existing text GANs, noting that many of these models have opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include a comparison with existing text GANs, including SeqGAN with a pretrained version. However, the comment lacks concrete details on which specific text GANs to compare against or how to conduct the comparison, making it 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, noting that many of these models have opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version. However, the comment does not specify which part of the paper this issue is related to, such as the experimental section or the discussion of related work. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in terms of what is missing (a comparison with existing text GANs), it lacks grounding as it does not clearly identify the part of the paper where this comparison should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, noting that many of these models have opensource implementations. While the comment highlights a potential area for improvement, it does not provide specific examples of which text GANs should be compared against or how the comparison should be conducted. This lack of detail makes the claim 3, as the authors would need to infer the specific comparisons to be made. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation by noting the absence of a comparison against existing text GANs, despite the availability of opensource implementations. It specifically mentions SeqGAN but does not test it with a pretrained version, which is a critical oversight. This feedback is clear and actionable, as it highlights a specific area where the authors can enhance the robustness and relevance of their work. By addressing this issue, the authors can provide a more comprehensive analysis of their proposed method\"s performance. However, the comment could be more helpful if it suggested specific text GANs to compare against or provided guidance on how to conduct the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not provide specific guidance on how to incorporate these aspects or what algorithmic elements should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to expand their focus on algorithmic aspects, but they lack concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section number. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic focus should be emphasized or how the novelty of the paper could be enhanced. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper seems limited after the concept of Blackwell winner is proposed. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. This feedback highlights a potential area for improvement in the paper, indicating that the authors might have overlooked an important aspect of their work. However, the comment lacks specific guidance or suggestions on how to enhance the algorithmic focus or what aspects should be emphasized. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete steps on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the comparison to the computer vision method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to a specific method from the computer vision setting, which would be more useful than comparing to lossbased sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. The authors can infer that it relates to the comparison section or the discussion of related work, but this inference is not explicit. The comment is specific in its suggestion to compare with a method from the computer vision setting, but it lacks grounding as it does not mention a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to explore the suggested comparison themselves to fully understand its potential impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. This feedback is 3 as it provides a specific suggestion for improvement, which could enhance the paper\"s relevance and utility. However, the comment lacks detailed guidance on how to adapt these methods or what specific aspects of the comparison would be beneficial. To be more helpful, the comment could include examples of how the suggested comparison could be made or what specific insights it might provide. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove the scalability properties. This is a clear and direct action that provides the authors with a specific task to perform. The comment also specifies what needs to be done, making it 5. The authors know exactly how to address the feedback by estimating the time complexity, which is a concrete step towards improving the scalability analysis of the learning algorithm.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is estimating the time complexity to prove the scalability properties. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be estimated to prove the scalability properties. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would impact the scalability of the algorithm. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by recommending that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is valuable as it directs the authors to a specific area that needs improvement, namely the estimation of time complexity, which is crucial for demonstrating the scalability of the algorithm. By addressing this suggestion, the authors can enhance the robustness and credibility of their work. However, the comment could be more helpful if it included additional guidance on how to estimate the time complexity or what specific aspects of scalability should be considered. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this connection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. This suggests that the authors should explore this connection, but it does not provide direct evidence or detailed reasoning to support the claim. The reference to a specific chapter provides some context, but the comment lacks explicit examples or detailed explanations, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. This feedback is 3 as it prompts the authors to consider a potential connection that could enhance their work. However, it lacks depth and does not provide specific guidance on how to explore this connection or what aspects of the paper might benefit from this consideration. The comment could be more helpful with additional context or suggestions on how to integrate this information into the paper. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion around equation (10) is very brief and not wellexplained. However, it does not provide any explicit or implicit actions for the authors to take to improve this section. There is no guidance on how to expand or clarify the discussion, nor are there suggestions for what specific aspects need more explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, noting that it is very brief and not wellexplained. This provides clear guidance on what needs to be addressed in the discussion section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is very terse and not wellexplained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is very brief and not wellexplained. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity and depth of their discussion. However, the comment could be more helpful if it provided suggestions on how to expand or clarify the discussion, such as by offering examples or additional explanations. Overall, the comment is 4 as it highlights a specific area for improvement but lacks detailed guidance for implementation."}
