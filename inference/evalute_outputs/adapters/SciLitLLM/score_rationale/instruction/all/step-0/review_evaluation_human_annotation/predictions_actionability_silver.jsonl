{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. It implies that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the dataset used in the study, specifically mentioning that it is artificially created and may contain noise. It suggests that the authors should analyze the quality of the dataset and the amount of noise it might have, particularly regarding the \"pristine\" set of tweets. However, the comment does not specify which part of the paper discusses the dataset or the analysis of its quality, making it weakly grounded. The suggestion is specific, as it clearly outlines what the authors should address regarding the dataset quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset used in the study is artificially created and may contain noise, such as misinformation or outofcontext images. The reviewer suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment lacks specific examples or references to support the claim about the dataset\"s noise, making it difficult for the authors to fully understand and address the issue. The suggestion to analyze the dataset quality is clear, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset used in the study, noting that it is artificially created and may contain noise, such as misinformation or outofcontext images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. This feedback is 3 as it points out a potential weakness in the study\"s methodology and encourages the authors to address it. However, the comment could be more helpful if it provided specific guidance on how to analyze the dataset\"s quality or suggested methods for identifying and mitigating noise. Overall, the comment offers a direction for improvement but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not delve into the theoretical aspects of the proposed algorithm, specifically the convergence properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting the inclusion of theoretical analysis or references to relevant literature. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of theoretical analysis, specifically the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the theoretical section, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. This feedback is valuable as it highlights an area where the authors can enhance the depth and rigor of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending relevant literature or methods to explore the convergence properties. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, and it questions the rationale behind the chosen operators. While the comment implies that the authors should consider these alternatives, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives and justify their choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 261&272,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly questions the rationale behind the chosen operators and suggests considering alternatives like the \"and\" operator or elementwise max, which correspond to the ideas of union and intersection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. While the comment raises a valid point about the potential alternatives, it lacks specific examples or references to support the claim that these operators are more appropriate. The reasoning is based on logical inference, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators used in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these operators correspond to the ideas of union and intersection from the \"or\" operator and elementwise min, and it questions the rationale behind the chosen operators. This feedback is 3 as it prompts the authors to consider alternative operators and provides a logical basis for their choice. However, the comment could be more helpful if it offered suggestions on how to justify the chosen operators or provided examples of how they are used in the paper. Overall, the comment provides a starting point for the authors to reflect on their choices, but it lacks depth and specific guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While the comment implies that the authors should explain their rationale for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors might infer that it relates to the experimental results or methodology, but this inference is not explicit. The comment is specific in questioning the selection process and its impact, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not provide any supporting evidence, reasoning, or references to justify why this selection might affect the results or how it could be addressed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it identifies a specific area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as 2, as it provides some insight but does not offer meaningful guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. It does not provide explicit instructions for the authors to follow, such as suggesting that they include a supporting explanation or clarify the data in the table. The action is implicit, as the authors need to infer that they should provide an explanation for the reported average duration. However, the comment is specific in its request for clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and requests an explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and requests an explanation. It does not contain a claim or suggestion that requires verification, as it is a factual inquiry seeking clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the purpose of the average duration reported in Table 1 and requests an explanation. This feedback is clear and actionable, as it prompts the authors to provide additional context or clarification regarding the data presented in the table. By addressing this question, the authors can enhance the transparency and comprehensiveness of their results, making the comment 4. However, it could be more helpful if it suggested how the authors might structure their explanation or what specific details should be included. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should correct the wording \"on par or better\" to address a perceived cognitive bias among NLP researchers. While the comment implies that the authors should make this correction, it does not provide explicit guidance on how to rephrase the results or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number (l.791), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential cognitive bias among NLP researchers and suggesting a correction to the wording. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to map instances where they perform worse to \"on par\" and all the rest to \"better\". While the reviewer provides a rationale for this claim, it lacks specific examples or references to support the assertion. The comment suggests that the authors should correct this bias, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the phrasing of the experimental results, suggesting that the authors might be using a cognitive bias to label their results as \"on par\" or \"better\" rather than providing a clear distinction. This feedback is 3 as it points out a potential area for improvement in the presentation of results. However, the comment lacks specific guidance on how to address this issue or suggestions for alternative phrasing, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the interpretation. The comment lacks concrete details or suggestions, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as the interpretation of results regarding the comparison of NVSB to GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the interpretation of results in Table 3, specifically regarding the comparison of NVSB to GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. While the comment identifies areas where clarification is needed, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the interpretation of their results. The feedback lacks actionable advice, leaving the authors with a general understanding of what needs clarification but without clear steps to take. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the overall appearance and readability of the tables. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to correct the formatting or improve the tables\" appearance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the presence of spaces between accuracy and standard deviation in some items but not in others, which affects the appearance and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, specifically noting the presence of spaces between accuracy and standard deviation in some items but not in others. This affects the appearance and readability of the tables. However, the comment does not provide any reasoning or evidence to support why this issue is problematic or how it impacts the overall quality of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting the presence of spaces between accuracy and standard deviation in some items but not in others. This observation is relevant as it affects the appearance and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting style or offering alternative solutions. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of novelty in the paper\"s contribution, noting that adversarial attacks by perturbing text have been done on many NLP and imagetext models. It suggests that the only new effort is applying similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects they should focus on to differentiate their contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of novelty in the paper\"s contribution, specifically mentioning adversarial attacks by perturbing text on NLP and imagetext models. It highlights that the only new effort is applying similar ideas to videotext models. However, the comment does not specify which part of the paper discusses the novelty or lack thereof, making it weakly grounded. The comment is specific in identifying the issue of lack of novelty and suggesting that the paper lacks originality in its approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty due to the similarity of adversarial attacks by perturbing text on NLP and imagetext models, which have been previously explored. The comment provides a logical reasoning by referencing the related work section of the paper, which presumably summarizes these prior efforts. However, the comment lacks specific examples or references to the exact works that have been done, making it 3. The authors would need to refer to the related work section to fully understand the claim, which adds a layer of complexity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper\"s contribution, specifically noting that adversarial attacks by perturbing text have been previously explored on NLP and imagetext models. It highlights that the only new effort is applying similar ideas to videotext models. This feedback is 3 as it points out a potential weakness in the paper\"s originality. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or differentiate it from existing research. Without actionable advice or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by dedicating separate paragraphs to each of the lexical features and sentencelevel features. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the organization of the section. The feedback is concrete and actionable, as it gives a specific direction for reorganizing the content. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the explanations for features are somewhat intertwined and confusing, and provides a concrete action to improve coherence by dedicating separate paragraphs to each feature. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by dedicating separate paragraphs to each feature. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested changes would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of explanations in Section 3.2, noting that the current structure is confusing due to the intertwined nature of the explanations for lexical and sentencelevel features. It provides a clear and actionable suggestion to improve coherence by dedicating separate paragraphs to each feature. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and organization of their paper, making it 4. However, it could be more helpful if it included specific examples of how the current structure is confusing or suggested how the new organization might look. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be a lot of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes could be made to the paper. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the amount of space dedicated to fleshing out the assumptions, specifically mentioning that it is a \"whole section of the paper plus experimental results.\" This provides some grounding as it indicates a specific part of the paper being discussed, but it does not specify which section or table this refers to, making it weakly grounded. The comment is specific in its critique of the space dedicated to the assumptions, but it lacks detailed guidance on how the authors might address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the amount of space dedicated to fleshing out assumptions, stating that it is \"a lot of space.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this amount of space is excessive or unnecessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the effort put into fleshing out the assumptions but expresses a concern about the amount of space dedicated to it, suggesting that it may be excessive. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this concern or improve the presentation of their assumptions. Without additional guidance or direction, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model, but it is unclear if this is adequately described in the paper. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment explicitly states the need for additional comparisons and baselines, it does not provide specific guidance on which models to include or how to implement these comparisons. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and questions whether this is adequately described in the paper. The comment also recommends including more baselines based on related work to strengthen the paper. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the comparison of models and the discussion of baselines. The comment is specific in detailing what needs to be addressed regarding the comparison and the inclusion of additional baselines. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and questions whether this is adequately described in the paper. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment identifies a potential issue with the comparison, it lacks specific examples or references to support the claim that the MST baseline is an appropriate comparison. The suggestion to include more baselines is a logical extension but remains somewhat vague without detailed guidance on which baselines to include. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s comparison of models, specifically questioning how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this comparison is not sufficiently described. The comment also recommends including more baselines based on related work to strengthen the paper. While the feedback highlights an important area for improvement, it could be more helpful if it provided specific suggestions on how to compare the models or which baselines to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs further attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks specific instructions or examples of what the authors should do to address the issue, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the selection of frame similarity factors and attributes similarity factors, which are specific elements of the paper. However, it does not specify which part of the paper discusses these factors, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the selection of these factors, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the selection of frame similarity factors and attributes similarity factors, but it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors, which is a crucial aspect of the paper\"s methodology. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect. Without actionable feedback or specific recommendations, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights an issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2. The comment also raises a question about why the authors did not mention objects in the context of \"latent in verbs.\" These actions are clear and specific, providing the authors with a detailed roadmap for improving their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). Additionally, it raises a question about why objects are not mentioned in the context of \"latent in verbs.\" This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and suggestions for improvement, such as discussing results for a specific task and using consistent terminology. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying areas for improvement in the paper. It suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it points out a potential inconsistency in terminology and questions the absence of object mention in the context of \"latent in verbs.\" This feedback is clear and provides the authors with concrete steps to enhance their draft, making it 4. However, it could be more helpful if it offered suggestions on how to discuss these topics or why they are important. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a specific error in the sentence on line 212, suggesting that the correct way to describe the process is to use a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is explicit and provides a clear action for the authors to take, which is to correct the sentence to accurately reflect the process described in Figure 2. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, suggesting that the correct description should involve a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This provides clear guidance on how to correct the sentence, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a more accurate description involving a bidirectional encoder. The reviewer provides a specific correction, \"do a bidirectional encoder that encodes the source sentence into a set of vectors,\" which is supported by the reference to Figure 2. This provides a clear and logical reasoning for the correction, making the claim 4. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the sentence on line 212, suggesting that the description of the process is not accurate. It provides a clear and actionable correction by recommending that the sentence should describe the process as involving a bidirectional encoder that encodes the source sentence into a set of vectors, as depicted in Figure 2. This feedback is 5 as it directly addresses a potential confusion in the paper and offers a precise way to correct the sentence, thereby enhancing the clarity and accuracy of the draft. The comment is specific and actionable, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of the reasoning chains in addressing implicit offensive texts. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what specific steps to take to address the concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses two main points: the absence of information regarding societal biases in the knowledge bases and the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the lack of information on societal biases and the example provided in Fig., but it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of Fig. suggests that the example is related to the effectiveness of reasoning chains, but without further details, the claim remains vague. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence or justification to fully support the claim.", "helpfulness_rationale": "The review comment raises two concerns: first, it questions whether the knowledge bases used are free from societal biases, and second, it expresses skepticism about the effectiveness of reasoning chains in addressing implicit offensive texts, using Fig. as an example. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it points out areas for consideration but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning MCNC and suggesting that the paper should include more baselines like those in 1. However, the comment does not provide explicit guidance on how to address this issue or what specific baselines should be included. The action is implicit and somewhat vague, as the authors can infer that they need to add more baselines, but they are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the lack of strong baselines in MCNC and suggests including baselines from a specific reference, 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 3 lacks strong baselines, specifically mentioning MCNC and suggesting that the paper should include more baselines like those in 1. However, the comment does not provide specific examples or detailed reasoning to support why these baselines are missing or why they are important. The suggestion to include more baselines from 1 is a logical response to the claim, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3, as it provides a basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, particularly those mentioned in 1. It suggests that the paper should include more baselines to provide a comprehensive comparison. While the comment highlights an important area for improvement, it does not provide detailed guidance on which specific baselines should be included or how they should be integrated into the table. This limits the comment\"s helpfulness, as it offers a clear direction but lacks depth and specificity. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on supplemental space to contain the paper, noting that this makes the paper less independent. It specifically mentions references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the paper more independent, but the comment does not offer concrete steps or examples of how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reliance on supplemental space to contain the paper, specifically mentioning references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. This provides some grounding as it allows the authors to identify the relevant sections of the paper. However, the comment does not specify what needs to be addressed or improved in these sections, such as how to make the paper more independent or how to effectively integrate the information from the supplemental material. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, making it less independent. This claim is 3 as it points out specific references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact issues from the references provided, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s reliance on supplemental space to contain certain information, noting that this makes the paper less independent. It provides examples of where this issue is particularly evident, such as references to Sup. Fig. 6 in section 3.1 and later references to the model comparison and other details of the span vs. sentence investigation. However, the comment does not offer suggestions or guidance on how the authors might address this issue or improve the paper\"s independence. While it highlights a potential problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about treating concept map extraction as a separate task and provides a rationale for why it might be necessary. It compares this task to generic summarization systems that build knowledge graphs and suggests that the concept map becomes increasingly difficult to distinguish as the number of nodes increases. However, the comment does not explicitly instruct the authors to treat concept map extraction as a separate task or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider treating concept map extraction separately. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also discusses the difficulty in distinguishing concept maps as the number of nodes increases. However, the comment does not specify which part of the paper this discussion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in its suggestion to treat concept map extraction as a separate task and provides reasoning for why this might be necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also discusses the difficulty in distinguishing concept maps as the number of nodes increases. While the comment provides a logical reasoning for why concept map extraction might be a separate task, it lacks specific examples or references to support the claim. The reasoning is 3, as it provides a plausible argument, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also discusses the difficulty in distinguishing concept maps as the number of nodes increases, suggesting that general summaries should be more readable. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or why it is important to treat concept map extraction separately. The feedback is 3 as it prompts the authors to consider the distinction between concept map extraction and generic summarization, but it does not provide actionable steps or detailed insights to enhance the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific set of questions for the authors to address, asking them to describe the traits of the experts, justify the need for expert annotation, and provide details about the linguistic challenges introduced. While the comment does not explicitly instruct the authors to make these descriptions or justifications, the questions are clear and provide a direct path for the authors to improve their draft. The feedback is concrete and actionable, as it guides the authors on what specific information to include to enhance their paper. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and detailing any linguistic challenges introduced. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts and the necessity of expert annotation, suggesting that the authors should provide more details. However, it does not provide specific evidence or references to support the claim that these aspects are lacking or need further explanation. The comment lacks detailed reasoning or examples to substantiate the need for additional information, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides a detailed set of questions for the authors to consider, aiming to clarify and expand upon the description of the experts and the justification for expert annotation. It prompts the authors to specify whether the experts are linguistic or domain experts, and whether the annotation process differs from that of nonexperts. Additionally, it questions whether the annotation introduces any linguistic challenges. This feedback is clear and actionable, offering specific areas for the authors to address to enhance the clarity and depth of their paper. However, it could be more helpful if it included suggestions on how to incorporate this information into the draft or examples of how to justify the need for expert annotation. Overall, the comment is 4, as it guides the authors toward improving their draft with detailed and constructive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the text, noting that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to correct the misleading statement or what changes should be made. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, noting that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed in the text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the text, noting that lines 102106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it points out a potential confusion in the text that the authors should address. By correcting this issue, the authors can improve the clarity and accuracy of their draft. However, the comment could be more helpful if it provided suggestions on how to rephrase the text to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so or specify which components or models should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of the system in action. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, which implies that it addresses the methodology or results section of the paper. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples of the system on actual texts, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While this feedback provides a clear direction for improvement, it lacks specificity and does not offer detailed guidance on how to incorporate these examples or what specific texts should be used. The comment is 3 as it identifies an area for enhancement but does not fully support the authors in implementing the suggestion. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the use of the Challenge Set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the section or sections discussing the Challenge Set. The authors can infer that it relates to the methodology or evaluation sections, but the comment does not provide explicit references to specific sections. The question is specific in its request for clarification on the use of the Challenge Set. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the use of the Challenge Set in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information to understand the methodology better. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. This feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the paper. The authors are left with a general suggestion to clarify the use of the Challenge Set, but without additional details or examples, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify why the new model is better than MH. This is a clear and direct action, giving the authors a specific task to perform. The comment also specifies what needs to be addressed, making it 5. The authors know exactly what information is needed to improve their draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is its abstract nature and the lack of clarity on why the new model is better than MH. The request for examples of spurious structures provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is abstract and lacks clarity on why the new model is better than MH. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the discussion is abstract or unclear. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks clarity on why the new model is better than MH. It provides a clear and actionable suggestion by asking the authors to provide examples of spurious structures. This feedback is valuable as it directs the authors to a specific area that needs clarification and improvement, offering a concrete way to enhance the clarity and impact of their discussion. However, the comment could be more helpful if it included additional guidance or examples of what constitutes spurious structures. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the comment explicitly states the action to be taken, it does not provide detailed guidance on how to implement this suggestion or what specific aspects of the comparison should be considered. The authors are aware of the action but may need additional information to fully execute it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental setup or methodology, but without explicit references, it remains unclear. The comment is specific in detailing the proposed baseline and the comparison criteria, but the lack of grounding makes it challenging for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. While the suggestion is clear, it lacks specific reasoning or evidence to support why this approach would be beneficial or how it would impact the comparison. The claim is 3 as it provides a logical rationale for the suggestion but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding a baseline smaller PCFG with state size being r, where the parameters $H, I, J, K, L$ are directly parameterized as learned matrices. It proposes that under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared. This feedback is 3 as it provides a specific suggestion for improving the experimental setup by adding a baseline that could enhance the analysis. However, the comment could be more helpful if it included additional details on why this approach would be beneficial or how it could impact the results. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While the action is explicit, it lacks concrete details on how this information should be presented or integrated into the paper. The authors know they need to include this information, but the comment does not provide guidance on where or how to incorporate it. Therefore, the comment is 3, as it identifies a specific piece of information that needs to be added but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the maximum number of tasks done by any annotator. This provides clear guidance on what additional information should be included in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, it does not provide any reasoning, evidence, or examples to support why this information is important or how it could impact the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include the maximum number of tasks done by any annotator. While this is a specific piece of information that could enhance the transparency and completeness of the paper, the comment lacks context or explanation as to why this information is important or how it could impact the analysis or results. Without additional guidance or reasoning, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the difficulty in understanding the overall message of the paper due to the presence of many empirical results and analyses. It questions what these results tell us about the underlying research question and the specific hypothesis tested. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the message or structure the results to make them more understandable. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in understanding the overall message of the paper due to the presence of many empirical results and analyses. It questions what these results tell us about the underlying research question and the specific hypothesis tested. However, the comment does not specify which part of the paper is causing this issue, making it weakly grounded. The authors can infer that it relates to the results section or the discussion, but this is not explicitly mentioned. The comment is specific in its critique, as it clearly identifies the problem of understanding the overall message and the need for clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the overall message of the paper due to the presence of many empirical results and analyses. It questions what these results tell us about the underlying research question and the specific hypothesis tested. However, the comment does not provide specific examples or detailed reasoning to support the claim that the results are difficult to understand. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a general concern but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the difficulty in understanding the overall message of the paper due to the presence of many empirical results and analyses. It questions what these results tell us about the underlying research question and the specific hypothesis tested, highlighting a potential gap in the paper\"s clarity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to structure the results or clarify the narrative. While it identifies a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. While the comment implies that the authors should include numerical results to demonstrate the method\"s effectiveness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include them. This makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not reference specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and the application of the method to popular algorithms, but it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement seeking clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a significant gap in the paper by noting the absence of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy (DP) algorithms. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a missing element but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not formal enough and recommends either formalizing this connection or adjusting the language to clarify it. While the action is explicit, it does not provide specific guidance on how to formalize the connection or what aspects of the language should be adjusted. The authors know they need to address the issue but may need additional information to fully implement the suggested changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of the probabilistic connection being drawn in the paper, suggesting that it is not formal enough to be considered more than motivational. However, it does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in its suggestion to either formalize the connection or adjust the language to clarify it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not formal enough to be considered more than motivational. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the probabilistic connection in the paper, noting that it is not formal enough to be considered more than motivational. It provides a clear suggestion for improvement by either formalizing the connection or adjusting the language to clarify it. This feedback is actionable and provides the authors with a clear direction for enhancing the clarity and rigor of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to formalize the connection. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for empirical evidence, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to justify why this evidence is necessary or how it would strengthen the paper. The lack of supporting evidence or detailed explanation makes the claim 3, as the authors would need to infer the importance of the evidence themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\"s performance in the Column Subset Selection problem. This feedback is 3 as it identifies a specific area where the authors can strengthen their paper by offering empirical evidence. However, the comment lacks depth and does not provide guidance on how to collect or present this evidence, which would be beneficial for the authors. Therefore, the comment is rated as 3, as it points out a potential improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could take to improve the scalability of their approach. As a result, the authors are left without a clear understanding of what changes or considerations are needed to address the scalability concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper this concern relates to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in detailing the scalability issue, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a logical deduction but lacks detailed justification or data to substantiate the claim. As a result, the comment is considered 2, as it provides some reasoning but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the robust training scheme to practical datasets, particularly those on highdimensional domains. It suggests that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. This feedback is 3 as it identifies a potential limitation of the approach and provides a specific area for improvement. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or explore alternative approaches. To be more helpful, the comment could include specific recommendations or examples of how to mitigate the scalability problem. Therefore, the comment is rated as 3, as it provides a starting point for the authors to consider but does not fully support their efforts to improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of datasets and the duration of the study period. It asks whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or what additional information they should include to better understand the model\"s performance. The comment lacks concrete actions or detailed advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, it does not specify which part of the paper this discussion is related to, such as a particular section or table. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions about the dataset and style shifts, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. This feedback highlights an important aspect that the authors should consider when evaluating their results and the generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional information they should include to better understand the model\"s performance. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern with the experiments, specifically noting that the paper reports only selfcomparisons and lacks an explanation for this choice. It also suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments, it does not provide explicit guidance on how the authors should address this concern or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to explain the selfcomparisons and consider additional comparisons, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the lack of comparisons with external work like SketchRNN. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which experiments are being referred to or what specific issues need to be addressed. The comment is specific in suggesting that comparisons with SketchRNN could be performed, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a concern because they only report selfcomparisons and lack an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. However, the comment lacks specific examples or detailed reasoning to support the claim that selfcomparisons are insufficient or why comparisons with SketchRNN would be beneficial. The suggestion to perform comparisons with SketchRNN is a logical extension but does not provide explicit evidence or justification for why it is necessary. Therefore, the claim is 3, as it provides a general direction for improvement but lacks detailed support or examples.", "helpfulness_rationale": "The review comment identifies a significant concern with the experiments section of the paper, specifically noting that only selfcomparisons are reported and that there is no explanation for this choice. It highlights the lack of motivation and suggests that comparisons with external work like SketchRNN could be performed in a generative setting. This feedback is clear and actionable, as it points out a specific area for improvement and provides a concrete suggestion for enhancing the paper\"s motivation and experimental rigor. However, the comment could be more helpful if it offered additional guidance on how to integrate these comparisons or what specific aspects of the experiments should be clarified. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the results are based on standard techniques but notes that they are not obvious a priori and require a fair degree of technical competency. While it highlights a potential issue with the results, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment lacks actionable details or concrete steps for improvement, leaving the authors uncertain about what specific aspects need attention or how to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, indicating that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not specify which part of the paper this observation pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the results being not obvious a priori, it lacks grounding as it does not clearly identify the part of the paper being discussed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges that the results are based on \"standard\" techniques but notes that they are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential issue with the results, suggesting that they may not be as straightforward as they appear. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the clarity of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not. While the comment implies that this distinction should be made, it does not explicitly instruct the authors to do so or provide specific guidance on how to implement this distinction. The action is implicit and somewhat vague, as the authors need to infer the need for this distinction and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates to the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. However, the comment does not provide detailed reasoning or examples to support why this distinction is necessary or how it would improve the paper. The mention of specific works provides some context, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment suggests making a distinction between hard prompt work updates to the frozen model and those that do not, referencing specific works like Schick and Sch\u00fctez. This feedback is 3 as it identifies a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide specific guidance on how to implement this distinction or why it is important. The authors are left with a general suggestion but without detailed instructions on how to apply it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their conclusion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or justification for their conclusions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with the conclusion, but without full grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed comparisons or statistical analysis. The lack of supporting details or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is the better of the two systems, given the small difference in performance and the amount of data used for training. It raises a valid concern about the reliability of the conclusion based on the limited data used for training the text disambiguation model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the paper: the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation. It explicitly states that the paper does not provide evidence or justification for GaRare\"s advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is explicit and provides concrete actions for the authors to take, such as providing theoretical justification and enhancing the algorithmic presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide a clear motivation for using GaRare and lacks evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for a more detailed algorithmic presentation is somewhat vague, as it does not specify what aspects of the algorithm should be clarified. Therefore, the comment is 3, as it provides some guidance but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the paper does not provide a clear motivation for using GaRare, suggesting that it lacks evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable, as it directs the authors to provide a more robust theoretical foundation for their choice of method. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it guides the authors to enhance the clarity and comprehensiveness of their methodology. Overall, the comment is 4 as it provides clear and actionable feedback that can significantly improve the draft. However, it could be more helpful if it offered specific examples or suggestions for how to address these issues, which would make it fully comprehensive. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not provide explicit guidance on how the authors should address this gap or suggest specific ways to incorporate these references into their work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references to strengthen their work\"s connection to existing literature. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. The authors can infer that it relates to the literature review or related work section, but this inference is not explicit. The comment is specific in detailing the missing link to similar work, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a connection to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure and the ability to perform exact inference. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to understand the exact nature of the missing link. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to support the assertion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a connection to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These references are relevant as they have a similar structure to the CRF and the ability to perform exact inference, which could enhance the paper\"s context and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might incorporate these references or address the gap. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It also questions the lack of insights into how WPA works, which could be crucial for future research directions. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the model\"s predictions with np.ones input and why Gaussian noise input does not work as well as WPA. The comment further suggests that the authors should provide more insights into how WPA works, which could spark future research directions. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should explain why WPA works, particularly with np.ones input, and why Gaussian noise input does not work as well as WPA. It questions the lack of insights into how WPA works, which could be important for future research directions. However, the comment does not provide specific examples or references to support the claim that Gaussian noise input does not work as well as WPA. The reasoning is based on the observation that Figure 2 suggests this, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by questioning the lack of explanation for why WPA works, particularly with np.ones input. It suggests that the authors should provide insights into the model\"s predictions and why certain inputs like Gaussian noise do not work as well as WPA. This feedback is valuable as it highlights an area where the paper could be improved, offering a clear direction for the authors to enhance their understanding and presentation of the method. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It requests more clarification on this similarity. While the comment implies that the authors should provide additional details or context to address this similarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the method part in relation to the cited work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is found in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its request for more clarification on the similarity, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method part of the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It suggests that the authors provide more clarification on this similarity. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what additional clarification is needed. This feedback is 3 as it points out a potential overlap but does not offer detailed advice on how to resolve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a personal belief about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less dataefficient and harder to train models using gradient descent. However, it does not specify which part of the paper this critique pertains to, nor does it provide detailed guidance on how the authors might address this concern. The lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to improve it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that the need for reinforcement learning in a static VQA task might be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any specific evidence, examples, or reasoning to support this claim. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of how to address this concern or improve their approach. As a result, the comment is not helpful, as it lacks the depth and specificity needed to guide the authors in enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding their contribution until the promised dataset is made publicly available. However, it does not provide explicit guidance on how the authors should proceed or what actions they should take to address this issue. The comment lacks concrete details or suggestions on how to handle the situation, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset not being publicly available, which is a concern regarding the contribution. However, it does not specify which part of the paper discusses the dataset or how it is relevant to the contribution. The authors can infer that it relates to the dataset section or the contribution section, but this inference is not explicit. The comment is specific in identifying the issue of dataset availability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset promised in the paper is not yet publicly available, suggesting a cautious approach until the dataset is openly accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the availability of the dataset promised in the paper, suggesting a cautious approach until the dataset is openly accessible. This feedback is important as it points out a potential limitation in the reproducibility and accessibility of the research. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the situation. While it identifies a critical concern, it does not provide actionable advice or detailed recommendations, making it 3. The authors are aware of the problem but may need additional support to effectively address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. However, the comment does not explicitly instruct the authors to perform these comparisons or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons to strengthen their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of achieving stateoftheart results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the results section or the discussion, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the need for comparisons with existing detection methods to substantiate the claim of stateoftheart performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, questioning the validity of this claim. It suggests that the performance is primarily due to the first step and recommends conducting comparisons with existing detection methods to validate the claim. However, the comment lacks specific examples or references to support the claim that the performance is not convincing or that the first step is the sole reason for the results. This makes the claim 3, as the authors would need to provide additional evidence or examples to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. While the comment identifies a potential issue with the claim, it lacks specific guidance or suggestions on how to conduct these comparisons or what aspects to focus on. The feedback is 3 as it points out a potential weakness in the paper\"s claims but does not provide detailed actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model. It specifically asks the authors to provide insight into why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. While the comment implies that the authors should explain this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm (CBN) to different layers, particularly layer 2 in addition to layers 3 and 4, compared to applying it to layers 4 and 3 only. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically questioning why applying CBN to layer 2 in addition to layers 3 and 4 deteriorates performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this observation. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, particularly in the context of the GuessWhat?! dataset. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 results in a deterioration of performance compared to applying it to layers 4 and 3 only. The comment is 3 as it identifies a specific area for improvement and prompts the authors to provide an explanation. However, it lacks detailed guidance or suggestions on how to address this issue, such as proposing alternative approaches or analyses. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the implicit call to the Witness oracle is confusing. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the concept, provide an alternative explanation, or offer specific steps to improve the clarity of the text. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact location. The comment is specific in its critique of the confusion caused by the implicit call, but it lacks grounding as it does not provide a clear reference to the section or part of the paper where this issue occurs. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the implicit call to the Witness oracle is confusing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the implicit call to the Witness oracle is confusing. However, it does not provide any suggestions or guidance on how the authors might clarify or address this confusion. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. The authors are left without a clear understanding of what steps to take to improve their draft, making the comment 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to handle headpose. The action is implicit and vague, as the authors are left to infer that they need to explore ways to incorporate headpose conditioning into their NeRF model. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method\"s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the headpose issue or the proposed method\"s limitations. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in questioning the method\"s limitations and referencing a previous work, but it lacks explicit grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, which is deferred to future work. It questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide specific reasoning or evidence to support why this is a significant issue or why it should be addressed. The reference to Gafni et al. provides a starting point, but the comment lacks detailed analysis or justification for the claim. Therefore, the claim is 3, as it provides a reference but lacks comprehensive reasoning or evidence to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed method, namely its inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. This feedback is 3 as it points out a potential gap in the current work and references a relevant previous study. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or incorporate headpose conditioning into their NeRF model. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The comment implies that the authors should consider the impact of these rare spurious examples on the trained model. However, it does not explicitly instruct the authors to make any specific changes or improvements. The action is implicit and somewhat vague, as the authors need to infer that they should address the potential impact of these triggers on their model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples from previous works by Chen et al. (2017) and Gu et al. (2019). The comment specifies that a few training examples with such triggers can have a large impact on the trained model. This level of detail and explicit reference to specific sections and examples makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The claim is supported by references to these works, which provide examples of triggers used in previous studies. This evidence helps to substantiate the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons between the spurious features and backdoor triggers, or by discussing the potential impact of these triggers on the trained model. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers, highlighting the potential impact of rare spurious examples on the trained model. This feedback is 3 as it points out a relevant area for consideration and provides references to existing literature. However, it could be more helpful if it offered specific suggestions on how the authors might address this issue or further explore the impact of these triggers. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which can be confusing and reduces the contribution. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for the authors to take, such as recommending a different approach or providing additional details on the structural optimization. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is mentioned several times in the paper, indicating that it is a main component. However, it does not specify which part of the paper this component is discussed in, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. This provides a clear direction for the authors to consider revising their presentation of the optimization algorithm to enhance its originality. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which is confusing and reduces the contribution. The comment provides a logical reasoning by pointing out the inconsistency between the emphasis on structural optimization and the lack of originality in the optimization algorithm. However, it lacks specific references or examples to support the claim, making it 3. The authors would need to infer the exact nature of the confusion and the potential impact on the contribution, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the structural optimization component, noting that it is emphasized as a main component but seems to be directly from previous works. This observation raises a concern about the originality and contribution of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing A. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific example of what needs to be included, making it 5. The authors know exactly what action to take and how to implement it, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work on modular networks for VQA\" and references A, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of related work on modular architectures for VQA in the introduction. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction seems to imply that no one does modular architectures for VQA, but it does not mention related work on modular networks for VQA. This claim is based on the observation that the introduction lacks a specific reference to related work, which could be inferred as a gap in the literature. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of the claim and the need for additional references, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper\"s discussion of related work, noting that it does not mention related work on modular networks for VQA. This is a crucial oversight as it could lead the reader to believe that no one has explored modular architectures for VQA. By pointing out this omission, the comment provides clear and actionable feedback, encouraging the authors to include relevant references or discussions to address this gap. This feedback is valuable as it helps the authors improve the comprehensiveness and accuracy of their literature review, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. While the comment implies that the authors should include these comparisons to provide a more comprehensive analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons to enhance their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the discussion or comparison of methods, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting that the authors should include these comparisons to provide a more comprehensive analysis, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, the comment does not provide specific examples or references to support the claim that these methods are computationally efficient or come with similar guarantees. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s focus, suggesting that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. This feedback is 3 as it points out an area where the authors could enhance the comprehensiveness of their work by including these comparisons. However, the comment lacks specific guidance on how to incorporate these comparisons or what aspects to focus on when contrasting the methods. To be more helpful, the comment could provide more detailed suggestions or examples of how these comparisons could be made. Therefore, the comment is rated as 3, as it offers a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies a gap in the presentation of results, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these cases in the tables, but the comment lacks concrete instructions on how to implement this change. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the performance without reinforcement learning dropped lower than without dependency tree, and the tables do not list the cases where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree, and the tables do not list the cases where dependency tree and RL are not used. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights a gap in the presentation of results, allowing the authors to address an important aspect of their analysis. However, the comment could be more helpful if it provided suggestions on how to include these cases in the tables or offered additional context on why this information is crucial. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific weakness in the paper, namely the limited consideration of datasets in the experiments section. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. The comment provides concrete examples of relevant works and datasets, giving the authors clear direction on how to improve their experimental evaluation. This feedback is explicit and provides detailed guidance on what actions to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the limited consideration of datasets in the experiments, particularly those from Federated learning benchmarks. The comment suggests relevant works for the authors to consider, such as FedProx and FedMAX, providing clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main weakness is the limited consideration of datasets in the experiments section, specifically mentioning CIFAR10 and suggesting the inclusion of datasets from Federated learning benchmarks like LEAF. The reviewer provides references to specific works, FedProx and FedMAX, which are relevant to the field and could serve as examples for the authors to consider. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples of how these datasets and works would enhance the paper\"s comprehensiveness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experimental evaluation, which is only conducted on the CIFAR10 dataset. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. This feedback is clear and actionable, providing the authors with a concrete direction to improve the comprehensiveness of their experimental evaluation. By addressing this issue, the authors could significantly enhance the depth and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim that the proposed modules improve accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. While the comment implies that the authors should consider using different datasets for their ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments with different datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, referencing a table. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This level of specificity is clear, as it directs the authors to consider alternative datasets for their ablation study. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. The comment implies that the current dataset may not be sufficient to demonstrate the effectiveness of the proposed modules. However, it does not provide specific evidence or reasoning to support why the current dataset is insufficient or why the suggested datasets would be more appropriate. The lack of detailed justification or examples makes the claim 3, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This feedback is 3 as it prompts the authors to consider alternative datasets for their ablation study, which could strengthen the evaluation of their proposed modules. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the proposed modules should be further examined. To be more helpful, the comment could provide more detailed suggestions or examples of how to use these datasets or what specific metrics should be considered. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It also points out that previous work has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment highlights potential issues and suggests areas for clarification, it does not provide explicit guidance on how the authors should address these concerns or improve the methodology. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The comment also raises concerns about the interpretability of the results. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issues with the methodology and the comparison to previous work, but without explicit grounding, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment provides a logical basis for questioning the methodology, it lacks specific references or examples to fully substantiate the claim. The suggestion to consider multiple vulnerabilities at a time is a reasonable point, but the comment could be strengthened by providing more detailed reasoning or evidence to support the claim. Therefore, the comment is 3, as it provides a basis for questioning but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. The comment also points out that the results are difficult to interpret and may be marginal improvements at best. While the comment identifies a potential issue with the methodology and provides a basis for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it highlights an area for improvement but does not offer detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. While the comment implies that more details are needed, it does not explicitly instruct the authors to provide these details or specify how to do so. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not know exactly what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions \"many graph notions\" and suggests that the writing is generally good but could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which sections or parts of the paper are being addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting what needs to be addressed, but the lack of grounding makes it challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that it deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. This feedback is 3 as it points out areas where the paper could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to improve the clarity and detail of their work, but the comment could be more actionable with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It explicitly asks for quantitative results on testing images, providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies what additional information is needed to strengthen the evaluation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the evaluation on transformations of training images and suggests the need for quantitative results on testing images. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It suggests the need for quantitative results on testing images. While the comment raises a valid concern about the evaluation methodology, it lacks specific examples or references to support the claim that transformations of training images are insufficient. The suggestion for quantitative results on testing images provides some direction but does not fully substantiate the claim. Therefore, the comment is 3, as it highlights an area for improvement but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It suggests the need for quantitative results on testing images, providing a clear and actionable feedback. This feedback is valuable as it guides the authors to consider additional metrics or methods to strengthen their evaluation, thereby enhancing the robustness and validity of their findings. However, the comment could be more helpful if it offered specific suggestions on how to quantify the results or which metrics to use. Overall, the comment is 4 as it directs the authors to an important area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. The comment implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it with the current work would provide a better understanding of the stateoftheart. While the comment explicitly identifies a related work that should be considered, it does not provide detailed guidance on how to integrate this paper into the draft or what specific aspects should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to incorporate this paper into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. It implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it with the current work would provide a better understanding of the stateoftheart. However, the comment does not specify which part of the paper this related work should be discussed in, nor does it provide detailed guidance on how to integrate this paper into the draft. The authors can infer that it pertains to the related work section, but the lack of specificity makes it difficult to pinpoint the exact part of the paper that needs revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, is a related work that was possibly missed by the authors. The comment suggests that this paper deals with hypergraph data and tensors, and it should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment does not provide specific details or examples of how this paper relates to the current work or what aspects should be compared. This lack of detailed justification or examples makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which the authors may have overlooked. It suggests that this paper deals with hypergraph data and tensors, and it recommends discussing and comparing it with the current work to provide a better understanding of the stateoftheart. This feedback is 3 as it points out a relevant piece of literature that could enhance the authors\" understanding of their work\"s context and potential contributions. However, the comment could be more helpful if it provided specific details on how the comparison could be made or what aspects of the related work should be highlighted. Overall, the comment offers a direction for the authors to improve their draft, but it lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It explicitly requests the authors to demonstrate the scalability of the method on normal machines with a couple of cores. Additionally, the reviewer asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. This feedback is explicit and provides concrete actions for the authors to take, such as demonstrating scalability and explaining the computation of optimal transport. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the scalability of the optimal transport method and questions the authors\" claim about the computation time. It explicitly mentions the scalability issue, asking for demonstration on normal machines with a couple of cores. Additionally, it raises a specific question about how the optimal transport distance is computed, given the use of the Sinkhorn method. This provides full grounding as it clearly identifies the parts of the paper being addressed and specifies what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the optimal transport method and questions the authors\" claim that it takes seconds to compute on a 36core machine. It requests a demonstration of scalability on normal machines with a couple of cores. Additionally, it asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about scalability. The request for clarification on the computation of optimal transport is clear but could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides some support but requires additional details to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises important questions about the scalability of the optimal transport method and the computation time claimed by the authors. It explicitly requests the authors to demonstrate the scalability of the method on normal machines with a couple of cores, which is a critical consideration for practical applications. Additionally, the comment questions the computation of optimal transport, specifically how the Sinkhorn method is used to achieve this. This feedback is clear and actionable, providing specific areas for the authors to address to improve the clarity and robustness of their methodology. However, it could be more helpful if it offered suggestions on how to demonstrate scalability or compute optimal transport more effectively. Overall, the comment is 4 as it guides the authors in enhancing the clarity and practicality of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to demonstrate generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the parameters in Table 1 are only applicable to image data and ViT models, suggesting that the authors should consider applying the same principles to other areas such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the method might not generalize to these areas, it does not provide specific examples or references to support this claim. The suggestion is based on a logical assumption about the potential limitations of the method, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate the method\"s generalizability. This feedback is valuable as it encourages the authors to expand their experimental scope and potentially enhance the applicability of their method. However, the comment could be more helpful if it provided specific suggestions or examples of how to adapt the method to these other areas. Overall, the comment is 4 as it directs the authors to an important area for further exploration and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the utility of tensor networks in representing the PMF of discrete variables and their relevance to machine learning algorithms or the analysis of the algorithm. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the significance of their paper. The comment lacks actionable guidance, leaving the authors without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the utility of tensor networks in representing the PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this critique pertains to, such as a specific section or result. The authors may have to infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the utility and significance of the results, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results of using tensor networks to represent the PMF of discrete variables are not clear in terms of their utility for machine learning algorithms or analysis of the algorithm. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s significance, questioning the utility of using tensor networks to represent the PMF of discrete variables and their relevance to machine learning algorithms or analysis of the algorithm. This feedback highlights a critical area for improvement, as it points out a potential weakness in the paper\"s contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the significance of their work. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\"s contributions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider evaluating the generalization to other fewshot learners, but it does not specify which methods or approaches to use or how to conduct this evaluation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the generalization of observations to fewshot learners beyond Prototypical Networks, which is a specific aspect of the paper. It is fully grounded as it explicitly mentions \"fewshot learners\" and \"Prototypical Networks,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the need to evaluate the generalization of observations, which is a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\"s contributions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the generalization of observations to fewshot learners beyond Prototypical Networks is not evaluated. This is a relevant observation that could impact the scope and applicability of the submission. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or methods to evaluate generalization. While it highlights an important area for improvement, the feedback is 3 as it provides a clear direction for the authors to consider but does not offer detailed guidance on how to implement it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the handling of different modalities in Equation 3, noting that the equation directly removes the modal subset of all instances. It explicitly asks the authors to address this issue, providing a clear and direct action for them to take. The comment specifies the problem and suggests a potential area for improvement, making it 5. The authors know exactly what needs to be done to address the concern, which is to deal with the problem mentioned above. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the paper deals with the potential difference in contribution of different modalities across different instances. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about Equation 3, questioning how it deals with the potential difference in contribution of different modalities across different instances. The comment suggests that some instances may have good performance with one modality, while others may perform better with another. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the nature of the problem and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 3, specifically questioning how the equation deals with the difference in contribution of different modalities across different instances. It highlights a concern that some instances may have good performance with one modality, while others may perform better with another, suggesting that the equation might not account for this variability. This feedback is clear and actionable, as it prompts the authors to consider how they might address this issue in their analysis. However, the comment could be more helpful if it provided suggestions on how to deal with this problem or offered alternative approaches to account for the variability in modalities. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit feedback on the abstract, stating that it does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The authors are aware of what needs to be improved but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the abstract lacks description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract lacks description of how the idea was evaluated and what the outcome was, and mentions minor language issues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it provides a good explanation of the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include more information about the evaluation process and outcomes. Additionally, the comment mentions minor language issues, which can be addressed to improve the clarity and precision of the abstract. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to enhance the abstract further. Therefore, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional suggestions. This aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusing description of the MFDA setting in the Method Section, specifically mentioning the use of \"single target domain with sparse labels\" and the labeling of the target distribution p_T(x, y) with label observation. It also questions the notation for the target domain \u03c7 and references the original MFDA paper (Yue et al., 2021a) for clarification. The reviewer points out that the problem setting description differs significantly from the original paper, leaving the authors with a clear action to take: clarify the description of the MFDA setting and ensure consistency with the original paper. However, the comment does not provide specific guidance on how to resolve the confusion or what aspects of the description need to be clarified. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the description of the MFDA setting, particularly the confusion regarding the labeling of the target domain and the unlabeled data in source domains. The comment references the original MFDA paper (Yue et al., 2021a) for clarification, providing a clear basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) to provide context and suggests that the problem setting description differs significantly from the original paper. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the original paper provides some support, but the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) for clarification, suggesting that the problem setting description differs significantly from the original paper. This feedback is clear and actionable, as it directs the authors to clarify the description of the MFDA setting and ensure consistency with the original paper. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or offered alternative ways to present the information. Overall, the comment is 4 as it provides a clear direction for improvement but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It suggests that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it does not explicitly instruct the authors to include this analysis in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion about the potential benefits of epochwise analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to incorporate this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, the comment does not provide specific examples or references to support the claim that epochwise analysis would be beneficial. While the suggestion is logical and could be supported by further evidence, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it suggests that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to implement this analysis or what aspects to focus on. The feedback is 3 as it offers a direction for enhancing the paper\"s analysis, but it lacks depth and actionable details, leaving the authors with a general idea of what could be improved but without concrete steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit feedback on the authors\" workload and suggests that the contribution of the article is incremental. It also points out that the article is essentially a combination of GraphRAG and GraphCare, and highlights missing key baselines. Additionally, it suggests that the paper should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This feedback is clear and provides specific actions for the authors to take, such as revising the contribution section to address the incremental nature of the work and ensuring that key baselines and algorithms are cited and discussed. The comment is 5 as it gives the authors concrete steps to follow to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" code and the article, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the incremental nature of the contribution, the combination of GraphRAG and GraphCare, and the missing key baselines. Additionally, it suggests specific algorithms like MedRetriever and KGRAG that should be introduced. This level of detail and explicitness makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental and consists of a combination of GraphRAG and GraphCare. It also points out missing key baselines and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. The reviewer provides references to support the claim, such as citations to GraphRAG and GraphCare, and mentions specific algorithms like MedRetriever and KGRAG. This provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides detailed feedback on the contribution of the article, noting that it is incremental and essentially a combination of existing works, GraphRAG and GraphCare. It highlights the absence of key baselines and suggests that the paper should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This feedback is clear and actionable, offering specific guidance on how the authors can improve their draft by expanding their discussion and referencing relevant works. The comment is 5 as it provides concrete suggestions for enhancing the paper\"s contribution and methodology, enabling the authors to make significant improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification and suggests potential issues, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to clarify the classification and the role of local regulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and references specific lines (438441) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the differentiation between the 3 classes of extreme speech and the classification of a particular instance. The comment is specific in detailing what needs to be addressed, namely, the differentiation between classes and the role of local regulation in annotations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the specific issues and how to address them, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the differentiation between the 3 classes of extreme speech, particularly the distinction between derogatory and exclusionary extreme speech. It raises a question about the classification of a particular instance and suggests that the authors need to clarify why it is categorized as exclusionary extreme speech. Additionally, the comment questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment highlights important areas for clarification and improvement, it could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the feedback is 3 as it prompts the authors to consider and potentially revise their classification criteria and the role of local regulation, but it lacks detailed guidance on implementation. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the evaluation of the timeaware model, suggesting that the effectiveness of the proposed methods might be questionable when the training and evaluation timesteps are the same. It implies that the authors should consider evaluating the model under different timestep scenarios to better understand its performance. However, the comment does not explicitly instruct the authors to conduct such evaluations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore different timestep scenarios. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same, suggesting that the authors should consider different timestep scenarios. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 shows similar performance between the baseline model and the timeaware model when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense under different timestep scenarios. However, the comment lacks specific examples or detailed reasoning to support the claim that the effectiveness of the proposed methods is questionable. The suggestion to consider different timestep scenarios provides some direction but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the timeaware model, noting that similar performance is observed between the baseline model and the timeaware model when trained and evaluated with the same timestep. This observation raises questions about the effectiveness of the proposed methods under these conditions. The comment suggests that the authors should consider evaluating the model under different timestep scenarios to better understand its performance. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in their analysis. However, it could be more helpful if it included specific recommendations or examples of how to conduct these evaluations. Overall, the comment is 4 as it guides the authors towards a meaningful improvement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors but does not provide details on how this is realized or guaranteed. The comment explicitly suggests that the authors should clarify this aspect, indicating a clear action for the authors to take. However, it does not provide specific guidance on how to address this issue, such as which sections or methods should be revised. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the realization and guarantee of disentanglement, but without full grounding, it is challenging for the authors to pinpoint the exact sections to revise. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which acknowledges a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not provide specific examples or detailed reasoning to support the claim that the disentanglement is not clear. The mention of a limitation in the \"Broader Impacts and Limitations\" section provides some context, but it does not substantiate the claim with additional evidence or analysis. Therefore, the comment is considered 2, as it lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that while the \"Broader Impacts and Limitations\" section acknowledges a limitation regarding obtaining fully disentangled latent vectors, it does not provide details on how this is realized or guaranteed. This feedback is 3 as it identifies a specific area where the paper lacks clarity and suggests that the authors should clarify this aspect. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how other works have handled similar challenges. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two separate issues. First, it questions whether Eq. 4 stands, implying that the authors should clarify or address this concern. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, specifically mentioning the marginal improvement on OfficeHome. However, the comment does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue regarding the improvement of the designed solutions, particularly on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the validity of Eq. 4, suggesting that if it stands, it implies a specific outcome for u^l in Eq. 3. This is a factual observation that does not require verification. The second part discusses the improvement of the designed solutions in Table 5, noting that the improvement is marginal on some datasets, such as OfficeHome. This part is 3 as it provides a specific example of a marginal improvement, but it lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises two distinct points. First, it questions the validity of Eq. 4, suggesting that if it stands, it implies a specific outcome for u^l in Eq. 3. This raises a potential issue that the authors should address to clarify their methodology. Second, the comment points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, particularly mentioning the marginal improvement on the OfficeHome dataset. This feedback is 3 as it identifies a specific area where the authors might need to provide more detailed explanations or evidence to support their claims. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered more detailed guidance on what aspects of the methodology or results need further clarification. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some stateoftheart references are missing in the face recognition experiment, specifically mentioning Baidu\"s work. It suggests that this work uses the triplet loss and reports results on a dataset similar to Webface, with the VRF achieving 98.65% on LFW, which is better than the result in Table 3 of the paper. While the comment identifies a gap in the literature and provides specific examples, it does not explicitly instruct the authors to include these references or discuss them in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should address this gap. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment of face recognition and references a specific work by Baidu. It also provides a link to the dataset results, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it details the missing references and provides a comparison with the results in Table 3, suggesting that the VRF achieves better performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning Baidu\"s work. It provides a link to the dataset results, which supports the claim by offering a specific example of a relevant work. However, the comment lacks detailed reasoning or analysis explaining why these references are missing or how they would enhance the paper. The mention of Baidu\"s work provides some context, but the lack of detailed justification or comparison makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s literature review by pointing out that some stateoftheart references are missing, specifically mentioning Baidu\"s work on face recognition. It provides a specific example of a relevant work that uses the triplet loss and reports results on a dataset similar to Webface, which is comparable to the dataset used in the paper. The comment also highlights that the VRF achieves better performance on LFW than the results reported in Table 3. This feedback is valuable as it directs the authors to include relevant references and provides a basis for comparison, which can enhance the paper\"s comprehensiveness and credibility. However, the comment could be more helpful if it suggested how the authors might integrate these references or discuss the implications of the comparison. Overall, the comment is 4, as it offers clear guidance on improving the paper\"s content and context."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalization or what steps to take to mitigate the problem. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to question answering, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the question answering process, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue with generalization, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process requires template mapping to transform questions into masked statements, which might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their approach. Without actionable steps or detailed feedback, the authors are left with a general understanding of the problem but without clear directions on how to resolve it. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more preferred. It also provides a specific action by recommending that the authors provide the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and provides a concrete path for the authors to follow, making it 5. The authors know exactly what needs to be done to improve their draft, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"comparing the performance of the model only pretrained on synthetic data\" and \"providing the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the current comparison and suggests a more appropriate approach. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more preferred. The comment provides a logical reasoning by suggesting that the authors should provide the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This reasoning is clear and provides a clear path for the authors to follow, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the current evaluation approach, specifically that comparing the performance of the model only pretrained on synthetic data is unfair. It suggests a more appropriate approach by recommending that the authors demonstrate the importance of the three projection errors by providing the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft. By addressing this issue, the authors can enhance the validity and relevance of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides an explicit suggestion to consider averaging over subword representations, referencing a specific example from Hewitt and Manning (2019, footnote 4). This feedback is concrete and provides a clear action for the authors to take, as it offers a specific method to improve their approach. By following this suggestion, the authors can enhance their draft by incorporating a more common practice in the field. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed suggestion to consider averaging over subword representations, referencing a specific example from Hewitt and Manning (2019, footnote 4). This provides clear guidance on how to improve the current approach. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that averaging over subword representations is a common practice, referencing a specific example from Hewitt and Manning (2019, footnote 4). This provides a clear and specific reference to support the claim, making it 5. The authors can easily verify the claim by consulting the referenced work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that averaging over subword representations is a common practice, as exemplified by Hewitt and Manning (2019, footnote 4). This feedback is actionable and offers a concrete method for the authors to enhance their approach. By following this suggestion, the authors can improve the consistency and effectiveness of their work. However, the comment could be more helpful if it explained why averaging over subword representations is beneficial or how it could impact the results. Overall, the comment is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a clear and explicit suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are concrete and provide specific steps for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the model discriminant ability may be hard to show its consistency between predicted scores and actual risk, and it highlights the importance of calibration curves to demonstrate this agreement. The comment further suggests proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that the model\"s AUC may not consistently reflect the actual risk, which could be a concern for clinical scoring systems. It recommends conducting calibration curves to demonstrate the agreement between predicted scores and actual risk, and it suggests proving the feasibility of the generated scoring system. While the comment provides a logical argument for the importance of calibration curves, it lacks specific examples or references to support the claim that the AUC may not consistently reflect actual risk. This makes the claim 3, as it provides a basis for the suggestion but requires further elaboration or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s discriminant ability, suggesting that the model AUC may not consistently reflect the actual risk, which could be crucial for clinical scoring systems. It provides a clear and actionable suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk. Additionally, the comment recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. This feedback is detailed and constructive, offering specific steps for the authors to improve their draft. Therefore, the comment is 5, as it provides clear guidance on how to enhance the paper\"s content and methodology."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the conditions for DICE are not well discussed, particularly regarding how to ensure that DICE meets the conditions of Lemma 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD is not significantly changed by sparsification, and that Lemma 2 requires approximately identical mean as the assumption. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these observations, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. This feedback is 3 as it points out areas where the paper could be improved by providing more detailed explanations or discussions. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these issues. To be more helpful, the comment could include examples or references to similar works that address these concerns, providing the authors with a clearer path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels as baselines, the absence of default settings, and the missing comparison with baselines related to Bayesian optimization with discrete and categorical variables. It also points out the lack of discussion on limitations and societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the use of position kernels, consider default settings, include missing baselines, and discuss limitations and societal impacts. However, the lack of concrete steps or detailed suggestions makes the action implicit and vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the experiments, such as the use of position kernels as baselines, the absence of default settings, and the missing comparison with baselines related to Bayesian optimization with discrete and categorical variables. It also mentions the lack of discussion on limitations and societal impacts. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that these issues pertain to the experimental section or the discussion, but they cannot pinpoint the exact sections. The comment is specific in detailing what needs to be addressed, such as the use of position kernels, default settings, and missing baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the experiments, specifically questioning the use of position kernels as baselines and suggesting that the paper should include default settings from the literature. It also points out missing baselines related to Bayesian optimization with discrete and categorical variables and the lack of discussion on limitations and societal impacts. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support these claims. The authors are left to infer the basis of the reviewer\"s concerns, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the experimental setup, the use of position kernels as baselines, the absence of default settings, and the missing comparison with relevant baselines. It also points out the lack of discussion on limitations and societal impacts. While the comment highlights important aspects that need attention, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer the necessary changes, making the feedback 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests that the presentation of bits should be clarified as representation bits in Section 4.3. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of bits as representation bits. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the lack of insight into why all sparsity patterns perform similarly and whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests clarifying the presentation of bits as representation bits in Section 4.3. While the comment raises valid questions about the analysis and presentation, it lacks specific examples or references to support these claims. The reasoning is somewhat logical, but the absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also points out a specific issue with the presentation of bits in Section 4.3, suggesting that they should be clarified as representation bits. While the comment highlights important areas for improvement, it lacks detailed guidance on how to address these issues or provide additional insights. The feedback is 3 as it directs the authors to areas that need further exploration and clarification, but it could be more comprehensive with specific suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a clear and explicit action for the authors to consider revising their claim. Second, it identifies a specific error in the inequality on line 310, pointing out that it has the wrong sign and suggesting a comparison with inequality line 227. This part is also explicit and provides concrete guidance on how to correct the error. Overall, the comment is 5 as it provides clear and specific actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the issues with the claim about additional assumptions and the error in the inequality on line 310. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a logical reasoning and common knowledge to support the claim, making it 4. The second part identifies a specific error in the inequality on line 310, comparing it with inequality line 227. This part is also 4 as it provides a clear comparison to correct the error. Overall, the comment is 4 due to the logical reasoning and specific examples provided.", "helpfulness_rationale": "The review comment provides two valuable pieces of feedback. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback prompts the authors to reconsider their claim and potentially revise it to reflect the actual assumptions involved. Second, the comment identifies a specific error in the inequality on line 310, pointing out that it has the wrong sign and suggesting a comparison with inequality line 227. This provides a clear and actionable correction for the authors to make. Overall, the comment is 4 as it offers both critical insights and specific guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, making it difficult for the authors to identify the exact section that needs attention. While the authors can infer that it pertains to Section 6, the comment lacks specificity in detailing what specific aspects of the perspective or contributions should be compared. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide any specific examples, references, or reasoning to support why such a comparison would be beneficial or how it could enhance the manuscript. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it identifies a potential area for improvement in the manuscript, specifically in terms of contextualizing the current work within the broader literature. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could include examples of prior efforts or suggest specific points of comparison. Therefore, the comment is 3, as it points out a potential enhancement but does not fully guide the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests examining the performance with different numbers of scenarios, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not as clear as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance of the model is closely related to the number of scenarios used for training. While this is a logical claim, it lacks specific evidence or examples to support the assertion that varying the number of scenarios would significantly impact performance. The comment does not provide detailed reasoning or references to substantiate the claim, making it 3. The authors would need to conduct additional experiments or provide more detailed analysis to fully understand the impact of the number of scenarios on performance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the performance of the model is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, which is a specific and actionable suggestion. This feedback provides a clear direction for the authors to explore, potentially leading to a better understanding of the model\"s performance and its limitations. However, the comment could be more helpful if it included specific recommendations on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the ability of the model to predict quality labels, even if it is trained on highquality data. It questions whether disturbances in the training data could affect the model\"s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate or mitigate potential disturbances. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the model\"s performance or evaluation, but without explicit references, it remains unclear. The comment is specific in detailing the concern about disturbances affecting the model\"s ability to generate correct quality labels, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance. However, the comment does not provide specific examples or evidence of disturbances or how they might impact the model. The reasoning is based on a logical assumption but lacks detailed justification or references to support the claim. As a result, the comment is considered 2, as it provides some insight but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the ability of the model to predict quality labels, even when trained on highquality data. It questions whether disturbances in the training data could affect the model\"s performance, which is a critical aspect to consider for the model\"s reliability. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or investigate potential disturbances. While it identifies an important area for consideration, the feedback is 3 as it prompts the authors to think about the robustness of their model\"s predictions but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a clear and direct action for the authors to take, which is to improve the clarity of the representation in Appendix A.2. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides a clear and actionable feedback for the authors to improve the presentation of this information. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or provided examples of how to improve the representation. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions. While the comment provides valuable information, it lacks actionable guidance on how the authors should utilize this information to improve their draft. Therefore, the comment is 3, as it provides some insight but does not offer clear instructions for implementation.", "grounding_specificity_rationale": "The comment discusses the bounded noise assumption and its limitations in stochastic optimization literature, referencing specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this critique pertains to, such as a particular section or discussion. This makes it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing the limitations of the bounded noise assumption and referencing relevant works, but it lacks grounding as it does not specify the part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide detailed reasoning or analysis to support why this assumption is restrictive or how the referenced works address this limitation. The references are not elaborated upon, leaving the authors without a clear understanding of how to address the critique or improve their work. Therefore, the claim is 3, as it provides some support but lacks depth and specific guidance.", "helpfulness_rationale": "The review comment highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and provides references to specific works that have extended these noise conditions. This feedback is valuable as it directs the authors to relevant literature that could inform their work. However, the comment does not offer specific guidance on how to incorporate these references or how they might impact the authors\" research. While it provides a starting point for further exploration, it lacks actionable advice, making it 3. The authors are encouraged to consider the referenced works but may need to seek additional guidance to fully integrate them into their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the motivation for using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their motivation or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the motivation for using characteristic function regularization, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or part of the paper the comment refers to, making it weakly grounded. However, the comment is specific in identifying the issue of unclear motivation, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the motivation for using characteristic function regularization. This feedback is valuable as it points out a potential weakness in the paper that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify their motivation or improve the explanation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, which are standard in contextual linear bandits. The reviewer notes that the combination of these techniques is not surprising and suggests that the contribution may be incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies that the combination of these techniques is not surprising, suggesting that the contribution may be incremental. However, it does not provide specific guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results are a combination of existing techniques, which is not surprising and may suggest that the contribution is incremental. However, the comment does not provide specific examples or references to support the claim that these techniques are indeed standard or widely known. Without detailed justification or evidence, the claim remains 3, as it lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the results appear to be a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the combination of these techniques is not surprising and may indicate that the contribution is incremental. While the comment highlights a potential issue, it lacks actionable feedback or suggestions for how the authors might address this concern or enhance their contribution. Without specific guidance or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed feedback or actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It explicitly asks what \"100 steps\" refers to, whether it is 100 sampled strategies. This question provides a clear and direct action for the authors to clarify the meaning of \"100 steps\" in their draft. The comment is explicit and concrete, as it directly instructs the authors to provide clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry that seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It asks whether \"100 steps\" refers to 100 sampled strategies, providing a clear and actionable inquiry for the authors to clarify their methodology or results. This feedback is helpful as it prompts the authors to ensure that their presentation is clear and accurate, which is essential for readers to understand the experimental setup and results. However, the comment could be more helpful if it suggested how the clarification could be presented or if it pointed out the potential confusion this might cause for readers. Overall, the comment is 4, as it directs the authors to address a specific point of clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it highlights the similarity between the model\"s motivation and goals to a prior VAE paper. However, it does not specify which part of the paper this observation pertains to, such as the introduction or related work section. The authors might infer that it relates to the motivation or goals section, but this is not explicitly mentioned. The comment is specific in identifying the potential for exploring energy models and the similarity to a prior VAE paper, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the motivation and goals of the model align with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper is a logical inference, but without further details or references, the claim remains 3. Therefore, the comment is rated as 3, as it provides some support but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model align with a prior VAE paper, suggesting that the authors should consider this related work. However, the comment lacks specific guidance or actionable suggestions on how the authors might integrate this information into their draft or improve their approach. While it identifies an area for further exploration, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should evaluate their method on a different benchmark, such as Atari, to assess its generalizability to other domains and its performance with discrete action spaces and highdimensional observations. This feedback is clear and provides a concrete action for the authors to take, making it 5. The reviewer specifies the benchmark and the aspects to consider, giving the authors a clear path forward in improving their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the evaluation of the method, specifically mentioning that it is evaluated only on tasks from the Meta World domain. It points out the difficulty in judging generalizability to other domains and suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This feedback is fully grounded as it explicitly mentions the evaluation on Meta World and the recommendation for additional experiments on Atari. The comment is also specific because it provides a clear suggestion for improvement, namely, to evaluate the method on a different benchmark. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the method is limited to a single domain, making it difficult to judge generalizability. The reviewer suggests running experiments on a different benchmark, such as Atari, to address this limitation. The claim is supported by logical reasoning, as it points out the need for broader evaluation to assess the method\"s generalizability. However, the comment could be strengthened by providing specific examples or references to similar studies that have successfully generalized across domains. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on tasks from the Meta World domain. This limits the ability to judge the method\"s generalizability to other domains. The reviewer provides a clear and actionable suggestion by recommending the use of a different benchmark, such as Atari, which is commonly used in the literature. This recommendation would allow the authors to assess the method\"s performance with discrete action spaces and highdimensional observations, thereby enhancing the robustness of their evaluation. The feedback is detailed and provides a concrete path for improvement, making it 5 for the authors to enhance the quality and impact of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be very interesting. However, it does not provide specific guidance on what aspects of the model should be analyzed or how this analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analysis of the model is missing, but it does not specify which part of the paper this analysis should be included in. The authors can infer that it relates to the method or the experiments, but the lack of explicit mention of specific sections makes it weakly grounded. The comment is specific in suggesting that an analysis of the model is missing, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the model is missing, but it does not provide any specific examples, references, or reasoning to support this claim. The comment lacks detailed justification or evidence to substantiate the need for additional analysis. Without further explanation or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the method is presented nicely and the experiments are good and complete, which is a positive assessment. However, it suggests that a deeper analysis of what the model does is missing, which could be very interesting. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to conduct this analysis or what aspects should be included. This limits the usefulness of the feedback for the authors, as it does not offer detailed suggestions or examples to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider scalability and potential hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the modulator, which is a specific element of the paper, providing a clear reference to the part of the paper being discussed. It also raises a concern about scalability and the potential need for hyperparameter tuning, which is specific and actionable. However, the comment does not specify which sections or figures discuss the modulator, making it weakly grounded. Despite this, the comment is specific in its critique, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the modulator, noting that it is heuristically designed and suggesting that there might be scalability concerns. It raises a concern about the need for tedious hyperparameter tuning for diverse training data, which is a valid point that could impact the practicality and generalizability of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or strategies for improving scalability. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the incorporation of domain knowledge into the structure of the experiments, suggesting that a less informed f_R/f_P might require an impractical amount of data to learn. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the incorporation of domain knowledge into the structure of the experiments, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the experimental design or methodology, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the need for a less informed f_R/f_P to require impractical amounts of data, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments incorporate a great deal of domain knowledge into their structure, suggesting that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiments, noting that the incorporation of domain knowledge into their structure might make a less informed f_R/f_P require impractical amounts of data to learn. This feedback is 3 as it points out a potential limitation of the experimental design. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable advice, the feedback provides some insight but does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should conduct such experiments, but it lacks concrete details or steps on how to implement them. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the need for experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue, as it clearly outlines what needs to be addressed regarding the experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data when applying imitation learning. This is a relevant and important point that could significantly impact the paper\"s conclusions and practical applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing experiments or methodologies to explore these aspects. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant gap but does not provide detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, questioning whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the authors acknowledge this in the conclusion, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their paper. The action is implicit and vague, as the authors are left to infer that they should clarify this connection in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the connection between overparameterization, robust memorization, and generalization, specifically questioning whether the necessary conditions have stronger implications if they are connected to generalization bounds. It also notes that the paper does not clearly address whether the constructions of ReLU networks for robust memorization lead to robust generalization. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion of overparameterization and generalization. The authors can infer that it relates to the conclusion or a section on generalization, but the comment does not provide explicit references. The specificity is clear as it identifies a specific area of concern regarding the connection between overparameterization and generalization. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the connection between overparameterization and generalization, specifically questioning whether the necessary conditions have stronger implications if they are connected to generalization bounds. The reviewer acknowledges that the authors address this in the conclusion but finds the question serious. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the necessary conditions are not connected to generalization bounds. This makes the claim 3, as the authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the connection between overparameterization and generalization, specifically questioning whether the necessary conditions have stronger implications if they are connected to generalization bounds. It highlights a potential gap in the paper\"s argument, noting that the constructions of ReLU networks for robust memorization do not necessarily lead to robust generalization. While the comment identifies a significant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their paper. The feedback is 3 as it points out a potential weakness in the paper\"s argument, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their OOD experiments. It also implies that the authors should ideally compare their method with those class of methods. While the comment explicitly states the actions to take, it does not provide detailed guidance on how to integrate this information into the paper or what specific comparisons to make. The authors are given a clear direction but may need to infer the exact implementation details. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Regarding the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al., and place their method in context. Additionally, it implies that the authors should ideally compare their method with those class of methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention untrained neural networks, such as the deep image prior by Ulyanov et al., in the context of their OOD experiments. It provides a logical reasoning by pointing out that untrained networks have been shown to be effective in solving inverse problems across a wide class of images. However, the comment lacks specific references or examples to support the claim that mentioning these untrained networks would be beneficial. While the suggestion is reasonable, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper\"s OOD experiments by suggesting that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al., and place their method in context. It also implies that the authors should ideally compare their method with those class of methods. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s context and potential comparisons. However, the comment could be more helpful if it included detailed guidance on how to integrate these suggestions into the paper or what specific comparisons would be most beneficial. Overall, the comment is 4 as it offers clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors conduct additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. The explicit mention of references and the suggestion to explore deeper networks and other network structures provides clear guidance on what the authors should do to strengthen their paper. The comment is 5 as it offers concrete steps and references for the authors to follow, ensuring they know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental section or methodology. The authors can infer that it relates to the experimental setup or results, but the comment does not specify the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines what additional experiments are needed to strengthen the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, are needed to strengthen the paper. It provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This provides a clear and specific suggestion for additional experiments, making the claim 4. However, the comment could be strengthened by explaining why these specific references are relevant or how they would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to further strengthen the paper. It provides specific references to relevant works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This feedback is 5 as it offers clear and actionable guidance for the authors to enhance their experimental setup and results, thereby improving the robustness and comprehensiveness of their paper. By following this suggestion, the authors can significantly strengthen their draft and provide a more comprehensive evaluation of their proposed method. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the sample selection mechanism need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim that the mechanism is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. While it identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing the draft. Therefore, it is rated as 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. While it acknowledges the thoroughness of the analysis, it does not provide explicit guidance or suggestions on how the authors might improve this aspect. The comment lacks specific instructions or examples of what additional models or approaches could be considered, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluation of results and analysis, specifically noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of the evaluation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim that the models are \"old\" or \"small,\" making it difficult for the authors to fully understand and address the issue. Additionally, the comment does not provide suggestions on how to improve the evaluation or what other models should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the detailed and comprehensive nature of the results and analysis, but it also points out a potential limitation: the evaluation is based on only two relatively old and small models. This feedback is 3 as it identifies a specific area for improvement, namely the need to consider more recent or larger models to enhance the comprehensiveness of the analysis. However, the comment lacks specific suggestions or guidance on how to address this limitation, such as recommending additional models or approaches to include. While it highlights an important aspect for consideration, the feedback could be more actionable with more detailed advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results (table 5). This is a clear and direct action, as it specifies what information the authors need to include to address the issue. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results (table 5) and requests clarification on why the performance degrades when using additional information about missing, wrong, or redundant data. This feedback is clear and actionable, as it prompts the authors to provide a detailed explanation or analysis of the observed performance degradation. By addressing this question, the authors can enhance the transparency and understanding of their results, which is beneficial for improving the draft. However, the comment could be more helpful if it suggested potential causes or methods for addressing the issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the first two sections of the paper, noting that the author stacked a number of previous approaches but failed to explain each method clearly. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the unclear sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide explicit guidance on how to address these issues or suggest specific changes to improve clarity. The authors are left to infer that they need to clarify the explanations, but the lack of concrete suggestions makes it difficult to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" This level of detail helps the authors understand what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the clarity of the paper, particularly in the first two sections. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide detailed reasoning or references to support why these statements are unclear or how they could be improved. The lack of specific examples or detailed explanations makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the paper, particularly in the first two sections. It points out that the author stacked a number of previous approaches but failed to explain each method clearly. The comment provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" This feedback is 3 as it highlights areas where the paper could be improved for clarity. However, it could be more helpful if it offered suggestions on how to clarify these points or provided examples of how to improve the explanations. Overall, the comment provides a starting point for the authors to address the issues but lacks depth and specificity, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a clear and direct action for the authors to take, which is to revise the introduction. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction needs revision or what aspects of the motivation are unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references to specific sections, and it is not specific enough to guide the authors in addressing the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples or reasoning to support why the motivation is unclear or how it could be improved. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation presented in the introduction. It provides a clear and actionable suggestion for improvement, recommending that the introduction be revised to make the paper easier to follow. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete step for improvement. However, the comment could be more helpful if it provided additional guidance on how to revise the introduction or what aspects of the motivation should be clarified. Overall, the comment is 4 as it highlights a critical issue and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the intuition behind including multiple local prompts, noting that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or discussion. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the paper need to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. This observation highlights a potential area for improvement or clarification in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the paper need further exploration. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general insight but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights an issue with the alignment of relabeled reward data with human annotator judgments, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps should be taken to improve the validation process. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue with the validation of the alignment, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the validation of the alignment of relabeled reward data with human annotator judgments. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their experiments to a broader range of molecules or exploring ways to generalize the method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the limited number of molecules and the indistribution testing provided. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of the method, suggesting that it might be limited if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value would be limited if it requires training for each molecule individually, suggesting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental setup, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly questions the origin of the test data used in Figure 3 and asks for clarification on the existence of a ground truth. This provides a clear and direct action for the authors to take, which is to explain the source of the test data and whether a ground truth is available. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the origin of the test data used in Figure 3 and the existence of a ground truth. These questions are factual in nature and do not express an opinion, judgment, or suggestion that requires verification. They are straightforward inquiries seeking clarification, which do not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, namely the lack of clarity regarding the origin of the test data and the existence of a ground truth. This feedback provides a clear direction for the authors to address, which is to clarify these aspects in their draft. However, the comment could be more helpful if it offered suggestions on how to resolve the issue or provided examples of how to present this information effectively. Overall, the comment offers some guidance but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes that the presentation and formatting, particularly in figures and tables, are lacking. However, the comment does not provide specific guidance or suggestions on how the authors might improve these aspects. The lack of actionable details or concrete steps for the authors to follow makes it difficult for them to address the issues effectively. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the paper\"s writing quality and presentation, specifically mentioning figures and tables. However, it does not specify which sections or parts of the paper are affected, making it difficult for the authors to identify the exact areas needing improvement. The comment is specific in its critique of the writing and presentation, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and possibly hurriedly written, making it difficult to read. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or detailed feedback, the authors may find it challenging to understand and address the issues effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the paper\"s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes that the presentation and formatting, particularly in figures and tables, are lacking. While the comment identifies areas for improvement, it lacks specific suggestions or actionable feedback on how the authors might enhance the writing or presentation. Without detailed guidance, the authors may find it challenging to address the issues effectively. Therefore, the comment is 3, as it points out areas of concern but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, suggesting that prior work already theoretically shows samplewise multiple descent in linear regression. It implies that the main contribution of the paper is the result that optimal regularization can remove double descent in certain anisotropic settings. The reviewer questions whether this is the case and suggests that the paper should better highlight the novelty of their results in relation to prior results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised to better highlight the novelty. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s contribution, specifically questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment mentions being unfamiliar with the techniques and tools used in the paper, which further complicates the authors\" ability to address the critique. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the techniques and tools used in the paper but finds the claims plausible. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s contribution, questioning whether the main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, given that prior work already theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of their results in relation to prior results. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the clarity of their contribution. While it identifies a potential issue, it does not provide actionable feedback or detailed advice on how to enhance the paper\"s novelty or contribution. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that the authors should provide more discussions. While the comment implies that the authors should address this issue by adding more discussions, it does not specify what kind of discussions are needed or how they should be structured. The action is implicit and somewhat vague, as the authors know they need to provide more discussions but are not given clear guidance on what those discussions should entail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the simplicity of the subtasks and the need for more discussions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for the bAbi task and suggests that the authors should provide more discussions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the subtasks are simplistic or why more discussions are necessary. Without additional context or justification, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. While it points out a potential weakness in the experimental setup, it lacks specific guidance or suggestions on how the authors might address this issue or what kind of discussions would be beneficial. The comment provides a general direction for improvement but does not offer detailed feedback or actionable steps, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the characterization of the study as an \"ablation\" study, stating that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might reframe their study or what specific aspects need to be addressed to align with the concept of an ablation study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table where the study is described. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique, as it clearly identifies the issue with the characterization of the study, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study about different subdomain sizes is not an \"ablation\" study because it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or evidence to fully support it.", "helpfulness_rationale": "The review comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This feedback is 3 as it identifies a potential mischaracterization of the study, which could be important for the authors to address. However, the comment lacks depth and does not provide specific guidance on how the authors might reframe their study or what aspects need to be clarified to align with the concept of an ablation study. Without actionable advice or detailed suggestions, the feedback is limited in its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. While the comment implies that the authors should consider this idea, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they should explore this possibility, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. However, it does not provide any reasoning, evidence, or references to support why this suggestion is necessary or beneficial. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the recommendation.", "helpfulness_rationale": "The comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This feedback is 3 as it provides a potential direction for expanding the scope of the work by integrating AccNet into a more comprehensive system. However, the comment lacks specific guidance on how to implement this suggestion or what benefits it might bring. To be more helpful, the comment could include details on how this integration could enhance the model\"s performance or functionality. Therefore, the comment is 3, as it offers a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment does not explicitly instruct the authors to do so or provide guidance on which datasets to use. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further testing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This provides some grounding as it refers to the testing of the metric, but it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional testing, as it suggests that the authors should consider testing the metric on multiple datasets to validate its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This feedback is valuable as it highlights a potential limitation in the evaluation of the metric\"s effectiveness. However, the comment lacks actionable guidance on how the authors might address this issue, such as suggesting additional datasets to test or providing examples of how to expand the testing. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for enhancement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that these comparisons should be made, it does not explicitly instruct the authors to include these specific methods or provide detailed guidance on how to conduct these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this evaluation is in or where these comparisons should be made. The authors can infer that it relates to the evaluation section, but the lack of explicit mention of specific sections or figures makes it weakly grounded. The comment is specific in suggesting a comparison with direct competitors, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. This is a logical suggestion that aligns with the reviewer\"s understanding of the field and the importance of direct comparisons. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the evaluation. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the significance of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential improvement in the evaluation section by suggesting that the base DA methods should be compared with and without the architectural competitors, such as AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for enhancing the evaluation by including direct comparisons with relevant competitors. By making these comparisons, the authors can strengthen their argument and provide a more comprehensive analysis of their proposed TransferNorm architecture. However, the comment could be more helpful if it included specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to related work that might be relevant. However, the comment does not explicitly instruct the authors to define these abbreviations or provide references to the related work. While the issues are clearly identified, the lack of explicit guidance on how to address them makes the comment 3. The authors can infer that they need to define the abbreviations and include references to the related work, but the comment does not provide detailed instructions on how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (L73 and L166) where abbreviations are not defined and superscript notation is not explained until later. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the abbreviations and superscript notation, providing references to related work that might be relevant. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on line 73 and superscript notation in Eq 6. It also notes that these definitions are not provided until much later in the text, which hinders understanding. The reviewer provides references to related work that might be relevant, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the abbreviations. While the references provide context, they do not directly address the issue of undefined abbreviations. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to related work that might be relevant, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al. This feedback is valuable as it highlights areas where the paper could be improved for clarity and understanding. By addressing these issues, the authors can enhance the accessibility and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to define these abbreviations or integrate the references into the text. Overall, the comment is 4 as it points out critical areas for improvement but lacks detailed guidance on implementation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the evaluation or what specific steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the issue with the baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation is weak because the baselines used in the paper are not designed for fair classification. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. This feedback is valuable as it points out a potential weakness in the methodology that could affect the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the setting in the first three paragraphs of section 2 needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback provides a clear and direct action for the authors to take, which is to clarify the setting. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the setting needs to be clarified and that the authors may be implying a greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting in the first three paragraphs of section 2 needs to be clarified, suggesting that the authors may be implying a greater generality than what is actually presented, which could be confusing. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue in the first three paragraphs of section 2, noting that the setting needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback is clear and actionable, as it directs the authors to clarify the setting to improve the clarity and coherence of their exposition. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what could be clarified. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the convincing nature of the experiments, specifically questioning the choice of the old baseline like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment implies that the authors should consider using more recent baselines and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should update their experiments and provide a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment does not explicitly mention a specific section, it is clear that it pertains to the experiments section, allowing the authors to infer the relevant part of the paper. However, the comment lacks specificity in detailing what aspects of the experiments are not convincing or how the proposed method compares to the suggested approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of old baselines like R3D and C3D for the experiments, suggesting that more recent and computationally efficient approaches like X3D and SlowFast should be considered. The reviewer provides a logical reasoning by pointing out that many papers have proposed these 3D CNNs to reduce computation complexity. However, the comment lacks specific examples or references to support the claim that the proposed method does not work on these 3D CNNs or what its advantages are compared to these approaches. This makes the claim 3, as it provides a basis for questioning the choice of baselines but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the choice of old baselines like R3D and C3D for the experiments, suggesting that more recent and computationally efficient approaches like X3D and SlowFast should be considered. It also questions whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it points out a potential weakness in the experimental setup but does not provide detailed advice on how to improve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, it does not provide specific guidance or suggestions on what additional analysis or improvements the authors should consider. The comment lacks explicit instructions or concrete details on how the authors might address this issue, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements made by the paper over previous works and selfimplemented baselines, noting that these improvements are marginal. However, it does not specify which tasks or experiments are being discussed, making it difficult for the authors to pinpoint the exact part of the paper being critiqued. Additionally, the comment lacks specificity regarding what further analysis or improvements are needed beyond the main experiments. Without clear grounding or detailed feedback, the authors may struggle to understand and address the issues raised. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any specific examples, data, or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on what additional analysis or improvements the authors should consider. Without detailed suggestions or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation of the theoretical result, which only provides utility guarantees under the assumption of Gaussian features and noise. It suggests that this is a strong requirement on the data and that the authors should compare their rates to existing rates in the literature. While the comment implies that the authors should address this limitation and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and specifies that it provides utility guarantees only when the features and noise are Gaussian. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the strong requirement on the data and suggests comparing the rates achieved by the procedure to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical result in the paper provides utility guarantees only under the assumption of Gaussian features and noise, which is a strong requirement on the data. The reviewer also notes that previous algorithms do not require this assumption. This claim is 3 as it highlights a limitation of the theoretical result but lacks specific references or examples to substantiate the comparison with existing algorithms. The suggestion to compare the rates achieved by the procedure to existing rates in the literature provides a direction for improvement but does not fully support the claim with detailed evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the theoretical result, which provides utility guarantees only under the assumption of Gaussian features and noise. This is a strong requirement on the data, and the reviewer points out that previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This feedback is clear and actionable, as it highlights a critical area for improvement and provides a specific direction for the authors to enhance their draft. By addressing this limitation and making the comparison suggested, the authors can significantly strengthen their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. While the comment implies that such a comparison would be useful, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in its suggestion to compare with the original approach and the type of data to use, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a comparison with a relevant existing work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific aspects of the original approach should be examined. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works (1, 2, 3) that address similar questions, implying that these comparisons should be included to provide a more comprehensive evaluation. While the comment explicitly states the action needed, it does not provide detailed guidance on which specific aspects of the proposed method should be compared or how to integrate these additional comparisons into the experimental section. The suggestion is concrete in terms of what needs to be added, but the lack of specific details on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison with additional baselines that address similar questions, referencing specific works (1, 2, 3) as examples. This provides clear guidance on what needs to be added to improve the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method, referencing specific works (1, 2, 3) that address similar questions. This provides a clear rationale for the claim, as it references existing literature that could be used for comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional comparisons would enhance the paper\"s evaluation. Despite this, the general direction and the reference to relevant works make the claim 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s experimental section, suggesting that the authors should include additional comparisons with other relevant works. It provides a clear rationale by referencing specific works (1, 2, 3) that address similar questions, indicating that these comparisons would enhance the evaluation of the proposed method. This feedback is actionable and provides a concrete suggestion for expanding the experimental section, making it 4 for the authors to improve their draft. However, the comment could be more helpful if it offered specific guidance on how to integrate these additional comparisons or what aspects of the proposed method should be compared. Overall, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve the focus of their paper. Without specific suggestions or directions, the authors are left without a clear understanding of what changes might be necessary. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper, which is learning to produce good prototypes for fewshot learning. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the distraction caused by the zeroshot version and its connection to density estimation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the zeroshot version and its connection to density estimation, suggesting they are somewhat distracting to the main point of the paper. However, the comment lacks specific reasoning or evidence to support why these aspects are considered distracting or how they impact the main focus. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential distraction in the paper, specifically the zeroshot version and its connection to density estimation, which may divert attention from the main focus on learning to produce good prototypes for fewshot learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the focus of their paper. While it highlights a potential problem, it lacks actionable feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance or suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed on the translation and filtering methodology used to create the Arabic climate change QA dataset. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the process. The comment specifies what needs to be addressed, making it 5. The authors know exactly what information to provide to improve the transparency and quality of their dataset description.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more information on the translation and filtering methodology to assess the dataset quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, and more information on the translation and filtering methodology is needed to assess the dataset quality. This claim is 3 as it identifies a specific area where the paper lacks detail, but it does not provide specific examples or references to support the need for additional information. The authors would need to infer the exact nature of the missing details, making the claim 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the importance of providing more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to include additional details that would enhance the transparency and credibility of their dataset. However, while it provides a clear direction for improvement, it could be more helpful if it offered suggestions on how to present this information or examples of similar datasets with detailed methodologies. Overall, the comment is 4, as it effectively guides the authors in addressing a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to know the extent of the performance difference resulting from using different image sizes and different variations of ResNets. While the comment implies that the authors should investigate and report this difference, it does not provide explicit instructions on how to conduct this analysis or what specific metrics or methods should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is understanding the performance difference resulting from using different image sizes and ResNet variations. This provides clear guidance on what the authors should investigate and report. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for more information, specifically asking for clarification on the performance difference resulting from using different image sizes and ResNet variations. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is 3 as it identifies a specific area where the authors could provide more information, namely the performance difference resulting from using different image sizes and ResNet variations. However, it lacks depth and does not offer suggestions on how to conduct this analysis or what specific metrics should be used to measure the performance difference. While it prompts the authors to consider an important aspect of their work, the feedback could be more comprehensive and actionable to be rated higher. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not provide specific guidance on what aspects of the algorithm should be detailed or how the description should be structured. The action is implicit, as the authors need to infer that they should provide a detailed description of the algorithm, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or subsection. Without explicit references to the paper, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be detailed or how the description should be structured. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to enhance understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. While this feedback highlights an area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the description or what aspects of the algorithm should be detailed. Without additional details or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that a runtime comparison is necessary and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, it does not specify which part of the paper discusses the use of Chebyshev polynomials or where the runtime comparison should be included. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to include a runtime comparison, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, the comment does not provide any reasoning, examples, or references to support why such a comparison would be beneficial or how it could be conducted. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a specific comparison that could enhance the paper\"s analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. To be more helpful, the comment could include specific suggestions or examples of how to implement the runtime comparison. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. It implies that the authors should explore this possibility or acknowledge that it is an open problem. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include a specific reference or discussion on this topic. The action is implicit but concrete, as the authors know what needs to be done to address the suggestion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and references a specific issue discussed in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it suggests exploring existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment provides a clear direction for improvement by suggesting that the authors either explore existing solutions or acknowledge the problem as open. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment implies that there might be alternative methods or approximations that could be explored. However, it does not provide specific references or examples of such work, making it 3. The authors would need to conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even if it\"s an approximation. This feedback is 3 as it points out a gap in the paper and suggests a direction for improvement. However, it could be more helpful if it provided specific references or examples of relevant work. Overall, the comment offers a clear direction for enhancing the paper\"s comprehensiveness and clarity, but it could be more detailed to fully support the authors in addressing the issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How does the number of images impact the model performance, and (2) whether more training images make the performance worse or better. Additionally, it suggests that BYOL should be explained in the abstract for its first appearance. While the questions provide some guidance on what the authors should consider, they do not explicitly instruct the authors to conduct specific experiments or analyses to address these issues. The suggestion to explain BYOL in the abstract is clear, but the other points are more implicit and require the authors to infer the actions needed. Therefore, the comment is 3, as it provides some direction but lacks explicit instructions on how to implement the suggestions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions about the impact of the number of images and the need for an explanation of BYOL, but without grounding, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions and a suggestion for clarification. The questions are logical and seek clarification on the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions or the suggestion. Without additional context or justification, the authors may find it challenging to understand the basis of these questions and how they relate to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s methodology and performance analysis. The first question explores the impact of the number of images on model performance, which is an important consideration for understanding the model\"s behavior. The second question suggests that the abstract should provide an explanation for BYOL, which is a common technique in the field. While these questions are insightful, they do not offer specific guidance or suggestions on how the authors might address these issues or improve their draft. The feedback is 3 as it identifies areas for clarification and potential improvements, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be addressed without detailed guidance on how to proceed. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should include more detailed explanations, it does not explicitly instruct them to do so or provide specific guidance on how to structure these explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"L_pixel\" component, which is a specific part of the paper, providing full grounding. It also specifies the issue by asking for stronger arguments or intuitions to explain why these particular losses are \"bound to help.\" This level of detail allows the authors to clearly identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding why the method works, specifically regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current explanation is unclear. This lack of detailed justification makes the claim 3, as the authors would need to infer the nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of improvement regarding the clarity of the explanation for why the method works, particularly focusing on the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation by offering more detailed reasoning or intuition. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments or intuitions. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for enhancement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the justification of using binary classification as a baseline metric, particularly regarding its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The action is implicit and vague, as the authors are left to infer that they need to reconsider their choice of baseline metrics or provide a more detailed justification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the baseline metrics or the TAL task, making it weakly grounded. The comment is specific in its critique of the binary classification\"s limitations, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. The reviewer acknowledges the importance of the TAL task but expresses uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\" understanding of finegrained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. This feedback is 3 as it identifies a potential limitation in the methodology and prompts the authors to consider alternative metrics or approaches. However, the comment lacks specific suggestions or guidance on how to address this concern, such as proposing alternative metrics or methods. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. It also questions the conditions under which SynTextBench should be used over other metrics. While the comment implies that the authors should conduct these comparisons, it does not provide explicit instructions on how to perform them or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and references \"other metrics proposed in the literature,\" such as MMLU and Big Bench. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison of SynTextBench to other metrics. The comment is also specific because it clearly specifies what needs to be addressed, namely, understanding the conditions under which SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there has been a large amount of work on LLM evaluation and that some metrics do not satisfy the proposed desiderata. It suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. The comment provides a logical reasoning by pointing out the existence of extensive work on LLM evaluation and the need for comparison. However, it lacks specific references or examples to fully substantiate the claim about the metrics not satisfying the desiderata. Therefore, the comment is 3, as it provides a basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. This feedback is 3 as it provides a specific direction for the authors to enhance their work by conducting additional comparisons. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment provides a clear suggestion for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the writing and annotations, stating that they are \"a little hard to follow.\" However, it does not provide specific suggestions or guidance on how the authors might improve their writing or annotations. Without actionable advice or examples of what needs to be changed, the authors are left without a clear understanding of how to address the issue. As a result, the comment lacks actionable guidance, making it 1.", "grounding_specificity_rationale": "The comment mentions \"Poor writing and annotations,\" but it does not specify which sections or parts of the paper are affected. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is specific in its critique of the writing and annotations, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a subjective observation about the writing and annotations being \"a little hard to follow.\" It does not contain any claims, opinions, or suggestions that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks depth and does not provide any specific suggestions or examples of what aspects of the writing or annotations are unclear or difficult to follow. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. As a result, the comment is 2, as it provides a general observation but does not offer meaningful insights or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting, while not achieving the best F1 score in all single types. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or what specific improvements are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and explain the discrepancies in the evaluation metrics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that only 8 out of 14 evaluation metrics achieve SOTA performances and questioning the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that the proposed method does not perform well in all single types. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method\"s performance in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. This feedback is 3 as it highlights a potential weakness in the evaluation and encourages the authors to investigate and explain the discrepancies in the evaluation metrics. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into improving the method\"s performance. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative approach they should consider. The comment lacks concrete details or actions for the authors to take, making it difficult for them to understand how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in questioning the rationale behind the choice, but it lacks grounding as it does not explicitly mention a part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle if all reports were included. This feedback prompts the authors to reconsider their experimental setup or data selection, which could lead to a more comprehensive analysis. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should generate more instances with constraints and variables to address the concern about the ability of LLMs to model problems with large instance sizes. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to generate these instances or what specific steps to follow. The action is somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate more instances with constraints and variables, particularly noting that only a few instances in the paper have more than 7 variables. This implies a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific in terms of what the authors should do to address the concern, but without explicit grounding, the authors may struggle to pinpoint the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should generate more instances with constraints and variables, particularly noting that only a few instances in the paper have more than 7 variables. This raises a concern about the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that LLMs struggle with large instance sizes. While the suggestion is logical, it would be more verifiable with additional evidence or references. Therefore, the comment is categorized as 3, as it provides some reasoning but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s dataset, specifically noting that only a few instances have more than 7 variables. It suggests that generating more instances with constraints and variables could help address this concern and better evaluate the ability of LLMs to model problems with large instance sizes. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their dataset and enhance the robustness of their findings. However, the comment could be more helpful if it included suggestions on how to generate these instances or what specific aspects to consider when doing so. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment implies that the authors should consider these suggestions, it does not provide explicit instructions on how to implement them or which specific baselines to include. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include different baselines and perspectives, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact suggestions being made. The lack of detailed examples or references limits the verifiability of the claim, as it does not provide a clear basis for the authors to follow the advice. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a direction for the authors to enhance their work by considering additional baselines. However, the comment lacks specificity and does not offer detailed guidance on which specific baselines to include or how to incorporate them into the paper. Without more detailed suggestions or examples, the authors may find it challenging to fully implement the feedback. Therefore, the comment is rated as 3, as it provides a general direction but lacks depth and actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion of the article and a summary of the paper\"s contributions need to be provided. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to improve the draft. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions are needed. However, it does not specify which part of the paper these should be included in, making it weakly grounded. The comment is specific in its request for a conclusion and summary, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where these additions should be made. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions are needed. However, it does not provide any reasoning, examples, or references to support why these additions are necessary or how they would improve the paper. Without specific evidence or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that a brief conclusion and a summary of the paper\"s contributions need to be provided. This feedback is clear and actionable, as it directs the authors to include these elements in their draft to enhance its completeness and clarity. However, the comment could be more helpful if it provided examples of how a conclusion and summary could be structured or what specific points should be included. Despite this, the feedback is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to take to improve the experiment or the explanation. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the synthetic experiment in a nonseparable case and asks how the data distribution illustrated in Figure 1 can be inseparable from the network model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. This feedback highlights a potential issue with the experimental design or interpretation, which is important for the authors to address. However, the comment lacks specific guidance or suggestions on how to resolve this issue or improve the experiment. While it identifies a problem, it does not provide actionable steps or detailed feedback, making it 3. The authors are aware of the concern but may need additional support to effectively address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should elaborate more on why the statement in line 134 holds, particularly in the context of the RNN compared to the URNN. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is elaborating on why the statement in line 134 holds, particularly in the context of the RNN compared to the URNN. This provides clear guidance on what additional explanation is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should elaborate on why a statement in line 134 holds, particularly in the context of the RNN compared to the URNN. The comment implies that the authors should provide additional explanation or reasoning to support their claim. However, it does not provide specific examples, references, or detailed reasoning to substantiate the need for elaboration. This makes the claim 3, as the authors would need to infer the extent of the elaboration required. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by elaborating on a statement about the RNN and URNN. It suggests that the authors should provide more detailed reasoning to explain why the statement holds, particularly in the context of the RNN compared to the URNN. This feedback is clear and actionable, as it directs the authors to a specific point in their paper where additional explanation is needed. However, the comment could be more helpful if it provided examples or references to support the elaboration. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. While the comment implies that this is a common practice, it does not explicitly instruct the authors to do so. The action is implicit, as the authors can infer that they should carry out this exercise, but it lacks concrete details on how to implement this suggestion. The authors know that they need to conduct multiple splits, but the comment does not provide guidance on how many splits to perform or how to analyze the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. However, it does not specify which experiments or results are being discussed, making it weakly grounded. The comment is specific in suggesting that the authors should carry out this exercise, but without explicit references to the experiments or results, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on GPs. The reviewer acknowledges that the size of the datasets considered in the work may make this process timeconsuming but encourages the authors to carry out this exercise. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that multiple splits are necessary. This makes the claim 3, as it provides a general rationale but could benefit from more detailed evidence or examples to fully substantiate the need for multiple splits. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reporting of results, specifically noting that the experiments are based on a single heldout test set. It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance, which is a common practice in papers on Gaussian Processes (GPs). While the comment highlights a gap in the current methodology, it does not provide specific guidance on how to implement this suggestion or what benefits it might offer. The authors are left with a general understanding of the need for multiple splits but without detailed instructions on how to execute this change. Therefore, the comment is 3, as it points out a potential improvement but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, implying that the authors should reconsider their phrasing. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. While the first part is somewhat vague, it does provide a clear direction for the authors to consider revising their language. The second part is explicit and concrete, offering specific suggestions for improvement. However, the overall comment lacks detailed guidance on how to tone down the statement or how to address the grammatical errors, making it 3. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 34\" and \"the method section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the statement about the neural network memorizing critical points, suggesting a revision. Additionally, it offers specific suggestions for improving the method section by compressing it and correcting grammatical errors, particularly regarding plurals and articles. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, which is a subjective claim that requires no verification. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors. This part is 4 as it offers clear suggestions for improvement, but it lacks detailed examples or references to support the grammatical corrections. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a mix of feedback. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and actionable suggestion for improving the clarity of the text. Additionally, it offers feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. This feedback is clear and provides the authors with concrete steps to improve their draft. However, the comment could be more helpful if it included specific examples of grammatical errors or suggested ways to compress the method section. Overall, the comment is 4 as it offers actionable advice for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what steps to consider. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what aspect of the paper needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the claim or justify why this is a concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. This feedback is 3 as it prompts the authors to clarify the meaning of this term and consider whether it is accurate or if there is room for improvement. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what additional work might be necessary. Therefore, it is rated as 3, as it identifies a potential area for clarification but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and second, it asks about the number of questions created for the zeroshot intent classifier and the accuracy of the system. While the comment explicitly mentions these areas of concern, it does not provide specific guidance on how the authors should address these issues. The questions are clear and direct, but the lack of detailed instructions on how to incorporate the suggested experiments or improvements makes the action implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses and asks about the number of questions created for the zeroshot intent classifier and the accuracy of the system. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two questions regarding the experimentation with domain ontologies and the number of questions created for the zeroshot intent classifier. These questions are factual inquiries seeking clarification on specific aspects of the paper. They do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions that are relevant to the paper\"s methodology and evaluation. The first question asks about the experimentation with domain ontologies to avoid generating placeholders in the evaluated responses, which is a critical aspect of the paper\"s approach. The second question seeks clarification on the number of questions created for the zeroshot intent classifier and the accuracy of the system. These questions provide clear and actionable feedback, prompting the authors to clarify and potentially expand on their methodology and results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4 as it directs the authors to clarify important aspects of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks citations to set it in the context of other MARL work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This feedback is clear and provides concrete guidance on what needs to be added to the paper to enhance its context and relevance. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MARL work\" and provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including to set their work in context. This level of detail allows the authors to accurately identify the parts of the paper that need to be revised. The comment is also specific, as it clearly specifies what needs to be addressed by adding citations to these papers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to set it in the context of other MARL work, specifically mentioning recent papers on selfplay and populationplay related to exploration and coordination. The comment provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This provides a clear and specific basis for the claim, making it 5. The authors can easily understand the need for these citations and the relevance of the referenced papers, allowing them to effectively address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks context by pointing out the absence of citations to set it in the context of other MARL work, particularly recent papers on selfplay and populationplay related to exploration and coordination. It provides specific examples of relevant papers (https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019) that the authors should consider including. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides concrete references to enhance the paper\"s context and relevance. By addressing this feedback, the authors can significantly improve the quality and comprehensiveness of their draft. Therefore, the comment is 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. While the comment implies that such a comparison would be beneficial, it does not provide explicit instructions on which specific methods to include or how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. The authors may infer that it relates to the comparison section or the introduction, but this inference is not explicit. The comment is specific in its suggestion to compare with noncontrastive methods, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without specific evidence or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is a constructive suggestion as it provides a direction for the authors to expand their analysis and potentially enhance the relevance and novelty of their work. However, the comment lacks specificity regarding which specific noncontrastive methods should be considered or how the comparison should be conducted. While it offers a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors\" claim of parameter efficiency and suggests that the conclusion is applicable to other related works. The comment includes a specific question about the experimental setup, asking why the authors switched the types of BPE vocabulary and whether this change affects performance. While the comment provides a clear question for the authors to address, it does not explicitly instruct them to make changes or provide detailed guidance on how to improve the comparison or experimental setup. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and potential adjustments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the overrating of this comparison. It also raises a concern about the parameter efficiency claim and suggests that the conclusion is applicable to other related works like RoBERTa, ELECTRA, and DeBERTa. Additionally, it asks a specific question about the experimental setup regarding the switch in BPE vocabulary types. While the comment does not explicitly mention specific sections of the paper, it is clear that it pertains to the comparison and experimental setup sections. The authors can infer the relevant parts but may need to make an educated guess. The comment is specific in detailing the issues and questions, making it somewhat grounded. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the overrating of the comparison with Megatron and questions the parameter efficiency claim. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are with similar sizes. The reviewer also asks a specific question about the experimental setup regarding the switch in BPE vocabulary types. While the comment provides some reasoning and references to other works, it lacks detailed justification or specific examples to fully support the claim about overrating. The question about the experimental setup adds depth but does not fully substantiate the initial claim. Therefore, the comment is 3, as it provides some reasoning but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a concern about the overrating of the comparison with Megatron and questions the parameter efficiency claim. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are with similar sizes. The comment also asks a specific question about the experimental setup regarding the switch in BPE vocabulary types and its impact on performance. While the comment identifies a potential issue with the comparison and provides a specific question for the authors to address, it lacks detailed guidance or suggestions on how to improve the comparison or experimental setup. The feedback is 3 as it prompts the authors to consider the validity of their claims and the consistency of their experimental setup, but it could be more comprehensive with additional advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of meaningful baselines in the paper, noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare their work with a chainofthought prompting approach. This feedback is clear and provides a concrete action for the authors to take, which is to include more meaningful baselines in their comparisons. The suggestion is specific and actionable, giving the authors a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors could compare their work with a chainofthought prompting approach. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with a chainofthought prompting approach provides some direction but does not fully explain why this comparison would be meaningful or how it would enhance the paper. Therefore, the comment is 3, as it provides a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s lack of meaningful baselines, noting that the authors limit their comparisons to simple naive baselines. It provides a specific suggestion by recommending the inclusion of a comparison with a chainofthought prompting approach, which could enhance the paper\"s comprehensiveness and validity. This feedback is clear and actionable, offering the authors a concrete direction for improvement. However, the comment could be more helpful if it provided additional context or examples of how the chainofthought prompting approach could be integrated. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment does not explicitly instruct the authors to make a change, it does provide a clear question that prompts them to clarify their pretraining methodology and its implications for generalization. The action is implicit but concrete, as the authors can directly address the question by providing the necessary information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the pretraining process and its implications for generalization, providing clear guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking about the pretraining process of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. The comment does not contain any claims or opinions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it prompts the authors to consider the implications of their pretraining methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are hardware or software dependent, or how this dependency might impact the paper. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be contextspecific. However, the comment lacks specificity and does not provide any guidance or examples on how this dependency might affect the paper or what implications it has for the authors. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to address this issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that there should be an indepth exploration of the reasons behind the experimental results in the analysis section. While the comment identifies areas for improvement, it does not explicitly instruct the authors to propose new metrics or conduct a detailed analysis. The action is implicit and somewhat vague, as the authors can infer the need for new metrics and deeper analysis but may not know how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics, specifically mentioning the need for an indepth exploration of the reasons behind the experimental results in the analysis section. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or table. While the authors can infer that it relates to the experimental analysis section, the comment lacks full grounding as it does not explicitly mention the section or table being addressed. The comment is specific in detailing what needs to be addressed, namely the exploration of reasons for the experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that there should be an indepth exploration of the reasons for the experimental results. However, the comment lacks specific examples or references to support the claim about the lack of new metrics or the need for deeper analysis. While the suggestion for an indepth exploration is logical, the absence of detailed justification or evidence makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of new evaluation metrics and the reliance on linearly combining existing metrics. It also points out the need for an indepth exploration of the reasons behind the experimental results, suggesting that the authors should provide a more detailed analysis. This feedback is clear and actionable, as it highlights specific areas where the paper could be improved to enhance its contribution and understanding. However, the comment could be more helpful if it provided examples of new metrics or detailed suggestions for the indepth exploration. Overall, the comment is 4 as it guides the authors towards improving their draft by addressing key weaknesses."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks actionable advice, such as suggesting alternative notations or recommending a consistent use of \"K.\" As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This provides some grounding as it refers to specific lines in the paper (L166 and L176), allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity as it does not explain why this ambiguity is problematic or suggest how the authors might resolve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused in the paper, being used ambiguously to represent both a known kernel function and the number of layers. This is a factual observation that does not require verification, as it is based on the reviewer\"s understanding of the text. The comment does not express an opinion, make a subjective claim, or suggest changes that would require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This is a clear and actionable observation that highlights a potential source of confusion in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or suggesting ways to clarify the usage of \"K.\" While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the practical relevance of their work. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical nature of the weak recovery problem and questions the practical impact of the AMP algorithm, particularly in nonGaussian problems. However, it does not specify which part of the paper this critique pertains to, such as a specific section or result. The authors might infer that it relates to the discussion of the weak recovery problem or the AMP algorithm, but this inference is not explicit. The comment is specific in its critique of the practical impact, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical relevance of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. This feedback is 3 as it highlights an important consideration for the authors to address, particularly in terms of the applicability of their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the practical relevance of their work. To be more helpful, the comment could include examples of nonGaussian problems or suggest ways to enhance the practical impact of the study. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific points need clarification. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" admission that the problem is reductionist and does not allow for bargaining and negotiation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition in light of the problem\"s limitations and suggests that the authors need to provide more citation for comparison against \"previously appreciated\" aspects. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment lacks specific examples or references to support the claim that behavioral economists would ignore these aspects, making it 3. The authors would need to provide more detailed reasoning or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation, which are commonly used by behavioral economists. The comment questions the authors\" statement about the potential impact of cognitive mechanisms on selforganization and suggests that it would be surprising if behavioral economists ignored these aspects. The reviewer also recommends providing more citations to support the claim and to compare it with \"previously appreciated\" aspects. This feedback is clear and actionable, as it prompts the authors to clarify their stance and provide additional context or references to strengthen their argument. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or what additional information should be included. Overall, the comment is 4, as it provides valuable insights and guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of comparison to simple feature acquisition baselines, such as expected utility, which is a significant weakness of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment also mentions writing style and other issues, but these are not elaborated upon. As a result, the authors are left without clear instructions on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment also mentions writing style and other issues, but these are not elaborated upon, leaving the authors without specific guidance on how to address them. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility, which is a significant weakness. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s credibility and impact. However, the comment does not provide specific suggestions or guidance on how the authors might include these comparisons or which baselines would be most appropriate. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifies that the text mentions separate embedding and addition with positional encoding but lacks details on how these embeddings are combined and fed into the CSCM. This provides a clear and direct action for the authors to take, which is to provide additional explanation or details on this process. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of how historical observations are combined with inputs known over all time, given differences in sequence lengths. The comment provides a clear direction for the authors to improve their draft by offering a specific area for additional explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It requests clarification on how this is achieved, specifically mentioning separate embedding and addition with positional encoding. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for clarification. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, given differences in sequence lengths. It highlights the need for clarification on how these elements are combined and fed into the CSCM, which is a critical aspect of the paper. By pointing out this gap in the explanation, the comment provides a clear and actionable suggestion for the authors to improve their draft. However, it could be more helpful if it offered specific guidance or examples on how to address this issue. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded. As a result, the authors are left without a clear understanding of what changes or additions are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this question or desire pertains to, such as a specific section or discussion. The authors may have an idea of where this topic is addressed, but the comment lacks explicit grounding, making it difficult for them to pinpoint the exact part of the paper being referred to. Additionally, the comment is specific in its request for more discussion on the power of different architectures, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a question and an expression of desire for more discussion on the power of different architectures. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. The comment does not offer guidance on what aspects of the power of different architectures should be discussed or how the authors might expand their analysis. As a result, the comment is 2, as it provides a general direction but does not offer detailed or actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their methods across different splits of trainvaltest rather than just different initialization seeds to obtain robust results. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations across different splits. The comment also offers concrete guidance on how to improve the robustness of the results, making it 5.", "grounding_specificity_rationale": "The comment suggests evaluating the methods across different splits of trainvaltest rather than just different initialization seeds to obtain robust results. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The comment is specific in its suggestion to evaluate across different splits, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating the methods across different splits of trainvaltest would provide more robust results than just different initialization seeds. While the comment implies that this approach would be beneficial, it does not provide specific reasoning or examples to support why this is the case. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that evaluating the methods across different splits of trainvaltest would provide more robust results than just different initialization seeds. This feedback is clear and actionable, as it provides a specific recommendation for improving the robustness of the experimental results. By suggesting a more comprehensive evaluation approach, the comment offers a clear direction for enhancing the draft. However, it could be more helpful if it included examples or further explanation of why this approach would be beneficial. Overall, the comment is 4 as it identifies a potential improvement area and provides a clear action for the authors to take, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is an explicit action that the authors can take to improve their draft by streamlining the presentation of their contributions. The suggestion is concrete, as it specifies which parts of the introduction need to be combined. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This provides full grounding as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what needs to be addressed, namely the combination of the first two points about contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two points about contributions, which are mentioned at the end of the introduction. This is a straightforward suggestion for improving the organization of the introduction, and it does not contain any subjective opinions, claims, or requests for changes. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the organization of the introduction by combining the first two points about contributions. This feedback is clear and actionable, as it directs the authors to streamline their presentation of contributions, which can enhance the clarity and flow of the introduction. However, the comment could be more helpful if it explained why combining these points would be beneficial or provided additional guidance on how to combine them effectively. Despite this, the feedback is 4 as it offers a concrete step for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s potential benefit to the neuroscience community and appreciates its focus on a specific problem. However, it raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these trends or what specific recent trends to refer to. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on a specific problem that somewhat differs from general segmentation problems and appreciates its potential benefit to the neuroscience community. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in suggesting that the authors need to refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. This provides clear guidance on what the authors should do to improve their work. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point acknowledges the paper\"s focus on a specific problem and appreciates its potential benefit to the neuroscience community. However, it raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. While the comment identifies a relevant issue, it lacks specific examples or references to recent trends in the vision community, making it 3. The authors would need to conduct additional research to fully address the suggestion, which limits the comment\"s verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s focus on a specific problem and appreciates its potential benefit to the neuroscience community. However, it raises a critical question about the paper\"s ability to improve over existing solutions and suggests that the authors should refer to more recent trends in the vision community to demonstrate the algorithm\"s robustness against weak boundaries. This feedback is 3 as it identifies a potential area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it offered specific examples or references to recent trends in the vision community that the authors could consider. Overall, the comment provides some actionable guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide explicit guidance on how the authors might address the lack of novelty or what specific aspects of the paper could be improved to enhance its originality. The feedback lacks actionable steps or concrete suggestions for the authors to consider, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items. However, it does not specify which part of the paper this critique applies to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer supports this claim by noting that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the paper lacks originality. The mention of different penalty coefficients for users and items provides some context but does not fully address the novelty claim. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it lacks depth and does not provide specific suggestions on how the authors might enhance the originality of their work. The feedback is 3 as it points out a potential issue with the novelty of the paper, but it does not offer actionable guidance or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance. It suggests that the authors should focus more on the pretraining method in the main paper. While the comment explicitly states the action needed (focusing more on the pretraining method), it does not provide specific guidance on how to implement this suggestion, such as which aspects of the pretraining method should be emphasized or how to structure the discussion. The action is concrete but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining in the main paper and suggesting that it is more important than other modules presented in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it lacks specific evidence or detailed reasoning to support this claim, such as comparisons with other methods or detailed analysis of the impact of unsupervised pretraining. The suggestion to focus more on the pretraining method in the main paper is based on a comparison with the ablation study in Table 5, but without further elaboration, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance as indicated in Table 4. It suggests that the authors should focus more on the pretraining method in the main paper, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to structure the discussion or what aspects of the pretraining method should be emphasized. Overall, the comment is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises an important consideration, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore different methods for handling gender in their pipeline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It also points out a potential drawback regarding the accuracy calculation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the issue with the accuracy calculation, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It also points out a potential drawback regarding the accuracy calculation, suggesting that it should be calculated after using a gender detection model in the pipeline. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the accuracy should be calculated after using a gender detection model. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match the speaker\"s identity. This feedback is valuable as it highlights an important consideration that could impact the accuracy and applicability of the proposed method. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored alternative approaches to handle gender in the pipeline. Overall, the comment is 4 as it identifies a significant area for improvement but lacks detailed guidance on how to implement the suggested changes. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide some intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It also asks how certain distributions $P^*$ might make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the proof and the determination of $P^*$. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing intuition for the proof and questioning the invertible function $f^*$, which depends on the fixed $P^*$. The comment further asks about the ease of determining $f^*$ for certain distributions $P^*$ and how to determine which $P^*$ to fix in practice. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It asks whether certain distributions $P^*$ make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. While the comment raises valid questions about the proof and the invertible function, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes the claim 3, as the authors would need to infer the basis of the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors provide more intuition for the proof of Theorem 1 and questions the invertible function $f^*$, which depends on the fixed $P^*$. It also asks how certain distributions $P^*$ might make it easier to determine $f^*$ and how to determine which $P^*$ to fix in practice. This feedback is 3 as it identifies specific areas where the authors could improve the clarity and understanding of their work. However, it lacks detailed guidance or suggestions on how to address these issues, such as providing examples or references to similar work. While it points out areas for improvement, the comment could be more actionable with additional guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the difference between Eqs. (7) and (10), specifically why one uses X and the other uses H^(1). While it raises a valid concern about the consistency in notation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what changes should be made or how the authors can ensure consistency in their notation. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the difference in notation between the two equations, specifically why one uses \"X\" and the other uses \"H^(1). This provides clear guidance on what needs to be addressed in terms of notation consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the consistency in notation between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1). While the comment raises a valid concern about notation consistency, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the consistency in notation between Eqs. (7) and (10), questioning why one uses \"X\" and the other uses \"H^(1). This feedback is clear and actionable, as it prompts the authors to review and ensure consistency in their notation. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided suggestions on how to achieve consistency or if it pointed out the potential impact of this inconsistency on the paper\"s readability or understanding. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to demonstrate the model\"s capture of realworld diffusion phenomena. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to obtain or present this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the applicability of the model to realworld diffusion processes, specifically mentioning the need for empirical evidence to demonstrate the model\"s capture of realworld diffusion phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the need for empirical evidence, but without grounding, it is challenging for the authors to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that empirical evidence is needed to demonstrate the model\"s capture of realworld phenomena. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes, which is a significant aspect of the paper\"s relevance and impact. It suggests that the authors provide empirical evidence to demonstrate the model\"s capture of realworld diffusion phenomena, which is a constructive and actionable suggestion. However, the comment could be more helpful if it offered specific guidance on how to obtain or present this evidence, such as which types of empirical data or methods would be most effective. Overall, the comment is 4 as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma in the equation. The reviewer suggests clarifying these points. The comment provides explicit actions for the authors to take, such as clarifying the description and the equation, which are concrete and actionable. However, it does not specify how to address the potential numerical instability issue, which could be addressed with additional suggestions. Overall, the comment is 4 due to its clear and concrete guidance on what needs to be clarified.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issues with the description and equation, particularly regarding the absence of the term r^q and the unclear meaning of sigma. The comment provides a clear suggestion to clarify these aspects, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma. The reviewer suggests clarifying these points, which is a logical and specific request for improvement. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the issue and how to address it, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, particularly regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma. The reviewer suggests clarifying these aspects, which is a clear and actionable feedback. Additionally, it raises a concern about the potential numerical instability of multiplying two sigmoid activations, which is a relevant point for the authors to consider. However, the comment could be more helpful if it provided suggestions on how to address the numerical instability issue. Overall, the comment is 4 as it directs the authors to clarify important aspects of their work and raises a potential concern that could impact the robustness of their approach."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the paper, noting that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance or suggestions on how the authors might address this concern. The feedback lacks actionable steps or concrete advice on how to enhance the novelty or improve the methodology. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that the ENCODE part is already proposed in 10 and that the incremental contribution lies in the decomposition part. However, the comment lacks specific examples or detailed reasoning to support the claim that the decomposition part is a significant contribution. The mention of 10 provides some context, but without further elaboration or evidence, the claim remains 3. The authors would need to conduct further research or analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps or detailed advice on how to improve the paper\"s originality. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere but not mentioned in the paper. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors can infer that they need to clarify the domain of the inputs, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, specifically noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact location where this information should be included. While the comment is specific in questioning the domain of the inputs, it lacks grounding as it does not provide explicit references to the paper\"s sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This is a relevant and important point that could impact the clarity and completeness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the paper. While it identifies a potential area for improvement, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in A. While the comment implies that such a comparison is necessary, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a performance comparison but are not given specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions \"proproses a CLN (region proposal generation algorithm)\" and suggests a performance comparison with work A. However, it does not specify which part of the paper this proposal is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting a performance comparison with a particular work, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a performance comparison with a CLN (region proposal generation algorithm) proposed in A. However, it does not provide any specific reasoning, examples, or references to support why such a comparison is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of this suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a performance comparison with a CLN (region proposal generation algorithm) proposed in A. While this is a logical suggestion for improving the paper\"s comprehensiveness, it lacks specificity and actionable guidance. The comment does not provide details on why such a comparison is important or how it could enhance the paper\"s contribution. Without additional context or suggestions, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the presentation is too equationdriven and the notation, particularly in chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure would be beneficial to help clarify the key concepts in section 3. This feedback is clear and provides a direct action for the authors to take, which is to include an illustrative figure to improve the clarity of their presentation. The suggestion is concrete, as it specifies what kind of figure would be helpful. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the presentation is too equationdriven and the notation is convoluted, making it clear what needs to be improved. Additionally, the comment suggests including an illustrative figure to help clarify the key concepts in section 3. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and the notation is convoluted, making it hard to follow. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks concrete evidence or references to substantiate the assertion that the presentation is too equationdriven or convoluted. Without additional context or examples, the authors may find it challenging to understand the specific issues and make improvements accordingly. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and the notation is convoluted, making it hard to follow. It provides a clear suggestion for improvement by recommending the inclusion of an illustrative figure to help clarify the key concepts in section 3. This feedback is actionable and provides a concrete step for the authors to take to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on what kind of figure would be most effective or how it could be integrated into the text. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example, mentioning \"Z'\" and \"the empty set,\" to illustrate the issue. However, the comment does not explicitly instruct the authors to address this conflict or suggest how to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and resolve the conflict. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (7) and the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the independence of variables x and y given W. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the independence of variables x and y given W. The reviewer provides a specific example by mentioning \"Z'\" and \"the empty set,\" which helps clarify the issue. However, the comment lacks detailed reasoning or references to support the claim fully. While the example provides some context, it does not offer a comprehensive explanation or justification for the conflict, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a clear example by mentioning \"Z'\" and \"the empty set,\" which helps the authors understand the problem. However, the comment does not offer suggestions or guidance on how to resolve this conflict or improve the paper. While it highlights an important area for clarification, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. While it implies that the authors should improve the visual presentation, it does not provide specific guidance on how to achieve this enhancement, such as suggesting changes to the font size, color, or layout. The action is implicit and somewhat vague, as the authors know they need to improve the visual presentation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, which need enhancement for better readability and aesthetic appeal. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support why the current presentation is insufficient. The comment lacks detailed justification or suggestions for improvement, making it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can address to enhance the clarity and professionalism of their figures. However, the comment could be more helpful if it offered additional guidance or examples of how to achieve this enhancement. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9page paper limit is grounds for rejection. While the comment identifies a specific issue with the paper\"s formatting, it does not provide any guidance or suggestions on how the authors might address this problem or improve the paper. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of reduced whitespace in the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. However, it does not specify which sections or parts of the paper are affected, making it weakly grounded. The comment is specific in detailing the issue with the formatting, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This claim is supported by the observation that the paper exceeds the 9page limit, which is a clear violation of the submission guidelines. The reviewer provides a logical reasoning by linking the reduction in whitespace to the violation of the page limit, making the claim 4. However, the comment could be strengthened by providing specific examples or references to the sections or figures affected, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the 9page paper limit, which could be grounds for rejection. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the paper\"s formatting. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment highlights an area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should address the clarity of the concept, but it lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its inquiry about the definition of local interactions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks any justification or examples to help the authors understand the issue or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. This feedback highlights an area of potential confusion in the paper, which is important for the authors to address to ensure their work is well understood by readers. However, the comment does not provide any suggestions or guidance on how the authors might clarify this concept or improve its presentation. While it identifies a potential issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy. The authors are left to infer that they need to investigate and possibly revise their results or methodology, but the lack of specific actions or directions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by pointing out a discrepancy between the paper\"s claim of better results and the observation that adding the proposed constrained method actually results in lower validity and diversity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim of better results in the Molecule generation experiment is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the paper\"s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. This feedback is 3 as it points out a potential issue that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this discrepancy or improve their results. The comment highlights a critical area for investigation but does not offer actionable steps for the authors to take, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the update of archetype positions after initialization in Algorithm 2. It explicitly requests the authors to comment on this aspect, providing a clear and direct action for the authors to take. The comment is explicit and concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the archetype positions are updated after initialization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the update of archetype positions after initialization in Algorithm 2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update of archetype positions after initialization in Algorithm 2. It provides a clear and direct question, asking the authors to clarify this aspect. This feedback is actionable as it prompts the authors to address a potential gap in their explanation, which could improve the clarity and understanding of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as mentioning missing information about the empirical study in the supplement, including details like recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also suggests adding a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplement,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as missing information about recording parameters, preprocessing steps, and the condition under which restingstate was recorded. Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be added or clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that there are missing details about the empirical study that should be included in the supplement, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. It also recommends mentioning the number of regions in the parcellation in the main text. While the comment identifies areas that need clarification, it does not provide specific examples or references to support the claim that these details are missing or important. The suggestion is logical and reasonable, but without detailed evidence or examples, it is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks important information that should be included in the supplement. It specifically mentions missing details such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate was recorded. Additionally, it suggests adding a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the completeness and clarity of their work. By addressing these points, the authors can significantly improve the transparency and reproducibility of their study. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can differ across datasets. It suggests that the paper lacks crossdataset experiments to test the generalization of the work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these crossdataset experiments or what specific datasets should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk in methods that exploit relationships between action units and the need for crossdataset experiments to test generalization. The comment is specific in detailing what needs to be addressed, namely the lack of crossdataset experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units can have different correlations across datasets, using examples of AU6 and AU1 to illustrate this point. It suggests that the paper lacks crossdataset experiments to test the generalization of the work. While the claim is based on logical reasoning and specific examples, it lacks detailed references or specific datasets to support the claim fully. This makes the claim 3, as the authors would need to further explore the literature or conduct additional experiments to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential risk in methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of AU6 and AU12, which can occur in different expressions and have different cooccurrences across datasets. The comment suggests that the paper lacks crossdataset experiments to test the generalization of the work, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to conduct these crossdataset experiments or which datasets should be used for testing. Overall, the comment is 4 as it points out a critical area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to include this description or specify how much detail is required. The action is implicit and somewhat vague, as the authors can infer the need for more information but lack concrete guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not specify which part of the paper this description should be included in, nor does it provide any details on what aspects of the Starcraft environment need more description. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not contain any claims, opinions, or suggestions that require verification. It is a request for additional information, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While this feedback highlights an area where additional information could be beneficial, it lacks specificity and does not provide detailed guidance on what aspects of the environment need more description or how this could enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. It explicitly states that the shape model is trained in pixel level and independently on all font images and characters, and that the parsing model is a highorder factor graph with four types of factors. However, the comment does not provide specific guidance on how to improve the efficiency or which existing work to compare with. While the action is explicit, the lack of detailed instructions on how to implement the suggested improvements makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this is not explicit. The comment is specific in detailing the issue of processing efficiency and the need for comparison with existing work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is trained in a timeconsuming manner due to its training in the pixel level and independently on all font images and characters. It also mentions that the parsing model is a highorder factor graph with four types of factors. However, the comment does not provide specific evidence, examples, or references to support the claim about the timeconsuming nature of the training process or the comparison with existing work. This lack of detailed justification makes the claim 3, as the authors would need to infer the significance of the claim without explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. This feedback is 3 as it points out a potential area for improvement in terms of efficiency and provides a direction for comparison with other methods. However, the comment could be more helpful if it offered specific suggestions or examples of existing work to compare with, or if it provided more detailed guidance on how to improve the efficiency of the models. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should consider alternative domain adaptation methods, it does not explicitly instruct them to do so or provide specific examples of these methods. The action is implicit and somewhat vague, as the authors need to infer that they should explore and implement more advanced domain adaptation techniques. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the combination of existing techniques to create a framework without innovation, specifically mentioning the use of adversarial attack or correction methods and domain adaptation methods. It also points out that the adopted domain adaptation method is an old and simple method proposed eight years ago. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue with the use of outdated domain adaptation methods, suggesting that the authors should consider more recent and effective methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. The claim is supported by logical reasoning, as it points out the lack of innovation in combining existing techniques and suggests that the use of an outdated domain adaptation method is suboptimal. However, the comment could be strengthened by providing specific examples of more recent and effective domain adaptation methods or references to support the claim. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach, noting that the authors combine existing techniques without innovation. It points out that the adversarial attack or correction method and the domain adaptation method used are proposed by prior work and that the adopted domain adaptation method is outdated. The comment suggests that the authors should consider using more recent and effective domain adaptation methods to improve the performance of their framework. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for the authors to enhance their work. However, the comment could be more helpful if it provided examples or references to specific recent domain adaptation methods. Overall, the comment is 4, as it guides the authors towards a potential improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the motivation or address the perceived incremental nature of the work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. However, it does not specify which part of the paper is being discussed or what aspects of the motivation are unclear. This lack of grounding makes it difficult for the authors to identify the specific sections or elements that need clarification. The comment is specific in its critique of the paper\"s motivation and incremental nature, but without grounding, it is not actionable. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and describes it as an incremental engineering paper. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide specific examples or suggestions for improvement, leaving the authors without actionable guidance on how to clarify the motivation or address the perceived incremental nature of the work. Without detailed feedback or constructive suggestions, the comment lacks the depth and specificity needed to be helpful. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, which would be beneficial to see. It also points out a specific scenario where the weighting method might have helped, referencing the underperformance of the method in the Atlantis game due to repetitive background sounds. While the comment implies that such an ablation would be valuable, it does not explicitly instruct the authors to conduct this study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This provides some grounding as it relates to a specific part of the paper, but it does not explicitly mention which section or experiment this relates to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing a rationale for its relevance, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the weighting method of the crossentropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors are expected to infer the relevance of the weighting method to the performance issue, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation study on the weighting method of the crossentropy loss, which could provide valuable insights into the performance of the method. It references a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds, indicating that the weighting method might have helped in this context. This feedback is clear and actionable, as it directs the authors to conduct a specific type of analysis that could enhance their understanding of the method\"s effectiveness. However, the comment could be more helpful if it provided additional guidance on how to structure the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It highlights that the paper addresses a specific problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or incremental nature of the work, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions the problem addressed, which is the design of semantic parsers for TexttoSQL, and highlights the design of a new dataset as a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, based on the work addressing a specific problem of column operations in designing semantic parsers for TexttoSQL. It mentions the design of a new dataset as a different train/test split of an existing dataset SQUALL and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim that these contributions are not novel or incremental. The lack of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without specific guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests using solid examples to support this explanation. This feedback is clear and provides a concrete action for the authors to take, making it 5. The authors know exactly what needs to be done to address the comment, which is to provide examples that demonstrate the importance of removing these assumptions. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"removing some of the assumptions like bounded variance and bounded gradients,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing examples to explain the importance of removing these assumptions. This level of detail provides clear guidance on how to improve the draft. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples or reasoning to support why these assumptions are significant or how their removal impacts the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, suggesting that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It provides a clear direction for the authors to enhance their draft by offering a specific action to take\u2014using solid examples to support their explanation. This feedback is actionable and provides a clear path for the authors to improve their work, making it 4. However, it could be more helpful if it included specific examples or guidance on how to develop these examples. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the accuracy levels. However, the comment does not explicitly instruct the authors to address this issue or suggest how to improve the implementation. While the information is detailed, the lack of a direct action or guidance on how to resolve the problem makes the comment 3. The authors know that the issue exists but may not be entirely clear on how to proceed with improvements.", "grounding_specificity_rationale": "The comment addresses the claim that the authors have implemented ImageNet for the first time, but it does not specify which part of the paper this claim is made in. The authors might infer that it relates to the introduction or methodology sections, but this is not explicitly stated. The comment provides specific details about the slowness and low accuracy of the implementation, mentioning the time taken to test an ImageNet picture using AlexNet and ResNet18 and the accuracy levels. However, without explicit grounding, the authors may struggle to pinpoint the exact part of the paper needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" claim of implementing ImageNet for the first time is inaccurate, as it is slow and has low accuracy. The reviewer provides specific examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the accuracy levels, which support the claim. This provides a clear and detailed justification for the assertion, making the claim 4. However, the comment could be strengthened by referencing specific literature or methodologies that demonstrate the expected performance of ImageNet implementations, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet18, and the accuracy levels, which are crucial for understanding the problem. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the implementation. While it highlights a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant problem but does not fully support the authors in resolving it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. The reviewer provides references to existing works in the field, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could guide the authors in exploring this idea further. However, the comment does not explicitly instruct the authors to incorporate labeled data into their consistency training or suggest specific steps to do so. While the suggestion is clear, it lacks concrete guidance on how to implement it, making the comment 4.", "grounding_specificity_rationale": "The comment raises a question about the use of labeled data for consistency training in graph anomaly detection, specifically mentioning the potential benefits of using exact labels. It references two papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or method. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to consider using labeled data for consistency training, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, referencing two existing works. While the comment provides references to support the idea, it lacks detailed reasoning or specific examples of how labeled data could enhance consistency training. The references are relevant to the topic, but the comment does not fully substantiate the claim with detailed analysis or evidence. Therefore, the claim is 3, as it provides a starting point for the authors to explore but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. By referencing existing works in the field, the comment provides a basis for further exploration and potential improvements in the authors\" approach. However, the comment could be more helpful if it offered specific suggestions or guidance on how to incorporate labeled data into the consistency training process or discussed the potential impact on the model\"s performance. Overall, the comment is 3 as it prompts the authors to consider an alternative approach but lacks detailed guidance for implementation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific guidance on what should be included in the experimental suggestions. This includes highlighting the superiority of the method and suggesting the inclusion of certain characteristics. The feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"experimental part\" and \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as reorganizing the content to better highlight the superiority of the method. This provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved to better highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is ineffective or how it could be improved. This lack of detailed justification makes the claim 3, as the authors would need to infer the necessary changes based on their own understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the experimental section, which is found to be lacking in highlighting the superiority of the method. It provides actionable feedback by suggesting that the experimental content should be reorganized to better showcase the method\"s advantages. The comment also offers specific guidance on what should be included in the experimental suggestions, such as highlighting certain characteristics. This level of detail and specificity is valuable for the authors as it directs them to make targeted improvements. However, the comment could be more helpful if it provided examples of how the reorganization could be achieved or suggested specific characteristics to include. Overall, the feedback is 4, as it provides clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. While the comment implies that the authors should provide more information or publish the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should publish the code to support their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not specify which part of the paper this question pertains to, such as a specific experiment or section. The authors may infer that it relates to the experiments or results section, but this inference is not explicit. The comment is specific in questioning the training time and suggesting code publication, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide any specific reasoning or evidence to support the claim that the training time is unreasonable or to justify the suggestion to publish the code. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings, which is a constructive suggestion for improving transparency and reproducibility. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might address this issue or what aspects of the code should be published. While it identifies a potential area for improvement, it does not offer detailed feedback or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD). It does not explicitly request additional experiments but rather points out a lack of clarity regarding what additional information CD captures beyond Predictive Uncertainty. The reviewer also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" While the comment implies that the authors should address these issues, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as describing alternate formulations for Confidence Diversity (CD) and questioning the use of entropy as a measure of \"amount of spreading of teacher predictions.\" The comment provides clear guidance on what additional information is needed to clarify the paper, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the paper regarding Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It suggests that the paper should describe alternate formulations for CD and questions the use of entropy as a measure of \"amount of spreading of teacher predictions.\" However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the authors describe possible alternate formulations for Confidence Diversity (CD). This feedback is actionable and provides a clear direction for enhancing the clarity and depth of the paper. It also raises a question about the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples,\" which could be addressed in the paper. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It suggests that this makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. Additionally, the comment points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the presentation of the human baseline. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the human baseline\"s limitations and ensure accurate representation in the abstract. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This provides full grounding as it explicitly mentions the human baseline and the specific aspect being addressed. The comment is also specific because it details the discrepancy and its impact on the human baseline, as well as pointing out a potential misrepresentation in the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings compared to the full 15 hours. This claim is 3 as it provides a specific comparison between the amount of speech recordings used by the human and the model, which could be considered a factor in the baseline\"s strength. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as how the difference in speech recordings affects the baseline\"s performance. Additionally, the mention of \"all the other factors mentioned in Section 4.1\" implies that there are additional factors that contribute to the human baseline\"s weakness, but these are not elaborated upon. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This discrepancy makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. While the comment highlights a significant issue, it does not provide detailed guidance on how the authors should address this discrepancy or improve the presentation of the human baseline. The feedback is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks depth and actionable suggestions, leaving the authors with a general understanding of the problem but no clear path forward. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the assumption of termination states of instructions being strong, particularly in the context of labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their approach. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the assumption of termination states of instructions being strong, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the assumption, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption of termination states of instructions being strong is expensive in terms of labeling a large number of data manually. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the assumption of termination states of instructions being strong, particularly in the context of labeling a large number of data manually. This feedback is 3 as it points out a potential weakness in the paper that could impact the practicality and feasibility of the approach. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable advice or further elaboration, the feedback is limited in its usefulness for the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the related work section, noting that it discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include these methods as baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the related work section, specifically mentioning the discussion of methods for training NMT models beyond MLE, such as RL methods. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the absence of these methods as baselines, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the related work section discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This claim is 3 as it identifies a gap in the literature review, but it lacks specific examples or references to support the claim fully. The authors would need to provide more detailed information or examples to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the related work section, noting that it discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This feedback is 3 as it points out a potential weakness in the paper\"s literature review. However, it lacks specific suggestions or guidance on how the authors might address this gap, such as recommending which RL methods to include as baselines or how to integrate them into the study. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding whether the authors are referring to a specific efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" is not a recognized entity, implying that the authors may be referring to a general concept of efficient proxies. However, the comment does not provide explicit guidance on how the authors should clarify this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"Efficient Proxy\" or provide a more precise definition of what is meant by \"efficient proxies.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It points out that the term is unclear, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the ambiguity of the term \"Efficient Proxy,\" but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"Efficient Proxy,\" suggesting that it could refer to a specific efficient proxy or a family of efficient proxies. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of terminology in the paper, specifically regarding the term \"Efficient Proxy.\" It points out that the term is ambiguous, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. However, the comment could be more helpful if it offered suggestions on how to resolve the ambiguity or provided examples of how to clarify the term. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the model is simple, which can be both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the simplicity of the model or whether it should be considered a feature or a bug. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why the model is considered simple or how it might be improved. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model\"s simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. The comment lacks actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the focus of the work, specifically mentioning that it is narrow in terms of the task (climate change QA) and the language (Arabic). However, it does not specify which part of the paper discusses this focus, making it weakly grounded. The comment is specific in identifying the narrow focus and its potential impact, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it affects the broader impact of their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, noting that it is focused on a narrow task (climate change QA) in a specific language (Arabic). This observation is relevant as it highlights a potential scope for broader impact. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without specific recommendations or examples, the feedback does not provide the authors with a clear path to improve their draft. Therefore, the comment is 3, as it points out an area for consideration but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are explicit and provide clear guidance on what the authors should include in their draft to enhance its motivation and applicability. The actions are concrete, as they specify exactly what information should be added and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and provides a suggestion for a rough example of runtimes in the experiments. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to include the computational cost and provide examples, but without explicit references to sections, it is challenging for the authors to pinpoint the exact location for these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of runtimes. This is a logical suggestion that could enhance the motivation for the method, but it lacks specific examples or references to support the claim. The comment is 3 as it provides a general suggestion but lacks detailed justification or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper, which could help motivate the method. It also recommends providing a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. This feedback is clear and actionable, offering specific suggestions for enhancing the motivation and applicability of the method. By addressing these points, the authors can improve the clarity and impact of their draft. Therefore, the comment is 4, as it provides valuable guidance for enhancing the manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends the authors to elucidate the procedure in greater detail, specifically regarding the role of the spatial arrangement of EEG sensors in the EEG token quantization process. This feedback is clear and provides a concrete action for the authors to take, which is to include more detailed information about the procedure. The suggestion is specific and actionable, as it guides the authors on what additional information to include to clarify the process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the ambiguity in interpreting EEG topography plots and suggesting that the authors elucidate the procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents EEG topography plots for both the input and output during the EEG token quantization process, leading to ambiguity in interpretation. The reviewer suggests that the authors elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. While the comment identifies a potential issue with the clarity of the presentation, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The suggestion to elucidate the procedure is a logical one, but without additional context or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it presents EEG topography plots for both the input and output during the EEG token quantization process, which may lead to ambiguity in interpretation. The reviewer provides a clear and actionable suggestion by recommending that the authors elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. This feedback is valuable as it guides the authors to clarify a potentially confusing aspect of their work, enhancing the clarity and comprehensibility of their draft. However, the comment could be more helpful if it included specific examples or detailed guidance on how to elucidate the procedure. Overall, the comment is 4, as it effectively directs the authors to improve their draft by addressing a specific area of ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB) and suggests that the authors should clarify the criteria behind this selection. It also implies that other tasks or datasets might provide different insights, which could be valuable information for the authors to consider. However, the comment does not explicitly instruct the authors to provide this clarification or explore other tasks or datasets. The action is implicit and somewhat vague, as the authors need to infer that they should address the generalizability concern and explore additional benchmarks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB), which provides full grounding as it explicitly mentions a specific part of the paper. It also specifies the issue by questioning the generalizability of the evaluation and suggesting that the authors clarify the criteria behind the selection and explore other tasks or datasets. This level of detail allows the authors to understand what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and explore other tasks or datasets that might yield different insights. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the generalizability of the evaluation. The suggestion to explore other tasks or datasets is a logical extension of the concern, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind their selection and explore other tasks or datasets that might provide different insights. This feedback is actionable as it prompts the authors to consider the broader applicability of their results and encourages them to expand their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples of other tasks or datasets that could be considered. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the introduction regarding what is being modelled, specifically mentioning the second paragraph where it discusses modelling curves. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the modelled entity. The comment implies that the authors need to clarify what is being modelled, but it does not offer concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"second paragraph\" of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding what is being modelled, particularly in the context of tumour growth. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction is unclear about what is being modelled, specifically mentioning \"modeling curves.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modeling curves but does not clarify what is being modeled, particularly in the context of tumor growth. This feedback is clear and actionable, as it directs the authors to address a potential confusion in their readers\" understanding. By providing a specific area for improvement, the comment helps the authors enhance the clarity and coherence of their introduction. However, it could be more helpful if it offered suggestions on how to clarify the modeling process or what aspects of tumor growth are being modeled. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more explanation to clarify the \"expected\" result and that the main contribution of the paper, the CBR, should be discussed in more detail. It specifically asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or only the first term. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. The authors are given a clear direction on what additional information or discussion is required, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"expected\" and \"Eq 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, providing more explanation and discussion on the CBR, different optimization strategies, and their results. This includes asking about the impact of minimizing both inter and intra terms or only the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation for the \"expected\" result and discusses the main contribution of the paper, the CBR. It asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or only the first term. While the comment provides a logical basis for the suggestion, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance and importance of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for more explanation regarding the \"expected\" result. It suggests that the paper should provide a clearer discussion on the contributions, particularly focusing on the CBR and its optimization strategies. The comment is specific in asking for a discussion on the impact of minimizing both inter and intra terms in Equation 3 or only the first term. This feedback is actionable and provides clear guidance for the authors to enhance the clarity and depth of their paper. However, it could be more helpful if it included specific examples or references to support the discussion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors to include such a definition. The action is implicit and somewhat vague, as the authors need to infer that they should add a definition but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, nor does it provide specific guidance on what aspects of the definition should be included. The authors can infer that it relates to the proofs, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact section or what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not provide any reasoning or evidence to support why this is necessary or how it would improve the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is 3 as it identifies a potential area for improvement by highlighting the importance of the treewidth concept. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this definition or what aspects of the proofs might benefit from it. To be more helpful, the comment could specify which proofs are particularly affected by the lack of a definition or offer suggestions on how to present the definition in a clear and accessible manner. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. While the comment implies that this analysis would be beneficial, it does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the quality of local minima produced by the algorithm, including the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on improving in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. While the comment implies that this analysis would be beneficial, it does not provide specific reasoning or evidence to support why this is necessary or how it would improve the paper. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the analysis of Algorithm 1 should include an examination of the quality of local minima, specifically the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis. By addressing this suggestion, the authors could potentially strengthen their work by providing a more comprehensive understanding of the algorithm\"s performance. However, the comment could be more helpful if it included additional details or examples to guide the authors in implementing this improvement. Overall, the comment is 4, as it offers a clear direction for enhancement but could be further expanded for maximum benefit."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand certain parts of the main paper. It also requests the release of the source code to facilitate reproducibility. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the selfcontainment of the main paper or what aspects of the paper should be clarified. The request for source code release is clear, but the comment lacks detailed instructions on how to enhance the paper\"s selfcontainment. Therefore, the comment is 3, as it provides a clear action but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment addresses the issue of selfcontainment in the paper, noting that the main paper is not selfcontained and requires the supplementary material for understanding. It also requests the release of the source code to facilitate reproducibility. However, the comment does not specify which parts of the main paper are not selfcontained or what specific sections require clarification. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code to allow for reproducibility. While the comment highlights a potential issue with the paper\"s selfcontainment, it does not provide specific examples or detailed reasoning to support the claim. The request for source code release is a clear suggestion, but without further explanation, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the main paper is not comprehensive enough to be understood without the supplementary material. This highlights a critical aspect that could hinder the paper\"s accessibility and reproducibility. Additionally, the comment requests the release of the source code, which is a constructive suggestion for enhancing reproducibility. However, the comment lacks specific guidance on how to improve the selfcontainment of the main paper or what aspects of the paper could be clarified. While it provides valuable feedback, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically asks for clarification on how this redundancy is built into these algorithms. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this question or what specific details they should include to clarify the implementation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the algorithms. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. However, it does not explicitly mention which part of the paper this sentence is located in, making it weakly grounded. The comment is specific in asking for clarification on how the redundancy is built into the algorithms, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. While the comment identifies a gap in the paper\"s explanation, it does not provide any actionable feedback or suggestions for improvement. The authors are left to infer that they need to clarify the implementation of information redundancy, but without specific guidance, the comment lacks depth and utility. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly instruct the authors to include this rationale. The comment is explicit in its suggestion but vague on how to implement it, as it does not provide specific guidance on what aspects of the choice should be clarified. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly mention which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not specify the exact section. The comment is specific in its suggestion to clarify the choice of algorithms, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the need for clarification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not provide specific guidance on how to clarify this. While the comment identifies a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The authors are given a direction to consider, but the feedback could be more comprehensive to fully support their improvement efforts. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results that exclude the mixup technique from the proposed method. This action is clear and direct, as it specifies what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides a concrete and actionable suggestion, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique to demonstrate the pure contribution of their proposed method. This is a logical suggestion based on the information provided in the paper, specifically in Section 4.2, where the mixup technique is mentioned. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim. While the suggestion is reasonable, it lacks detailed justification or references to support the claim fully. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the authors should include experimental results that exclude the mixup technique from their proposed method. This is important because it allows the authors to demonstrate the pure contribution of their method without the influence of the mixup technique. The comment provides a clear and actionable suggestion, guiding the authors on how to enhance the clarity and robustness of their experimental results. By addressing this feedback, the authors can strengthen their paper\"s contribution and provide a more comprehensive evaluation of their proposed method. Therefore, the comment is 5, as it offers a specific and actionable way to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. While the comment implies that the authors should address this gap in their theoretical analysis, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed analysis of the theoretical support for Fourier features. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the theoretical section or discussion on Fourier features, but this inference is not precise. The comment is specific in questioning the theoretical support for Fourier features, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors are left without guidance on how to address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed, which is an important consideration for the theoretical underpinnings of the work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional analysis might be necessary. While it identifies a potential gap in the theoretical analysis, it lacks actionable advice, making it 3. The authors are prompted to consider a theoretical aspect of their work, but the feedback could be more comprehensive and actionable to be rated higher."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue regarding the methodology, specifically questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific information needs to be included in the paper. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or additions are necessary. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the methodology of the paper, specifically asking for details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is 3 as it highlights a potential gap in the paper\"s explanation, prompting the authors to clarify or provide additional details on the methodology. However, the comment lacks depth and does not offer suggestions on how to address this issue or improve the clarity of the explanation. To be more helpful, the comment could include specific questions or suggestions for further elaboration. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other relevant details. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to provide more detailed information about the experimental setup, but the comment lacks concrete guidance on what specific details should be included. Therefore, the comment is 3, as it highlights a need for clarification but does not provide explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on the experiment setup, including data augmentation methods, learning rate, and other relevant details. The comment provides a clear reference to the section and specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the experiment setup in Section 3.3, specifically asking for clarification on data augmentation methods, learning rate, and other details. It references a specific paper, \"BadNets,\" which provides a context for the discussion. However, the comment does not provide detailed reasoning or examples to support why this information is crucial or how it affects the experiment. The reference to \"BadNets\" is a step towards verification, but the lack of specific details or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the experiment setup in Section 3.3, asking for clarification on data augmentation methods, learning rate, and other relevant details. It references a specific paper, \"BadNets,\" which provides a context for the discussion. While the comment identifies a gap in the paper\"s clarity, it does not offer detailed guidance or suggestions on how to improve the experiment setup or what specific details should be included. The feedback is 3 as it highlights a need for clarification, but it lacks depth and actionable advice, leaving the authors with a general direction to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about potential errors in the initial calibration steps (steps 1 & 2) of the original algorithm, which the authors used. It suggests that this might explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to investigate or correct the potential error. The action is implicit and vague, as the authors are left to infer that they should look into the calibration steps and possibly conduct further analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III\" of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what the authors need to investigate. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about potential errors in the initial calibration steps of the original algorithm, suggesting that this might explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide specific evidence, examples, or references to support the claim of an error. The reasoning is based on the reviewer\"s observation of the disparities, but without detailed justification or evidence, the claim remains 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a concern about potential errors in the initial calibration steps of the original algorithm, suggesting that this might explain the speed disparities observed between the RSPs and FDs. This feedback is 3 as it identifies a specific area for improvement and provides a potential explanation for the observed discrepancies. However, the comment lacks detailed guidance or suggestions on how the authors might investigate or address this issue, such as specific steps or methods to verify the calibration steps. While it prompts the authors to consider a possible cause for the disparities, it does not offer actionable advice or detailed recommendations for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a specific area of inquiry, it does not provide explicit guidance or suggestions on how the authors should address this question or what additional information or analysis is needed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of nonparametric emission distributions on inference tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or analysis of HMMs with nonparametric emission distributions. The authors can infer that it relates to the main body of the paper, but the comment lacks explicit grounding. The specificity is clear as it identifies a specific area of inquiry regarding the impact of nonparametric emission distributions on inference tasks. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment does not contain an explicit claim or suggestion, it poses a logical inquiry that requires the authors to clarify or expand upon their work. The comment does not make a subjective judgment or require justification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is important as it challenges the authors to clarify the limitations or capabilities of their approach. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what additional analysis or discussion is needed to provide a comprehensive answer. While it identifies a critical area for exploration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results to understand the reasons behind the observed performance. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a deeper analysis but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of analysis of the underlying reasons for the poor performance of the scope prompting method on GPT3.5turbo. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a specific issue with the analysis but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to conduct a more detailed analysis to understand the reasons behind the observed performance. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider comparing these methods in the remaining 110 datasets. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to conduct these additional comparisons. The action is implicit and somewhat vague, as the authors can infer the need for further analysis but lack specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider comparing these methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this discussion is related to, such as a specific section or table where the comparison is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the rationale behind the dataset selection, but without explicit grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It does not provide any specific reasoning or evidence to support the claim that the authors should compare these methods in the remaining 110 datasets. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider comparing these methods in the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these additional comparisons or what specific aspects should be considered. The feedback is 3 as it points out a potential limitation in the study\"s scope, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the sensitivity of performance and sample efficiency to the lambda parameter, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, including 1, 2, and 3, which could help the authors address these issues. However, the comment does not explicitly instruct the authors to use these references or provide specific guidance on how to improve their understanding or explanation. While the feedback is informative, it lacks explicit action or concrete steps for the authors to take, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific page numbers and line numbers, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the lambda parameter, and the lack of understanding of how lambda is computed. Additionally, it questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment and provides references to relevant literature. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to the lambda parameter and the computation of lambda. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, including 1, 2, and 3, which could help the authors address these issues. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims about the sensitivity of performance and sample efficiency to the lambda parameter. While the references provide a basis for further exploration, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas of concern: the sensitivity of performance and sample efficiency to the lambda parameter, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, which could be beneficial for the authors to explore and potentially incorporate into their work. However, the comment lacks detailed guidance or suggestions on how the authors might address these issues or improve their understanding. While it highlights important areas for clarification, the feedback could be more actionable with specific recommendations or examples. Therefore, the comment is 3, as it provides valuable insights but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used for solving the minmin problem, which is mentioned as an alternating direction method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify which specific method is being used, provide more details about the method, or explore alternative methods. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"minmin problem\" and the \"alternating direction method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to solve the minmin problem, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. While it identifies a gap in the paper\"s description, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment highlights potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the effectiveness of their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the effectiveness of lower bound double qlearning and the performance decrease of Clipped DDQN in certain environments. The comment further highlights the potential overestimation of the true maximum value. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment provides some reasoning and examples, it lacks detailed evidence or references to support the claim fully. The authors may find it challenging to address these concerns without additional context or specific examples. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, particularly in the context of the MsPacman environment in Figure 2. It notes that the algorithm shows a slight performance decrease for Clipped DDQN in certain environments and suggests that the algorithm might converge into the same solutions. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the effectiveness of their approach. The feedback provides some insight into areas that need further investigation but does not offer actionable steps for improvement. Therefore, the comment is 3, as it highlights weaknesses but does not fully support the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve the novelty of their work. Without actionable suggestions or explicit directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may infer that it relates to the interpretation of predictions or model interpretation, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the approach are considered limited or how the authors might address this critique. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the approach is limited, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. While it identifies a potential issue with the novelty of the work, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the critique or enhance the originality of their approach. Therefore, the comment is 2, as it points out a concern but does not offer constructive feedback or actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to clarify their results. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation or justification for the observed performance trend. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, and it provides a clear expectation that the performance should approach that of vanilla methods from above but from below. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation or explain why the performance trend is unexpected. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the reviewer\"s expectation. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as seen in Figures 3 and 4. The reviewer expresses an expectation that the performance should approach that of vanilla methods from above but from below. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation of their results. While it identifies a potential area for improvement, the feedback is vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with earlier research work from 2020, noting that the authors have explained their reasons in the author response. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be made. The comment suggests that the authors have compared their results to earlier systems with worse performances, but it does not offer concrete advice on how to improve this aspect of the paper. The action is implicit and vague, as the authors are left to infer that they should include comparisons with more recent work, but without specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of comparison with earlier research work from 2020, specifically mentioning that the authors have explained their reasons in the author response. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in pointing out the absence of comparisons with recent work and the authors\" justification for not doing so. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not compare the results with earlier research work from 2020, despite the authors explaining their reasons in the author response. However, the comment does not provide specific examples or references to the earlier work that should have been compared, nor does it offer detailed reasoning or evidence to support the claim. The lack of specific examples or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s comparison, specifically noting that the results are not compared with earlier research work from 2020. It acknowledges the authors\" explanation in the author response but points out that the comparison is made with earlier systems with worse performances. The comment suggests that the authors should include comparisons with more recent work, which could enhance the paper\"s relevance and impact. However, the feedback lacks specific guidance on which earlier work should be included or how to conduct these comparisons effectively. While it highlights an important area for improvement, the comment could be more helpful with additional details or suggestions. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to elaborate on the Hoeffding\"s bound and its application in stochastic algorithms. It explicitly instructs the authors to address the issue of conditioning on the previous iterate, which guarantees the Hoeffding inequality holds. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is elaborating on the Hoeffding\"s bound and its application in stochastic algorithms, particularly regarding conditioning on the previous iterate. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Hoeffding\"s bound holds true for any w as long as the samples are drawn independently, and stochastic algorithms impose conditioning on the previous iterate, guaranteeing the Hoeffding inequality. The comment suggests that the authors should elaborate on this. While the claim is based on logical reasoning and common knowledge in the field, it lacks specific references or examples to fully substantiate the claim. The suggestion to elaborate is a request for more detailed explanation, which is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out a potential area of clarification in the paper. It highlights the need for the authors to elaborate on the application of Hoeffding\"s bound in stochastic algorithms, particularly regarding conditioning on the previous iterate. This feedback is actionable and offers a clear direction for the authors to enhance their draft by providing additional explanation or examples. However, the comment could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is 4 as it guides the authors towards improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While the comment implies that the authors should consider incorporating these approaches, it does not provide explicit instructions on how to implement them or why they would be beneficial. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the potential benefits of adding these approaches. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of the paper this table is in or provide any context about the table itself. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in suggesting the addition of a particular approach, but without grounding, it is challenging for the authors to understand the context or relevance of this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, the comment does not provide any justification or reasoning for why these approaches should be included or how they would enhance the table. Without specific examples, references, or logical reasoning, the claim lacks verifiability. The authors are left without guidance on how to implement this suggestion or why it would be beneficial, making the comment barely verifiable.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it identifies a potential enhancement to the paper by suggesting a specific method that could be included. However, the comment lacks detail on why this approach would be beneficial or how it could be integrated into the table. To be more helpful, the comment could provide additional context, such as how these approaches could improve the results or enhance the analysis. Overall, the feedback is 3 as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks an ablation study to explain why the chosen prompt is effective, particularly mentioning the potential benefits of fewshot examples for CoT. While the comment implies that an ablation study should be conducted to justify the choice of prompt, it does not explicitly instruct the authors to perform this study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and understand the specific aspects to investigate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of fewshot examples for CoT. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing what is missing\u2014a lack of ablation study and the potential benefits of fewshot examples for CoT\u2014but it lacks full grounding as it does not pinpoint the exact section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of fewshot examples for CoT. However, the comment does not provide specific examples or detailed reasoning to support why an ablation study is necessary or how it would improve the paper. The suggestion is vague and lacks concrete evidence or references to substantiate the claim. As a result, the comment is considered 2, as it provides some direction but lacks sufficient justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting an ablation study to explain the choice of prompt. It highlights the potential benefits of including fewshot examples for CoT, which could enhance the paper\"s understanding and justification of the chosen methodology. However, the comment lacks detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it provides a clear direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it offers a valuable suggestion but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from temporal relationships. This feedback is clear and direct, providing a specific action for the authors to take. It gives them a clear understanding of what needs to be addressed and how to correct it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that \"causality is different from temporal relationship,\" providing clear guidance on what needs to be addressed. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"causality is different from temporal relationship,\" which is a factual statement rather than a claim or suggestion. It does not require verification or evidence, as it is a clear and accurate statement of fact. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out a potential confusion in terminology regarding \"causal mechanisms\" and \"causality\" on page 1. It instructs the authors to use these terms carefully, emphasizing the distinction between causality and temporal relationships. This feedback is specific and actionable, helping the authors to improve the clarity and accuracy of their terminology. However, it could be more helpful if it included examples or further explanation of why this distinction is important. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the relationship between the results and the referenced work, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for improvement by pointing out a relevant reference that could enhance the paper\"s discussion. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this discussion or what aspects of the results should be highlighted. To be more helpful, the comment could specify which parts of the paper the discussion should address or how it would contribute to the overall understanding of the results. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider how well the assumptions underlying PCA are met. While the comment highlights potential issues, it does not provide explicit guidance or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to evaluate the assumptions of PCA and possibly provide additional context or evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concerns about the novelty and significance of the results, as well as the need to evaluate assumptions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions of PCA are met in the context of the paper. While the reference provides a starting point for the authors to consider, the lack of detailed analysis or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the authors should consider how well the assumptions underlying PCA are met, referencing a relevant paper for further exploration. While the comment identifies a potential area for improvement, it lacks specific guidance or actionable suggestions on how the authors might address these concerns or enhance the significance of their results. The feedback is 3 as it points out a potential weakness but does not provide detailed advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the fewshot RC models considered in the paper are not stateoftheart, and it suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of fewshot RC models in the paper and suggests comparing their performance to relation extraction/generation models in fewshot settings. However, it does not specify which part of the paper discusses these models, making it weakly grounded. The comment is specific in its suggestion to compare the performance of the models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart, suggesting that the authors should compare their performance to relation extraction/generation models in fewshot settings. However, the comment does not provide specific examples or references to support the claim that the models are not stateoftheart. Without detailed evidence or comparisons, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart. It suggests comparing the performance of these models to relation extraction/generation models in fewshot settings. This feedback is 3 as it points out an area for improvement and provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included specific examples or references to stateoftheart models or detailed suggestions on how to conduct the comparison. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the results in section 4, stating that they apply only to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or what steps they should consider to expand the scope of their results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a limitation in the results, stating that they apply only to shallow fullyconnected ReLU networks. This provides clear guidance on what aspect of the results needs further exploration or clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the results presented in section 4, specifically noting that they are restricted to shallow fullyconnected ReLU networks. This feedback is 3 as it points out a potential scope limitation that the authors should consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their results. Without actionable advice or further elaboration, the comment provides only a partial benefit to the authors in terms of improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. While the comment implies that the authors should include results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to present results, but the comment lacks specific guidance on how to present them or what results to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the discussion of using sequential MCB vs a single MCT layers for the decision head. It is fully grounded as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies what is missing, which is the inclusion of results related to this discussion. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. This feedback is clear and actionable, as it directs the authors to include results that would enhance the discussion and provide more insight into the topic. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific results should be included. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their choice of distribution sets and consider the impact of selecting a limited number of sets. However, the comment lacks concrete details on how to implement these clarifications, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table where this choice is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the choice of distribution sets and their impact, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification or the potential impact of the choice of distribution sets. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it relates to the overall quality of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern regarding the choice of distribution sets, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is 3 as it prompts the authors to consider the implications of their choice of distribution sets, but it does not provide detailed advice or actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models instead of the obsolete ngram HMM and RNN models. This action is clear and concrete, as it provides a specific direction for the authors to improve their draft by aligning it with current NLP trends. The comment offers a clear and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of perplexity experiments with obsolete language models, specifically mentioning ngram HMM and RNN. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the use of perplexity experiments. The comment is also specific because it clearly specifies the need to use transformerbased models to improve alignment with current trends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of perplexity experiments with obsolete language models (ngram HMM and RNN) is outdated and recommends using transformerbased (masked) language models to better align with current NLP trends. The comment provides a logical reasoning for the suggestion, as transformerbased models are more prevalent and effective in the current NLP landscape. However, it lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to conduct additional research or provide specific examples to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the use of perplexity experiments with obsolete language models (ngram HMM and RNN). It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more aligned with current NLP trends. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and currency of their work. By following this suggestion, the authors can significantly improve the alignment of their research with contemporary practices in the field. However, the comment could be more helpful if it included additional context or examples to further support the recommendation. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to clarify the estimation of mu. Without specific suggestions or directions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the estimation of mu, which is the proportion of missing observations. However, it does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the estimation of mu, but it lacks detailed guidance on how to address this issue or what aspects need clarification. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any supporting evidence, reasoning, or references to justify why this estimation is unclear or problematic. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand and address the issue. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the estimation of mu, which is the proportion of missing observations. It points out that it is not clear how mu can be estimated, suggesting a potential weakness in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their estimation methods. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific action for the authors to take, which is to present the performance as a function of the distance of initialization M^0 to the groundtruth M^*. This involves varying the distance c and randomly sampling a matrix M^0 for initialization, then reporting the performance accordingly. The comment provides a clear and concrete suggestion on how to address the sensitivity to initialization, specifying the steps to be taken. This level of detail and explicitness makes the action fully actionable, as the authors know exactly what needs to be done to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests a specific action for the authors to present the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which involves varying the distance c and randomly sampling a matrix M^0 for initialization. This provides a clear and concrete suggestion on how to address the sensitivity to initialization, making the comment fully grounded. The authors can accurately identify the part of the paper where this suggestion would be relevant, such as the experimental section or results. The comment is also specific, as it details the exact steps to be taken to improve the analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific method for presenting the performance as a function of the distance of initialization, which involves varying the distance c and randomly sampling a matrix M^0 for initialization. The rationale provided is logical and provides a clear explanation of why this approach would be beneficial for understanding the sensitivity to initialization. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have used this method. Despite this, the suggestion is 4, as it offers a clear and reasonable approach to address the issue of sensitivity to initialization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the analysis of sensitivity to initialization. It proposes presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which involves varying the distance c and randomly sampling a matrix M^0 for initialization. This approach allows for a more comprehensive understanding of how the performance changes with different levels of initialization quality. The comment is clear and actionable, offering a concrete method for the authors to enhance their analysis and improve the robustness of their results. This level of detail and practical guidance makes the comment 5, as it empowers the authors to significantly improve their draft by addressing a specific area of concern. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the absolute value operation in the definition of the Frobenius norm is unnecessary since tensor entries are real numbers. This observation is explicit and provides a clear action for the authors to take, which is to remove the absolute value operation. The comment is concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, noting that it is unnecessary since tensor entries are real numbers. This provides clear guidance on what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that aligns with common mathematical knowledge. The reviewer provides a clear explanation of why the absolute value operation is redundant, which is a wellsupported argument. However, the comment could be strengthened by providing a specific reference or example to further substantiate the claim. Therefore, the comment is 4, as it is wellsupported but lacks some additional evidence or references.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically noting that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their definition. By addressing this point, the authors can enhance the precision of their mathematical notation, which is beneficial for the overall quality of the paper. However, the comment could be more helpful if it included additional context or suggestions for how to present the corrected definition. Overall, the comment is 4, as it guides the authors toward a specific improvement that can significantly enhance the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds instead of only bounds in expectation. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement them, such as which specific ensemble methods to use or how to calculate error bars. The authors are given a clear direction but may need to further explore the suggested methods to fully implement the changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"highprobability bounds\" and \"ensemble methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of ensemble methods to achieve highprobability bounds and adding measures of robustness like error bars or standard deviation to the experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and questions whether highprobability bounds could be obtained. It proposes using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed examples of how ensemble methods or robustness measures have been successfully applied in similar contexts. This makes the claim 3, as the authors would need to explore the suggested methods further to fully understand and implement the changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that only bounds in expectation are provided, suggesting that highprobability bounds could be more informative. It offers a specific suggestion to use ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to improve their work. By addressing these suggestions, the authors can enhance the robustness and reliability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the author is not an expert in pruning but finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the results and consider additional evaluation aspects, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the author\"s expertise in pruning and finds the motivation to be good, but it raises concerns about the results being less impressive and suggests evaluating them from additional aspects, such as latency, memory consumption, and network size. However, the comment does not specify which part of the paper these concerns relate to, making it weakly grounded. The authors can infer that it pertains to the results section or discussion, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely, the evaluation of results from multiple aspects. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the author\"s expertise in pruning and finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests evaluating them from additional aspects, such as latency, memory consumption, and network size. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to support the claim that the results are less impressive or how they should be evaluated from additional aspects. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment acknowledges the author\"s expertise in pruning and finds the motivation to be good. However, it raises concerns about the results being less impressive and suggests that the results should be evaluated from additional aspects, such as latency, memory consumption, and network size. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these concerns or enhance the evaluation. The feedback is 3 as it points out potential weaknesses but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the novelty of the paper, suggesting that it may be incremental. It asks the authors to clarify how their work differs from a previous publication, specifically mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This comment implicitly suggests that the authors should provide a detailed comparison or explanation of the differences between their work and the referenced publication. However, it does not explicitly instruct the authors to make these comparisons or provide specific details on what aspects need to be addressed. The action is concrete in terms of what needs to be done, but it is inferred rather than explicitly stated. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment questions the novelty of the paper, suggesting that it may be incremental. It asks the authors to clarify how their work differs from a specific publication, mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This provides some grounding as it references a specific paper, but it does not explicitly mention which part of the paper this question pertains to, such as a particular section or methodology. The comment is specific in its request for clarification on the differences between the current work and the referenced publication. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty of the paper, suggesting that it may be incremental. It asks the authors to clarify how their work differs from a specific publication, https://aclanthology.org/2021.findingsacl.57.pdf. This question is logical and seeks clarification on the uniqueness of the proposed methodology or approach. However, the comment does not provide specific examples or detailed reasoning to support the claim that the novelty is incremental. The authors are left to infer the nature of the differences, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the paper, questioning whether it offers incremental improvements over a previous publication. It prompts the authors to clarify the differences between their work and the referenced publication, specifically mentioning https://aclanthology.org/2021.findingsacl.57.pdf. This feedback is actionable as it directs the authors to provide a detailed comparison or explanation of their work\"s uniqueness. However, the comment could be more helpful if it suggested specific areas where the authors should focus their explanation or provided examples of how their work differs. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what steps they should consider to resolve it. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results of the ablation studies on the CUB and SOP datasets, highlighting a discrepancy where the complete loss function performed worse than those with some terms missing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. This feedback is 3 as it identifies a potential issue with the reported results, prompting the authors to investigate and possibly clarify or correct the findings. However, the comment lacks specific guidance or suggestions on how the authors might address this discrepancy or improve their analysis. To be more helpful, the comment could provide additional context, reasoning, or potential explanations for the observed results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the abstract, noting that the statement \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions\" is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. While the comment points out a specific area of confusion, it does not provide explicit guidance on how to clarify the statement or what aspects of the abstract should be made more highlevel. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the abstract without providing detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which is its unclear nature due to the technicalities mentioned. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technicalities are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that the abstract should be more highlevel. The comment provides a rationale by stating that technicalities are not necessary for a highlevel understanding, which supports the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the technicalities that are unclear, which limits the clarity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the abstract, noting that a statement about ensuring a lowrank feature subspace and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. This feedback is clear and actionable, as it provides a specific area for improvement and offers guidance on how to simplify the abstract. By addressing this feedback, the authors can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 4, as it effectively directs the authors to improve the clarity of their abstract without fully addressing all aspects of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, the comment does not provide explicit guidance on how to incorporate these results or what specific languagerelated tasks should be considered. The suggestion is vague and lacks concrete details on how to implement the action, making it 3. The authors know that they should consider including results in other modalities, but the comment does not provide clear instructions on how to do so. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider other modalities and the importance of OOD performance, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, the comment does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The suggestion is based on a general observation about the importance of OOD performance in language tasks, but without detailed reasoning or evidence, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests expanding the results section to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. This feedback is 3 as it provides a direction for the authors to consider additional experiments or analyses that could enhance the comprehensiveness of their work. However, the comment lacks specific guidance on which languagerelated tasks to include or how to measure OOD performance, which limits its usefulness. The authors are given a general idea of what could be improved but are left without detailed instructions on how to implement these suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, particularly in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment implies that the authors should address these issues, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the justification of the work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fewshot learning\" and \"graph link prediction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the motivation, such as the lack of consideration for effectively using \"fewshot\" and guaranteeing generalization to new tasks. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, particularly in the context of fewshot learning. It suggests that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. The comment provides a logical reasoning by pointing out the lack of consideration for the \"fewshot\" aspect and the need for generalization. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact points that need clarification or improvement, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the justification of the motivation. It points out that while the paper defines a fewshot situation for graph link prediction, it does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to address a significant gap in their work. By providing a specific area for improvement, the comment offers valuable guidance that can help the authors enhance the clarity and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of Gaussian Process (GP) and mentions that dynamical modeling has been widely investigated in the GP community, referencing the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their use of GP or address the critique. The comment lacks actionable advice, leaving the authors without a clear understanding of what changes or additions are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may have an idea of where the critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The comment is specific in its critique of the use of GP and references a specific paper, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is \"kind of straightforward and naive,\" suggesting that it is not innovative or sophisticated. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of dynamical modeling and the reference to a specific paper (NIPS 2005) provides some context, but it does not substantiate the claim. Without additional evidence or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Process (GP) and suggests that its application is \"kind of straightforward and naive.\" It references the Gaussian Process Dynamical Model in NIPS 2005, implying that dynamical modeling has been widely investigated in the GP community. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their use of GP or address the critique, leaving the authors without a clear path forward. Therefore, the comment is 2, as it identifies a potential issue but does not provide actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It also points out that this is not consistent with the author\"s experience, suggesting that the baseline models may not be properly regularized. The reviewer further asks if dropout is applied to the hidden states in addition to the embeddings. While the comment identifies a potential issue and provides a specific question for the authors to consider, it does not explicitly instruct them to address this concern or provide guidance on how to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization of their models and possibly clarify the statement in the supplemental section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for LM compared to the GAN model, suggesting that this is not consistent with the author\"s experience. The comment also raises a specific question about whether dropout is applied to the hidden states in addition to the embeddings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. 2014, which suggests that the baseline models may not be properly regularized. The comment also asks if dropout is applied to the hidden states in addition to the embeddings. While the reviewer provides a specific reference to support their claim, the comment lacks detailed reasoning or examples to fully substantiate the critique. The addition of a question about dropout further complicates the verification, as it requires the authors to address both the initial claim and the new inquiry. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification and examples.", "helpfulness_rationale": "The review comment raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It points out that this is not consistent with the author\"s experience, suggesting that the baseline models may not be properly regularized. The reviewer also asks if dropout is applied to the hidden states in addition to the embeddings. This feedback is 3 as it identifies a potential issue with the regularization of the models and prompts the authors to consider whether their models are adequately regularized. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the issue or improve the regularization. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some ablations mentioned in previous sections are difficult to locate in the subsequent contents, implying that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to find. The action is implicit and somewhat vague, as the authors need to infer which sections to focus on and how to improve the writing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not specify which sections or ablations are problematic, making it difficult for the authors to identify the exact areas needing improvement. The comment lacks grounding as it does not reference specific sections or elements of the paper, leaving the authors without a clear understanding of where to focus their efforts. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved. However, the comment does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand which ablations are problematic or how to improve the writing. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s writing, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback is 3 as it points out a potential area for improvement in terms of clarity and organization. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to improve the indexing or organization of the ablations. Without actionable advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends that the online algorithm and robustness be highlighted as novel and interesting, and that the experimental results in the appendix be moved to the main paper. While the comment provides clear guidance on what needs to be improved and where the focus should be, it does not specify how the authors should address the \"halfbaked\" aspect or how to present the online algorithm and robustness more effectively. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think through it more clearly. It also mentions the online algorithm and robustness as novel and interesting, and suggests moving the experimental results from the appendix to the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application or the online algorithm, making it weakly grounded. The feedback is specific in suggesting improvements and clarifications, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the application is \"halfbaked.\" The suggestion to move the experimental results is clear, but without further explanation, it is difficult for the authors to understand the rationale behind this recommendation. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a concern about the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, recommending that the experimental results be moved to the main paper. While the comment provides some insight into areas for improvement, it lacks specific suggestions or guidance on how to address the \"halfbaked\" aspect of the differential privacy application or how to present the online algorithm and robustness more effectively. The feedback is 3 as it points out a potential issue but does not offer detailed actionable advice, leaving the authors with a general direction to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation. However, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to their methodology. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the methodology\"s scope but lacks grounding, as it does not point to a particular section or element of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. This feedback is 3 as it prompts the authors to consider the scope of their methodology and whether it could be more generalizable. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or expand the applicability of their work. As a result, the feedback is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment lacks actionable details, such as recommending specific methods or analyses to ensure comparability, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches, noting that studying Geffect of each learning objective in isolation raises this issue. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the results are not comparable. This lack of detailed evidence or justification makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the study\"s methodology, specifically regarding the comparability of Geffect values across various unlearning objectives and approaches. It highlights that studying Geffect of each learning objective in isolation raises concerns about the comparability of results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the consistency of UNIFORM\"s advantage over other procedures, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this scenario. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of UNIFORM\"s advantage over other procedures, specifically mentioning the tables that show UNIFORM\"s performance in the 1shot setting. It also suggests that the authors should provide a theory to explain why the method is not as effective in this scenario. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the results and theory sections. The comment is specific in detailing what needs to be addressed, namely, providing a theory for the method\"s performance in the 1shot setting. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as shown in the tables. It suggests that the authors should provide a theory to explain why the method is not as effective in the 1shot setting. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide a theory is a logical step but is not fully supported by the evidence provided. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of UNIFORM\"s advantage over other procedures, particularly in the 1shot setting. It highlights that the tables show a lack of clear advantage for UNIFORM in this scenario. The comment suggests that the authors should provide a theory to explain why the method is not as effective in the 1shot setting. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their work by offering a theoretical explanation. However, the comment could be more helpful if it provided additional guidance on how to develop this theory or what aspects of the method might be contributing to its performance issues. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. However, the comment does not explicitly instruct the authors to include this theory or provide specific guidance on how to integrate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for existing linguistic theory and consider incorporating it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue, which is the authors\" consideration of the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain it. The comment suggests that incorporating such theory could strengthen the paper, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain it. However, the comment does not provide any specific references, examples, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or examples on how to integrate this theory or what linguistic theory might be relevant. The feedback is 3 as it points out a potential avenue for enhancement, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should spend more time discussing the potential benefits of using AutoML approaches, such as extracting hints that can be reused in the design of new network architectures. It implies that the authors should provide more detailed comments on the findings of the study, particularly regarding the most significant takeaways from the discovered architecture. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed comments on the findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to discuss the biggest takeaways from the found architecture, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, suggesting that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s value and contribution. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might address this issue. To be more helpful, the comment could include suggestions on what specific aspects of the findings should be highlighted or how the authors might structure their discussion to effectively communicate these insights. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This implies that the authors should clarify or redefine T_a(t) in Section 3.1 to ensure consistency and proper understanding. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides a clear indication of the specific part of the paper being addressed, making the comment fully grounded. However, the comment does not specify what needs to be addressed in terms of clarifying or redefining T_a(t) in Section 3.1. While the authors can infer that they need to address the inconsistency, the comment lacks specificity in detailing the exact steps or changes required. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This observation is factual and does not contain subjective opinions or claims that require verification. It is a straightforward statement of a potential issue in the paper, which the authors can address by clarifying or redefining T_a(t) in Section 3.1. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4, which suggests a potential inconsistency or lack of clarity. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify or redefine T_a(t) to ensure consistency and proper understanding. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific way to clarify or redefine T_a(t). Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the author has only conducted experiments on two typical games and questions the performance of ReBeL on more complex problems, particularly those with larger depths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting additional experiments or methods to evaluate ReBeL on more complex problems. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically questioning the limited scope of the experiments conducted on two typical games and the potential performance of ReBeL on more complex problems with larger depths. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in detailing the issue with the limited scope of experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the scope of the experiments conducted, specifically mentioning that the author only tested ReBeL on two typical games and raises concerns about its performance on more complex problems with larger depths. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient or that the performance on complex problems is a significant issue. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental scope of the paper, specifically questioning the performance of ReBeL on more complex problems with larger depths. This feedback highlights an area where the authors might need to expand their experiments to better validate the performance of their method. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional experiments or methods to evaluate ReBeL\"s performance on complex problems. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not explicitly instruct the authors to provide additional evidence or arguments, nor does it offer specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for more substantial evidence but lack concrete steps on how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in identifying the need for more substantial evidence or arguments to establish this as a significant contribution, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s primary contribution, suggesting that it is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment lacks specificity and does not provide guidance on how the authors might strengthen their claims or what specific evidence or arguments are needed. This feedback is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a missing aspect in the paper, specifically the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on the theoretical guarantee, but the comment lacks concrete details on what specific aspects should be covered or how to structure this discussion. Therefore, the comment is 3, as it highlights a necessary addition but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment highlights a specific area of the paper that lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing theoretical guarantee, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a factual statement that does not require verification, as it is a matter of fact that the paper does not include such a discussion. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant and important aspect that the authors should address to provide a more comprehensive understanding of their work. However, the comment does not offer suggestions or guidance on how the authors might address this issue, such as recommending specific references or methods to include in the discussion. While it highlights a gap in the paper, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of quantitative measures to evaluate the generated VCEs, noting that the evaluation is primarily based on visual inspection. While the comment identifies a gap in the current evaluation process, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should consider incorporating quantitative measures to enhance the evaluation, but the comment lacks concrete suggestions or examples of what these measures might be. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights a general issue with the paper, specifically the lack of quantitative measures to evaluate the generated VCEs. However, it does not specify which part of the paper this issue is related to, such as the evaluation section or specific experiments. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in identifying the need for quantitative measures, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, relying primarily on visual inspection for evaluation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the extent of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides some insight but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation process, specifically the lack of quantitative measures to assess the generated VCEs. It highlights that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is valuable as it points out a critical area for improvement, encouraging the authors to consider incorporating quantitative measures to enhance the rigor and reliability of their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While the comment points out a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their performance claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not specify which part of the paper this observation is based on, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. The reviewer provides a logical reasoning by comparing the improvements to the error bars, which supports the claim. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is clear, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range. It suggests that the performance differences between methods are not very significant, which could be a concern for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left to infer that they need to clarify or justify their performance claims, but without specific guidance, the feedback remains incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, and it questions how to select representative images. While the comment identifies a specific area of improvement, it does not provide explicit guidance or suggestions on how to achieve this diversity or representativeness. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of the evaluation set, but the comment lacks concrete steps or examples. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of making the new proposed evaluation set more diverse and representative than the previous method, specifically questioning how to select representative images. However, it does not specify which part of the paper this evaluation set is discussed in, making it weakly grounded. The comment is specific in its request for guidance on how to achieve diversity and representativeness, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the diversity and representativeness of the new proposed evaluation set, specifically asking how to select representative images. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to improve their draft accordingly. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed evaluation set, questioning its diversity and representativeness compared to previous methods. It highlights a lack of clarity on how to select representative images, which is a critical aspect for ensuring the validity and generalizability of the evaluation. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending specific criteria for selecting representative images or methods for enhancing diversity. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it directs the authors\" attention to an important area for improvement but does not offer detailed guidance on how to achieve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to clarify the connection between the term and the referenced work. As a result, the authors are left without a clear understanding of what action to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the work need further explanation. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it highlights an area of potential concern but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might expand their experiments to address this limitation or what specific datasets they should consider. Without actionable suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not specify which part of the paper discusses the experiments or where this limitation is most relevant. The authors may infer that it pertains to the experimental section, but this inference is not explicit. The comment is specific in identifying the limitation of the dataset used in the experiments, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it might impact the validity or generalizability of the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to help the authors understand the significance of this limitation or how to address it. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are limited to MNIST and a single realworld dataset. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider expanding their experiments to include more datasets. However, the comment lacks specific guidance or suggestions on how to address this limitation, such as which additional datasets might be relevant or how to structure the expansion of the experiments. Without actionable advice, the feedback provides some insight but does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. It questions why 10 cannot use these side information. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so or provide concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment compares the proposed method to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is relevant to, making it weakly grounded. The comment is specific in questioning why 10 cannot use these side information, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is similar in spirit to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, the comment lacks specific reasoning or evidence to support why this is the case, such as detailed comparisons or examples. The claim is based on a comparison to another work, but without further elaboration, it remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. It questions why 10 cannot use these side information, implying that the authors should consider this possibility. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore this idea or address the question. The feedback is 3 as it points out a potential avenue for further development, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It suggests that this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest alternative approaches to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider adding a sparsity constraint, but the comment does not offer concrete steps or examples on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. It provides a clear explanation of how this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not explicitly mention which part of the paper discusses the proposed method or the sparsity constraint, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the issue with the lack of a sparsity constraint and its potential impact, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increasing number of factors and increased computation with more tasks. The comment provides a logical reasoning by comparing the proposed method with a factorized model with an IBP prior, which inherently imposes a sparsity constraint. This comparison offers a clear explanation of why the proposed method might face these issues, making the claim 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It explains that this could lead to an increasing number of factors and increased computation with more tasks. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the model\"s efficiency. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, as it specifies what additional experiments are required to improve the evaluation. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include additional experiments, but without grounding, the authors may struggle to identify the exact sections that need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section, suggesting that experiments on distributed deployment and a larger model are needed. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work. By addressing these suggestions, the authors can strengthen their evaluation and potentially improve the overall quality of their paper. However, the comment could be more helpful if it provided additional context or guidance on how to conduct these experiments or what specific aspects to focus on. Despite this, the feedback is 4 as it directs the authors toward meaningful enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more explanations regarding the consistency between training and inference, which is mentioned in the paper. However, it does not specify what aspects of the explanations are lacking or how the authors should expand on this topic. The action is implicit and somewhat vague, as the authors need to infer the exact details of what needs to be added or clarified. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) in the paper where the authors discuss the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the need for more explanations regarding the consistency between training and inference, particularly due to the smoothness of neural models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanations regarding the consistency between training and inference, particularly due to the smoothness of neural models. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference, particularly due to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that could be clarified. However, the comment could be more helpful if it provided examples or detailed suggestions on how to enhance the explanations. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the authors\" claim of achieving superior performance with fewer parameters, specifically questioning whether the improvements are due to the smaller word embedding and LSTM sizes or if the baseline model was tested with standard parameter settings. The reviewer suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. This feedback is explicit in its request for additional evidence to support the claim, making it 4. The authors are given a clear direction on what additional information is needed to strengthen their argument, but the comment could be more specific about the exact experiments or analyses required. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" claim of achieving superior performance with fewer parameters and references a specific baseline model 1. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the validity of the claim by suggesting that the improvements might be due to the baseline model\"s standard parameter settings. It further requests evidence of improvements when using larger word embedding and LSTM parameters. This provides clear guidance on what additional information is needed to support the claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the authors\" claim of achieving superior performance with fewer parameters, specifically questioning whether the improvements are due to the smaller word embedding and LSTM sizes or if the baseline model was tested with standard parameter settings. The reviewer suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the baseline model was tested with standard parameter settings. This makes the claim 3, as it provides a direction for the authors to address but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the authors\" claim of achieving superior performance with significantly fewer parameters compared to a baseline model. It questions whether the improvements are due to the smaller word embedding and LSTM sizes or if the baseline model was tested with standard parameter settings. The reviewer suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. This feedback is clear and actionable, as it prompts the authors to conduct additional experiments or provide detailed analysis to support their claims. By addressing this concern, the authors can strengthen their argument and provide a more robust evaluation of their model\"s performance. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment does not provide specific guidance on how to reproduce these features or what aspects of the previous models need to be replicated. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the regularization approach used in the LN models and compares it to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment does not specify which part of the paper discusses the regularization or the LN models, making it weakly grounded. The suggestion to reproduce the main features of previous models is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the regularization approach applied to the LN models, noting that it differs from previous models. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment lacks specific examples or references to the previous models, such as Pillow et al., which would provide more context and support for the claim. Without detailed references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. This feedback is 3 as it points out a potential inconsistency in the methodology and encourages the authors to ensure a fair comparison. However, the comment lacks specific guidance on how to reproduce the features of previous models or what aspects need to be addressed. The authors are left with a general suggestion to improve the comparison, but without detailed steps or examples, the feedback remains 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including some failure cases and related discussion would be beneficial. However, it does not provide explicit guidance on which specific failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add failure cases and discuss them, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this feedback pertains to. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in its suggestion to include failure cases and discuss them, but it lacks grounding as it does not specify the exact sections or parts of the paper where this should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including some failure cases and related discussion, but it does not provide any specific reasoning, examples, or references to support why this would be beneficial. Without such details, the authors may find it challenging to understand the rationale behind the suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including some failure cases and related discussion would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific failure cases to include or how to structure the discussion. This limits the usefulness of the feedback for the authors, as it does not offer actionable steps or detailed suggestions for enhancing their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. While the comment implies that an ablation study would be beneficial, it does not explicitly instruct the authors to perform the study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to clarify its necessity. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in its request for an ablation study to address the question, providing clear guidance on what needs to be done. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. However, the comment does not provide any specific reasoning or evidence to support why this encoding is unclear or unnecessary. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to clarify this. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct the ablation study or what aspects to focus on. The feedback is 3 as it points out a potential weakness in the paper but does not provide detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes.\" This provides a clear and direct action for the authors to take, specifying what needs to be added or elaborated upon. The comment also suggests a specific area for improvement, namely the computational complexity of counting homomorphisms, which is not adequately discussed in the current draft. This level of detail and specificity makes the comment 5, as it gives the authors a clear path to follow for improving their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of computational complexity, suggesting that the authors should add upper bounds and elaborate on empirical runtimes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, despite making brief statements about it. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The suggestion to add upper bounds and empirical runtimes provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a more detailed discussion of the computational complexity of counting homomorphisms. It highlights that the current discussion is brief and suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs further development. By addressing this suggestion, the authors can enhance the depth and comprehensiveness of their paper. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It identifies specific errors in the text, such as correcting the letter \"f\" to \"g\" in line 108 and removing the extra period in line 115. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question implies that the authors should provide more details or evidence to support their claim of convergence. The feedback is clear and actionable, giving the authors specific steps to address the identified errors and a question to consider regarding their baseline method. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (line 108 and line 115), allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as correcting the letter \"f\" to \"g\" and removing the extra period, providing clear guidance on what needs to be revised. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured convergence of the networks. This question adds specificity by prompting the authors to provide more details or evidence regarding the convergence of their baseline method. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question regarding the baseline MCL with deep learning. The corrections are straightforward and do not require any justification or evidence. The question about the baseline method is logical and requires an explanation from the authors, but it does not contain a claim that needs verification. Therefore, the comment is categorized as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two typographical errors in the manuscript: the correction of a letter \"f\" to \"g\" in line 108 and the removal of an extra period in line 115. These corrections are clear and would help improve the clarity and professionalism of the paper. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question prompts the authors to provide more detailed information or evidence regarding the convergence of their baseline method, which is a valuable point for improving the robustness of their work. Overall, the comment is 4 as it offers specific corrections and a thoughtprovoking question that can guide the authors in enhancing their draft."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. While the action is explicit, it does not provide specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are left with a clear direction but without detailed instructions on execution, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. The authors can infer that it relates to the methodology or results section, but this inference is not explicit. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous topdown and bottomup pose estimation methods. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are left with a clear direction but without detailed instructions on execution, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim regarding evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes variance and centers activations, implying that these limitations should be discussed explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It also points out that Batch Normalization standardizes variance and centers activations, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion of evolutional dropout, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of lowvariance units. It contrasts this with Batch Normalization, which standardizes variance and centers activations. The comment implies that these limitations should be discussed explicitly. However, the claim lacks specific examples or references to support the comparison between evolutional dropout and Batch Normalization, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and points out its limitations, particularly in only increasing the variance of lowvariance units. It contrasts this with Batch Normalization, which standardizes variance and centers activations, suggesting that these limitations should be discussed explicitly. This feedback is 3 as it highlights a potential area for improvement in the paper\"s discussion of evolutional dropout. However, it could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be emphasized. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution should be described or how to enhance the description. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the contribution without being given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper, but it does not specify which part of the paper this contribution is discussed in or what aspects of the contribution need more description. This lack of specificity makes it difficult for the authors to identify the exact sections that need revision. The comment is 1 because it does not provide any explicit references to specific parts of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution need more description or how to enhance the description. This lack of detail makes it difficult for the authors to understand the exact areas that require improvement and limits the usefulness of the feedback. As a result, the comment is 2, as it provides a general suggestion without actionable advice. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of minor comments and suggestions for improvement. It explicitly suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide specific guidance on how the authors can improve their draft. The comments are explicit and concrete, allowing the authors to directly address each point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses several minor points, including suggestions for organizing the main contributions, describing the layerwise attention mechanism, and referencing normalization or feature scaling. However, it does not specify which sections or parts of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its suggestions, providing clear guidance on how to improve the organization and clarity of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, such as recommending the separation of contributions and the description of attention mechanisms. These suggestions are based on logical reasoning and common sense, as they aim to enhance the structure and flow of the paper. However, the comment lacks specific examples or references to support the suggestions, making it 3. The authors would need to infer the exact changes needed to address these suggestions, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a list of minor suggestions for improving the organization and clarity of the paper. It suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and actionable, offering specific guidance on how the authors can enhance the structure and presentation of their work. However, the comment could be more helpful if it provided examples or detailed explanations of how these changes would improve the paper. Overall, the feedback is 4 as it directs the authors toward specific improvements, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It further recommends including a supervised baseline to provide a comparison with selfsupervised methods. While the comment explicitly states the need for a supervised baseline, it does not provide specific guidance on how to implement this addition or which supervised methods to use. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It provides a rationale for including a supervised baseline, which is a concrete suggestion for improvement. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in its suggestion to include a supervised baseline for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, especially considering the scale of the datasets used in the experiments. The reviewer provides a logical reasoning by suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images in practice. This reasoning is supported by common knowledge about dataset sizes and annotation practices. However, the comment could be strengthened by providing specific examples or references to similar studies that have included supervised baselines for comparison. Overall, the claim is 4 due to the logical reasoning and common knowledge provided, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a logical rationale for including such baselines, noting that it is reasonable to assume full annotation for a dataset of scale ~100k images in practice. The comment suggests that including a supervised baseline would be informative and would allow for a more comprehensive comparison with selfsupervised methods. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could significantly enhance the paper\"s analysis and conclusions. However, the comment could be more helpful if it offered additional guidance on how to implement the suggested baseline or which supervised methods to consider. Overall, the comment is 4, as it effectively directs the authors towards a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and second, it questions why BEAR is missing from the baselines. The first question implies that the authors should provide an explanation for the method\"s benefit in deterministic environments, while the second question suggests that the authors should include BEAR as a baseline for comparison. However, the comment does not explicitly instruct the authors to make these additions or provide detailed guidance on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the need for clarification and inclusion of additional baselines. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and second, it questions why BEAR is missing from the baselines. While the comment does not explicitly mention specific parts of the paper, it is clear that it pertains to the discussion of the method\"s performance and the choice of baselines. The authors can infer that it relates to the experimental results or methodology sections, but the comment does not provide explicit references to specific sections. The questions are specific in that they seek clarification on the method\"s benefit and the inclusion of BEAR as a baseline. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and second, it asks why BEAR is missing from the baselines. The comment does not contain any claims or opinions that require verification. It is a series of questions seeking clarification or explanation, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two important questions that could help the authors improve their draft. First, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This feedback encourages the authors to expand their experimental evaluation, which could provide more insight into the method\"s applicability. Second, the comment questions why BEAR is missing from the baselines, which could be a significant oversight that affects the comprehensiveness of the comparison. By addressing these points, the authors could enhance the robustness and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on how to evaluate the method on nondeterministic domains or why BEAR should be included as a baseline. Overall, the comment is 4 as it identifies areas for improvement and suggests potential enhancements, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. While the comment implies that these techniques are important for performance, it does not explicitly instruct the authors to include this justification. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. However, the comment does not provide specific guidance on how to structure this justification or what aspects to focus on. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for a theoretical explanation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this information should be added. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed explanation or evidence to substantiate the need for a theoretical justification, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging improve results. This is a valuable suggestion as it highlights the importance of understanding the underlying principles of the methods used in the study. However, the comment lacks specificity and does not provide detailed guidance on how to develop this justification or what aspects of the theory should be emphasized. While it identifies an area for improvement, the feedback could be more helpful if it offered more detailed advice or examples. Therefore, the comment is 3, as it points out a potential weakness but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that additional information is needed, it does not provide explicit instructions on what specific details should be included or how to present them. The action is somewhat vague, as the authors can infer that more explanation is needed but lack concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its request for additional details on the method, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these details are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is 3 as it identifies specific areas where the paper lacks clarity and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have addressed similar issues. Overall, the comment provides a good starting point for the authors to enhance their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about the label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to take. It specifies what needs to be verified and which datasets and models to use, making the action concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of theoretical findings relating to realworld deep learning models, suggesting that the authors verify their conclusions on MNIST and CNN. However, it does not specify which part of the paper this relates to, making it weakly grounded. The comment is specific in suggesting a verification on MNIST and CNN, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings should be verified on realworld deep learning models, specifically mentioning MNIST and CNN. However, the comment does not provide any specific reasoning or evidence to support why these models are relevant or why the verification is necessary. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support or evidence.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the relevance of theoretical findings to realworld deep learning models. It suggests that the authors verify their conclusions about label noise and model size on specific datasets like MNIST and CNN. This feedback is clear and actionable, providing a specific direction for the authors to improve the applicability of their findings. However, the comment could be more helpful if it offered additional context or suggestions on how to conduct the verification or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors towards a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it 1. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without further justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. The comment points out that cosine similarities for such large weight decay strengths are not reported, and the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is 3 as it highlights a specific area where the authors might need to investigate further or provide additional analysis. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to improve their results. While it provides a starting point for the authors to consider, it does not fully support them in making actionable improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. It suggests that this issue must be fixed for publication. The reviewer acknowledges that they did not have time to review the supplementary material due to the constraints of the review process, but emphasizes the importance of addressing this issue. The comment provides a clear and direct action for the authors to take, which is to ensure that the title, abstract, introduction, and discussion accurately reflect the unsupervised nature of the random forests results. This guidance is explicit and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation regarding the unsupervised nature of the random forests results. The comment further emphasizes the importance of addressing this issue for publication and provides a rationale for why it is a serious omission. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The reviewer provides a rationale for why this is important, stating that casual readers might remember the wrong conclusions if this information is not included. The comment also acknowledges that the reviewer did not have time to review the supplementary material due to the constraints of the review process, which adds context to the concern. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the omission and its potential impact on readers. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the title, abstract, introduction, and discussion sections of the paper, specifically noting that they do not explain that the results are for unsupervised random forests. This is a critical omission that could lead to misinterpretation by readers. The reviewer emphasizes the importance of addressing this issue for publication, as it could affect the credibility of the results. While the comment highlights a clear area for improvement, it does not provide specific suggestions or guidance on how to correct this issue. The authors are left with a general understanding of the problem but without detailed steps on how to resolve it. Therefore, the comment is 3, as it points out a significant oversight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It explicitly asks the authors to compare the computational complexity with other methods, providing a clear and direct action for the authors to take. The comment also highlights the impracticality of training multiple iterations/epochs with large models and datasets, which adds context to the comparison. This level of specificity and directness makes the comment 5, as it gives the authors a clear path to follow in addressing the issue. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the claim that the proposed method requires much more computation than other methods, suggesting that it is impractical to train multiple iterations/epochs with large models and datasets. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in questioning the computational complexity of the method compared to others, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification or improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational complexity of the proposed method compared to other methods. It questions whether the method requires much more computation than other methods and suggests comparing the computational complexity with other methods. However, the comment does not provide specific examples or references to support the claim about the computational complexity, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for the authors to explore but does not offer a comprehensive basis for their response. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the computational complexity of the proposed method compared to other methods, suggesting that it may require much more computation. It explicitly asks the authors to compare the computational complexity with other methods, providing a clear and actionable direction for improvement. This feedback is valuable as it prompts the authors to consider the efficiency of their method and potentially optimize it for practical use. However, the comment could be more helpful if it included specific examples or references to other methods for comparison, which would further guide the authors in addressing the issue. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment explicitly identifies the need for significance testing, it does not provide detailed guidance on how to conduct this testing or which specific tests to use. The authors are left with a clear action to take but without explicit instructions on how to execute it, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of significance testing to support claims of method differences. The comment provides a detailed example of a claim that lacks supporting evidence, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment provides a logical argument for the need for significance testing, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear rationale but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh>en ChatGPT and GPT4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s methodology and provides a specific example of where significance testing is needed. However, the comment could be more helpful if it offered suggestions on how to conduct the significance testing or which specific tests to use. Overall, the comment is 4, as it effectively guides the authors in addressing a significant weakness in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. While the comment implies that additional evidence or analysis should be provided, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to include more supporting evidence, but it lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its request for additional evidence or analysis, but without grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional supporting evidence or analysis. However, the comment could be more helpful if it offered suggestions on how to gather or present this evidence, such as which specific aspects to focus on or where to find relevant data. Overall, the comment is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 5 is difficult to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and recommends extending CATER to other languages in the future. This feedback is clear and provides specific actions for the authors to take, such as adding more details about the baselines and considering the extension to other languages. The comments are explicit and concrete, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is hard to comprehend and suggesting the need for more details about the two baselines presented. Additionally, it points out the limitation of the study focusing only on Englishcentric datasets and recommends extending CATER to other languages. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and recommends extending CATER to other languages. While the comment provides a logical reasoning for the need for more details and suggests an extension, it lacks specific examples or references to support the claim fully. The suggestion to extend CATER to other languages is a reasonable recommendation but could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides some support but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend. It provides a clear suggestion for improvement by recommending that the authors provide more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study\"s focus on Englishcentric datasets and suggests an extension to other languages, which could enhance the scope and relevance of the research. This feedback is actionable and provides the authors with a clear direction for improving their draft, making it 4. However, it could be more helpful if it included specific suggestions on how to enhance the details or extend the study, which would make it fully comprehensive. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review in the paper needs improvement, specifically noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and direct, giving the authors a specific action to take: to enhance the clarity and comparative analysis of the literature review. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and specifies the issue with it, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly outlines what needs to be improved, such as providing a more explicit and comparative analysis of related work. This level of detail helps the authors understand what aspects of the literature review need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and lacks clarity on the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issues and how to address them. This lack of detailed justification or evidence makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It provides a clear and actionable suggestion for improvement, recommending that the paper should provide a more explicit and comparative analysis of related work. This feedback is valuable as it directs the authors to a specific area for enhancement, offering a clear path for improving the clarity and impact of their literature review. However, the comment could be more helpful if it provided examples of how to achieve this improvement or suggested specific references for comparison. Overall, the comment is 4, as it effectively guides the authors towards enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific actions for the authors to consider. The first action suggests adding performance metrics on word similarity and sentence translation tasks, as seen in the MUSE paper and others, to enhance the credibility of the framework\"s robustness and effectiveness. The second action recommends including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is a minor suggestion. Both actions are explicit and provide clear guidance on what the authors should include in their experiments to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two clear actions for the authors to consider: adding performance on word similarity and sentence translation tasks, as in the MUSE paper, and including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages. This provides detailed guidance on how to enhance the robustness and effectiveness of the framework. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding performance metrics on word similarity and sentence translation tasks, as well as experiments with morphologically rich and lowresource languages, to enhance the credibility of the framework. The reviewer provides specific examples of similar tasks and languages that could be included, which provides a clear rationale for the suggestion. However, the comment could be strengthened by referencing specific studies or papers that have used these tasks or languages to support the claim. Overall, the comment is 4, as it offers a logical basis for the suggestions but lacks detailed references or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for enhancing the robustness and effectiveness of the framework. The first suggestion is to include performance metrics on word similarity and sentence translation tasks, which are commonly used in the field and can provide additional credibility to the framework. The second suggestion is to include experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which can further validate the framework\"s applicability across diverse linguistic contexts. These suggestions are clear and provide the authors with concrete steps to improve their work, making the comment 5. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or examples of how they might be integrated into the paper. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions. The first question asks about the utility of node importance in the 1shot scenario, which is a specific and concrete action for the authors to address. The second question points out the absence of the 1shot setting in the experiments, suggesting that the authors should include this setting in their experiments. Both questions provide clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment raises two specific questions about the paper. The first question addresses the utility of node importance in the 1shot scenario, which is a direct and concrete issue that the authors can address by providing clarification or evidence. The second question points out the absence of the 1shot setting in the experiments, which is also a specific issue that the authors can address by including this setting. The comment is fully grounded as it explicitly mentions the sections or aspects being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions that seek clarification or explanation. The first question asks about the utility of node importance in the 1shot scenario, which is a request for clarification rather than a claim. The second question questions the absence of the 1shot setting in the experiments, suggesting that related works like RALE include this setting. This is also a request for clarification or explanation, as it does not make a claim that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions that are relevant to the paper\"s methodology and experimental design. The first question seeks clarification on how node importance is utilized in the 1shot scenario, which is a critical aspect of the paper\"s approach. The second question points out the absence of the 1shot setting in the experiments, noting that related works like RALE include this setting. This feedback is actionable as it prompts the authors to address these gaps in their paper, providing clear directions for improvement. However, the comment could be more helpful if it offered suggestions on how to incorporate these elements or if it provided additional context or references to support the questions. Overall, the comment is 4, as it identifies areas for improvement and provides a basis for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that additional discussions are needed, it does not specify which sections of the paper should include these discussions or how they should be structured. The action is implicit and somewhat vague, as the authors need to infer that they should add more detailed explanations and potential solutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the issue of LLMs struggling with finegrained hard constraints, but it lacks grounding as it does not reference specific sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any specific examples, references, or reasoning to support why these discussions are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with finegrained hard constraints and how to address these problems. This feedback is 3 as it identifies a specific area where the paper could be improved by offering additional context and potential solutions. However, the comment lacks depth and does not provide specific examples or suggestions on how to address the issue, leaving the authors with a general direction but no detailed guidance. Therefore, the comment is rated as 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions are currently hidden in the experimental section and recommends that the paper highlight these observations and conclusions. This feedback is explicit and provides a clear action for the authors to take, which is to make these observations and conclusions more prominent in the paper. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While it does not explicitly mention a specific section, the authors can infer that it pertains to the experimental section. The comment is specific in its suggestion to highlight the observations and conclusions, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the tradeoffs between annotation effort and training performance. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors may infer that the observations and conclusions are indeed hidden, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for readers to better understand the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific recommendation for improving the clarity and accessibility of the paper. However, it could be more helpful if it offered additional guidance on how to effectively highlight these observations or conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments. The comment also specifies what needs to be done, making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing ablation experiments to validate the model performance further, which is a clear and actionable request. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. However, the comment does not provide any specific reasoning or evidence to support why these ablation experiments are necessary or how they would improve the validation of the model performance. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This feedback is clear and actionable, as it directs the authors to conduct specific experiments to support their claims. However, the comment could be more helpful if it provided additional guidance on which specific modifications to focus on or how the ablation experiments should be structured. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It also questions whether it is possible to show a comparison of the performance on datasets where the decision space is beyond binary. While the comment highlights a potential issue and suggests a comparison, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include such a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it is possible to show a comparison of performance on datasets with a decision space beyond binary, as mentioned in Zhang et al. 44. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It questions whether this is a problem for other approaches, referencing Zhang et al. 44 as an example. However, the comment lacks specific details or examples to substantiate the claim that this is not a problem for other approaches. The reference to Zhang et al. 44 provides some context, but it does not fully support the claim. Therefore, the comment is 3, as it provides a starting point for the authors to explore but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment raises a concern about the requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It questions whether this is a problem for other approaches, referencing Zhang et al. 44 as an example. The comment suggests that it would be beneficial to show a comparison of the performance on datasets where the decision space is beyond binary. This feedback is 3 as it identifies a potential issue and provides a direction for further investigation. However, it lacks specific guidance on how to conduct the comparison or what aspects to focus on, which limits its comprehensiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks about the impact of the capacity of the SR model on the FID, and second, it mentions unexpected artifacts in the proposed pipelining method. While the questions provide some guidance on what aspects to consider, they do not offer explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should investigate the impact of model capacity on FID and address any unexpected artifacts in their pipelining method. However, the lack of specific guidance or detailed suggestions makes the action implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two questions: first, it asks about the impact of the capacity of the SR model on the FID, and second, it mentions unexpected artifacts in the proposed pipelining method. However, it does not specify which part of the paper these questions relate to, such as specific sections or figures. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its questions about the impact of model capacity and unexpected artifacts, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions regarding the impact of the capacity of the SR model on the FID and the presence of unexpected artifacts in the proposed pipelining method. These questions are factual inquiries seeking clarification or information, rather than claims or opinions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: first, it asks about the impact of the capacity of the SR model on the FID, and second, it mentions unexpected artifacts in the proposed pipelining method. While the questions provide some insight into areas that need further exploration or clarification, they lack specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider important aspects of their work, but it does not offer detailed or actionable advice, leaving the authors with a general direction to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include content in Appendix A and clarify the purpose of Proposition B.1, but without detailed instructions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of content in Appendix A and the unclear purpose of Proposition B.1, which is meant to illustrate the classic partitioning principle of Kmeans. Additionally, it points out the missing \"proof.\" This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition may only illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. However, the comment lacks specific examples or references to support the claim that the \"proof\" is missing. While the comment identifies potential issues, it does not provide detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the missing content or proof, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the appendices of the paper. It points out that Appendix A is left blank, which is a significant oversight, and that the purpose of Proposition B.1 in Appendix B is unclear. The comment also questions whether the proposition is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it notes that the authors\" \"proof\" is missing. This feedback is clear and actionable, as it provides specific areas for improvement and suggests that the authors should include content in Appendix A and clarify the purpose of Proposition B.1. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the appendices or provided examples of how to address these issues. Overall, the comment is 4, as it directs the authors to specific areas that need attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several approximations introduced by the authors and points out the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107110. While the comment implies that the authors should address these vulnerabilities to reassure readers, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on vulnerabilities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the approximations introduced by the authors and points out the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107110. However, it does not specify which part of the paper these approximations are introduced in, making it weakly grounded. The comment is specific in identifying the need to address potential vulnerabilities, but without explicit references to sections or lines, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approximations introduced by the authors leave loose ends and that the possible vulnerabilities need to be expanded to reassure readers. The comment provides a logical reasoning by acknowledging the necessity of approximations for deriving clean results but suggesting that the authors should address the potential vulnerabilities to provide reassurance. However, the comment lacks specific examples or references to support the claim of possible vulnerabilities, making it 3. The authors would need to infer the exact vulnerabilities being referred to, which adds to the ambiguity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the approximations introduced in the paper, noting that they leave loose ends and potentially introduce vulnerabilities. It acknowledges the necessity of approximations for deriving clean results but suggests that the authors should expand their discussion on possible vulnerabilities to address readers\" concerns. This feedback is clear and actionable, as it directs the authors to consider and address potential weaknesses in their work. However, the comment could be more helpful if it provided specific examples or suggestions on how to expand the discussion on vulnerabilities. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to conduct a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed model on various benchmarks, specifically mentioning that it demonstrates impressive performance. However, it does not specify which benchmarks are considered \"old\" or provide details about the \"data curation\" process. This makes it difficult for the authors to pinpoint the exact part of the paper that needs further analysis or clarification. While the authors can infer that it relates to the experimental results section, the comment lacks specificity in terms of what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the model\"s impressive performance on benchmarks might be due to the data curation process, implying that the data might have been indirectly seen by the model. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks, suggesting that the data might have been indirectly seen by the model through the \"data curation\" process. This observation is relevant and could prompt the authors to investigate and address this concern. However, the comment lacks specific guidance or suggestions on how to conduct a more thorough analysis or what aspects of the evaluation procedures need further details. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. While the comment implies that the authors should consider including collaborative games in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental setup to include collaborative games. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning or evidence to support why collaborative games are important or how they would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting the absence of collaborative games in the experiments. It suggests that including collaborative games would be interesting and could provide valuable insights into how the evaluated methods behave in different settings. This feedback is clear and actionable, as it directs the authors to expand their experimental setup to include collaborative games, which could enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on how to incorporate collaborative games or examples of how this could be done. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. This provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is explicit and concrete, giving the authors a straightforward task to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by noting that the experimental settings are missing, which makes the figures difficult to be convincing. This level of detail is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing, which makes the figures difficult to be convincing. This feedback is clear and actionable, as it directly points out a gap in the presentation of results that could impact the paper\"s credibility. By highlighting this omission, the authors are given a clear direction to improve their draft by including the necessary experimental settings. However, the comment could be more helpful if it provided suggestions on how to present the experimental settings or examples of how other studies have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment does not provide explicit guidance on how the authors should address this ambiguity or clarify their approach. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of how their method avoids hindering the acquisition of new task knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It suggests that the authors propose pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment notes that some parameter isolation methods are tailored to leverage this sparsity, and it questions the clarity of how the proposed method avoids impeding the learning of new task knowledge. While the comment mentions specific aspects of the work, it does not explicitly reference a particular section or part of the paper, making it weakly grounded. The comment is specific in detailing the issue with the clarity of the proposed method, but without explicit grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It notes that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment lacks specific examples or references to support the claim that the proposed method avoids hindering learning. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale of the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment lacks specificity and does not provide actionable feedback on how the authors should address this ambiguity or clarify their approach. While it points out a potential area for improvement, it does not offer detailed guidance or suggestions for enhancing the clarity of the rationale. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by suggesting that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper. The comment specifies what needs to be done and how to implement it, making the action 5. The authors know exactly what changes to make to improve their draft, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparisons with existing fairness algorithms. The comment suggests integrating benchmark comparisons against stateoftheart fairness algorithms to enhance the paper\"s evidence and positioning within the FairML research landscape. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper\"s evidence and positioning within the FairML research landscape. The claim is supported by logical reasoning, as it highlights the importance of benchmark comparisons in evaluating the performance of the proposed method. However, the comment could be strengthened by providing specific examples of existing fairness algorithms or references to relevant literature that could be used for comparison. This would make the claim more verifiable. Therefore, the comment is categorized as 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of comparisons with existing fairness algorithms in the experimental section. It provides a clear and actionable suggestion by recommending the integration of benchmark comparisons against stateoftheart fairness algorithms. This feedback is 5 as it guides the authors on how to enhance the paper\"s evidence and positioning within the existing FairML research landscape. By addressing this suggestion, the authors can significantly improve the quality and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homolumo gap, using TransformerM on QM9. It highlights that TransformerM performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their model. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the supervised pretraining of TransformerM on QM9, highlighting that it performs poorly on most tasks other than homo, lumo, and gap. This is a clear and specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Despite this, the comment is specific in detailing the problem, so the overall assessment aligns with a score of 3.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, as demonstrated by TransformerM\"s performance on QM9. The reviewer provides a specific example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a generalpurpose neural network model. This claim is 3 as it provides a specific example of negative transfer, but it lacks detailed reasoning or references to support the claim fully. The authors would need to further investigate and provide additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the supervised pretraining of TransformerM on QM9, specifically noting that it performs poorly on most tasks other than homo, lumo, and gap. This observation challenges the claim that TransformerM is a generalpurpose neural network model. The comment provides a specific example of negative transfer, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve the model\"s generalizability. Overall, the comment is 3 as it highlights a critical area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. While the comment implies that the authors should provide an explanation or justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their reasoning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 8082\" and \"Figure 4 A&B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating otherwise in lines 8082. The comment clearly specifies what needs to be addressed, namely, the rationale behind using the metric in this context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. While the comment raises a valid concern, it lacks specific reasoning or evidence to support the claim that the metric is not insightful elsewhere. The authors may need to provide additional context or justification to fully address the reviewer\"s question. Therefore, the comment is 3, as it highlights a potential inconsistency but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. This feedback is 3 as it prompts the authors to clarify their reasoning or provide an explanation for their choice. However, the comment could be more helpful if it suggested how the authors might address this inconsistency or provided additional guidance on how to justify the use of the metric in this context. Overall, the comment provides a starting point for the authors to consider but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the term \"distributional generalization\" and suggests that it might be too strong to describe the empirical phenomenon presented. It questions whether the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero is realistic, given the limited number of test functions on which the outputs match. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their description. The action is implicit and vague, as the authors are left to infer that they should reconsider the term used to describe the phenomenon. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used to describe the phenomenon of distributional generalization. It points out that the term might be too strong to capture the empirical phenomenon presented, as it implies an ideal state that might not be realistic based on the limited number of test functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The feedback is specific in identifying the concern with the term \"distributional generalization\" and its potential misrepresentation of the phenomenon. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the term \"distributional generalization,\" suggesting that it might be too strong to describe the empirical phenomenon presented. The reviewer questions whether the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero is realistic, given the limited number of test functions on which the outputs match. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a basis for the critique but requires further elaboration for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a concern about the term \"distributional generalization,\" suggesting that it might be too strong to describe the empirical phenomenon presented. The reviewer questions whether the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero is realistic, given the limited number of test functions on which the outputs match. This feedback is 3 as it identifies a potential issue with the terminology used in the paper, prompting the authors to reconsider their choice of words. However, the comment could be more helpful if it provided suggestions on alternative terminology or ways to clarify the concept. Overall, the comment provides a basis for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to make this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L240 and L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the meaning of \"is sufficient\" and suggests that the authors should clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. This comment does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While it identifies a potential area for clarification, the comment lacks specific guidance or suggestions on how the authors should address this issue. It provides a starting point for the authors to consider, but it does not offer detailed feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers any further \"explanation\" of how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the scientific insight or provide additional explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model and formalism, questioning whether it provides a scientific insight beyond prior taskoptimized approaches. The comment highlights the lack of explanation regarding the model\"s approximation to nonlinear RNN models and its emergent behavior, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers any further \"explanation\" of how these nonlinear models attain solutions through optimization. The comment provides a logical reasoning by comparing the model to prior approaches and questioning its novelty or scientific contribution. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 offers any additional explanation or scientific advancement beyond what has been previously established. The comment highlights a specific gap in the paper, namely the lack of demonstration that the model is a prototype approximation to nonlinear RNN models with emergent behavior. This feedback is clear and actionable, as it directs the authors to clarify the scientific contribution of their work and provide a more detailed explanation of the model\"s novelty. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how to demonstrate the model\"s scientific insight. Overall, the comment is 4 as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It explicitly asks how the groundtruths are built and whether the network parts responsible for each part can predict all keypoints. However, it does not provide any guidance or suggestions on how the authors should address these questions or what specific changes they should make to their draft. The comment lacks actionable details, leaving the authors without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address the issue. Without additional context or justification, the claim remains 1, as it lacks the necessary details to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material, questioning how the network parts responsible for each part can predict all keypoints. This feedback is 3 as it identifies a potential area for improvement and raises a critical question that the authors should address. However, it lacks detailed guidance or suggestions on how to resolve the issue or improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant difference between the proposed method and a previous work, 10, in terms of computation time and search space. It suggests that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific comparison between the proposed method and a previous work, 10, regarding computation time and search space. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this comparison is made in, making it weakly grounded. The authors can infer that it relates to the comparison section or the results, but this is not explicitly stated. The comment is specific in detailing the issue of information loss in the output, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. The claim is 3 as it provides a logical reasoning for the observed difference in computation time and output information. However, the comment lacks specific references or examples to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a significant difference between the proposed method and a previous work, 10, in terms of computation time and search space. It points out that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. This observation is insightful and provides a clear comparison that the authors might consider in their work. However, the comment lacks specific suggestions or guidance on how the authors could address this issue or improve the performance of their method. While it identifies a potential area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what needs to be added to the discussion section, making it 5.", "grounding_specificity_rationale": "The comment suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is fully grounded as it explicitly mentions the discussion section and provides specific details on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. This feedback is based on logical reasoning and specific examples, making it 4. However, it could be strengthened by providing references or further justification for the importance of this discussion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their discussion section. By addressing this suggestion, the authors can provide a more comprehensive and insightful analysis of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify the distinction between the two methods. While the comment identifies specific areas of confusion and requests clarification, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions, questioning the differences between anchorbased regression and RepPoints in RetinaNet, and suggesting that the authors clarify this problem. The comment also references ATSS and provides a rationale for why the authors might need to clarify the distinction between the two methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It references ATSS and suggests that the regression methods do not significantly influence the results. The reviewer questions the motivations behind RepPoints, implying that the authors should clarify the distinction between the two methods. While the comment raises a valid point about the potential equivalence of the methods, it lacks specific examples or references to support the claim that the regression methods do not influence results. This makes the claim 3, as it provides a basis for questioning but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the definitions in Table 1 regarding the differences between anchorbased regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify this problem. The comment provides a logical basis for the question, referencing ATSS and its findings on the insensitivity of regression methods. This feedback is clear and actionable, as it prompts the authors to clarify the distinctions between the methods and their motivations, which are crucial for the paper\"s coherence and understanding. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4, as it guides the authors towards improving the clarity and robustness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their presentation. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance the experimental design. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not specify which parts of the paper are unclear or lack intuition, nor does it provide specific suggestions for improvement. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not provide enough detail to guide the authors in addressing the issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is difficult to follow due to a lack of clear intuition and insufficient experiments. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the clarity and coherence of their work. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending ways to improve the intuition or structure of the presentation. While it points out a problem, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment explicitly requests additional metrics, it does not provide specific guidance on how to calculate or present these metrics. The action is clear but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the training of the student and refinement networks simultaneously and questions the fairness of the comparison with the teacher network. It suggests providing KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or the comparison with the teacher network, making it weakly grounded. The comment is specific in its request for KID/FID metrics, but without grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. However, the comment does not provide any specific reasoning or evidence to support why the comparison might be unfair or how the KID/FID metrics would resolve this issue. The request for metrics is a logical suggestion but lacks detailed justification or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment identifies a potential issue with the comparison, it lacks specific guidance on how to calculate or present these metrics, which could be beneficial for the authors. The feedback is 3 as it points out a potential area for improvement but could be more actionable with detailed instructions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector and suggests that scaling the vector before applying attention weight might be beneficial. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they might need to explore the idea of scaling the vector before attention weight, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scaling of the refined region vector and suggests that scaling the vector before attention weight might be beneficial. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests that scaling the vector before attention weight might be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the scaling of the refined region vector in the paper. It points out that the attention weight is in 0, 1 and sums up to 1 for all image regions, suggesting that the refined vector would only scale the most important regions by a factor of two before global pooling. The comment then suggests that scaling the vector before attention weight might be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this idea. The authors are left with a question but without actionable steps to address it. Therefore, the comment is 3, as it prompts the authors to consider an alternative approach but does not fully guide them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its potential causes, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This claim is 3 as it provides a logical explanation for the observed failures, linking them to the issue of goal misspecification. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This feedback is 3 as it highlights a critical area for improvement and provides a clear explanation of the problem. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve their approach. As it stands, it provides a starting point for the authors to consider, but it lacks depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could be improved by conducting a more detailed analysis of how specific models behave differently when using ReGuide. It explicitly mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides a clear and direct action for the authors to take, as it specifies what additional analysis should be conducted and how it should be presented. The feedback is explicit and concrete, offering a clear path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by conducting a more detailed analysis of how specific models behave differently when using ReGuide. It implies that the authors should present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or table. While the authors can infer that it relates to the discussion or results sections, this inference is not as clear as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by conducting a more detailed analysis of how specific models behave differently when using ReGuide. It implies that presenting differences in false positive rates (FPR) between models with and without ReGuide would provide a better comparison. However, the comment does not provide specific examples or references to support the claim that such an analysis would be beneficial. The suggestion is logical and reasonable, but without detailed justification or evidence, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that a deeper investigation into how specific models behave differently when using ReGuide could add nuance to the conclusions. It provides a specific example of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is clear and actionable, offering the authors a concrete direction to enhance their analysis and results. By addressing this suggestion, the authors can significantly improve the depth and relevance of their findings. Therefore, the comment is rated as 5, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. While the comment implies that the authors should provide additional results or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more results or comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that more results or comparisons are needed, but without explicit references to the sections or figures where this comparison is mentioned, the authors may struggle to identify the exact areas needing supplementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the comparison or what specific aspects should be addressed. The comment is 3 as it points out a potential gap in the paper, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting a specific change to the figure or providing examples of how the axes could be clarified. As a result, the authors are left without a clear understanding of what steps to take to improve the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding what the axes represent in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty in understanding the axes in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to a specific area that needs clarification. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as labeling the axes or providing a key. Overall, the comment is 4 as it highlights a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and emphasizes the importance of including them to demonstrate the efficiency of the proposed approach. It provides a clear and concrete action for the authors to take, which is to conduct these comparisons. The comment also explains why these comparisons are necessary, making the action explicit and actionable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Direct runtime comparisons with existing methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, which is the direct runtime comparison with existing methods. The comment highlights the importance of including these comparisons to demonstrate the efficiency of the proposed approach, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which usually requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are essential for demonstrating the efficiency of the proposed approach. However, the comment could be strengthened by providing specific examples or references to similar studies that have included such comparisons. Therefore, the claim is 4, as it is wellsupported but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It explains that the proposed approach is based on implicit differentiation, which typically involves additional computational costs. By emphasizing the importance of including these comparisons to demonstrate the efficiency of the proposed approach, the comment provides clear and actionable feedback. This feedback is valuable as it guides the authors on what specific comparisons are necessary to strengthen their work. However, the comment could be more helpful if it suggested specific methods or approaches for conducting these comparisons. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide explicit guidance on how the authors should reframe their focus or what specific aspects of the differences in representation should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach, but they lack concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique, as it highlights a potential misalignment with the paper\"s motivation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this shift would be more appropriate or beneficial. Without specific examples or logical reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. This feedback is 3 as it identifies a potential misalignment with the paper\"s motivation and offers a suggestion for improvement. However, the comment lacks depth and does not provide specific guidance on how the authors might explore these differences or why this shift would be beneficial. To be more helpful, the comment could include examples of how examining differences in representation could enhance the paper\"s contribution or provide a framework for the authors to follow. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to clarify the motivation. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it relates to the evaluation or discussion of the DCI framework, but this inference is not explicit. The comment is specific in detailing the need for clarification on the motivation for considering explicitness(E) and size(S) as extra evaluations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific examples or references to support the claim that the DCI framework already considers these factors. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that it may already consider explicitness(E) and size(S) as evaluation factors. It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the motivation for considering these factors as extra evaluations. While it identifies a potential area for improvement, the feedback is 3 as it provides some insight but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment does not provide specific guidance on how to address these issues or suggest concrete steps for improvement. The authors are left with a general understanding of what needs to be fixed but without clear instructions on how to implement the changes. Therefore, the comment is 3, as it highlights areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not well organized and identifies specific issues with the layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks detailed reasoning or examples to support these claims, making it difficult for the authors to understand the extent of the issues or how to address them. The lack of specific evidence or references to justify the claim makes it challenging for the authors to effectively improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks actionable guidance on how to address these issues or suggestions for improvement. While it points out areas that need attention, it does not provide detailed advice or examples of how to correct these problems, leaving the authors with a general understanding of what needs to be fixed but without clear steps to take. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider whether the types of interventions included in the paper are practical and safe for querying in the real world. While the comment implies that the authors should evaluate the practicality and safety of their interventions, it does not provide specific guidance on how to conduct this evaluation or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the types of interventions included in the paper, suggesting that they are reasonable computationally but questioning their practicality and safety for querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider the practicality and safety of the interventions, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for querying in the real world. While the comment raises a valid concern about the practicality and safety of the interventions, it lacks specific examples or references to support this claim. The authors may find it challenging to address the concern without additional context or evidence. Therefore, the comment is considered 2, as it provides a logical suggestion but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the practicality and safety of the interventions discussed in the paper. It suggests that while the interventions may be reasonable computationally, they should also be evaluated for their practicality and safety in realworld querying. This feedback is 3 as it points out an important aspect that the authors should consider, but it lacks specific guidance or examples on how to assess the practicality and safety of the interventions. The authors are left with a general suggestion to think about these aspects, but without detailed instructions, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a clear and explicit action for the authors to take, as it instructs them to define the notation \"cal P\" with a subscript in the same section where it is first used. The comment provides a specific and concrete action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the notation \"cal P\" with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of definition for the notation \"cal P\" with a subscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a factual observation that does not require any supporting evidence or justification. It is a straightforward statement of a potential issue in the paper, but it lacks depth or context, making it difficult for the authors to understand the significance of the claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"cal P\" with a subscript being used without being defined in the same section. This is a clear and actionable feedback that highlights a potential confusion for readers who might not be familiar with the notation. By pointing out this issue, the comment provides the authors with a specific area to address, which could significantly improve the clarity and readability of their draft. However, the comment could be more helpful if it suggested how the authors might define the notation or provided an example of how to do so. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment questions the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper\"s approach or methodology are being questioned. Without clear grounding or detailed feedback, the authors cannot effectively address the concern. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting they could be interchangeable. However, it does not provide any specific reasoning, evidence, or examples to support this skepticism. Without detailed feedback or actionable suggestions, the authors are left without a clear understanding of how to address this concern or improve their approach. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests evaluating the performance of each component separately, such as by comparing with baseline detection or parsing techniques, to better support the claim. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of each component. The suggestion is concrete, as it outlines a specific approach to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the clarity of the proposed method, specifically questioning which component contributes to the performance gain. It suggests evaluating each component separately, such as by comparing with baseline detection or parsing techniques. This feedback is fully grounded as it explicitly mentions the \"proposed method\" and the \"two major components,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of unclear contribution and provides a suggestion for evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the proposed method, specifically questioning which component contributes to the performance gain. It suggests evaluating each component separately, such as by comparing with baseline detection or parsing techniques, to better support the claim. While the comment provides a logical reasoning for the need to evaluate each component, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests evaluating each component separately, such as by comparing with baseline detection or parsing techniques, to better support the claim. This feedback is clear and actionable, providing a specific direction for the authors to improve the clarity and robustness of their work. By addressing this concern, the authors can enhance the credibility and comprehensiveness of their paper. Therefore, the comment is 5, as it offers a clear path for improvement and empowers the authors to strengthen their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process, specifically questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the manual disentangling process, particularly questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not specify which part of the paper discusses the manual disentangling process, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not precise. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or why learning disentangling would be more interesting. The suggestion is based on a subjective opinion rather than a verifiable claim, as it does not provide detailed justification or examples. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue or explore alternative methods. Therefore, it is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve the clarity of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to a specific section or discussion, the lack of explicit grounding makes it challenging to determine the exact area of concern. The comment is specific in its focus on the Lipschitz Hessian assumption, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a valid point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their method. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. It suggests that the authors should provide more clarity by checking the original paper. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the presentation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the presentation of existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"pieces using existing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of existing methods in the paper, particularly referring to equation (12). It points out that the presentation is vague and suggests that the authors should provide more clarity by checking the original paper. While the comment highlights a potential area for improvement, it lacks depth and does not offer specific suggestions or guidance on how to enhance the clarity of the presentation. This limits its usefulness for the authors, as they may find it challenging to fully address the issue without additional context or direction. Therefore, the comment is 3, as it points out a specific area for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern about the writing or presentation being jumbled, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the writing or presentation, nor are there suggestions for specific areas that need clarification or reorganization. Without actionable advice or specific feedback, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"writing\" and \"presentation,\" but it does not specify which sections or parts of the paper are being referred to. This makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled or unclear. Without clear grounding and specific details, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the writing or presentation being jumbled, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the writing or presentation being jumbled, but it does not provide specific examples or detailed feedback on what aspects are unclear or confusing. Without actionable guidance or suggestions for improvement, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable advice makes the comment unhelpful, as it does not provide the authors with a clear path to improve their draft. Therefore, the comment aligns with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should investigate the computational complexity and power demand of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and power demand, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support the claim about computational complexity or power demand. The reasoning is based on the reviewer\"s imagination and speculation, which makes the claim 3. The authors would need to conduct further analysis to address this concern, making the comment 3.", "helpfulness_rationale": "The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device, which is a relevant consideration for practical applications. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a critical aspect of the work, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully guide them in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible for a single instance to hold all the training data from realworld datasets. However, it does not provide explicit guidance on how the authors should address this issue or whether they should develop a distributed version of the method. The action is implicit and somewhat vague, as the authors are left to infer that they might need to explore scalability options. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, specifically mentioning that it may not be feasible for a single instance to hold all the training data from realworld datasets. However, it does not specify which part of the paper discusses the method\"s scalability, making it weakly grounded. The comment is specific in identifying the issue of scalability and the need for a distributed version, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable, suggesting that a distributed version would be necessary. However, the comment lacks specific reasoning or evidence to support why this is the case. It does not provide examples or detailed explanations of how the current method struggles with scalability or what specific issues might arise. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential scalability issue with the method, suggesting that it may not be feasible for a single instance to hold all the training data from realworld datasets. This is a valid concern that could impact the practical applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as exploring distributed versions or alternative approaches. While it highlights an important area for improvement, the feedback is 3 as it provides a direction for potential enhancement but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific feedback on the vagueness of the comment at line 15, suggesting that the authors should refer to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. It also critiques the reinforcement learning/agent analogy, suggesting that it is out of place and recommending that the authors focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. While the comment provides clear guidance on what to include and where to find relevant information, it does not explicitly instruct the authors to make these changes themselves. The feedback is concrete and specific, but the action is inferred, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L15,\" \"L16,\" \"L17,\" and \"L18,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the comment, such as the vagueness of the RNNs work and the outofplace nature of the reinforcement learning/agent analogy. The comment further provides specific references to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/, offering concrete guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific references to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. This provides a clear and verifiable basis for the claim, making it 5. The comment also critiques the reinforcement learning/agent analogy, suggesting it is out of place and recommending that the authors focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. This feedback is wellsupported by logical reasoning and specific references, making the claim 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft. It identifies a vague comment at line 15 and suggests referencing the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to provide a more concrete example of RNNs working well for certain natural language reasoning tasks. Additionally, it critiques the reinforcement learning/agent analogy, suggesting that it is out of place and recommending that the authors focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. This feedback is clear and provides the authors with concrete steps to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the tuplelike structure of triples denoted as $(e_1, r, e_2)$ in line 122. This feedback is clear and direct, providing a specific action for the authors to take. It specifies what needs to be done to improve the clarity of the presentation, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of the tuplelike structure of triples denoted as $(e_1, r, e_2)$. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures rather than sets. This is a logical suggestion based on the typical representation of triples in graph structures. However, the comment does not provide specific examples or references to support why this change is necessary or how it would improve the clarity of the presentation. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the significance of the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to improve the clarity of the presentation by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuplelike structures rather than sets. This feedback is clear and directly addresses a potential issue in the paper, offering a concrete way for the authors to enhance the readability and understanding of their work. By following this advice, the authors can make their draft more accessible and easier to follow for readers. Therefore, the comment is rated as 5, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also points out that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. The reviewer suggests that the quantization is a bottleneck for the method, questioning its relevance. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to find a way to mitigate the scalability problem without being given concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the quantization process is costly in terms of both the number of data points (N) and the dimensionality (M). The comment also highlights that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. However, it questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. While the comment mentions specific parts of the paper, such as the abstract and introduction, it does not explicitly refer to a particular section or figure. The authors can infer that it relates to these parts, but the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the scalability issue and its implications for the method, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It further explains that even with clustering, the quantization process is costly in terms of both the number of data points (N) and the dimensionality (M). The comment also highlights that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. However, it questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. While the comment provides some reasoning and context, it lacks specific examples or references to support the claim fully. This makes the claim 3, as the authors would need to further explore the scalability issue and its implications for the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also points out that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. The comment questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. This feedback is clear and actionable, as it highlights a significant limitation of the method and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address the scalability issue or alternative approaches to consider. Overall, the comment is 4, as it effectively identifies a critical area for improvement and provides a starting point for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to take. It suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. Additionally, it recommends that the paper aim for a more applicationoriented venue if it does not address these issues. The comment is concrete, as it specifies the exact steps the authors need to take to improve their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"contrastive response tuning\" as part of the core methodology, allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, such as comparing effectiveness against existing methods and addressing issues mentioned above. The comment further suggests that the paper should aim for a more applicationoriented venue if it does not address these issues. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also recommends that the paper aim for a more applicationoriented venue if it does not address these issues. However, the comment does not provide specific examples or references to support the claim that the paper should compare against existing methods or address the issues mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their methodology, specifically contrastive response tuning, against existing methods such as contrastive decoding. This comparison would help validate the effectiveness of their approach and provide a benchmark for future work. Additionally, the comment highlights the need to address the issues mentioned above and suggests that the paper should aim for a more applicationoriented venue if it does not address these issues. This feedback is detailed and constructive, offering specific guidance on how the authors can improve their work. Therefore, the comment is 5, as it empowers the authors to make significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed. The reviewer also expects the authors to further elucidate the technical contribution. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or concrete steps to take. The actions are implicit and somewhat vague, leaving the authors to infer the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the algorithm\"s effectiveness, problem, and validation experiments. It points out that the algorithm requires access to the entire training dataset and suggests considering how it operates when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not analyzed. The comment is fully grounded as it explicitly mentions the algorithm\"s effectiveness and problem, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific in detailing what needs to be addressed, such as the need for comprehensive validation experiments and analysis of time complexity and efficiency. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment provides a logical reasoning for the concerns raised, such as the need for comprehensive validation and analysis of efficiency. However, it lacks specific references or examples to fully substantiate the claims, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the algorithm\"s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, the comment points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The reviewer also expects the authors to further elucidate the technical contribution. While the comment provides valuable insights and suggestions for improvement, it could be more helpful if it offered specific guidance or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that every kernel can be described by a feature space parameterized by a neural network, noting that this is not true for infinitedimensional RKHSs, such as those associated with RBF kernels. The reviewer suggests that the limitation of NNs in representing such kernels should be made clearer. While the comment identifies a specific issue and provides a clear suggestion for improvement, it does not offer explicit guidance on how to address this limitation or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to clarify the limitation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, particularly noting the limitation for infinitedimensional RKHSs, such as those associated with RBF kernels. The comment suggests that the limitation should be made clearer, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper, specifically regarding the ability of neural networks to represent kernel functions. It provides a specific example, the RBF kernel, to illustrate that the claim is not true in practice due to the infinitedimensional RKHS associated with it. The reviewer suggests that the paper should clarify this limitation. While the comment includes a specific example to support its claim, it lacks detailed reasoning or references to further substantiate the argument. This makes the claim 3, as the authors would need to delve deeper into the literature to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear example, the RBF kernel, to illustrate that this claim is not true in practice due to the infinitedimensional RKHS associated with it. The reviewer suggests that the paper should clarify this limitation, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provided additional context on why this clarification is important. Overall, the comment is 4 as it highlights a critical point for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding during inference. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. The reviewer asks if this limitation affects the benefits of the linear attention mechanism. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or what steps they could take to improve their approach. As a result, the authors are left without a clear understanding of what changes or clarifications are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not specify which part of the paper discusses the linear attention mechanism or the autoregressive decoding process, making it weakly grounded. The question is specific in its inquiry about the limitations of the linear attention during inference, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. The reviewer points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or justification, the claim remains 1, as it lacks the necessary details to help the authors understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the handling of autoregressive decoding with the linear attention mechanism, specifically addressing the inference phase. It points out that while the network can be trained with a batch of inputs with long token dimensions, only a limited number of tokens are used for generating the next token during inference. This raises a concern about the benefits of the linear attention mechanism in this context. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. It lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential area for improvement but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests the need for additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the possibility of GPI with noise reproducing data similarly well and suggests additional measures to demonstrate this. The comment further specifies the need for a discussion on the suitability of the approach for modeling pattern separation tasks, which is relevant to the paper\"s focus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate this. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims or suggestions. The lack of detailed evidence or justification makes it difficult for the authors to fully understand and address the points raised. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment raises a question about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also points out the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment identifies areas for improvement and provides some guidance, it lacks specific suggestions or detailed feedback on how to address these points. The authors are given a direction to consider, but the comment could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to perform the comparison or provide guidance on how to execute it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison and understand the context of the \"small learning rate for attention parameters\" benchmark. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not specify which part of the paper this benchmark is discussed in or how it relates to the proposed approach. The authors can infer that it pertains to the section where the benchmark is mentioned, but the comment lacks explicit grounding. It is specific in suggesting a comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, the comment does not provide any reasoning, evidence, or justification for why this comparison would be beneficial or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This feedback is 3 as it provides a clear direction for potential future work that could enhance the paper. However, it lacks depth and does not offer guidance on how to conduct the comparison or what specific aspects should be evaluated. The authors are left with a general idea of what could be improved but without detailed instructions on how to implement it. Therefore, the comment is rated as 3, as it provides a suggestion for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what experiments might be necessary. The feedback is vague and lacks concrete steps for the authors to take, making it difficult for them to know how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the carelessness in resolving a debate that was previously left open and suggesting that the distribution might have changed. The comment further asks whether experiments have been conducted to disentangle changes in distribution from the removal of information. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper\"s approach is flawed or incomplete. This lack of detailed evidence or justification makes the claim 3, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the paper\"s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. This feedback is 3 as it identifies a potential issue with the paper\"s methodology and encourages the authors to consider alternative explanations or experiments. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or what additional experiments could be conducted. To be more helpful, the comment could provide more detailed advice or examples of how to investigate these issues. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the compared methods using the same settings as the proposed method, specifically mentioning the use of AdamW with cosine lr for training. This action is clear and concrete, as it provides a specific step for the authors to take to ensure a fair comparison. The comment also highlights the importance of using the same settings as the compared methods, which is a logical and actionable suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. It suggests that the direct comparison is unfair and recommends reproducing the results of the compared methods using the same settings as the proposed method. This feedback is fully grounded as it explicitly mentions the comparison of methods and the specific training settings, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue with the comparison and provides a solution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the direct comparison of methods is unfair because the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests reproducing the results of the compared methods using the same settings as the proposed method to ensure fairness. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a solution to address it. However, it lacks specific examples or references to support the claim about the unfairness of the comparison, which could strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods in the paper. It points out that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests that this difference in training settings could make the comparison unfair. They recommend reproducing the results of the compared methods using the same settings as the proposed method to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific suggestion for improving the fairness of the comparison. However, it could be more helpful if it included additional guidance on how to reproduce the results or what specific aspects of the results should be compared. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. It suggests that the plots should be much clearer, which is a direct and concrete action for the authors to take. The comment provides specific areas for improvement, such as increasing the size of the plots, improving color differentiation, and clarifying axis labels. This level of detail and specificity makes the action explicit and actionable, allowing the authors to know exactly what changes to make. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"plots,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. The reviewer supports this claim by providing specific examples of these issues, such as the difficulty in distinguishing between pink and red colors. This level of detail and specificity makes the claim 4, as it provides clear reasoning and examples to substantiate the critique. However, the comment could be strengthened by including references to best practices or examples of welldesigned plots for further justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. It highlights that these issues make the plots difficult to read and understand, which is crucial for presenting experimental results. By pointing out these problems, the comment provides clear and actionable feedback that can help the authors improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending larger plot sizes or clearer label differentiation. Overall, the comment is 4 as it directs the authors\" attention to critical areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific experiments to perform. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the performance of the feedback network, specifically regarding the information about incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in its inquiry about the performance with and without these types of information, providing a clear direction for the authors to explore. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network, asking for a comparison between the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is crucial or how it might affect the network\"s performance. Without such support, the claim remains 1, as the authors are left without guidance on how to address the issue or what specific aspects to focus on. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. This feedback is 3 as it prompts the authors to conduct a specific analysis that could reveal valuable insights into the effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance or suggested specific methods for conducting these comparisons. Overall, the feedback is 3, as it directs the authors to an area for improvement but lacks depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. It also provides specific guidance on what needs to be addressed, such as including standard deviations in the table. This feedback is clear and direct, giving the authors a concrete action to take. The comment is 5 as it provides explicit instructions on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. This includes including standard deviations in the table. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks specific examples or references to support the claim that including standard deviations would strengthen the submission. The suggestion to include more extensive experiments is not elaborated, leaving the authors without clear guidance on how to improve their work. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also provides a clear suggestion for improvement by stating that the submission would be stronger if the experiments were more extensive, including the inclusion of standard deviations. This feedback is actionable and provides the authors with a clear direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to incorporate standard deviations or suggested specific areas where more extensive experiments could be conducted. Overall, the comment is 4 as it effectively directs the authors to improve their submission."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that using a better Unary baseline might still result in a performance boost. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to investigate this further. The action is implicit and vague, as the authors are left to infer that they should explore the performance boost with a better baseline. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the performance boost due to additional parameters in LinearTop and NLTop compared to the performance of the Unary model. The comment also references a specific paper (14) for context, providing additional specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper (14) for context, suggesting that using a better Unary baseline might still result in a performance boost. However, the comment lacks detailed reasoning or evidence to support the claim that the additional parameters are the sole reason for the performance boost. The reference to 14 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a starting point for the authors to explore but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper (14) for context, suggesting that using a better Unary baseline might still result in a performance boost. This feedback is 3 as it prompts the authors to consider the impact of additional parameters on performance and encourages them to explore alternative baselines. However, the comment could be more helpful if it provided specific suggestions or guidance on how to investigate this further or what additional experiments might be necessary. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the paper\"s structure, specifically recommending a clearer organization of sections (introduction, method, experiments) and more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests improving the visualization of Figures 7 and 8. These actions are clear and concrete, giving the authors a specific plan for enhancing their draft. The feedback is actionable because it provides clear guidance on what needs to be improved and how to achieve it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests improvements to the paper\"s structure, specifically recommending a clearer organization of sections and more focus on the IEM in Figure 3. It also mentions the need to improve the visualization of Figures 7 and 8. While the comment does not explicitly mention specific sections or figures, it provides enough context for the authors to understand the areas needing attention. The suggestion to improve the structure and focus on the IEM is specific, allowing the authors to address the feedback effectively. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to follow and recommends improvements to the structure and visualization of certain figures. However, it does not provide specific examples or detailed reasoning to support why the structure is unclear or why Figure 3 is considered the main figure. The lack of detailed justification or evidence makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the structure of the sections and the clarity of the figures. It suggests a specific reorganization of the paper\"s content, focusing on the introduction, method, and experiments sections. Additionally, it highlights the importance of Figure 3, which the reviewer considers the main figure, and recommends improvements to Figures 7 and 8. This feedback is clear and actionable, providing the authors with concrete steps to enhance the clarity and organization of their draft. However, the comment could be more helpful if it offered specific suggestions or examples for improving the figures. Overall, the comment is 4, as it guides the authors in making significant improvements to their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It also raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. While the comment provides a clear action for the authors to take, it does not specify how to determine the optimal learning rate or how to address the potential issue. The action is explicit but somewhat vague, as it does not provide detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of needing the final used learning rates and the concern about the optimal learning rate potentially being outside the tested interval. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a factual request for additional information and does not contain any claims or opinions, making it a normal statement. The second part raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. This part is a claim, as it suggests a potential issue that could impact the results. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the overall classification is 3.", "helpfulness_rationale": "The review comment is 4 as it provides clear and actionable feedback. It explicitly requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is a specific and relevant piece of information that could significantly impact the results and understanding of the study. Additionally, the comment raises a concern about the possibility of the optimal learning rate for the baseline being outside the tested interval, which could affect the results. While the comment does not provide detailed guidance on how to address this issue, it highlights an important area for consideration. Overall, the comment offers valuable insights and suggestions for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment implies that the authors should provide a detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. It requests the authors to explain why the absence of locality bias in transformers is not a concern. However, the comment does not specify which part of the paper this concern relates to, making it weakly grounded. The authors can infer that it pertains to the methodology or discussion section, but this is not explicitly mentioned. The comment is specific in detailing the issue with the absence of locality bias and the need for explanation, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment highlights a potential issue, it lacks specific evidence, examples, or references to support the claim that transformers without locality bias are not suitable. The reasoning is based on a general observation about information propagation, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment identifies a potential issue and prompts the authors to provide an explanation, it lacks specific suggestions or guidance on how to address this concern. The feedback is 3 as it highlights an area for improvement but could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two issues with the results presented in Table 2: the lack of consistent performance improvement over baselines and the unclear superiority of the proposed methods. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. While the comment implies that the authors should conduct further experiments or analysis, it does not provide specific guidance on which experiments to perform or how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the results, such as the lack of consistent performance improvement and the unclear superiority of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods due to the lack of consistent performance improvement and the unclear superiority of the proposed methods. The reviewer provides a logical reasoning by pointing out that the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a strong logical basis but lacks detailed examples or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three. It also points out the lack of a consistent trend in the results, making it unclear which proposed method is better. This feedback is clear and actionable, as it highlights a critical weakness in the paper\"s experimental validation. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims made in the paper. This constructive feedback provides the authors with a clear direction for improving their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the presence of combinatorial and heuristic aspects in the proposed framework, particularly in the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information on the impact of these components, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should clarify the impact of the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed framework for ReC, specifically mentioning the NonAmbiguous Query Generation procedure. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights the impact of heuristic components, particularly the sophisticated filtering template used in the procedure. This provides clear guidance on what needs to be clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC, but it also notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components, particularly the NonAmbiguous Query Generation procedure. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact impact of the heuristic components, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the engineering method presented in the paper for ReC. However, it points out that the framework incorporates combinatorial and heuristic aspects, particularly in the NonAmbiguous Query Generation procedure. The comment suggests that the authors clarify the impact of these heuristic components. While the feedback identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left with a general understanding of what needs clarification but without detailed steps on how to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not provide comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that a detailed comparison is needed, it does not provide explicit instructions on how to conduct this comparison or which specific aspects should be highlighted. The action is somewhat implicit, as the authors can infer that they need to include a more detailed comparison, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to include a detailed comparison of time complexity and competitiveness, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is 3 as it identifies a specific area for improvement that could enhance the paper\"s comprehensiveness and relevance. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or which aspects of related work should be highlighted. To be more helpful, the comment could include examples of relevant works or suggest specific metrics to compare. Therefore, the comment is rated as 3, as it points out a potential area for improvement but does not fully guide the authors in implementing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests two actions for the authors to take: conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method, and conducting experiments on the full dataset instead of the lowresource regime. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is 5 as it offers concrete steps for the authors to follow, ensuring they know exactly what changes to make to enhance their experimental evaluation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lack of experimental results on more datasets\" and provides specific suggestions for improvement, such as conducting experiments on more datasets and evaluating the method on the full dataset instead of the lowresource regime. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also recommends evaluating the method on the full dataset rather than the lowresource regime. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more datasets are necessary or that the current evaluation is insufficient. This makes the claim 3, as the authors would need to infer the significance of these suggestions based on their own understanding of the field. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of experimental results on more datasets. It provides a clear and actionable suggestion for the authors to conduct additional experiments on more datasets to provide a more comprehensive evaluation of their proposed method. Additionally, the comment suggests evaluating the method on the full dataset instead of the lowresource regime, which could further enhance the evaluation. This feedback is clear and provides the authors with a specific direction for improving their draft, making it 4. However, it could be more helpful if it included additional guidance on how to select or prioritize additional datasets for evaluation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment identifies areas of concern, it does not provide specific guidance or suggestions on how the authors might clarify or simplify these aspects. The feedback lacks explicit instructions or concrete steps for improvement, leaving the authors uncertain about how to address the issues. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the clarity of the generic argument task and the random argument task, as well as the dataset transformation and experimental setup. However, it does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of clarity and the cumbersome nature of the dataset transformation and experimental setup, but it does not provide detailed guidance on how to improve these aspects. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task do not clearly support the authors\" claims, and the dataset transformation and experimental setup are cumbersome. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding how the generic argument task and the random argument task support the authors\" claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment highlights areas that need improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback provides some insight into potential weaknesses but does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant omission in the paper, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and the use of multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, giving the authors a specific action to take: to include an analysis of the impact of additional parameters and computational effort. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and the use of multiple discriminators. It explicitly mentions the need for an analysis to provide a fair comparison with the baseline, which is 31, 33, *. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and the use of multiple discriminators. The reviewer suggests that the authors should provide this analysis for a fair comparison with the baseline. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed justification or evidence, the claim remains 3, as it lacks the necessary depth to fully substantiate the need for the analysis.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and the use of multiple discriminators. It provides a clear and actionable suggestion for the authors to include this analysis for a fair comparison with the baseline. This feedback is valuable as it guides the authors to address a critical aspect that could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct this analysis. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions whether this trend holds across different model architectures and lacks theoretical evidence. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or theoretical evidence. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, specifically questioning the trend across different model architectures and the absence of theoretical evidence. However, it does not specify which part of the paper this analysis is found in, making it weakly grounded. The comment is specific in detailing what is missing or unclear, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, questioning whether this trend holds across different model architectures and lacking theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It questions whether this trend holds across different model architectures and lacks theoretical evidence. This feedback is 3 as it points out a potential weakness in the analysis, prompting the authors to consider whether their findings are robust and generalizable. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered guidance on how to strengthen the analysis. Overall, the comment provides a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out two issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This provides clear and direct actions for the authors to take, such as removing duplicates and ensuring that all publications include their respective venues and years. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment identifies specific issues with the references list, mentioning duplicates and missing publication venues and years. However, it does not specify which references are duplicates or which papers lack publication details, making it weakly grounded. The comment is specific in detailing the issues with the references, but without explicit references or sections, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This feedback is clear and actionable, providing the authors with a straightforward list of tasks to address. By correcting these issues, the authors can improve the accuracy and completeness of their reference list, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it offered suggestions on how to avoid duplicates or provided examples of how to include publication venues and years. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it specifically points out the lack of clarity regarding the error bound. It also suggests that the authors need to analyze and compare their theoretical results to other comparable methods. This feedback is clear and provides a direct action for the authors to take, which is to clarify the theoretical analysis and compare it with other methods. The comment is explicit and concrete, offering a clear path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, particularly the lack of clarity regarding the error bound and the need for comparison with other methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear what the error bound means. It provides a clear and actionable suggestion for the authors to analyze and compare their theoretical results with other comparable methods. This feedback is valuable as it directs the authors to a specific area of improvement, offering a clear path for enhancing the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it provided additional guidance on how to analyze and compare the results or suggested specific methods for doing so. Overall, the comment is 4, as it effectively highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of lowresource language pairs in finetuning a multilingual model and suggests using the R3F method to maintain generalization ability. It also mentions a specific improvement of 0.8 in lowresource language translations, but questions its practical significance. The comment provides a reference to a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could be used to support the argument. However, the comment does not explicitly instruct the authors to include this reference or discuss the implications of the R3F method in their work. While the suggestion is clear, the lack of explicit action leaves the authors with some ambiguity about how to address the feedback. Therefore, the comment is 4, as it provides a clear direction but lacks concrete details on implementation.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs in finetuning a multilingual model and mentions the R3F method as a potential solution. It also questions the practical significance of the claimed improvement of 0.8 in lowresource language translations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the practical significance of the improvement and suggesting a reference for further discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs in finetuning a multilingual model is not practical, as the improvement of 0.8 is insignificant. It also suggests using the R3F method to maintain generalization ability. The comment provides a reference to a relevant paper, \"Better FineTuning by Reducing Representational Collapse,\" which could support the argument. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the practical significance of the improvement. While the reference provides a basis for the claim, the lack of specific examples or detailed reasoning makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs in finetuning a multilingual model, questioning the practical significance of the claimed improvement of 0.8. It suggests using the R3F method to maintain generalization ability and provides a reference to a relevant paper for further discussion. This feedback is 3 as it highlights a specific area for improvement and offers a potential solution, but it could be more helpful if it included more detailed guidance on how to implement the R3F method or discuss its implications in the context of the paper. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. While the comment implies that the authors should provide results for other types of noise, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their results to include other types of noise. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\" and \"images corrupted using Gaussian noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\"s ability to handle various image noise types. This provides clear guidance on what aspect of the paper needs further clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\"s ability to handle various image noise types. This is a logical question that seeks clarification on the authors\" rationale. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why this is a concern. As a result, the comment is considered 1, as it lacks the necessary justification or evidence to support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why only results on images corrupted with Gaussian noise are shown, given the claim that the model can handle various image noise types. This feedback prompts the authors to consider expanding their experimental setup to include other types of noise, which could enhance the robustness and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as which types of noise to include or how to structure the additional experiments. While it identifies a potential weakness, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. While the comment implies that this visualization would be beneficial, it does not explicitly instruct the authors to perform this task or provide guidance on how to create the visualization. The action is implicit and somewhat vague, as the authors need to infer that they should include a visualization and how to create it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The authors can infer that it pertains to the motivation or discussion section, but this inference is not explicit. The comment is specific in its suggestion to visualize the effect, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not provide any specific reasoning, examples, or references to support why this visualization would be beneficial or how it would enhance the paper. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. This is a constructive suggestion that could enhance the paper by providing a clearer understanding of the research motivation. However, the comment lacks specific guidance on how to create the visualization or what aspects should be included. While it identifies a potential improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, as it provides a direction for enhancement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the claim made in lines 180182, stating that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider to strengthen their argument. As a result, the comment is 1, as it does not offer any direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This claim is 3 as it provides a logical reasoning based on the information presented in the paper. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the paper to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim made in lines 180182, noting that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, without necessarily implying that it minimizes the expected convex surrogate. This feedback is 3 as it points out a potential weakness in the argument, prompting the authors to reconsider or clarify their claims. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or improve the argument. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The feedback lacks concrete suggestions or steps for improvement, leaving the authors uncertain about how to enhance their model. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the simplicity of the evolution model. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average because the reassignment probability is 1/n, which allows for very slow dynamics. It also notes that the evolution model is simplistic as it only changes edges associated with the 1 node changing cluster on average. While the comment provides a logical explanation for the slow dynamics and the simplicity of the model, it lacks specific references or examples to fully substantiate the claim. The reasoning is clear but could be strengthened with additional evidence or references. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could benefit from more detailed support.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. This feedback is clear and actionable, providing the authors with concrete areas to address and improve upon. By highlighting these weaknesses, the comment offers a valuable direction for enhancing the model\"s complexity and dynamics. However, it could be more helpful if it suggested potential solutions or ways to address these issues. Overall, the comment is 4 as it provides actionable feedback but could be further enhanced with more detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add missing details about the division of the dataset into training and test sets, including the numbers involved and the method used for division (e.g., random or other considerations). This feedback is clear and direct, providing a specific action for the authors to take. The comment does not leave any ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"division to train and test sets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, such as the numbers involved and the method used for division. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the division of the dataset into training and test sets. It points out that the numbers and the method used for division are missing, which is a crucial aspect for understanding the experimental setup. By suggesting that these details should be added, the comment provides clear and actionable feedback that can help the authors improve the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have handled similar details. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions that the longtext input could restrict the scalability of the framework. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or methods to mitigate the need for human labor and optimize the textual format. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenges and potential limitations, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in the paper, which is the need for human labor in building text descriptions for each task. It also points out the lack of an optimal textual format for policy learning, which varies from task to task and model to model. Additionally, the comment raises a concern about the scalability of the framework due to longtext input. While the comment highlights important issues, it lacks specific suggestions or actionable steps for the authors to address these challenges. The feedback is 3 as it provides insight into potential areas for improvement but does not offer detailed guidance or concrete recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It suggests using tables to present the key improvements more intuitively and in detail. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3\" and \"table,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the performance improvement of the proposed methods is not significant and suggests using tables to present the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It also suggests using tables to present the key improvements more intuitively and in detail. However, the comment lacks specific examples or detailed reasoning to support the claim about the significance of the performance improvement. The suggestion to use tables is a logical recommendation but does not provide evidence or examples to substantiate the need for this change. Therefore, the claim is 3, as it provides a general observation but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the improvement is not significant, as indicated by the largest improvement of approximately 0.02 in the bank dataset. It also suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a specific area for improvement and offers a practical suggestion for enhancing the clarity and impact of the results. However, the comment could be more helpful if it provided additional guidance on how to effectively use tables to present the improvements or examples of how this could be done. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a constructive suggestion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to prove new theoretical results. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not specify which part of the paper this claim pertains to, such as the methodology, results, or discussion sections. The authors may have to infer that it relates to the theoretical contributions or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of new theoretical results, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or references to existing literature, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s theoretical contributions, noting that the use of a novel type of loss in a specific setting does not result in any new theoretical results. This observation is important as it highlights a gap in the paper\"s contribution. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the theoretical aspects of their work. Without specific recommendations or examples, the authors may find it challenging to understand how to enhance their draft. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. While the action is explicit, it does not provide specific guidance on how to implement these additions or what exactly should be included in the baselines. The authors are aware of the need to include these baselines but may need to infer the details of how to implement them. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. While the comment provides a clear idea of what needs to be addressed, it lacks grounding as it does not explicitly mention the table or section being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it would enhance the understanding of the gap. Without specific justification or evidence, the claim remains 1, as the authors may not fully understand the reasoning behind the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and semisupervised learning (SSL) for these models. This feedback is clear and actionable, as it provides a specific recommendation for improving the understanding of the results presented in the table. By including fullysupervised baselines, the authors can gain insights into the performance differences between supervised and semisupervised approaches, which is a valuable addition to the analysis. However, the comment could be more helpful if it provided additional context or guidance on how to implement these baselines or what specific metrics or comparisons should be included. Overall, the comment is 4 as it directs the authors towards a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the dataset used in the experiments is small and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific guidance on how to address this concern. The authors are left with a general suggestion but without concrete steps or examples on how to implement it. The action is implicit and somewhat vague, as it does not offer detailed instructions on how to improve the dataset or what specific results should be included. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the small dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting a potential improvement to the dataset, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the small size of the dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific reasoning or evidence to support why this is a concern or how it affects the overall quality of the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the small size of the dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific guidance or suggestions on how to address this concern. While it identifies a potential area for improvement, the comment lacks actionable advice or detailed feedback, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues regarding the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The feedback is 3 as it points out areas for improvement but lacks concrete suggestions on how to implement them. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the limitations section or the title, but this is not explicit. The comment is specific in its critique of the title and the concept of \"brittle convergence properties,\" but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the limitations of evolutionary methods and suggests that the title is too generic and vague. It questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment lacks specific examples or references to support the claim about the limitations of evolutionary methods or the meaning of \"brittle convergence properties.\" The suggestion to be more precise and honest is a general observation without detailed evidence or reasoning, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s discussion of evolutionary methods, suggesting that there are deeper aspects to consider regarding leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and vague, recommending that the authors be more precise and honest in their critique. The comment provides a clear direction for improvement by highlighting specific areas that need further exploration and clarification. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is 4 as it guides the authors towards enhancing the depth and clarity of their work, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not require apriori knowledge about dimensions of subspaces. While the comment implies that such justification is necessary, it does not explicitly instruct the authors to include this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include empirical evidence to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, which is that the proposed algorithm does not require apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment suggests that empirical justification is needed for this claim, but it does not provide specific details on what kind of empirical evidence would be necessary. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is that the proposed algorithm does not require apriori knowledge about dimensions of subspaces, unlike other existing algorithms. However, the comment lacks specific examples or empirical evidence to support this claim. While it suggests that empirical justification is needed, the absence of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient support or evidence.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s first claimed contribution, suggesting that the authors should provide empirical justification for their claim that the proposed algorithm does not require apriori knowledge about dimensions of subspaces. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct this empirical justification or what kind of evidence would be most effective. The feedback is 3 as it points out a gap in the paper\"s claims but could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. It explicitly recommends that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a specific action to take: to include a detailed comparison with RMED in their paper. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the similarity between the proposed S1DBED algorithm and RMED (Komiyama et al. 2015), suggesting that the novelty of the proposed algorithm is limited. It implies that the paper needs to provide a sufficient discussion on the comparison with RMED. However, the comment does not explicitly mention which part of the paper discusses the proposed algorithm or the comparison with RMED, making it weakly grounded. The comment is specific in identifying the need for a detailed comparison, but without explicit grounding, it is challenging for the authors to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. The reviewer provides a reference to RMED, which could help the authors understand the context and potential similarities. However, the comment lacks specific details or examples of where the similarity lies, making it difficult for the authors to fully grasp the critique. The mention of RMED provides some support, but the lack of detailed comparison or analysis makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to address this concern. This feedback is clear and actionable, as it directs the authors to include a detailed comparison with RMED to enhance the novelty and originality of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this comparison. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or what aspects of the discussion are lacking. This lack of detail makes it difficult for the authors to understand exactly what needs to be addressed or how to improve their draft. Without explicit guidance or concrete suggestions, the authors are left without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or sections of the paper are being referred to, making it weakly grounded. The comment is specific in identifying the need for a more detailed discussion of previous work, but without explicit references or examples, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not give a comprehensive discussion of previous work on the topic. However, it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, noting that the authors do not provide a comprehensive discussion of previous work on the topic. This feedback is clear and actionable, as it directs the authors to ensure a thorough review and discussion of prior research in their paper. However, the comment could be more helpful if it provided examples of previous work that should be discussed or suggested ways to enhance the discussion. Overall, the comment is 4 as it highlights a critical area for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it implies that the authors should provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the introduction of the importance of unsupervised feature selection from a diffusion perspective. It also raises a question about the difference between similarity and exit times, which is relevant to the paper\"s methodology. However, the comment does not specify which part of the paper this discussion is in, making it weakly grounded. The authors can infer that it relates to the introduction or a section discussing feature selection, but without explicit references, it remains challenging to pinpoint the exact location. The comment is specific in questioning the difference between similarity and exit times, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a request for clarification, which is a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a specific question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it identifies a gap in the authors\" explanation, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not provide explicit guidance or suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore the capabilities of the framework in different contexts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate this inquiry. The comment lacks specific examples or references to external works that might address this concern, making it difficult for the authors to understand the basis of the question. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the inquiry.", "helpfulness_rationale": "The review comment raises a valid concern about the limitations of the unified framework, specifically questioning whether it can handle general POMDP formulations, including continuous or infinite spaces. This is an important consideration for the authors to address, as it impacts the applicability and versatility of their framework. However, the comment does not provide any suggestions or guidance on how the authors might explore or address these limitations. While it identifies a potential area for improvement, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the dataset creation is optional and mentions that the Kialo dataset is wellstudied and cleaner than the dataset created in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the creation of the dataset, specifically mentioning the Kialo dataset and its cleanliness compared to the dataset created in the paper. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in pointing out the comparison between the Kialo dataset and the one created in the paper, suggesting that the latter can be additional data to learn from. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point compares the dataset created in the paper with the Kialo dataset, suggesting that the latter is cleaner and more suitable for the authors\" needs. However, the comment lacks specific evidence or reasoning to support the claim that the Kialo dataset is cleaner or more appropriate. It does not provide examples or detailed comparisons to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the creation of the dataset is optional and highlights the availability of the Kialo dataset, which is wellstudied and cleaner than the dataset created in the paper. However, it does not provide specific guidance or suggestions on how the authors might use the Kialo dataset or whether it should be included in the paper. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path for improvement. As a result, the comment is 2, as it identifies a potential area of improvement but does not offer actionable insights or suggestions for the authors to follow. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might infer that it relates to the methodology or results sections, the lack of explicit references or specific details makes the comment weakly grounded. The comment is specific in its critique of the novelty and significance of the crosslayer modification and the ablation study results, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the novelty of using the Transformer in NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study. The comment provides some reasoning by mentioning the limited improvement (<1%) in the ablation study, but it lacks specific examples or detailed explanations to fully substantiate the claim. The authors might infer that the critique is based on the comparison with other methods, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the novelty of using the Transformer in NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the crosslayer modification and the limited improvement observed in the ablation study, suggesting that the main improvements come from using a \"naive\" transformer rather than the proposed modification. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it identifies areas for concern, it does not provide actionable feedback or detailed advice on how to enhance the draft. Therefore, the comment is 3, as it highlights potential weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and provides a specific direction for the authors to improve their experiments. The action is explicit and concrete, as it outlines exactly what additional experiments need to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments\" and \"sentence similarity tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the limitation of the current experiments, suggesting that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what additional experiments are needed to enhance the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, without mentioning other tasks involving sentence pairs. The reviewer suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This claim is 3 as it provides a logical reasoning for the claim that the experiments are limited, but it lacks specific examples or references to support the suggestion of additional tasks. The authors would need to conduct further research or experimentation to fully address this feedback, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental evaluation, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks, which may not fully represent the breadth of tasks involving sentence pairs. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness of their experimental evaluation. By addressing this suggestion, the authors can improve the robustness and relevance of their work. Therefore, the comment is 4, as it offers valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity does not appear in earlier layers. While the comment raises a valid concern about the rationale behind the analysis, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the motivation for their analysis. However, the comment lacks concrete details on how to improve the motivation, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in questioning the rationale behind the analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. While it identifies a potential gap in the paper\"s rationale, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The comment highlights an area that needs clarification but does not provide actionable feedback or detailed advice, leaving the authors with a general direction to explore. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider including a human evaluation, it does not explicitly instruct them to do so or provide guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include a human evaluation and understand how to integrate it into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this evaluation should be included in or how it should be integrated. The authors can infer that it relates to the evaluation section, but the comment lacks specificity in terms of what needs to be addressed or how to implement the suggestion. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, the comment does not provide specific examples or references to support the claim that automatic metrics are misleading. While the suggestion is logical, it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it identifies a potential limitation in the current evaluation approach and provides a suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects should be considered. To be more helpful, the comment could include examples of how human evaluation could be implemented or what criteria should be used. Overall, the feedback offers a direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, noting that the theoretical proof appears straightforward due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It suggests that the convergence proof lacks substantial novelty and rigor. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the proof. The action is implicit and vague, as the authors are left to infer that they need to enhance the proof\"s novelty and rigor but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Theoretical proof for convergence\" and references \"Assumption 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the convergence proof, noting that the proof appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The comment further explains that the convergence proof lacks substantial novelty and rigor, providing a clear basis for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, based on the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a logical reasoning by referencing Assumption 4.1 and Modification 1 in Appendix C, which suggests that the convergence proof lacks novelty and rigor. This is supported by the reviewer\"s explanation of how the covariance matrix is derived and how it relates to the i.i.d. assumption. However, the comment could be strengthened by providing specific examples or references to similar works that might highlight the lack of novelty. Overall, the claim is 4 due to the logical reasoning and references provided, but it could be further strengthened with additional examples or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The reviewer provides a clear explanation of how this assumption leads to a straightforward proof, suggesting that the convergence proof lacks novelty and rigor. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to consider revising their theoretical framework to enhance its novelty and rigor. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to improve the proof. Overall, the comment is 4 as it directs the authors\" attention to a significant weakness in their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a contradiction in the paper\"s statements regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly requests clarification on this apparent contradiction. However, the comment does not provide specific guidance on how the authors should address this issue or what additional information or analysis is needed to resolve the contradiction. While the action is clear, the lack of detailed instructions on how to implement the clarification makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the statements about the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. It explicitly mentions these two statements, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies the contradiction and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a logical inconsistency by noting that the paper simultaneously claims both a performance loss for the multienv model and its outperformance due to knowledge sharing. This is a clear claim that requires clarification. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the specific statements being referred to, which adds to the complexity of addressing the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a logical inconsistency in the paper\"s claims regarding the multienv model\"s performance loss and its ability to outperform the singleenv model due to knowledge sharing. By pointing out this contradiction, the comment provides a clear and actionable suggestion for the authors to clarify their statements. This feedback is valuable as it helps the authors address a potential confusion in their paper, ensuring that their claims are consistent and wellsupported. However, the comment could be more helpful if it offered specific guidance on how to resolve the contradiction or suggested ways to clarify the statements. Overall, the comment is 4, as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing them. While the comment implies that the authors should include more information about the metrics, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide more details or citations, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of the metrics used in the paper, suggesting that it is limited and recommending either an explanation or a citation. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion to provide more information about the metrics, but without grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation or citing the metrics. However, the comment does not provide specific examples or references to support the claim that the metrics are not wellexplained. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that either an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the metrics used. However, the comment could be more helpful if it offered additional guidance on how to explain the metrics or suggested specific references for the authors to consider. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the empirical analysis is based on static datasets, which may not fully align with the paper\"s objective. The reviewer implies that the paper should provide a more compelling motivation for the problem, but does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed motivation for the problem. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem of designing fast label aggregation algorithms in a streaming setting, specifically noting that the empirical analysis is based on static datasets. However, it does not specify which part of the paper lacks motivation or where the static datasets are used. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem of designing fast label aggregation algorithms in a streaming setting, as it does not discuss the applications where such algorithms are needed. The reviewer also notes that the empirical analysis is based on static datasets, which may not align with the paper\"s objective. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s motivation and relevance. It points out that the paper\"s objective of designing fast label aggregation algorithms for a streaming setting is not adequately supported by a discussion of the applications where such algorithms are needed. Additionally, the comment notes that the empirical analysis is based on static datasets, which may not align with the streaming setting. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s motivation and methodology. By addressing this issue, the authors can enhance the relevance and applicability of their work. However, the comment could be more helpful if it provided suggestions on how to improve the motivation or discussed potential applications. Overall, the comment is 4, as it effectively guides the authors towards a more comprehensive and impactful revision."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, suggesting that it is underspecified. It implies that the work focuses on injecting a CoTbased approach to smallscale Language Models, and if that is not the case, it points out that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. The reviewer also asks a clarifying question (Question A) to further address this issue. While the comment implies that the authors should clarify the scope and include additional baselines, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer the need for clarification and additions. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the scope of the study is underspecified and suggesting that additional relevant CoT baselines for incontext learning of Large Language Models are missing. The comment further clarifies that this is particularly relevant for text003 and ChatGPT. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified, suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. The reviewer implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. However, the comment does not provide specific examples or references to support the claim that the scope is underspecified or that additional baselines are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and suggesting that the work focuses on injecting a CoTbased approach to smallscale Language Models. The reviewer implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. By pointing out this gap and asking for clarification, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of additional baselines that could be included. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the figure\"s readability, such as suggesting changes in font size, color contrast, or layout. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the figure is \"very hard to read anything on the figure,\" which is a clear and specific description of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the difficulty of reading Figure 3, which is a claim that can be verified by the authors themselves. However, the comment does not provide any reasoning, examples, or references to support why the figure is hard to read or how it could be improved. This lack of supporting evidence makes the claim 3, as the authors would need to independently assess the figure\"s readability and determine how to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it does not provide any suggestions or guidance on how the authors might improve the figure\"s readability or what specific elements are causing the difficulty. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment implies that the authors should clarify or discuss this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this connection in their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the mention of tensor decomposition being harder in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This question prompts the authors to clarify or discuss this connection, which could be an important aspect to address in their draft. However, the comment does not provide specific guidance or suggestions on how to improve the connection or what aspects of the discussion should be expanded upon. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to replace `n^2/(2*s^2)` with an arbitrary parameter `lambda` and to clarify the justification for using a SGD learning rate of ~0.1. These actions are clear and concrete, as they specify what needs to be changed and why. The authors know exactly how to address these issues, making the comments 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` (lines 119121) and the use of SGD learning rate ~0.1 (line 164). These references provide full grounding, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it details what needs to be addressed in each case, such as justifying the use of SGD learning rate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two claims: the first claim suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, and the second claim questions the justification for using a SGD learning rate of ~0.1. The first claim is 3 as it provides a suggestion for improvement but lacks specific reasoning or examples to support the need for this change. The second claim is more verifiable, as it questions the justification for a specific learning rate, but it could be strengthened with additional context or references to support the claim that the default value of Adam is different from 0.1. Overall, the comment is 4, as it provides some reasoning but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas for improvement in the manuscript. It suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a clear and direct recommendation for enhancing the clarity and flexibility of the mathematical expressions. Additionally, it questions the justification for using a SGD learning rate of ~0.1, pointing out that this value is unclear and lacks explanation. These suggestions are valuable as they guide the authors in making improvements to their draft, making the comment 5. However, the feedback could be more comprehensive if it provided additional context or guidance on how to justify the choice of learning rate. Overall, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should analyze the domain gap and discuss the gap between datasets. It also recommends adding discussions about the adaption issue and the value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a clear direction for improvement, it does not specify which parts of the paper should be revised or how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discusses the gap between datasets, suggesting that some datasets may be closer, making the adaptation issue less significant. It also recommends that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discusses the gap between datasets, recommending that some datasets may be closer, making the adaptation issue less significant. It also suggests that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. While the comment provides a logical reasoning for the suggestions, it lacks specific examples or references to support the claim about the datasets\" closeness or the potential value of finetuning on synthetic data. This makes the claim 3, as the authors would need to explore these suggestions further to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap and provides specific guidance on how to address it by discussing the gap between datasets. It acknowledges that some datasets may be closer, which could affect the adaptation issue. Additionally, the comment highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is clear and actionable, offering the authors a direction for improvement and suggesting ways to enhance the value of their approach. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to analyze the domain gap or discuss the datasets. Overall, the comment is 4, as it provides valuable insights and suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific work, 1, which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear and explicit action for the authors to take, as they are directed to include a comparison with an NCEbased method. The comment also offers a specific reference to guide the authors in their selection. Therefore, the comment is 5, as it provides a direct and concrete action for the authors to implement.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific work, 1, which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear reference and a specific example of what could be included for comparison, making the comment fully grounded. The suggestion is also specific, as it directs the authors to include a comparison with an NCEbased method, which is a concrete action. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including at least one NCEbased method for comparison, referencing a specific work, 1, which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the inclusion of an NCEbased method would enhance the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests including at least one NCEbased method for comparison, referencing a specific work, 1, which demonstrates the possibility of learning an energybased model (EBM) on natural images with a strong noise distribution. This feedback is clear and actionable, as it provides a specific recommendation for the authors to include a comparison with an NCEbased method. By referencing a relevant work, the comment offers a concrete example of what could be included to enhance the comparison. However, the comment could be more helpful if it provided additional guidance on how the inclusion of this method would improve the paper or what specific aspects of the NCEbased method should be highlighted. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear direction for enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the need for designing a new curriculum learning method for text graphs is not justified, and it questions why existing methods cannot be applied. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the existing methods are not applicable. The comment lacks concrete details on how to improve the justification or what specific aspects of the existing methods need to be addressed. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the need for designing a new curriculum learning method for text graphs, specifically mentioning Section 1 where several curriculum learning methods are discussed. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the justification for needing a new method and highlights the lack of discussion on why existing methods cannot be applied. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods can be applied. However, the comment does not provide specific examples or references to support why existing methods are not applicable or how they could be adapted for text graphs. This lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the justification for needing a new curriculum learning method for text graphs, suggesting that existing methods could be applied. However, the comment lacks specificity and does not provide detailed reasoning or examples to support this claim. It does not offer actionable suggestions or guidance on how the authors might address this issue or improve their justification. As a result, the feedback is 3, as it points out a potential weakness but does not provide enough detail or direction for the authors to effectively address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This action is explicit and provides a clear direction for the authors to follow. It also offers concrete guidance on how to implement this change, making the comment 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use pretrained models and compare transfer parts, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. While the comment provides a logical reasoning for this suggestion, it lacks specific references or examples to support the claim that these models are more effective in overcoming domainshift problems. The reasoning is 3, as it aligns with common knowledge in the field, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s methodology. It suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest ngram features. This feedback is specific and offers a concrete way to enhance the paper\"s experimental setup and analysis. By following this advice, the authors can potentially strengthen their results and make their findings more robust. However, the comment could be more helpful if it included additional context or examples to further justify the recommendation. Overall, the comment is 4, as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the explanation provided in line 1967 regarding the difference between two quantities and how it captures the difference in learning settings. It suggests that more explanation is needed. However, the comment does not provide explicit guidance on what additional explanation is required or how to address the issue. The authors are left to infer that they need to provide a clearer explanation, but the comment lacks concrete details on what specific aspects need clarification. Therefore, the comment is 3, as it identifies a need for more explanation but does not provide clear instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for more explanation regarding why the two quantities are different and how they capture the difference in learning settings. The reviewer\"s stance on acceptance is also included, providing additional context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in line 1967, asking for more details on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that more explanation is needed. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the explanation provided in line 1967 regarding the difference between two quantities and how it captures the difference in learning settings. It suggests that more explanation is needed to clarify these points. While the comment identifies a gap in the paper\"s explanation, it does not provide detailed guidance or suggestions on how to improve the clarity or depth of the explanation. This limits the comment\"s helpfulness, as it prompts the authors to address a specific issue but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request provides a clear and direct action for the authors to take, as it specifies what aspect of the model they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the discussion of the sensitivity of any fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should focus on in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to discuss the sensitivity of fixed tuning parameters in their model, both in terms of strengths and weaknesses. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of any fixed tuning parameters in their model, both in terms of strengths and weaknesses. This feedback provides a clear direction for the authors to enhance their analysis and understanding of their model. However, the comment could be more helpful if it included specific examples or guidance on how to approach this discussion, such as which parameters are particularly sensitive or how to quantify their sensitivity. Overall, the comment offers a good starting point for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. However, it does not provide explicit instructions on how to conduct these experiments or what specific policy gradient approaches to consider. The request for \"experiment results\" is somewhat vague, as it does not specify which experiments are being referred to or what additional information is needed. The comment lacks concrete details on how to implement the suggested exploration, making it 3. The authors can infer that they need to conduct additional experiments, but the lack of specific guidance on what to include in these experiments limits the actionability.", "grounding_specificity_rationale": "The comment suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional information about the experiments, but without clear grounding, the authors may struggle to identify the exact section or aspect of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies. However, it does not provide any reasoning, evidence, or references to support why this exploration is necessary or how it would impact the framework. The request for additional information is clear but lacks justification or context, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for the authors to explore by investigating the proposed framework with different policy gradient approaches. This suggestion could potentially expand the scope of the study and provide additional insights into the framework\"s performance. However, the comment lacks specificity regarding which policy gradient approaches to consider or how the exploration should be structured. Additionally, it does not provide guidance on how to conduct these experiments or what specific results to expect. While the suggestion is intriguing, it does not offer detailed or actionable feedback, making it 3. The authors can gain some insight into potential future directions but would need to develop their own strategies for implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing could be improved in some places, specifically mentioning two examples. The first example is the definition of \"relevant\" auxiliary model weights in definition 2.1, which the reviewer finds difficult to interpret. This feedback provides a clear and explicit action for the authors to take, which is to clarify the definition of \"relevant\" auxiliary model weights. The second example is not specified, but the first example gives a concrete action for the authors to address. Therefore, the comment is 5, as it directly instructs the authors on what needs to be improved and how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the difficulty in interpreting the definition of \"relevant\" auxiliary model weights. This provides clear guidance on what the authors need to clarify or improve in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved, specifically mentioning a difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the writing is difficult to understand. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the writing, specifically mentioning the difficulty in interpreting the definition of \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their work. However, the comment could be more helpful if it provided suggestions on how to improve the definition or offered alternative ways to express it. Overall, the comment is 4 as it highlights a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA 1 as an alternative. While the comment identifies a potential issue and suggests a solution, it does not provide explicit instructions on how to address the concern or integrate ULiRA into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider the robustness of MIA testing and adopt ULiRA as a more reliable metric. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the reliance on MIA testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA as an alternative. However, the comment does not specify which part of the paper discusses MIA testing or unlearning effectiveness, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the issue with MIA testing and suggesting an alternative, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not robust for privacy guarantees and suggests using ULiRA as an alternative. However, the comment does not provide specific evidence, examples, or references to support the claim about the unreliability of MIA testing. The suggestion to use ULiRA is not accompanied by an explanation of why it is a better alternative or how it addresses the issue. Without detailed justification or references, the claim remains 1, making it difficult for the authors to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the effectiveness of MIA testing itself is not robust for privacy guarantees, which is a critical concern for the paper\"s claims. Additionally, the comment suggests using ULiRA as an alternative, providing a specific recommendation for improvement. While the comment highlights a significant weakness in the methodology, it does not offer detailed guidance on how to implement ULiRA or address the issue with MIA testing. The feedback is 4 as it directs the authors to consider an alternative metric but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit guidance on how the authors should incorporate these suggestions into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these connections and present them in a different context. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore connections with kernel regression and smoothing, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" This feedback is 3 as it points out a potential connection that the authors might explore, which could expand the scope of their work. However, the comment lacks specific guidance on how to make this connection or what aspects of the paper should be rephrased or restructured to accommodate this suggestion. Without detailed instructions or examples, the authors may find it challenging to fully implement the feedback. Therefore, the comment is rated as 3, as it provides a direction for potential improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback provides a clear and explicit action for the authors to take, which is to include these settings in their draft. The suggestion is concrete, as it specifies what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. While it does not specify which part of the paper this suggestion pertains to, it implies that it is relevant to the methodology or experimental setup sections. The authors can infer that it relates to the methods or results sections, but they cannot pinpoint the exact location. The comment is specific in suggesting what needs to be addressed, namely, the inclusion of settings for the algorithm, which would help the community. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This claim is 3 as it provides a suggestion for improvement but lacks specific examples or references to prior work that would demonstrate the importance of this suggestion. The authors would need to infer the relevance and impact of including these settings, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for various \"knobs\" of the algorithm, such as Dagger and searn, to mimic prior work. This feedback is clear and actionable, as it provides a specific way for the authors to enhance the transparency and reproducibility of their work. By including these settings, the community would benefit from a more comprehensive understanding of the experimental setup, which could aid in replicating the results and building upon the work. However, the comment could be more helpful if it provided examples of how these settings are typically presented or discussed in similar papers. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an unclear aspect regarding the generalizability of the biases discussed in the paper. It mentions specific examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1), but questions the generalizability of these situations. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or clarify the generalizability of the findings. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence to support the generalizability of the biases. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the generalizability of the biases discussed in these sections. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the biases discussed in the paper, specifically mentioning examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1). However, the comment does not provide specific examples or detailed reasoning to support the claim that these biases are not generalizable. The lack of detailed evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the generalizability of the biases discussed in the paper. It highlights that while the paper presents examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1), it does not provide evidence or discussion on how these biases might generalize to other situations. This feedback is 3 as it points out a potential weakness in the paper\"s analysis, prompting the authors to consider the broader implications of their findings. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provided additional context to support the claim. Overall, the comment provides some guidance but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide specific guidance on which datasets would be most useful or how they should be incorporated into the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks concrete details on what datasets to include or how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not specify which datasets are currently being used or which additional datasets would be most relevant. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs improvement. While the comment implies that the datasets section or methodology should be addressed, it does not provide clear guidance on what specific datasets should be added or how they would enhance the study. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide any specific examples or reasoning to support why additional datasets are necessary or how they would enhance the study. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets would be most relevant or how they could be incorporated into the study. The feedback is 3 as it points out a potential enhancement, but it does not offer actionable advice or detailed suggestions, leaving the authors with limited guidance on how to address this issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. While the comment implies that the authors should explore these unique tasks, it does not explicitly instruct them to do so. The action is somewhat implicit and concrete, as the authors can infer the need to explore additional tasks but are not given a direct instruction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment does not specify which part of the paper discusses the tasks or the dataset, making it weakly grounded. The authors can infer that it relates to the tasks or dataset sections, but this inference is not explicit. The comment is specific in suggesting unique tasks that could be explored, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. However, the comment lacks detailed reasoning or evidence to support why these tasks are standard or why introducing unique tasks would be beneficial. The suggestion is based on a general observation rather than a comprehensive analysis or reference to existing literature. Therefore, the claim is 3, as it provides a specific example but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential limitation in the tasks presented in the paper, noting that they are somewhat standard and suggests that the authors could introduce unique tasks to showcase the diversity of the dataset. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, that could be considered. This feedback is 3 as it offers a clear direction for enhancing the diversity of tasks and the potential impact of the dataset. However, it could be more helpful if it provided additional suggestions or examples of unique tasks that could be explored. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows the previous work, Luciddreamer. It explicitly requests the authors to clarify if there is any additional novel effort in this part. This feedback provides a clear and direct action for the authors to take, which is to address the novelty of their contribution in this section. The comment is explicit and concrete, guiding the authors on what specific aspect of their work needs clarification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the section on 3D Gaussians generation is novel or follows previous work, Luciddreamer. The comment clearly specifies what needs to be addressed, namely, the novelty of the contribution in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows previous work, specifically Luciddreamer. The comment seeks clarification on the novelty of the contribution in this part. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that the section is not novel. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the novelty of the section on 3D Gaussians generation, specifically in relation to the previous work, Luciddreamer. It prompts the authors to clarify whether there are any additional novel contributions in this part of the paper. This feedback is 3 as it identifies a potential area for improvement in terms of novelty and encourages the authors to provide more detailed explanations or evidence of their contributions. However, the comment could be more helpful if it provided specific suggestions or examples of what additional novel aspects could be highlighted. Overall, the comment offers a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is an explicit suggestion that provides a clear direction for the authors to explore. However, the comment does not specify how to implement this action or what specific aspects of the sparsification process to focus on. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014sparsifying the trained models and comparing their accuracy to the proposed model. This provides clear guidance on what needs to be done to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. However, the comment does not provide any reasoning, evidence, or justification for why this action might be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is a clear and actionable suggestion that could potentially enhance the analysis and provide additional insights into the performance of the models. However, the comment does not provide specific guidance on how to implement this suggestion or what aspects of sparsification to focus on. While it offers a direction for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the paper\"s reproducibility, noting that while the pseudocode is provided in the supplementary material, it does not feel like the paper is written to be reproduced. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback implies that the authors should include these details to enhance the reproducibility of their work. However, the comment does not explicitly instruct the authors to add these details, leaving the action somewhat implicit. The authors can infer that they need to provide more technical details, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of reproducibility, specifically mentioning the lack of details about the RNN implementation, such as the number of units. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional technical details to enhance reproducibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, despite the presence of pseudocode in the supplementary material. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This claim is 3 as it points out a specific area of concern regarding the lack of detailed information for reproducibility. However, the comment lacks detailed examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s reproducibility, noting that while pseudocode is provided in the supplementary material, the paper does not feel written to be reproduced. The reviewer highlights the need for additional details, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback is clear and actionable, as it directs the authors to include more technical details to enhance the reproducibility of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to include these details. Overall, the comment is 4 as it effectively identifies a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores could introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they might need to consider alternative approaches or metrics to mitigate these biases. However, the lack of specific suggestions or examples makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED for determining chunk significance, specifically mentioning the potential issue of introducing biases when basing eviction decisions solely on utility scores. However, it does not specify which part of the paper discusses this approach or where the potential biases might be discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in identifying the potential issue with the utilitybased approach and its implications, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the utilitybased approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential issue, it lacks specific examples or references to support the claim of introducing biases. The reasoning is based on a logical deduction, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It points out that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. This feedback is 3 as it highlights a specific area where the authors might need to consider alternative approaches or metrics to mitigate these biases. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address this issue, such as proposing alternative methods or metrics. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how different parts of the framework contribute to the final result and suggests that the authors should provide either quantitative experiments or detailed explanations. While the comment identifies a specific area for improvement, it does not explicitly instruct the authors to conduct these experiments or provide detailed explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative experiments or detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of how different parts of the framework contribute to the final result, specifically mentioning the lack of quantitative experiments and detailed explanations in the result section. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, such as quantitative experiments and detailed explanations, which helps the authors understand the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of different parts of the framework and provides a suggestion for improvement. However, it does not provide specific examples or references to support the claim that the framework\"s performance is unclear. The mention of \"promising visual stimuli result\" in the result section provides some context, but without further elaboration, the claim remains vague. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s clarity regarding the performance of different parts of the framework and their contribution to the final result. It points out the lack of quantitative experiments or detailed explanations, which is crucial for understanding the framework\"s effectiveness and potential improvements. The comment also suggests that the authors should provide either quantitative experiments or detailed explanations, offering a clear direction for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or present detailed explanations. Overall, the feedback is 4 as it highlights a critical area for enhancement and provides actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to clarify this point. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the model\"s capabilities, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. This is a valid concern that could impact the paper\"s contribution and significance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the model\"s capabilities. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors present a simplified version of theorem 2 for the general audience, similar to theorem 1. While the comment implies that the current presentation of definition 2 and theorem 2 is difficult to understand, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should simplify theorem 2. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2 and theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding these sections for the general audience. The comment provides a clear direction for improvement by suggesting a simplified version of theorem 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of definition 2 and theorem 2 is difficult for the general audience to understand, similar to theorem 1. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of theorem 2, suggesting that it might be difficult for the general audience to understand due to its complexity. It compares this difficulty to that of theorem 1, implying that a simplified version of theorem 2 could be beneficial. However, the comment lacks specific suggestions or guidance on how to simplify the presentation or what aspects might be contributing to the complexity. While it points out a potential area for improvement, the feedback is 3 as it provides a direction for the authors to consider but does not offer detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution, specifically mentioning 224*224. While the comment implies that the authors should consider conducting experiments with different image resolutions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore different resolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the performance of experiments with larger image resolutions, specifically mentioning 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as a particular experiment or section. The authors can infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution, specifically mentioning 224*224. However, the comment does not provide any reasoning, evidence, or references to support why this would be interesting or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for further exploration by suggesting that the performance of the experiments could be evaluated with larger image resolutions, specifically mentioning 224*224. This feedback provides a clear and actionable suggestion for the authors to consider, encouraging them to expand their experimental setup. However, the comment could be more helpful if it included specific reasons why exploring larger resolutions might be beneficial or how it could impact the results. Overall, the comment is 4 as it offers a direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking what the \"keypoint mask averaged feature vector\" is and whether it is obtained by multiplying each feature map elementwise by H_psi. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this aspect in their draft. However, the comment is 3 because it directs the authors to a specific area that needs clarification, but it lacks concrete details on how to implement this clarification. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the nature of the \"keypoint mask averaged feature vector\" and asks whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific aspect of the paper, namely the calculation of the \"keypoint mask averaged feature vector.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the calculation of the \"keypoint mask averaged feature vector\" in the KeyQN section. It asks whether this vector is obtained by multiplying each feature map elementwise by H_psi. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, the comment could be more helpful if it provided additional context or suggested how this clarification might impact the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area that needs clarification, which is beneficial for improving the draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or analysis to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the central contribution of modeling weight evolution using ODEs, particularly the problem of neural ODEs exhibiting inaccuracy while recomputing activations. It references a previous paper that first reported this issue, indicating that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need for more evidence or analysis to support the claim, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the central contribution of modeling weight evolution using ODEs, specifically questioning the issue of neural ODEs exhibiting inaccuracy while recomputing activations. It suggests that a previous paper first reported this issue and implies that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. However, the comment does not provide specific references or detailed reasoning to substantiate the claim, making it difficult for the authors to address the concern effectively. The lack of explicit evidence or examples makes the claim 3, as the authors would need to independently verify the issue and provide additional support to refute the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the central contribution of the paper, which is the modeling of weight evolution using ODEs. It questions the issue of neural ODEs exhibiting inaccuracy while recomputing activations, suggesting that a previous paper first reported this issue. The reviewer expresses doubt about the problem and notes that the current paper lacks a convincing analytical argument or empirical evidence to support this claim. This feedback is 3 as it highlights a potential weakness in the paper\"s contribution and suggests that the authors need to provide more evidence or analysis to support their claim. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue or improve the paper\"s argument. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not explicitly instruct the authors to include this information or provide guidance on where or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should make this mention but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on why this information is important or how it could be integrated into the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger data sets, noting that compute might be an issue. While the comment implies that the authors should consider this suggestion, it does not provide explicit guidance on how to address the compute limitations or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger data sets, noting that compute might be an issue. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments, but without grounding, the authors may struggle to identify the exact section or context where this suggestion is relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests additional experiments on larger data sets, noting that compute might be an issue. However, it does not provide any specific reasoning or evidence to support why these experiments would be beneficial or how they might address the concerns raised. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger data sets, noting that compute might be an issue. While this feedback is relevant and could potentially enhance the robustness of the study, it lacks specificity and does not provide detailed guidance on how to address the compute limitations or what specific experiments should be conducted. The comment also acknowledges the authors\" response, indicating that their concerns have been addressed. However, without actionable steps or detailed suggestions, the comment is 3, as it provides a direction for potential improvement but does not fully support the authors in implementing it. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the performance of the models in Table 4, noting that the performance on REC and RES is behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT. However, the comment does not explicitly instruct the authors to make any changes or improvements to their models or results. While it points out a potential area for improvement, it lacks concrete guidance on how to address this issue. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT. The comment provides clear examples of other models achieving better results, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES is behind more recent models, providing specific examples of other models that achieve better results. This claim is supported by references to GLaMM and UNINEXT, which provide concrete examples of models that outperform the ones discussed in the paper. The references to specific metrics (RES cIoU and REC accuracy) and the comparison to other models enhance the verifiability of the claim. Therefore, the comment is 5, aligning with a score of 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that the results on REC and RES are behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT, which helps the authors understand the gap in performance. However, the comment could be more helpful if it suggested ways to address this issue or provided guidance on how to improve the models. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the weakness of the method might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not specify which part of the paper this observation pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method or comparison are being suggested. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the method\"s weakness would be more pronounced in these scenarios. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, suggesting that its weakness might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. This feedback is 3 as it points out a specific area where the method might struggle and suggests a potential direction for further investigation. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the authors would need more detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to include this explanation or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should add more explanation but are not given concrete steps on how to implement this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its suggestion to provide more explanation of the bounds, but without grounding, the authors may struggle to identify the exact sections that need this additional explanation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional explanation is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the bounds need clarification or how this additional explanation could enhance the paper. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or suggestions for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment implies that the authors should consider revising their explanation, it does not explicitly instruct them to do so or provide guidance on how to simplify the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should streamline the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels with OpenAI\"s Triton, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is in, making it weakly grounded. The comment is specific in its suggestion to simplify the explanation, but without explicit references to the paper, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the implementation of kernels with OpenAI\"s Triton is wellknown and does not require a fullpage explanation. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment identifies a potential area for simplification, it does not provide specific guidance or suggestions on how to streamline the explanation or what aspects of the implementation are particularly noteworthy. The feedback lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it points out a potential area for simplification but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to the difficulty of the source and target tasks. It also suggests that the authors clarify the transferability aspect in the paper, particularly regarding the policy transfer from simpler to more complex tasks. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to make these clarifications or provide specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It suggests that the authors clarify the transferability aspect in the paper, particularly regarding the policy transfer from simpler to more complex tasks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides logical reasoning by suggesting that the transferability might be limited by the real difficulty of the source and target tasks. The reviewer also points out specific examples, such as the Walkerrun task being harder than the Walkerwalk task, and the manipulation scenario involving tasks with different complexities. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the concerns raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples, such as the Walkerrun task being harder than the Walkerwalk task, and the manipulation scenario involving tasks with different complexities. The comment suggests that the authors clarify these aspects in the paper to avoid misleading readers. While the feedback identifies areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or offered alternative approaches to enhance the clarity of the paper. Overall, the comment is 3 as it points out critical areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of neural networks contributes less and suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies an issue with the analysis, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analysis of neural networks, specifically mentioning \"Section 3.2, 3.3,\" which provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies the issue by pointing out that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of neural networks, suggesting that the work does not contribute significantly to the understanding of neural networks. It points out that the extension from linear models to wide fullyconnected neural networks is trivial, implying that the work may not address the core problem of overparametrized neural networks. However, the comment lacks specific suggestions or guidance on how the authors might improve their analysis or address this issue. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a confusing aspect in the paper regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting a revision of the text or providing a clearer explanation. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, referencing a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context. This provides full grounding, as the authors can accurately identify the part of the paper being discussed. The comment also highlights a confusing aspect in the abstract and introduction regarding the terms \"relatively inexpensive\" and \"expensive to evaluate.\" However, it does not specify what needs to be addressed in terms of clarity or how to resolve the confusion. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction are confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in the abstract and introduction, respectively. It references a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context, which provides some grounding for the authors. However, the comment lacks actionable feedback or suggestions on how to address the confusion or improve the clarity of the text. While it highlights an issue, it does not offer guidance on how to resolve it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and whether it supports this claim through the experiments. It also asks if the proposed method requires subtaskspecific rewards, which would be similar to providing dense rewards. Additionally, it inquires about the ability of other methods (Qmix) to solve sparsereward tasks when given the sum of lowlevel rewards as the global reward. While the comment raises valid questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples, references, or detailed explanations, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their draft. The feedback is 3 as it prompts the authors to consider additional aspects of their method, but it could be more actionable with more detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly instruct the authors to make a change, it does highlight a potential issue that needs to be addressed. The authors can infer that they should clarify this aspect in their paper to ensure a fair comparison. However, the comment lacks specific guidance on how to address this issue, such as suggesting a way to clarify the dataset usage or providing examples of how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or experimental setup. The authors can infer that it relates to the dataset usage or training process, but the comment does not specify the exact part of the paper where this information is discussed. Therefore, the comment is weakly grounded as it does not provide a direct reference to a specific section, but it is specific in its request for clarification. This aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the clarity of dataset usage in the paper. It specifically asks whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. This feedback is valuable as it highlights a potential issue with the experimental setup that could affect the validity of the results. By addressing this question, the authors can ensure that their methodology is transparent and that their results are comparable to those of other methods. However, the comment could be more helpful if it provided suggestions on how to clarify this aspect or offered examples of how to address the issue. Overall, the comment is 4 as it identifies a significant area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and mentions specific examples of previous works that have been evaluated on this set. Additionally, it recommends comparing the paper to other approaches where corresponding publications are available. These actions are clear and provide specific guidance on how the authors can improve their draft by ensuring a more comprehensive comparison with existing works. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as comparing the results on the official COOC leader board and the blind test set, and suggesting that the paper should at least compare to other approaches where corresponding publications are available. This provides detailed feedback on how the authors can enhance their work. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. The comment provides a specific reference to the COOC leader board and mentions previous works that have won the challenge and been evaluated on the blind challenge set. This provides some justification for the claim, but it could be strengthened by including more detailed reasoning or examples of why these comparisons are important. Therefore, the comment is 3, as it offers a basis for the claim but lacks full detail and specific references to support the suggestion fully.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s comparison with related work. It highlights that the paper should compare its results on the official COOC leader board, specifically on the blind test set, which is a more rigorous and standardized evaluation method. The comment also references specific examples of previous works that have won the challenge and been evaluated on the blind challenge set, providing a benchmark for the authors to follow. Additionally, it suggests that the paper should at least compare to other approaches where corresponding publications are available, which is a valuable piece of advice for ensuring a comprehensive comparison. This feedback is clear, actionable, and provides the authors with a concrete path to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. While the comment implies that the authors should provide more context or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms used. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of the term \"wrong\" and suggests clarifying what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. This feedback is valuable as it prompts the authors to revisit and clarify their terminology, which could improve the clarity and precision of their explanations. However, the comment could be more helpful if it provided examples or specific suggestions on how to clarify these terms. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It suggests that this comparison is necessary to prove the superiority of the schema searched by the author\"s method (ELF) over the schema in Mid Vision Feedback (MVF). While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct this comparison or what specific metrics or results should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically pointing out the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely a comparison with the image classification result of Mid Vision Feedback (MVF). This provides clear guidance on what needs to be added to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by stating that the absence of this comparison does not prove the superiority of the schema searched by the author\"s method (ELF) over the schema in Mid Vision Feedback (MVF). However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact comparison that should be made to address the issue, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a specific area where the authors can enhance their paper by providing a more comprehensive comparison. By suggesting the inclusion of this comparison, the comment offers a clear direction for improvement, making it 4. However, it could be more helpful if it provided additional guidance on how to conduct this comparison or what specific results should be included. Overall, the comment is valuable in guiding the authors towards a more robust evaluation of their method\"s contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should expand their discussion on the types of activities and their significance, but the comment lacks concrete suggestions or examples on how to do so. Therefore, the comment is 3, as it provides a direction for improvement but lacks specific details on execution.", "grounding_specificity_rationale": "The comment suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for more discussion on the types of activities and their significance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area that needs further exploration, which could potentially enhance the paper\"s depth and relevance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which types of activities should be discussed or how they relate to energy efficiency. To be more helpful, the comment could provide examples or references to similar studies that have addressed this topic, offering a clearer path for improvement. Therefore, the comment is rated as 3, as it highlights an important area for expansion but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of state, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions\" in the context of the paper. It suggests that more elaboration is needed to clarify this aspect. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to elaborate or what specific details should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the concept of state, questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" The comment provides a clear direction for the authors to elaborate on this aspect, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of state, specifically regarding the equivalence of \"elements\" to \"states\" or \"actions.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of state in the paper, particularly in relation to the elements and their equivalence to states or actions. It provides a clear and actionable suggestion for the authors to elaborate on this aspect, which could help clarify the paper\"s understanding of the state concept. However, the comment could be more helpful if it offered additional guidance or examples on how to elaborate on this concept. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section where this comparison should be made. The comment is specific in its suggestion to use a Jaccard index for comparison, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any reasoning, evidence, or references to support why this comparison would be interesting or beneficial. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This suggestion could provide additional insights into the effectiveness of the proposed scheme. However, the comment does not offer specific guidance on how to conduct this comparison or what aspects should be considered, leaving the authors with a general idea but without detailed instructions. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of these comparisons or what specific aspects need to be clarified. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper the comment addresses, making it weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but without grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the theoretical comparisons to adaptive learning of GPRGNN. However, it lacks detail and does not provide any suggestions or guidance on how the authors might clarify or improve these comparisons. Without actionable feedback or specific examples, the authors are left without a clear understanding of what needs to be addressed or how to enhance their draft. Therefore, the comment is 2, as it points out a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what alternative measures they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion about object hallucination. Without explicit references or detailed context, the authors may find it challenging to identify the exact part of the paper being addressed. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. This feedback highlights a potential limitation in the evaluation methodology, prompting the authors to consider alternative measures or metrics for assessing object hallucination. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative methods might be more appropriate. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detail on the innovation of the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify what aspects of the innovation should be detailed or how the authors should present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the innovation, but they are not given clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to identify the exact section being referred to. The comment suggests that the innovation should be detailed, but it does not provide specific guidance on what aspects of the innovation need more explanation. This lack of grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovation should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed FRM, noting that it is a simple combination of channel and spatial attention mechanisms. It suggests that the innovation should be detailed, implying that the authors should provide more context or explanation about the novelty of their approach. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the innovation should be elaborated upon or how to present this information. While it points out a potential area for improvement, it does not provide actionable feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights a need for more detail but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of connection between the improved variance control of prediction y^ and the smoothness of the loss landscape with zeroshot learning effectiveness. It suggests that the authors need to provide more details to clarify this connection. However, the comment does not explicitly instruct the authors on how to achieve this clarification or what specific details should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context or examples to strengthen the connection. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in detailing the issue of poor clarity and the need for more details to clarify the connection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" suggesting poor clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the connection between improved variance control of prediction y^, the smoothness of the loss landscape, and zeroshot learning effectiveness. It highlights a specific area where the paper could be improved by providing more details or examples to clarify the relationship between these concepts. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as which sections or parts of the paper need further explanation. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to perform these analyses or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for these analyses and how to carry them out. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of certain approaches, such as simple greedy selection over more principled acquisition functions, and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what the authors should investigate, but without grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of certain approaches, such as simple greedy selection over more principled acquisition functions, and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide specific examples or references to support the claim that these approaches are indeed superior. The suggestion lacks detailed reasoning or evidence to substantiate the need for these analyses, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is valuable as it points out a potential area for deeper investigation that could enhance the novelty and understanding of the paper\"s contributions. However, the comment lacks specific guidance on how to conduct these analyses or what aspects to focus on, which limits its usefulness. While it identifies a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for a citation where the kmax problem was discussed elsewhere in the paper. This request provides a clear and direct action for the authors to take, which is to include a citation to the relevant section or work. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kmax problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a citation for where the kmax problem was discussed elsewhere in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for a citation, which is a factual statement rather than a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide a citation where the kmax problem was discussed elsewhere in the paper. This feedback is specific and directly addresses a gap in the paper, guiding the authors to include necessary references. However, it could be more helpful if it suggested where to find or include such citations. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The action is implicit, as the authors need to infer that they should provide more information on the estimation process and the reliability of the model. The comment is vague because it does not specify how to implement these additions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting the absence of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This feedback is clear and actionable, as it directs the authors to provide additional details that would enhance the transparency and credibility of their work. However, the comment could be more helpful if it suggested specific methods or references for estimating the function or assessing reliability. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions should be in the main sections rather than the appendix. While the comment explicitly states these actions, it does not provide specific guidance on how to restructure the paper or what changes to make. The authors are aware of the issues but lack detailed instructions on how to address them. Therefore, the comment is 4, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment addresses the issue of forward referencing in the paper, specifically mentioning Figure 1 and the need for clearer explanation of contributions in the Introduction. It also notes that supporting material for the main contributions is in the appendix, which is not in the main sections. This provides some grounding as it mentions specific elements of the paper, such as Figure 1 and the appendix, but it does not explicitly mention the sections where these issues are present. The comment is specific in detailing what needs to be addressed, such as the need for clearer explanation of contributions and the placement of supporting material. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It also notes that the material supporting the main contributions is in the appendix, which is not in the main sections. The comment provides specific examples, such as Figure 1 and the deeprag algorithm, to illustrate the issue. This level of detail and specificity makes the claim 4, as it offers clear evidence and examples to support the assertion. However, it could be strengthened by providing more detailed reasoning or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions should be in the main sections rather than the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and organization of the paper. By addressing these points, the authors can enhance the coherence and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to restructure the paper or provide examples of how to clarify the contributions. Overall, the comment is 4, as it directs the authors to make significant improvements in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the presentation of test settings in the visual dialog domain. It highlights that while there are two test settings, only one is shown in Table 1, specifically the discriminative setting. The reviewer questions why the generative setting is not included and asks for the results on this setting. This feedback is explicit and concrete, as it directly instructs the authors to provide results for the generative setting, which is a clear and actionable suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the presentation of test settings in visual dialog, questioning why only the discriminative setting is shown and asking for results on the generative setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the presentation of test settings in the visual dialog domain, specifically noting that only the discriminative setting is shown in Table 1, while the generative setting is not. The reviewer questions why the generative setting is not included and asks for results on this setting. This comment is 3 as it highlights a specific discrepancy in the presentation of results, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that only one of the two test settings in the visual dialog domain is shown in Table 1. It highlights a potential discrepancy by questioning why the generative setting is not included and asks for results on this setting. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive presentation of their results, which is crucial for a complete understanding of the study\"s findings. By addressing this issue, the authors can enhance the transparency and completeness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide specific guidance on how to achieve this, such as suggesting additional examples, case studies, or detailed explanations. The comment also mentions a \"little thing,\" but it does not specify what this is. Without explicit or concrete actions, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for additional convincing evidence, but without grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should do more to convince the reader that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for additional convincing, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more convincing evidence to demonstrate the feasibility of a query of the type \"SEARCH\" in a realistic scenario. This feedback is 3 as it identifies a specific area where the authors could improve their draft by offering additional context or examples. However, the comment lacks detailed guidance on how to achieve this or what specific aspects of the query\"s feasibility should be addressed. To be more helpful, the comment could include suggestions on how to present this evidence or what kind of examples would be convincing. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to test the approach in other language families. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section, table, or figure this comment pertains to, making it weakly grounded. The comment is specific in identifying the need for testing the approach in other language families, but it lacks detailed guidance on how to conduct these tests or what specific language families should be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to similar work, the authors are left without guidance on how to address this concern or improve their approach. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, specifically questioning its effectiveness for other language families. This is a valid concern that the authors should consider, as it highlights an area where the current work may not be fully applicable. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or conduct further research to test the approach in other language families. Without specific recommendations or steps, the feedback is limited in its usefulness. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the named works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about providing this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the named works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not specify which specific works are being referred to or where in the paper these works are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to provide more detailed descriptions of the differences, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works are being referred to or why more detailed descriptions are needed. Without detailed justification or examples, the claim is not 5, as it lacks the necessary evidence to substantiate the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, suggesting that more detailed descriptions of the differences between named works are needed. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by clarifying the distinctions between related works. However, the comment could be more helpful if it offered examples of how to provide these detailed descriptions or suggested specific aspects of the related works that need further elaboration. Overall, the comment is 4 as it guides the authors towards improving their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by examining PPP maps. While the comment implies that the authors should provide this explanation, it does not specify how to do so or what aspects of the explanation are needed. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but may not know exactly how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific point about the importance of reliable PPP metrics and the lack of explicit explanation in the article. It explicitly mentions the importance of understanding PPP effects in different tasks, which grounds the comment well. However, it does not specify which part of the article lacks this explanation, making it weakly grounded. The comment is specific in its request for an explicit explanation of what type of understanding one can gain by examining PPP maps. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should provide an explicit explanation of what type of understanding one can gain by examining PPP maps, given the importance of reliable PPP metrics for understanding PPP effects in different tasks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the explanation needed. The lack of detailed reasoning or references leaves the claim 3, as it requires the authors to infer the specific details needed for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the article by noting that while the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, this explanation is not explicitly provided in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by examining PPP maps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the concept, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to structure this explanation. Overall, the comment is 4 as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include for comparison. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional comparisons to enhance the credibility of their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a lack of comparison with stateoftheart methods for spanrelated tasks, specifically mentioning SpanBERT. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for comparison with other methods, which is a clear issue for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. However, the comment does not provide specific examples or references to support the claim that SpanBERT or other methods are the only relevant ones. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s evaluation by pointing out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or which methods to include for comparison. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors are aware of the need for comparison but may struggle to implement it effectively without additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained and suggests that Figure 2(b) should be redrawn to better represent the schematic of the forward prediction model. Additionally, it points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and provides specific actions for the authors to take, such as revising the figure and improving the connection between the text and the figure. The authors know exactly what needs to be done to address the issues raised, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figure does not effectively represent the schematic of the forward prediction model and that it is difficult to connect the text, figure, and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, and specifically mentions that Figure 2(b) does not effectively represent the schematic of the forward prediction model. The reviewer suggests that the figure should be redrawn to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim that the figure is not effective or how it could be improved. The suggestion to redraw the figure provides a direction for improvement but does not offer a comprehensive explanation or justification for the need for revision. Therefore, the comment is 3, as it provides a basis for improvement but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, noting that Figure 2(b) does not effectively represent the schematic of the model. It also points out that the connection between the text, figure, and equations is difficult to follow. This feedback is clear and actionable, as it provides specific suggestions for improvement, such as redrawing the figure to enhance clarity. By highlighting these areas for improvement, the comment offers valuable guidance that can help the authors enhance the clarity and effectiveness of their draft. However, it could be more helpful if it provided additional suggestions or examples of how to improve the representation of the forwardprediction model. Overall, the comment is 4, as it directs the authors to a specific area needing attention and provides a clear path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their baseline. The action is implicit and vague, as the authors are left to infer that they need to provide a stronger baseline or address the issue of rewardless actions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This feedback is fully grounded as it explicitly mentions \"RBI\" and \"rewardless actions,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the training process and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment lacks specific examples or detailed reasoning to support the claim that ignoring rewardless actions is a critical factor. The suggestion to provide a stronger baseline is a logical response but does not directly address the initial claim. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a specific concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This observation suggests that this oversight could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer questions whether this is the case and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. This feedback is clear and actionable, as it identifies a potential weakness in the current experimental setup and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or enhance the baseline. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the multiscale statement, suggesting that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multiscale statement or provide a more accurate explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the multiscale statement, specifically pointing out that the slow and fast RNN operate on the logical time scale rather than the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment also specifies the issue with the multiscale statement, namely the reduction in gradient path by the slow RNN. This level of detail makes the comment 5, as it clearly identifies the part of the paper being addressed and what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the multiscale statement, pointing out that the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. This feedback is 3 as it identifies a potential issue with the multiscale statement and provides a clear explanation of the problem. However, the comment could be more helpful if it suggested ways for the authors to address this issue or offered alternative explanations. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the baseline methods, noting that they are weak and do not present stateoftheart approaches. It also points out the lack of discussion on limitations and suggests that the authors address this in the conclusion. Additionally, it raises questions about the difference between the work and reinforcement learning, proposing that the conclusion should discuss the similarity and difference and the generalizability of the results to RL settings. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, suggesting they are weak and not presenting stateoftheart approaches. It also points out the lack of discussion on limitations and proposes that the authors address this in the conclusion. Additionally, it raises questions about the difference between the work and reinforcement learning, suggesting that the conclusion should discuss the similarity and difference and the generalizability of the results to RL settings. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the issues are related to the methodology and conclusion sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, such as the need for a stronger baseline, discussion of limitations, and comparison with reinforcement learning. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and do not present stateoftheart approaches, and it suggests that there is no discussion of limitations. The reviewer also raises questions about the difference between the work and reinforcement learning, proposing that the conclusion should discuss the similarity and difference and the generalizability of the results to RL settings. While the comment provides a logical basis for the claims, it lacks specific examples or references to support the assertion that the baseline methods are weak or outdated. The suggestion to discuss limitations and the proposed direction for the conclusion are reasonable but not fully substantiated by evidence or examples. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including weak baseline methods and the absence of a discussion on limitations. It also raises questions about the difference between the work and reinforcement learning, suggesting that the conclusion should address these issues. The comment provides a clear direction for improvement by recommending that the authors discuss the limitations and the generalizability of their results to RL settings. However, it could be more helpful if it offered specific suggestions or examples of how to strengthen the baseline methods or address the limitations. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear path for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It suggests that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. However, the comment does not provide specific guidance or suggestions on how the authors should address these issues or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2, and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the exponential dependence on the diameter $M$ and the weakness of the proposed approaches. The comment is specific in detailing what needs to be addressed, such as the definition of $e_l$ and the implications of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It claims that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. However, the comment lacks specific examples or references to support the claim about the exponential dependence on $M$ and the impact on the performance. While it suggests that the results may exhibit a weakness, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It points out that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their draft. While it highlights potential areas for improvement, it does not provide specific steps or examples for the authors to follow, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the potential issue of oversmoothing in addition to oversquashing and vanishing/exploding gradients, which are known issues with deep graph networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or incorporate it into their analysis. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, mentioning oversquashing, vanishing/exploding gradients, and oversmoothing as potential issues. However, it does not specify which part of the paper discusses these issues or where the authors should focus their attention. The comment lacks grounding as it does not provide explicit references to sections or figures, making it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while it mentions oversmoothing as another phenomenon, it does not provide specific details or examples of how this issue might manifest in the context of very deep graph networks. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not provide specific evidence, examples, or references to support these claims. The mention of oversmoothing as another phenomenon is not elaborated upon, leaving the authors without a clear understanding of how this issue affects their work. Without detailed reasoning or references, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning,\" which provides additional context and potential solutions. However, the comment lacks actionable guidance on how the authors might address these issues or incorporate the referenced work into their analysis. While it highlights an important area for improvement, the feedback is 3 as it points out a potential weakness but does not offer detailed suggestions for resolution. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment notes that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the problem. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the problem formulation is unclear, the comment lacks full grounding as it does not provide specific guidance on what aspects need clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the problem and how to address it. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or detailed examples, the authors are left without a clear path to improve their draft. As a result, the comment is 2, as it highlights a potential weakness but does not offer constructive advice for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and direct action for the authors to take, which is to include these experiments to enhance the paper\"s applicability and generalizability. The suggestion is concrete, as it specifies the types of models to consider, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or methodology. This makes it difficult for the authors to identify the exact section that needs attention. While the comment is specific in suggesting the need for additional experiments, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s applicability and generalizability. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It provides a clear and actionable suggestion by recommending that the authors conduct trials with models like OPT, BLOOM, or other alternatives. This feedback is valuable as it guides the authors on how to enhance the applicability and generalizability of their method. However, the comment could be more helpful if it included specific guidance on how to design and execute these experiments or if it highlighted the potential benefits of including such experiments. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also mentions that the process described in the first part does not align with the title\"s expectations, which could be computationally demanding. However, the comment does not provide specific guidance or suggestions on how the authors might strengthen the connections or address the mismatch between the title and the content. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not specify which sections or parts of the paper these connections are discussed in, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in its critique of the mismatch between the title and the content, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that they are weak. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions that the process described in the first part does not align with the title\"s expectations, but it lacks specific details or evidence to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that they are weakly connected. It provides a specific example of the author\"s initial expectations, which were not met, and notes that the process described is computationally demanding. However, the comment lacks actionable guidance or suggestions on how the authors might strengthen the connections or address the mismatch between the title and the content. While it identifies a potential issue, it does not offer concrete steps or examples for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include results for linear scalarization + Concorde for a better comparison, given that the obtained Pareto front is not highly nonconvex. This is an explicit action that the authors can take to improve their draft. The comment also provides a specific suggestion on which baseline to include, making the action concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific comparison between learningbased and heuristicbased solvers. It also references the single objective TSP and the Pareto front, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it suggests including results for linear scalarization + Concorde to provide a better comparison, given the nature of the Pareto front. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers outperform heuristicbased solvers in the experimental results, but the SOTA heuristicsolver (e.g., Concorde) usually has the best performance for single objective TSP. The reviewer suggests including results for linear scalarization + Concorde for a better comparison. This claim is 3 as it provides a logical reasoning based on the experimental results and the nature of the Pareto front. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines in the experimental results. It points out that while learningbased solvers perform better overall, the SOTA heuristicsolver (Concorde) is typically superior for single objective TSP. The comment suggests including results for linear scalarization + Concorde to provide a more comprehensive comparison, especially since the Pareto front is not highly nonconvex. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the paper\"s analysis and conclusions. However, it could be more helpful if it provided additional context or guidance on how to integrate these results into the paper. Overall, the comment is 4, as it directs the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using generalized Voronoi graphs or semantic maps, and methods that employ longterm storage through pose graphs in SLAM. While the comment implies that the authors should compare their method with these existing approaches, it does not provide explicit instructions on how to conduct this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using generalized Voronoi graphs or semantic maps, and methods that employ longterm storage through pose graphs in SLAM. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what the authors should discuss, namely, the comparison with existing methods for exploration and longterm storage. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods for exploration, such as reasoning topologically and longterm storage. The reviewer provides examples of existing methods, such as those using generalized Voronoi graphs or semantic maps, and references to the graphbased SLAM appendix section. This provides some support for the claim, making it 3. However, the comment could be strengthened by offering more detailed comparisons or specific examples of how the proposed method differs or improves upon these existing methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, noting that some of its general ideas are already present in other methods for exploration. It provides specific examples, such as reasoning topologically and longterm storage, which are captured by existing methods like generalized Voronoi graphs, semantic maps, and SLAM techniques. The comment suggests that the paper should discuss the proposed method in relation to these existing approaches, which is a constructive suggestion for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to frame the discussion or what aspects of the existing methods should be compared with the proposed method. Overall, the comment is 4 as it directs the authors to a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a suggestion for improvement or a point that needs clarification. Without any actionable advice or direction, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the consideration of finer grouping for quantization instead of pertensor and perchannel. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in questioning the choice of quantization granularity, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of pertensor and perchannel. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be beneficial or why the current approach is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the question and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of pertensor and perchannel. While it identifies a potential area for improvement, the comment lacks depth and does not provide any suggestions or reasoning to support the need for finer grouping. Without additional context or guidance, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it points out a potential area for consideration but does not offer actionable advice or insights."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples. This feedback is explicit, as it directly instructs the authors to conduct a study on the impact of the ratio of unseen classes. The comment also provides a concrete example of what aspect to investigate, making it 5. The authors know exactly what action to take and how to implement it, aligning with a score of 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes, specifically how the performance varies with different ratios of unseen classes unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors can infer that it pertains to the experimental design or results, but this inference is not explicit. The comment is specific in its suggestion to study the impact of the ratio of unseen classes, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any specific reasoning, examples, or references to support why this is important or how it could be studied. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the significance of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples, which is a relevant and actionable suggestion. This feedback encourages the authors to explore a potential area of improvement that could enhance the depth and applicability of their work. However, the comment could be more helpful if it included specific guidance on how to conduct this study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for further investigation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While the comment implies that the authors should justify their choice of architectures, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for their architectural choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, it does not specify which part of the paper discusses these architectures or where the improvements are mentioned. The authors can infer that it relates to the methodology section, but the comment lacks explicit grounding. It is specific in questioning the choice of architectures and their impact on performance, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this combination might be beneficial or why it could lead to improvements. Without additional context or explanation, the claim remains 1, as the authors are left without guidance on how to address the question or improve their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While it identifies a potential area for improvement or clarification, it lacks specific guidance or suggestions on how the authors might address this issue or justify their architectural choices. The comment provides a starting point for the authors to consider, but it does not offer detailed feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a theoretical limitation in the paper, specifically that the theory does not seem to be applicable to the used model. It also highlights the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts of graph neural networks in general. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be elaborated upon. The action is implicit and somewhat vague, as the authors can infer the need for elaboration but lack detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical limitations of the paper, specifically noting that the theory does not seem to be applicable to the used model. It also points out the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the theoretical aspects and limitations of the work. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. The specificity is clear as it identifies the theoretical limitations and suggests areas for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theory presented in the paper does not seem to be applicable to the used model, and that this limitation is not honestly mentioned in the limitations section. The reviewer also notes the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The claim is 3 as it provides a logical reasoning for the claim, suggesting that the authors should have acknowledged the theoretical limitations more explicitly. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a theoretical limitation in the paper, specifically noting that the theory does not seem to be applicable to the used model. It also points out the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts of graph neural networks in general. This feedback is 3 as it highlights specific areas where the paper could be improved, such as clarifying theoretical limitations and addressing potential societal impacts. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues or specific examples of how to elaborate on the societal impacts. Overall, the comment offers some actionable insights but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the text. As a result, the authors are left without a clear understanding of what action to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...,\" providing a clear indication of what needs to be clarified or addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilongreedy ...,\" suggesting that there might be epsilongreedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively support the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning. It suggests that the discussion is necessary and could help distinguish the paper from related work. However, the comment does not provide explicit guidance on which parts of the framework are crucial or how the discussion should be structured to achieve this distinction. The action is implicit and somewhat vague, as the authors need to infer that they should focus on clarifying the critical components and enhancing the discussion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning. It suggests that the discussion is necessary and could help distinguish the paper from related work, but it does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. The specificity is weak because it does not provide detailed guidance on what aspects of the discussion should be clarified or how to distinguish the paper from related work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning, suggesting that the discussion is necessary but lacks clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is necessary or how it could be improved. Without specific references or detailed explanations, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the critical components of the framework that utilize CLIP for weakly supervised learning, suggesting that the discussion is necessary but lacks clarity. It implies that the discussion could help distinguish the paper from related work. However, the comment does not provide specific guidance or suggestions on how to clarify the discussion or what aspects should be emphasized. While it identifies an area for improvement, the feedback lacks actionable details, making it 3. The authors can infer that they need to clarify the discussion, but the comment does not offer concrete steps or examples to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. It implies that the proposed methodology might have limited implications due to this limitation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors could address this issue or explore alternative implications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning that it might only show meaningful performance gains on bitserial accelerators. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in identifying the potential limitations and suggesting that the proposed methodology might have limited implications due to the common use of bitparallel fixedpoint numbers in existing ML accelerators. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This claim is 3 as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are not commonly used in existing ML accelerators. This observation is relevant and could prompt the authors to consider the implications of their methodology in a broader context. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or explore alternative implications. While it highlights an important consideration, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. The comment explains that the proposed approach does not improve the phenomenon of information distortion and references specific examples from Fig1(b) and Fig5(b) to illustrate the issue. Additionally, it highlights that the quantization of MHSA is not unique to the ViT model and references existing work in the NLP domain. While the comment provides specific examples and references, it does not explicitly instruct the authors on how to address these issues or improve their analysis. The feedback is detailed and informative, but the lack of explicit guidance makes it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Line 45,\" \"Fig1(b),\" and \"Fig5(b),\" allowing the authors to accurately identify the sections being addressed. It also provides specific details about the issues with the analysis of vit quantification, including the information distortion and the loss of precision introduced by quantization. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point presents a claim about the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. The comment provides specific examples from the paper, such as the comparison of values in Fig1(b) and Fig5(b), to support the claim. Additionally, it references existing work in the NLP domain to highlight that the issue is not unique to the ViT model. This provides a clear and detailed justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. It provides specific examples from the paper, such as the comparison of values in Fig1(b) and Fig5(b), to illustrate the issue. Additionally, it references existing work in the NLP domain to highlight that the issue is not unique to the ViT model. This feedback is clear and actionable, offering the authors a detailed understanding of where their analysis could be improved and how it compares to existing literature. However, the comment could be more helpful if it suggested specific ways to address these issues or provided additional guidance on how to improve the analysis. Overall, the comment is 4, as it provides valuable insights but could be further enhanced with more detailed suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness in the work, which is the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It also points out that the proposed Xtransformation is similar to STN but applied locally, and that PointNet uses a variant of STN. The comment suggests that the technical novelty is limited and that there should be empirical or conceptual comparisons to STN. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or analyses should be conducted. The action is implicit and somewhat vague, as the authors can infer the need for comparisons and novelty enhancements but lack detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the technical novelty of the work, specifically regarding the use of spatial transformer networks (STN) and the proposed Xtransformation. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture. However, the comment does not specify which part of the paper discusses STN or the proposed Xtransformation, making it weakly grounded. The comment is specific in detailing the issues with the technical novelty and the lack of comparisons to existing works, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty with respect to spatial transformer networks (STN) and does not provide comparisons to existing works that use STN. It also notes that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture. The comment provides a logical reasoning by comparing the proposed Xtransformation to STN and existing works, suggesting that the technical novelty is limited. However, it lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a main weakness in the work, specifically regarding the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty is limited. The comment also highlights the need for empirical or conceptual comparisons to STN in the work. While the comment provides clear and actionable feedback on weaknesses and areas for improvement, it could be more helpful if it offered specific suggestions or examples of how to enhance the technical novelty or comparisons. Overall, the comment is 4 as it guides the authors towards addressing critical aspects of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests correcting a labeling error in the supplementary material (Row 821, \"Fig.7\" should be \"Fig.12\") and recommends attaching proof links to each theorem and corollary in the main paper for easier reader navigation. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion. While the comment does not specify how to address these concerns, the actions are clear and concrete, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the labeling error and provides a clear suggestion for improvement. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion, which are specific to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a mix of factual statements and suggestions. The factual statements, such as the correction of a labeling error, are clear and verifiable. However, the suggestion to attach proof links to each theorem and corollary in the main paper is more subjective and lacks specific examples or references to support the claim that this would improve the paper. While the suggestion is logical, it could be strengthened with more detailed reasoning or examples to fully justify the claim. Therefore, the comment is 4, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two main points: a labeling error in the supplementary material and the need to attach proof links to theorems and corollaries in the main paper. This feedback is clear and directly addresses the authors\" need to correct an error and improve the reader\"s understanding of the paper. Additionally, the comment raises concerns about motivation, methodology soundness, and experiment persuasion, which are important aspects for the authors to consider in enhancing the paper\"s quality. While the comment does not delve into detailed suggestions for addressing these concerns, it provides a strong foundation for the authors to improve their draft. Therefore, the comment is 4, as it offers clear guidance on specific issues and areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework (Line 167174, Sec. 4) does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of feature selection need enhancement. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. Additionally, it suggests that the feature selection in Section 4.2 could be improved by considering representation learning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment identifies a potential issue with the focus of the proposed module, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of representation learning in the appendix provides some context but does not offer explicit guidance on how to address the issue. Therefore, the comment is 3, as it provides some support but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to incorporate representation learning or what specific aspects of feature selection need enhancement. The feedback is 3 as it points out a potential gap in the paper but does not provide comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify or provide more information about the design of rewards, but it does not offer concrete steps or examples of what should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights a specific area where details are missing, mentioning the lack of understanding of how to design rewards. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft lacks detail, specifically mentioning the lack of understanding of how to design rewards. This feedback is clear and actionable, as it points out a specific aspect that needs clarification or elaboration. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other studies have approached the design of rewards. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions that the experimental design is good. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment highlights a potential weakness, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The action is implicit and vague, as the authors are left to infer that they should consider code release or other means to enhance the novelty of their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the incremental nature of the work compared to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also mentions the good experimental design and raises a concern about the lack of code release, which could impact the reproducibility of the results. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in detailing the critique, it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges that the work is an incremental improvement to a KNN based MT approach, lacking significant novelty but requiring substantial engineering and execution effort. It also notes the good experimental design. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment provides some reasoning and context, it lacks specific examples or detailed explanations to fully substantiate the claim about the lack of novelty. The mention of personal execution (replicable) beating the idea (novelty) adds a subjective element, but it does not provide concrete evidence or references to support this claim. Therefore, the comment is 3, as it provides some reasoning but lacks comprehensive justification.", "helpfulness_rationale": "The review comment acknowledges that the work is an incremental improvement to a KNN based MT approach, noting that it lacks significant novelty but requires substantial engineering and execution effort. It also highlights the good experimental design. However, the comment raises a concern about the lack of code release, which could impact the reproducibility of the results. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback lacks depth and actionable advice, making it 3. The authors gain some insight into the critique but are left to infer potential improvements on their own. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. While the comment implies that the authors should address the runtime, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the runtime. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the runtime of Prithvi WxC as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need to discuss the runtime as a limitation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be placed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. This claim is 3 as it provides a logical reasoning based on the computational cheapness of MLbased emulators, which is a common characteristic of such models. However, the comment lacks specific examples or references to support the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of Prithvi WxC, specifically its runtime, which is relevant to MLbased emulators of climate model parametrizations. It suggests that the runtime should be discussed as a limitation, given the large parameter count of Prithvi WxC. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. However, the comment could be more helpful if it offered suggestions on how to discuss the runtime or provided examples of similar discussions in the literature. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contribution. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the framing are problematic or how they contribute to the paper\"s clarity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed feedback on how the framing could be improved or what aspects of the method are being oversold. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to address the issue. This lack of detail and specificity makes the comment 2, as it provides a general observation but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding. It also recommends using a notation table to clarify the use of symbols. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the generative process and the use of symbols and a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or subsection. This makes it difficult for the authors to identify the exact area needing improvement, resulting in weak grounding. The comment is specific in suggesting ways to improve the model description, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to clarify the use of symbols. While the comment provides a suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors may find it challenging to understand the exact issues without additional context or examples. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that presenting the generative process in separate steps would enhance understanding. It also recommends using a notation table to clarify the use of symbols, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided examples of how the generative process could be broken down or detailed, or if it offered specific suggestions for the notation table. Overall, the feedback is 4 as it directs the authors to improve the clarity and organization of their model description, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework to nonLLMbased models like HiTeA and InternVideo. While the comment implies that the authors should expand their analysis to include these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper discusses the FlippedQA framework or how it is currently applied to LLMbased models. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to expand the analysis to nonLLMbased models, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. The reviewer provides a logical reasoning by stating that the framework is a general approach for various generative VideoQA models, but the authors have only applied it to LLMbased models. This implies that the framework\"s applicability and effectiveness should be tested on other models as well. However, the comment lacks specific examples or references to support the claim that HiTeA and InternVideo are suitable models for this purpose. While the suggestion is reasonable, it could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s scope, suggesting that the FlippedQA framework should be further verified for its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo. This feedback is valuable as it encourages the authors to expand their analysis and consider a broader range of models, which could enhance the applicability and impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct this verification or what aspects to focus on. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not provide specific suggestions or guidance on how the authors might improve the writing. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance clarity. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are difficult to follow or provide specific suggestions for improvement. This lack of detail makes it challenging for the authors to identify the exact areas needing attention. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the writing, stating that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it does not provide specific suggestions or guidance on how the authors might improve the writing or clarify the content. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a problem but lacks actionable insights."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. The reviewer is willing to improve their score if the authors can address these concerns. While the comment implies an action, it does not provide explicit guidance on how to address the lack of theoretical novelty or what specific aspects need to be improved. The action is somewhat vague, as the authors are left to infer the exact steps needed to enhance the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical novelty of the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction or methodology sections, making it weakly grounded. The comment is specific in identifying the lack of theoretical novelty and suggesting a potential area for improvement, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method lacks significant theoretical novelty, primarily because it builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer provides references to specific works by Clopper and Pearson, as well as Golub and Van Loan, which support the claim. However, the comment could be strengthened by elaborating on how these existing methods are integrated into the proposed method and why they are considered novel. The inclusion of references provides some level of support, but the lack of detailed explanation or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination, lacking significant theoretical novelty. The reviewer is willing to improve their score if the authors can address this concern. While the comment highlights a potential weakness in the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might enhance the theoretical contribution or differentiate their work from existing methods. This limits the comment\"s helpfulness, as it does not offer actionable feedback or detailed advice for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly identifies a specific sentence in the abstract as being cumbersome and suggests that it can be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made. The authors are left with a clear understanding of what needs to be improved but are not given concrete steps on how to implement the suggested changes. Therefore, the comment is 3, as it provides a direct action but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 1217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, which is its cumbersome nature and suggests that it can be made clearer. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning, examples, or references to support why the sentence is cumbersome or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the abstract, noting that the sentence in lines 1217 is cumbersome and suggesting that it can be made clearer. While the comment highlights a potential problem, it does not provide any guidance on how to improve the clarity or what specific changes should be made. This lack of actionable advice limits the usefulness of the feedback, making it 3. The authors are aware of the issue but are left without clear instructions on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also highlights that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy. The comment concludes by recommending that the authors address these issues and continue their work for future submission. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance comparison of the proposed approach with Decouple Kang et al. and highlights the tradeoff between head and tail categories. It suggests that the paper is not ready for submission to ICLR due to the lack of investigation into the tradeoff for the baselines. The comment is fully grounded as it explicitly mentions \"Table 5\" and references \"Decouple Kang et al.,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as investigating the tradeoff for the baselines and suggesting a potential improvement in Decouple Kang et al.. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also suggests that the tradeoff between head and tail categories has not been fully investigated for the baselines, and provides a specific example of how Decouple Kang et al. could improve tail accuracy. However, the comment lacks detailed evidence or specific examples to fully substantiate the claim about the proposed approach\"s performance. While the suggestion to investigate the tradeoff for the baselines is logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s performance, noting that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to address these issues and continue their work for future submission. This feedback is valuable as it highlights specific areas for enhancement and offers a concrete direction for the authors to improve their draft. However, the comment could be more helpful if it provided additional guidance or examples on how to investigate the tradeoff for the baselines. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional scenarios, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the reliance on 4 OCR QA datasets and the need for more scenarios like the LLaVA benchmark. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the limited evaluation and suggests including more scenarios for ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. The claim is 3 as it points out a specific limitation in the evaluation and suggests a potential improvement. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide more context or evidence to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, specifically noting that it relies heavily on 4 OCR QA datasets and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This feedback is 3 as it points out a potential weakness in the current evaluation methodology and provides a clear suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to incorporate additional scenarios or benchmarks or detailed examples of what these scenarios might look like. Overall, the comment provides a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, noting that they are unintuitive and difficult to solve. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not specify which part of the paper these tasks are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the tasks are problematic or how they could be simplified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment lacks specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. The comment also seeks clarification on whether the current formulation is the best approach. While it identifies potential issues, the feedback lacks specific suggestions or actionable steps for the authors to address these concerns. The comment provides a starting point for reflection but does not offer detailed guidance on how to improve the draft. Therefore, it is 3, as it prompts the authors to consider alternative approaches but does not fully support them in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide concrete steps to enhance the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that weak supervision could be better evaluated by questioning the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" This provides a clear and detailed justification for the claim, making it 5. The authors can easily understand the basis of the critique and the need for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, suggesting that the authors should consider the realism of the evaluated tweets. It provides detailed examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"author embeddings initialized by averaging the corresponding artificial tweets.\" This feedback is clear and actionable, offering the authors a concrete direction for enhancing the evaluation of weak supervision. However, the comment could be more helpful if it suggested specific ways to assess the realism of the tweets or provided examples of more realistic scenarios. Overall, the comment is 4 as it provides valuable insights for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or examples of what specific visualizations or comparisons are missing, leaving the authors without a clear understanding of how to improve this aspect of their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for more visualization, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, noting the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending specific types of visualizations or comparisons that could be included. Without actionable advice or examples, the comment is vague and does not offer the authors a clear path to improvement. Therefore, it is 2, as it highlights a potential weakness but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is necessary to make changes. As a result, the authors are left without a clear understanding of what steps to take in response to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a large number of discourse relations in the treebank and suggests that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. This feedback is 3 as it prompts the authors to consider whether their classification criteria are consistent with other languages in the Universal Dependencies (UD) project. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or whether it is necessary to make changes. To be more helpful, the comment could provide additional context or examples to support the claim or offer potential solutions for addressing the identified concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the current state of output quality, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, setting a higher standard. The reviewer suggests that there is room for improvement in result quality. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the output quality or address the limitations of novelty, low resolution, and hardware requirements. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, setting a higher standard. The reviewer suggests that there is room for improvement in result quality. However, the comment does not specify which part of the paper discusses the output quality or the results, making it weakly grounded. The feedback is specific in identifying the need for improvement in result quality, but without clear grounding, the authors may struggle to pinpoint where to make changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive quality. The reviewer suggests that the bar for result quality has become higher and that there is room for improvement. However, the comment lacks specific examples or detailed reasoning to support the claim that the output quality is not realistic or how it compares to recent GAN works. Without explicit references or detailed analysis, the claim is 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive quality. It suggests that there is room for improvement in result quality, which is a valid observation. However, the comment lacks specific suggestions or actionable feedback on how the authors might enhance the output quality or address the limitations of novelty, low resolution, and hardware requirements. While it identifies areas for improvement, the comment does not provide detailed guidance or examples, making it 3. The authors gain some insight into potential weaknesses but are left without clear steps to address them. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to extend the curve. The action is implicit and somewhat vague, as the authors need to infer the need for further analysis and experimentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the results, particularly the use of soft labels in relation to CRM and Cross entropy. It mentions the iNaturalist19 dataset and suggests that a higher beta value might be more effective, implying that the authors should extend the curve further. However, the comment does not explicitly mention which part of the paper this discussion pertains to, such as specific figures or sections. While the authors can infer that it relates to the results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue with the hyperparameters and suggesting an extension of the curve, making it specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. However, the comment lacks specific evidence or detailed reasoning to support the claim that the hyperparameters are subpar or why extending the curve would be beneficial. The suggestion to extend the curve is not fully justified, as it does not provide a clear rationale or examples of how this would improve the results. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in the context of CRM and Cross entropy, suggesting that the results may be impressive but are based on subpar hyperparameters. It implies that the authors should extend the curve further, particularly for iNaturalist19, where a higher beta value might be more effective. While the comment identifies a potential issue with the hyperparameters, it lacks specific guidance or suggestions on how the authors might address this concern or improve their results. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the number of images in the VioT dataset, suggesting that it may be insufficient to validate the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting additional data collection or analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifying that it consists of 20 images in each of the 4 categories. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify what aspect of the dataset is problematic or how the number of images affects the validity of the approach. The comment is specific in identifying the dataset size as an issue, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may affect the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the VioT dataset, noting that it consists of only 20 images in each of the four categories. This observation is relevant as it questions the sufficiency of the dataset to validate the approach. However, the comment lacks specific guidance or suggestions on how the authors might address this concern, such as whether additional data collection is necessary or how the dataset\"s limitations might affect the results. While it highlights an important consideration, the feedback is incomplete and does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an ablation study on the number of layers and performance, which is a concrete and explicit action for the authors to consider. The response from the authors indicates that they have revised their score upward, likely due to the authors\" agreement to make the content more specific to NER. This feedback provides clear guidance on what the authors should do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment suggests an ablation study on the number of layers and performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors can infer that it pertains to the experimental results or methodology, but this inference is not explicit. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an ablation study on the number of layers and performance, which is a suggestion for further exploration. The response from the authors indicates that they have revised their score upward, presumably due to the authors\" agreement to make the content more specific to NER. However, the original comment does not provide any justification or reasoning for why an ablation study on the number of layers and performance would be interesting or beneficial. Without additional context or explanation, the claim is not 5, as it lacks the necessary support to understand the rationale behind the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests an ablation study on the number of layers and performance, which is a specific and actionable suggestion for the authors to consider. This feedback provides a clear direction for enhancing the depth and comprehensiveness of the experimental analysis, potentially leading to a more robust understanding of the model\"s performance. The response from the authors indicates that they have revised their score upward, likely due to the authors\" agreement to make the content more specific to NER. This feedback is 4 as it offers a concrete suggestion for improvement, but it could be more helpful if it included additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment provides valuable insights that can guide the authors in enhancing their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and that figure captions should include additional explanations and legends, such as explaining the colors in Figure 2. However, the comment does not provide specific guidance on how to improve the mathematical derivations or the figure captions, nor does it offer concrete examples of what kind of explanations would be more intuitive. The authors are left with a general understanding of what needs to be improved but without clear instructions on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the difficulty in following the paper and suggests improvements in the mathematical derivations and figure captions. It specifically mentions Figure 2, indicating that the authors can identify the part of the paper being discussed. However, it does not specify which sections of the paper are hard to follow or what specific aspects need improvement. The comment is specific in its suggestions for improving the figure captions, but it lacks full grounding as it does not clearly identify all parts of the paper that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations on mathematical derivations are needed. It also points out the lack of explanations in figure captions, such as the colors in Figure 2. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that the paper is hard to follow and suggesting that more intuitive explanations on mathematical derivations are needed. It also points out the lack of explanations in figure captions, such as the colors in Figure 2, and notes that Figures 1 and 2 did not contribute much to the understanding of the paper. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to enhance the clarity and intuitiveness of the mathematical derivations or figure captions. The authors are left with a general understanding of what needs to be addressed but without detailed instructions on how to implement these changes. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices and emphasizes the importance of addressing this issue. It suggests that the authors should consider this aspect and potentially revisit the rating if the issue is resolved. While the comment highlights a critical area for improvement, it does not provide explicit guidance on how to address the sensitivity or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the sensitivity of their results and potentially revise their rating. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the sensitivity of the empirical results to hyperparameter choices, which is a critical aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the importance of addressing this issue, as it could potentially undermine the method\"s effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a valid concern in any study. However, the comment does not provide specific examples or detailed reasoning to support why this issue is particularly critical or how it could affect the study\"s conclusions. The mention of \"conceivably\" suggests that the reviewer is speculating on the potential impact, which makes the claim 3. The authors would need to provide more detailed evidence or examples to fully address this concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an important concern about the sensitivity of the empirical results to hyperparameter choices, which is a critical aspect in any study. It highlights the potential impact of incorrect hyperparameter choices on the study\"s conclusions, emphasizing the need for thorough investigation. The comment is specific in its suggestion that the authors should address this issue and potentially reconsider the rating if it is resolved. This feedback is actionable and provides clear guidance for the authors to improve their draft by ensuring robustness in their experimental setup. However, the comment could be more helpful if it offered suggestions on how to assess and mitigate the sensitivity of the results to hyperparameters. Overall, the comment is 4, as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to clarify the novelty and contribution of their proposed method by addressing the similarity to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of the novelty, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of existing attack methods on a surrogate model and suggests that the novelty and contribution of the proposed method should be clarified. However, it does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion to clarify the novelty, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that the novelty and contribution of the proposed method should be clarified. However, the comment does not provide specific examples or references to existing work that the authors should compare their method against. This lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the claim is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model. It suggests that the authors need to clarify the novelty and contribution of their work by addressing the similarity to existing methods. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might differentiate their work or enhance its novelty. The feedback is 3 as it points out a potential weakness but does not provide detailed advice on how to address it, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate comments. The first comment explicitly states that the text in Table 1 is too small and hard to read, providing a clear and direct action for the authors to take. The second comment mentions a missing gradient symbol in Algorithm 1, which is also an explicit action. Additionally, the comment provides references to external works, which can guide the authors in understanding the context or potential improvements. Both actions are concrete and provide specific guidance on what needs to be addressed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the small text in Table 1 and the missing gradient symbol in Algorithm 1. The references to external works are specific, providing the authors with concrete examples to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate comments. The first comment is a factual observation about the readability of text in Table 1, which is a descriptive statement and does not contain a claim or suggestion that requires verification. The second comment mentions a missing gradient symbol in Algorithm 1, which is also a factual observation. Therefore, the overall comment is composed of factual statements, making it \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the draft: the small text in Table 1, which makes it difficult to read, and the missing gradient symbol in Algorithm 1. These are clear and actionable points that provide the authors with specific areas to address, such as improving the legibility of the table or ensuring all necessary symbols are included in the algorithm. However, the comment could be more helpful if it offered suggestions on how to improve the readability of the table or how to incorporate the missing symbol. Overall, the feedback is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of discussion on computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to discuss computational aspects more thoroughly, possibly including methods to handle highdimensional data or alternative approaches. However, the comment lacks concrete details on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects, specifically mentioning the appendix and the experiments performed on smallscale datasets. However, it does not explicitly mention which sections of the paper discuss computational aspects, making it weakly grounded. The comment is specific in detailing the issue with the proposed methods being impractical for highdimensional data due to the complexity of solving LPs and the difficulty in calculating parameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly regarding the practicality of their methods for highdimensional data. It highlights that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. The claim is 3 as it provides a logical reasoning based on the complexity of the algorithm and the scale of the experiments. However, it lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s discussion of computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. This feedback is valuable as it highlights a critical area that needs attention, namely the scalability and practical applicability of the proposed methods. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as discussing potential computational optimizations or alternative approaches to handle highdimensional data. Overall, the comment is 3 as it points out a significant weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It also suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison, as it would be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this alternative baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the ResNet in the experiments shares parameters between residual blocks and suggests an alternative baseline by comparing to a deeper ResNet with parameter sharing. This comparison is relevant to the discussion of ODE nets with a fixed timestep Euler integrator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the parameter sharing in the ResNet experiments in section 7.1 and suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a relevant or interesting comparison. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the parameter sharing in the ResNet experiments in section 7.1 and suggests that a deeper ResNet with parameter sharing could serve as an interesting baseline for comparison. This comparison is relevant because it would be equivalent to an ODE net with a fixed timestep Euler integrator. By pointing out this potential baseline, the comment provides a clear and actionable suggestion for the authors to consider, which could enhance the comprehensiveness of their experimental setup. However, the comment could be more helpful if it included specific details on how to implement this comparison or why it would be beneficial. Overall, the feedback is 4 as it offers a constructive suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the motivation are unclear or need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point challenges the claim that the crossencoder architecture \"ignores crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. It provides a counterpoint by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support the claim that the architecture is not as finegrained as implied. This makes the claim 3, as it provides a logical argument but requires more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores, which is a significant point of clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their motivation or clarify their claims. While it identifies a critical area for improvement, it does not offer actionable feedback or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an odd design choice of trimming questions after the first 10, given that the question model is a bag of words and encoding longer sequences is not expensive. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design choice. The comment lacks actionable guidance, leaving the authors without a clear direction for revising their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the design choice of trimming questions after the first 10, noting that it seems odd given the nature of the question model. The comment provides a clear rationale for this concern, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and encoding longer sequences is not expensive. The reviewer provides a logical reasoning by pointing out the inconsistency between the design choice and the nature of the question model. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact reasoning behind the concern, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the design choice of trimming questions after the first 10, noting that the question model is a bag of words and encoding longer sequences is not expensive. This observation raises a valid concern about the efficiency and effectiveness of the design. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their design choice. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, the comment is 3, as it points out a potential area for concern but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work uses an antiquated GNN model and method, which impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or methods, nor are there suggestions for alternative approaches or references to more recent work. As a result, the authors are left without any actionable steps to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an antiquated GNN model and method, as well as the antiquated baseline algorithms/methods. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what specific aspects of the model or methods are outdated or how they impact the performance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an antiquated GNN model and method, which impacts the performance of the framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to more recent and effective models, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which is likely to impact the performance of the framework. It also points out that the baseline algorithms/methods are also antiquated. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations for improvement, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it highlights a concern but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should provide more detailed explanations or clarify the method\"s workings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanation in Figure 1, questioning the clarity of how the proposed method produces the explanation and suggesting the need for additional adhoc postanalysis to extract shared motifs. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \"mutagens contain the NO2 group.\" It suggests that additional adhoc postanalysis might be necessary to extract shared motifs to explain a set of instances. While the comment provides a logical reasoning for the need for additional analysis, it lacks specific examples or references to support the claim that the analysis is easier with the proposed method. This makes the claim 3, as it provides a basis for the concern but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, questioning the clarity of the explanation provided. It points out that the explanation seems to require additional adhoc postanalysis to extract shared motifs for a set of instances. This feedback is clear and actionable, as it directs the authors to clarify the explanation in Figure 1 and potentially provide more detailed analysis. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided examples of how the analysis could be simplified. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the absence of true feature importance. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The reviewer provides a specific suggestion to strengthen the experiment by considering the difference in the number of perturbations. However, the comment does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors know what needs to be done but may not have a clear idea of how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment\" and \"Prop 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the reliance on pseudo feature importance and the difficulty in judging the experiment\"s trustworthiness due to the small difference between the tested method and the pseudo feature importance. The comment provides clear guidance on how to strengthen the experiment, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiment\"s reliance on pseudo feature importance due to the absence of true feature importance makes it difficult to judge the experiment\"s trustworthiness. The reviewer supports this claim by referencing \"Prop 3.2\" and suggesting that a large enough perturbation value is needed for the pseudo feature importance to be correct. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the suggestion to strengthen the experiment by considering the difference in the number of perturbations is a logical step, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment, noting that the reliance on pseudo feature importance due to the absence of true feature importance makes it difficult to judge the experiment\"s trustworthiness. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The comment provides clear and actionable feedback, offering a specific direction for improvement by considering the difference in the number of perturbations. This guidance empowers the authors to enhance the robustness and credibility of their experimental results. However, the comment could be more helpful if it included additional suggestions or examples to further clarify the improvements needed. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct the color of two lines in the supplementary material, specifying that they should be in green. It provides specific references to the lines in question, such as L502, L507, and L509, and indicates the corresponding sections or elements, such as SuppMat, Table 4, and Algorithm 1. This level of detail and specificity makes it clear and actionable for the authors to make the necessary changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and references, such as L502, L507, and L509, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be corrected, namely the color of the lines, which should be changed from red to green. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a factual statement about the need to correct the color of specific lines in the supplementary material. It provides explicit references to the lines in question, such as L502, L507, and L509, and specifies the changes needed, such as changing the color from red to green. This level of detail and specificity makes the claim 5, as it provides clear guidance on what needs to be corrected. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback by identifying errors in the color of lines in the supplementary material. It clearly specifies the lines that need to be corrected, such as L502, L507, and L509, and indicates the corresponding sections or elements, such as SuppMat, Table 4, and Algorithm 1. This level of detail and specificity empowers the authors to make the necessary corrections, ensuring that their draft is accurate and consistent. The feedback is clear and actionable, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide explicit guidance on how to conduct such an analysis or what specific aspects should be addressed. The comment acknowledges that this is a short paper, implying that the authors may not have the space to include such an analysis, but it does not offer concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of how to address this feedback, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what specific aspects of the analysis would be beneficial. The authors cannot confidently determine which part of the paper the comment addresses, nor do they have a clear idea of what needs to be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment acknowledges that the paper is short, which may limit the inclusion of such an analysis, but it does not offer a detailed explanation or justification for why this is a significant improvement. As a result, the claim is 1, as it lacks the necessary evidence or reasoning to support the suggestion.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it acknowledges that this is a short paper, implying that the authors may not have the space to include such an analysis. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might address this issue within the constraints of a short paper. As a result, the feedback is 3, as it points out a potential area for enhancement but does not offer detailed suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include a deeper connection to metalearning and cite relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. While the comment implies that the authors should take these actions, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. However, the comment does not specify which part of the paper should be revised or how the authors should incorporate these suggestions. The authors can infer that it pertains to the discussion or literature review sections, but the lack of explicit grounding makes it difficult to pinpoint the exact sections needing attention. The comment is specific in its suggestions but not fully grounded, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. The comment provides a logical reasoning by suggesting that these connections could enhance the paper\"s depth and relevance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to explore the suggested connections themselves to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that there is a deeper connection to metalearning, which has several approaches. It recommends citing relevant works that do not directly target continual learning but are still relevant, and it suggests linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s depth and relevance. By following these suggestions, the authors can significantly improve their draft. However, the comment could be more helpful if it included specific examples of relevant metalearning works or detailed guidance on how to integrate these connections into the paper. Overall, the comment is 4, as it offers valuable insights and actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback. It suggests that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect a reallife situation. While the comment implies an action\u2014exploring different types of feedback\u2014it does not provide explicit instructions on how to implement this suggestion. The authors are left to infer that they should consider generating diverse feedback, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to explore different types of feedback to better reflect a reallife situation, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect a reallife situation. However, the comment does not provide specific examples or references to support the claim that the diversity is lacking. The suggestion to explore different types of feedback is a logical response to the concern, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect a reallife situation. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the diversity of feedback. However, it could be more helpful if it included specific examples or suggestions on how to generate diverse feedback. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. It also includes a question, which is an explicit request for clarification. However, the comment does not provide specific guidance on how to summarize the results or what aspects should be emphasized. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. However, it does not specify which part of the main text should be revised or how the additional experiments should be summarized. The authors can infer that the comment pertains to the main text, but the lack of specific guidance makes it difficult to pinpoint the exact sections needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a request for clarification regarding the presence of additional experiments in the supplement and a question about summarizing their results. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the main text, suggesting that it should clarify the presence of additional experiments in the supplement and ideally summarize their results. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to summarize the results or what aspects of the additional experiments should be highlighted. Overall, the comment is 4 as it directs the authors to an area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 and the claim about the effectiveness of the proposed prompts across various language pairs and domains. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to strengthen their claim. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the slight improvement observed in ChatGPT compared to ChatGPT+DSP and the claim about the effectiveness of the proposed prompts across various language pairs and domains. This provides clear guidance on what needs to be addressed in the tables to support the claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 does not support the claim about the effectiveness of the proposed prompts across various language pairs and domains. However, the comment lacks specific reasoning or evidence to substantiate this claim. It does not provide examples or detailed analysis to explain why the slight improvement is insufficient to validate the claim. Without additional context or justification, the claim remains 1, as it does not offer a clear path for the authors to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 and the claim about the effectiveness of the proposed prompts across various language pairs and domains. This feedback is 3 as it points out a potential issue that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this discrepancy or strengthen their claim. Without additional context or actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis of the Cycle FC align feature is insufficient and implies that there could be various designs of this feature. It provides a specific suggestion by mentioning experiments or analysis with different sampling intervals and sample sizes. However, the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to improve the analysis. While the action is implied, it lacks concrete details on how to implement the suggested changes, making it 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the Cycle FC align feature, suggesting that it is insufficient and could be improved with different designs. However, it does not specify which part of the paper this analysis is in, making it weakly grounded. The comment is specific in suggesting that experiments or analysis with different sampling intervals and sample sizes could be conducted to enhance the analysis. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the Cycle FC align feature is insufficient and implies that there could be various designs of this feature. However, it does not provide specific examples or references to support the claim that the analysis is insufficient or how different designs could improve it. The mention of experiments with different sampling intervals and sample sizes is a suggestion for improvement but lacks detailed justification or evidence. Therefore, the comment is 3, as it provides a general direction for improvement but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the analysis of the Cycle FC align feature, suggesting that the analysis could be more comprehensive by exploring different designs. It provides a specific suggestion by mentioning experiments with different sampling intervals and sample sizes, which could enhance the analysis. However, the comment lacks depth and does not offer detailed guidance on how to conduct these experiments or what specific aspects of the analysis could be improved. While it points out a potential area for enhancement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the absence of standard deviations in the paper makes it difficult to assess the reliability of the results. It questions whether the best method is truly the best or if other Random Forest (RF) configurations have performances close to it. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or alternative ways to present the data. The action is implicit and vague, as the authors are left to infer that they should include standard deviations but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which makes it difficult to assess the reliability of the results. It questions whether the best method is truly the best or if other Random Forest configurations have performances close to it. However, the comment does not specify which part of the paper lacks standard deviations, making it weakly grounded. The authors can infer that it relates to the results section or figures, but this is not explicitly mentioned. The comment is specific in its critique of the lack of standard deviations, which is a clear issue that needs addressing. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper makes it difficult to assess the reliability of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the absence of standard deviations in the results section. This omission makes it difficult for readers to assess the reliability and robustness of the findings, as it does not provide a measure of variability or confidence in the results. The comment highlights a potential limitation that could impact the interpretation and generalizability of the study. However, it does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of standard deviations or alternative ways to present the data. While it points out a significant gap, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is explicit in its request for clarification regarding the feature extractor used for the dimensionality of each region, which is specified as 512. This is a clear and direct action for the authors to take, as it prompts them to provide the specific feature extractor used in their work. The comment is concrete, as it specifies exactly what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the feature extractor used for the dimensionality of each region, which is specified as 512. This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement seeking clarification about the feature extractor used for a specific dimensionality. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is clear and actionable, seeking clarification on the feature extractor used for the dimensionality of each region, which is specified as 512. This is a specific and direct request for additional information that can help the authors improve the clarity and completeness of their draft. By addressing this question, the authors can provide more detailed information about their methodology, which is beneficial for enhancing the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how the authors might incorporate this information into their paper or discussed the implications of using a specific feature extractor. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add these details but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper lacks these details or where they should be included. This makes it difficult for the authors to identify the exact sections that need revision. The comment is 1 because it does not reference specific parts of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not provide any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While this is a valid suggestion, it lacks specificity and does not offer actionable guidance on how to include these details or where they should be placed in the paper. Without further elaboration, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks the authors to explain how they chose the value p < 0.4 in Algorithm 1. This is a direct and explicit request for clarification, providing the authors with a clear action to take. The comment is specific in its request, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for an explanation of how the value p < 0.4 was chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a direct request for clarification regarding the choice of p < 0.4 in Algorithm 1. It does not provide any feedback or suggestions on how this choice might impact the results or the overall methodology. While it identifies a specific area that needs further explanation, it lacks depth and actionable guidance for the authors to improve their draft. Therefore, it is 2, as it provides a clear question but does not offer insights or suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It also suggests references for further reading. While the comment provides explicit actions for the authors to take, such as conducting additional analysis and comparing their approach to others, it does not offer concrete guidance on how to implement these actions. The authors are left with a clear direction but without detailed instructions on how to execute the suggested improvements. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment highlights two specific areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It also suggests references for further reading. However, the comment does not specify which part of the paper these issues are addressed in, making it weakly grounded. The authors can infer that these issues pertain to the analysis section or the discussion of data augmentation methods, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as the need for analysis and comparison to other methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the effectiveness of each data augmentation method is insufficient and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to support the claim, such as 1 and 2, which are relevant to the topic of language models and paraphrasing. However, the comment does not fully explain why these comparisons are necessary or how they would enhance the analysis. While the references provide some support, the lack of detailed reasoning or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the proposed method. Additionally, the comment provides references to relevant literature, which can guide the authors in expanding their analysis and understanding of the topic. This feedback is clear and actionable, offering specific suggestions for improvement that can enhance the paper\"s depth and contribution. However, it could be more helpful if it included more detailed guidance on how to conduct the analysis or what specific aspects to focus on when comparing the methods. Overall, the comment is 4, as it provides valuable insights and suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what implications it might have for the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario in their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the experimental results or discussion of negative samples. While the comment is specific in its question, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how to address this question or what implications it might have for the paper. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it identifies a potential area for exploration but does not offer actionable insights or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the scalability of RLCD compared to RLAIF, specifically mentioning the advantage of RLCD shrinking as the language model size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve the scalability of RLCD. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the comparison between RLCD and RLAIF, specifically mentioning Tab. 2, which indicates full grounding as the authors can accurately identify the part of the paper being discussed. The comment also specifies the issue by noting that the advantage of RLCD over RLAIF diminishes as the language model size increases, and it questions whether RLCD can scale to even larger models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the language model size increases, specifically mentioning Tab. 2. However, the comment lacks detailed reasoning or evidence to support this claim, such as specific data or analysis from Tab. 2. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment highlights a potential issue with the scalability of RLCD compared to RLAIF, specifically mentioning that the advantage of RLCD diminishes as the language model size increases. It also raises a question about whether RLCD can scale to even larger language models. This feedback is 3 as it identifies a potential limitation in the scalability of the proposed method, which could be an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of RLCD. Without actionable advice or detailed recommendations, the feedback is incomplete, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. This feedback is clear and direct, providing the authors with a specific action to take: conducting a quantitative analysis to support their claims. The comment also offers concrete suggestions on what aspects to measure, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the claim of computational benefits from replacing the MAE model with a CNNbased data augmentation strategy. It also specifies what is missing, namely, the need for measurements like GPU hours, memory usage, or training time to substantiate these claims. This provides clear guidance on where the authors need to focus their efforts to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time to substantiate the efficiency improvements claimed by the paper. The comment provides a clear rationale for why such measurements are important, as they would provide stronger evidence of the efficiency improvements. However, the comment could be strengthened by including specific examples or references to similar studies that have conducted such analyses. Overall, the claim is 4 as it offers a logical reasoning for the need for quantitative analysis, but it could be more robust with additional supporting evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by pointing out the lack of quantitative measurements to substantiate the claimed computational gains from replacing the MAE model with a CNNbased data augmentation strategy. It provides a clear and actionable suggestion by recommending the inclusion of specific measurements, such as GPU hours, memory usage, or training time, to support the efficiency improvements claimed in DQ V2. This feedback is 5 as it guides the authors on how to strengthen their claims and provides a concrete path for improving the paper\"s rigor and verifiability. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, implying that the method is less efficient for these scenes. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the time factor in their comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of methods, specifically mentioning COLMAP and scenebyscene finetuning. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the time taken for these processes should be considered when comparing methods, indicating what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the time taken for COLMAP and scenebyscene finetuning should be considered when comparing methods, suggesting that the method is less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, specifically mentioning the time taken for COLMAP and scenebyscene finetuning. It suggests that this time factor should be considered when comparing methods, implying that the method may be less efficient for these scenes. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it points out a relevant aspect, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as the authors are left to infer that they should consider reporting results during learning or exploring the impact of early training. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the reporting of results and the potential impact of early training, but it lacks grounding as it does not reference specific sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The suggestion is purely speculative, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the reporting of results only after a significant amount of training, suggesting that the agent\"s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. This feedback is 3 as it points out a potential area for improvement in the paper\"s methodology or results presentation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes they should consider. While it highlights an important aspect, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the contribution of the paper may be marginal because the methods used are welldesigned and demonstrated. It questions the necessity of adding another stream for lowresolution data, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors could address this concern or improve their contribution. The action is implicit and vague, as the authors are left to infer that they might need to reconsider the contribution or provide a stronger argument for its significance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper may be marginal because the methods used are welldesigned and demonstrated. It questions the necessity of adding another stream for lowresolution data, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methods section, or results. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed feedback on how the contribution could be improved or what aspects of the methods could be further developed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used are welldesigned and demonstrated, and adding another stream for lowresolution data might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of how the methods are welldesigned or why adding another stream would not be a significant contribution. Without detailed justification or references, the claim remains 1, making it difficult for the authors to understand and address the critique effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper may be marginal because the methods used are welldesigned and demonstrated. It questions the necessity of adding another stream for lowresolution data, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific suggestions or guidance on how the authors could address this concern or improve the contribution. While it identifies a potential issue, it does not provide actionable feedback or detailed advice on how to enhance the paper\"s contribution. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It highlights that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning, which is the DSCL part. The reviewer asks for clarification on any other motivations for PBSD. While the comment implies that the authors should provide additional context or motivation for PBSD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this question in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It references the ablation study and the paper\"s motivation, which is primarily supervised contrastive learning. However, the comment does not specify which part of the paper this discussion is related to, such as a particular section or paragraph. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the motivations for PBSD, but without explicit grounding, it is challenging for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It highlights that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning, which is the DSCL part. The reviewer asks for clarification on any other motivations for PBSD. This comment is 3 as it points out a potential inconsistency in the paper\"s motivation and suggests a need for further explanation. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component. It highlights that while the ablation study shows performance gains from PBSD, the paper is primarily motivated by supervised contrastive learning, which is the DSCL part. The reviewer asks for clarification on any other motivations for PBSD. This feedback is 3 as it identifies a potential area of confusion or lack of clarity in the paper. However, it could be more helpful if it provided specific suggestions or examples of what other motivations might be relevant for PBSD. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It specifically asks if the tester immediately yields an (\u03b5, \u03b4)identity tester and questions how it deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, and it raises a specific concern about how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, specifically asking if the tester immediately yields an (\u03b5, \u03b4)identity tester. It also questions how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential area of confusion, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a specific question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It highlights a potential gap in the paper\"s explanation, asking if the tester immediately yields an (\u03b5, \u03b4)identity tester and how it deals with specific cases involving (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between the testers and provide a detailed explanation of how the tester handles these specific cases. By addressing this question, the authors can improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 4, as it provides valuable insights for enhancing the paper\"s clarity and completeness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the clarity of the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify the distribution or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the clarity of the detailed distribution of the proposed dataset. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how they might be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the detailed distribution of the proposed dataset, which is a critical aspect of the paper. However, it lacks actionable guidance or suggestions on how the authors might clarify this distribution or improve its presentation. Without additional context or specific recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it points out a potential weakness but does not provide actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method\"s reliance on annotated labels for learning semantic tokens limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to implement this change or provide detailed guidance on how to transition to a selfsupervised approach. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for annotated labels in the proposed method, suggesting that a selfsupervised pretraining approach without annotations could be more appealing. However, it does not specify which part of the paper discusses the use of annotated labels or the proposed method. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks explicit grounding. It is specific in suggesting a potential improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method\"s reliance on annotated labels limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which is its reliance on annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is clear and actionable, as it points out a potential area for improvement and provides a specific direction for the authors to consider. By suggesting a selfsupervised approach, the comment offers a concrete way to enhance the applicability and versatility of the method. However, it could be more helpful if it included specific examples or guidance on how to implement a selfsupervised approach. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should expand their experiments to include these tasks, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional experiments, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on scalability. This makes it difficult for the authors to identify the exact section where this improvement is needed. Additionally, the comment lacks specificity in detailing what specific challenges or tasks should be addressed to demonstrate scalability. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why such tasks are important for demonstrating scalability. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks. It suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and demonstrate the broader applicability of their method. However, the comment could be more helpful if it included suggestions on how to design or conduct these experiments or if it provided examples of existing methods that have successfully addressed similar challenges. Overall, the comment is 4 as it guides the authors towards a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any explicit or implicit actions for the authors to take regarding these references. There is no guidance on how the authors should incorporate these references into their paper or what specific aspects of their work should be compared or discussed with these references. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of how to address the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions specific references, such as MISA, M2FNet, and MMDFN, which provides some grounding as it allows the authors to identify the context of the discussion. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or paragraph. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline for crosssensory interaction, but it does not provide specific details on why this is problematic or how the authors might address this issue. Therefore, the comment is weakly grounded because it does not explicitly mention a specific part of the paper, and it is not specific about the issue being addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered out of fashion. However, the comment does not provide any specific evidence or reasoning to support this claim. It lacks detailed references or examples to substantiate the assertion that MULT is outdated or out of fashion. Without additional context or justification, the claim remains 1, as it does not provide the authors with a clear understanding of why MULT is considered outdated or how it compares to other works in the field. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any specific feedback or suggestions on how the authors might incorporate these references into their paper or what aspects of their work should be compared or discussed with these references. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline for crosssensory interaction, but it does not provide specific details on why this is problematic or how the authors might address this issue. Without actionable guidance or detailed feedback, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a major issue with the comparison against other models in the experiments, specifically noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It explicitly instructs the authors to compare the tensor completion results for all models while ensuring that they have the same number of model parameters. The reviewer provides a specific suggestion to compute the number of model parameters by adding the number of entries of all core tensors for each model. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the value of the used ranks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, noting that the ranks are omitted, which makes it impossible to conduct a fair comparison. The comment further provides a concrete suggestion for improvement by instructing the authors to compare tensor completion results for all models with the same number of model parameters. This detailed guidance ensures that the authors know exactly what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all models. The reviewer suggests that this makes it impossible to conduct a fair comparison. The comment provides a specific suggestion for improvement, which is to compare the tensor completion results for all models while ensuring they have the same number of model parameters. This is a logical and reasonable suggestion that would help clarify the comparison. However, the comment could be strengthened by providing examples or references to support the claim about the importance of ranks in tensor completion or by explaining why having the same number of model parameters is crucial for a fair comparison. Despite this, the feedback is 4, as it offers a clear direction for improvement based on logical reasoning and a specific suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the comparison against other models in the experiments. It points out that the omission of the value of the used ranks for all models makes it impossible to conduct a fair comparison. The reviewer provides a clear and actionable suggestion for improvement, instructing the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. This feedback is detailed and provides a concrete path for the authors to enhance the clarity and fairness of their experimental comparisons. By offering specific guidance on how to address the issue, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module, suggesting that it appears different in the two versions but seems to be the same based on the text. It also recommends standardizing pictograms and addressing a minor issue with Fig. 4 regarding symbol overlap in the 0/50 latency range. Additionally, it mentions a minor problem with the text on page 4 after the equation. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to resolve these concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures,\" \"Fig. 4,\" and \"page 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the normalization module, pictograms, and the 0/50 latency range in Fig. 4. The comment is specific in detailing what needs to be addressed, such as the need for standardization of pictograms and clarification of the chosen symbols. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the normalization module and the pictograms in Fig. 4, suggesting that they appear different but seem the same based on the text. It also notes a minor problem with the text on page 4 after the equation. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The mention of \"Fig. 4\" provides some context, but the lack of detailed feedback or references limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including concerns about the normalization module and the pictograms in Fig. 4. It suggests that the normalization module appears different in the two versions but seems the same based on the text, and recommends standardizing the pictograms. Additionally, it points out a minor problem with Fig. 4 regarding symbol overlap in the 0/50 latency range. The comment also mentions a minor issue with the text on page 4 after the equation. While the feedback is specific and highlights areas for improvement, it could be more helpful if it provided suggestions on how to address these issues or offered alternative solutions. Overall, the comment is 4 as it provides clear guidance on what needs attention, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide explicit guidance on how the authors should address this issue or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"observation\" and the \"theoretical part\" of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the lack of detail on how the proposed algorithm removes subdivision splines and whether it incurs extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific examples or references to support the claim that the algorithm lacks detail or incurs extra computation cost. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional details are needed. The feedback is 3 as it highlights an area that requires further clarification, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the same procedure is used as was used for baselines, noting that most baselines do not use this dataset. The reviewer suggests that this could provide an unfair advantage to the proposed method if it is used in all experiments. While the comment highlights a potential issue, it does not explicitly instruct the authors to clarify this point or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental methodology\" and references the use of the 300WLP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the experimental methodology, particularly regarding the use of 300WLP in all experiments, which could provide an unfair advantage to the proposed method. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It questions whether the same procedure is used as was used for baselines, noting that most baselines do not use this dataset in their training. The reviewer suggests that this could provide an unfair advantage to the proposed method if it is used in all experiments. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that most baselines do not use the 300WLP dataset. This makes the claim 3, as the authors would need to investigate further to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the clarity of the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out a potential inconsistency in the claim that the same procedure is used as was used for baselines, noting that most baselines do not use this dataset. This observation is important because it could affect the fairness of the comparison between the proposed method and the baselines. The comment provides a clear and actionable suggestion for the authors to clarify whether the 300WLP dataset is used in all experiments or just some, which could significantly impact the interpretation of the results. This feedback is valuable as it helps the authors ensure the integrity of their experimental setup and the validity of their claims. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that some aspects of the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these concerns or what specific improvements might be necessary. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques or where they are applied, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of these techniques are not novel or how they could be improved. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of some aspects of the algorithm, specifically mentioning computation offloading and gradient augmentation. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve the novelty of their work. Without actionable feedback or detailed insights, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis of this training dynamics would strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in questioning the lack of analysis and suggesting that providing such analysis would strengthen the paper, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the lack of indepth analysis regarding why inverse scaling occurs over compute. It suggests that providing such analysis would significantly strengthen the paper. However, the comment does not offer specific guidance or examples on how to conduct this analysis or what aspects should be included. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully guide the authors in making the necessary improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analyses. The action is implicit and vague, as the authors are left to infer that they need to conduct more comprehensive analyses or provide a clearer explanation of their method\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the issue with the comprehensiveness of the analyses and the question regarding the performance improvement claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\" method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are not comprehensive enough. The authors are left to infer that more detailed analyses are needed, but the comment does not provide explicit guidance or evidence to substantiate this claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s experimental analysis, noting that the majority of the experiments focus on presenting results rather than comprehensively analyzing the method itself and the experimental outcomes. It highlights a potential limitation in the paper\"s claims, questioning the extent to which the performance improvement brought by the pretraining method can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. This feedback is 3 as it points out a critical area for improvement in the paper\"s analysis and raises a valid concern about the authors\" claims. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or enhance their analysis. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might expand the scope of their work or what specific aspects they should consider to enhance the applicability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this critique pertains to, such as a particular section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s focus on explaining multitask models limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the paper\"s focus on explaining multitask models, suggesting that this focus may limit the applicability of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the literature review ignores several papers that seem relevant, specifically mentioning VRMARINA for online problems from 1 and DASHAMVR from 2. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to include these papers in their literature review. The action is implicit and vague, as the authors are left to infer that they need to update their literature review, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the literature review ignores several papers that seem relevant, specifically mentioning VRMARINA and DASHAMVR. The comment further provides a suggestion to include these papers in the literature review, which is a clear and specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA and DASHAMVR. However, the comment does not provide specific examples or detailed reasoning to support why these papers should be included or how they relate to the current literature. The mention of \"seemed to be relevant\" lacks substantiation, making it difficult for the authors to understand the basis of the claim. Without additional context or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential oversight in the literature review, specifically mentioning that it ignores several papers that seem relevant. It provides specific examples, such as VRMARINA for online problems and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment also includes a question, suggesting that the authors should consider including these papers in their literature review. However, the comment lacks detailed guidance on how to integrate these papers or what specific aspects of the literature review should be revised. While it highlights an important area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, as it provides a clear direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions asking for additional insights into modest performance gains on the Clothing1M dataset and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While the questions provide a clear direction for the authors to explore, they do not explicitly instruct them to make specific changes or additions to their draft. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional insights or comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment consists of two questions, one asking for additional insights into modest performance gains on the Clothing1M dataset and the other asking about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are 1 as they do not specify which part of the paper they relate to, making it difficult for the authors to identify the exact sections that need attention. The questions are specific in that they request additional insights and comparisons, but without grounding, the comment remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance comparisons. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment consists of two questions that seek additional insights and performance comparisons. The first question asks for more information about modest performance gains on the Clothing1M dataset, while the second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions provide the authors with valuable feedback on areas where they can enhance their understanding and presentation of their results. However, the comment does not offer specific guidance or suggestions on how to address these questions or improve the draft. While it prompts the authors to consider additional aspects of their work, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper does not describe the hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the lack of description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the hyperparameters and evaluation methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not describe the hyperparameters used by each defense nor how they are derived. It suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This claim is 3 as it points out a specific gap in the paper\"s methodology, but it lacks detailed examples or references to support the suggestion of a maximally charitable evaluation. The authors would need to infer how this suggestion could be implemented, making the claim 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not describe the hyperparameters used by each defense nor how they are derived. This is a critical aspect of the methodology that could affect the evaluation and interpretation of the results. The comment also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and showing the amount of clean data required to remove the attack. This feedback is clear and actionable, as it provides a specific area for improvement and a method to enhance the robustness of the evaluation. However, the comment could be more helpful if it offered additional guidance on how to optimize hyperparameters or what constitutes a maximally charitable evaluation. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear direction for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment does not provide explicit guidance on how to achieve this or what additional takeaways should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more practical implications or takeaways. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and suggests that they lack immediate practical implications, which is understandable given the novelty of the work. It also mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main takeaway point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the main takeaway point, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that more takeaway points for practitioners would be beneficial, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks specific examples or references to support the claim that this observation is novel or unique to the paper. While the comment provides a logical reasoning for the suggestion, it is 3 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks depth and does not provide specific guidance on how to enhance the practical implications or what additional takeaways should be included. While it identifies a potential area for improvement, the feedback is 3 as it provides a starting point for the authors to consider, but it could be more comprehensive and actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information they provide beyond T/I/O. While the comment raises a valid point about the need for clarification, it does not explicitly instruct the authors to provide this information or suggest specific details to include. The action is implicit and somewhat vague, as the authors can infer that they need to explain the purpose and additional information of the separators, but the comment does not provide concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of introducing separators and asks for clarification on the additional information they provide beyond T/I/O. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or what specific issues might arise. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the purpose and additional information provided by the introduction of separators in section 4. It prompts the authors to clarify why these separators are necessary and what specific information they convey beyond the traditional T/I/O (transmission, input/output) framework. This feedback is 3 as it encourages the authors to provide more detailed explanations, which could enhance the clarity and depth of their paper. However, the comment could be more helpful if it suggested specific areas for clarification or provided examples of how the information could be better presented. Overall, the comment offers a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate different pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling and suggests considering other pooling strategies. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of mean pooling and suggests considering other pooling strategies. It does not contain any subjective opinions, claims, or suggestions that require verification. Instead, it is a request for clarification or further explanation, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how they might be implemented. The comment lacks depth and actionable advice, making it 3. The authors are given a direction to consider, but the feedback could be more comprehensive and detailed to be fully beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This request provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"training details\" and specifically asks about the pretraining of the VQGAN and its training on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what part of the paper needs clarification. The comment is specific because it identifies the exact details that are missing, allowing the authors to address the issue directly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on specific training details, specifically whether the VQGAN is pretrained or trained on a particular dataset. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on a specific dataset. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what potential implications it might have for the results. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the approach and suggests an alternative method that could be used to achieve the same results. It implies that the authors should consider this alternative approach, but it does not explicitly instruct them to do so. The comment provides a logical reasoning for the suggestion, explaining why the alternative method might be more efficient. However, it lacks concrete guidance on how the authors should implement this alternative or why it would be beneficial. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not specify which part of the paper this critique pertains to, such as the experimental section or specific results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the experimental approach, suggesting a more efficient alternative. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the approach, questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. The comment provides a logical reasoning for the suggestion, explaining why the alternative method might be more efficient. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is 3 as it identifies a potential weakness in the experimental design and provides a logical suggestion for improvement. However, the comment could be more helpful if it included specific examples or references to support the claim or if it offered additional guidance on how to implement the suggested alternative method. Overall, the comment provides a basis for improvement but lacks depth and detail, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify what Omega is and to be more explicit about the link function and the theorem in 32 that provides the regret guarantee. These requests are direct and specific, providing clear actions for the authors to take. The comment also suggests that OMD is a family of algorithms, which could be clarified. Therefore, the comment is 5, as it provides explicit and concrete guidance on how the authors can improve their draft by addressing these specific points.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying what Omega is, being more explicit about the link function, and specifying the theorem in 32 for the regret guarantee. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions asking for clarification on specific aspects of the paper, such as the definition of Omega, the link function used, and the theorem referenced for the regret guarantee. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the authors can improve their draft. It points out the need to clarify the definition of Omega and provides additional details about the OMD family of algorithms, suggesting that the authors be more explicit. Additionally, it asks about the link function and references a specific theorem in 32 for the regret guarantee, offering actionable feedback for the authors to enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided examples or further guidance on how to address these issues. Overall, the feedback is clear and provides valuable insights for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using longer video sequences (e.g., 16 frames) to address issues like inconsistent motion, changing color, or objects disappearing over time in the synthesized results for UCF101. It also recommends running the LSTM over many time steps for videos with a longer duration. While the comment provides a clear direction for improvement, it does not specify how to implement these suggestions or what specific changes are needed. The action is implicit and somewhat vague, as the authors know they need to address the issues but may not have a clear idea of how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of inconsistent motion, changing color, or objects disappearing over time in the synthesized results for UCF101. It suggests using longer video sequences and running the LSTM over many time steps to address these issues. However, the comment does not specify which part of the paper discusses these results or the experiments, making it weakly grounded. The authors can infer that it relates to the results section or figures, but this is not explicitly mentioned. The comment is specific in detailing the issues and suggesting improvements, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the synthesized results for UCF101 exhibit inconsistent motion, changing color, or objects disappearing over time, suggesting that using longer video sequences and running the LSTM over many time steps could address these issues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion to use longer sequences is somewhat vague and lacks concrete evidence or examples to substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color, and object presence over time. It suggests using longer video sequences and running the LSTM over many time steps to address these issues. This feedback is 3 as it points out a potential area for improvement and provides a clear direction for addressing the problem. However, the comment could be more helpful if it included specific suggestions on how to implement these changes or if it provided examples of how to improve the results. Overall, the comment offers a good starting point for the authors to consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment implies that conducting this experiment could strengthen the paper, but it does not explicitly instruct the authors to perform the experiment. The action is implicit and somewhat vague, as the authors need to infer that they should consider conducting the experiment to enhance the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in questioning the impact of the number of bits in logits on robustness, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external works that could validate the suggestion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment provides a potential area for further exploration that could strengthen the paper, but it lacks specific guidance or suggestions on how to conduct the experiment or what results to expect. While it identifies a potential avenue for improvement, the feedback is 3 as it prompts the authors to consider additional experiments but does not offer detailed advice on how to implement them. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which gives the authors a clear direction on how to address the issue. This level of specificity and directness makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the concept of meta solvers and their relation to centralized RL, specifically mentioning the need for clarification on the difference between the two. It provides a reference to a specific paper, \"Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which helps the authors understand the context and potential issues. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be clarified, namely the distinction between meta solvers and centralized RL. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which supports the claim by offering a comparison with a related work. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by elaborating on the specific aspects of the meta solvers that are centralized and how they differ from centralized RL with shared weights. Despite this, the overall justification is robust, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential area of confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which helps the authors understand the context and potential issues. By suggesting that the authors clarify this distinction, the comment offers a clear and actionable feedback that can help improve the clarity and accuracy of the paper. However, the comment could be more helpful if it provided additional guidance on how to clarify the distinction or what aspects of the meta solvers are centralized. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their categorization. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the discrepancy and providing an example, such as the BERT paper being available on arXiv from October. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper categorizes papers based on their publication years, but many papers are available on arXiv much earlier. This claim is 3 as it provides a specific example, the BERT paper being available on arXiv from October, which supports the assertion. However, the comment lacks detailed reasoning or references to explain why this discrepancy is problematic or how it affects the paper\"s analysis. Therefore, the comment is rated as 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. It provides a specific example, mentioning the BERT paper being available on arXiv from October. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their categorization. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are aware of the issue but are left without clear steps to take to resolve it. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. While the action is explicit, it is somewhat vague because it does not specify which part of the paper this definition is found in or how the examples should be structured. The authors know they need to provide examples, but the comment lacks detailed guidance on how to do so effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the notation used to define M_T is unclear and proposes providing examples to clarify this concept. However, the comment does not provide specific examples or detailed reasoning to support why the notation is unclear or how examples would help. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used to define M_T, specifically noting that it is unclear whether M_T is defined over the probabilities of atomic events. The reviewer suggests that providing examples could help clarify this concept. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to present these examples or what aspects of the notation are particularly confusing. This feedback is 3 as it points out a potential area of confusion but does not offer comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the performance. The comment lacks actionable details, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not specify which part of the paper discusses these enhancements or where further refinement is needed. This lack of grounding makes it difficult for the authors to identify the exact sections that require attention. The comment is specific in suggesting a need for further refinement, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that the enhancements are modest or to suggest where further refinement is needed. Without additional context or justification, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. While it identifies a potential area for improvement, the comment lacks specificity and actionable guidance. It does not provide any suggestions on how the authors might address this issue or what specific aspects need further refinement. As a result, the feedback is vague and does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to provide more convincing evidence or address the issues mentioned. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not specify which part of the paper these experiments are located in, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in questioning the effectiveness of the proposed method and suggesting potential issues, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are not convincing or how the similarity to IRM might be problematic. Without additional context or evidence, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above, implying that the results may not be robust. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the experimental results. While it identifies a potential issue, it does not provide actionable feedback or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is 3, as it highlights a concern but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in Figure 2, asking why it is important and what the difference is between detecting just the long one. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this question or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the purpose of detecting both entities and provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting just the long one. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the necessity of detecting both entities in Figure 2, asking why it is important and what the difference is between detecting just the long one. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2, asking why it is important and what the difference is between detecting just the long one. This feedback prompts the authors to clarify their approach and the significance of detecting both entities, which could help them improve the clarity and effectiveness of their presentation. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as whether it is necessary to detect both entities or if there is a specific reason for including both. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks empirical validation and suggests that the authors should include experiments to validate the bounds. This feedback is clear and direct, providing a specific action for the authors to take. It specifies what needs to be added to the paper to improve its quality, making the comment 5.", "grounding_specificity_rationale": "The comment points out the absence of empirical validation in the paper, specifically mentioning the need for experiments to validate the bounds. However, it does not specify which part of the paper lacks this validation or where these experiments should be included. The authors can infer that the validation is missing from the results or discussion sections, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on what specific experiments are needed or how they should be conducted. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, specifically mentioning the need for experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of empirical validation, specifically mentioning the need for experiments to validate the bounds. This feedback is clear and actionable, as it directs the authors to a specific area where their work lacks empirical support. By suggesting the inclusion of experiments, the comment provides a clear path for improvement, making it 4. However, it could be more helpful if it offered suggestions on how to design or conduct these experiments or provided examples of similar studies that have successfully validated bounds. Overall, the comment is 4 as it highlights a critical area for enhancement but could be further improved with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" in line 285, specifically asking if \"chunk\" is still considered sequential information. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the meaning of \"nonsequential information\" and \"chunks\" in their draft. However, the comment lacks concrete details on how to resolve the confusion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"nonsequential information such as chunks,\" questioning whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific phrase in the text, \"nonsequential information such as chunks.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the authors clarify whether \"chunk\" is still considered sequential information. This feedback is clear and actionable, as it prompts the authors to address a potential area of confusion in their draft. By providing a direct question, the comment helps the authors improve the clarity and precision of their writing. However, it could be more helpful if it included additional context or suggestions on how to resolve the confusion. Overall, the comment is 4, as it guides the authors toward improving the clarity of their text."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply highlights a potential issue without suggesting how the authors should address it. As a result, the authors are left without guidance on how to improve their draft in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption of a separate node with 0 neighbors and explaining why the upper bound would be 0, which is not true. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. The reviewer points out that the upper bound in this case would be 0, which is not true. This raises a logical inconsistency that the authors need to address. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about Theorem 1, pointing out a potential inconsistency in the assumption of a separate node with 0 neighbors. It highlights that the upper bound in this case would be 0, which is not true, and asks for an explanation. This feedback is clear and actionable, as it directs the authors to address a specific issue in their theoretical framework. However, it could be more helpful if it provided additional context or suggestions on how to resolve the inconsistency. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, coattention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the novelty of their work. As a result, the authors are left without a clear understanding of what steps to take to enhance the technical novelty of their paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, coattention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not specify which part of the paper these comparisons are based on, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity in detailing what aspects of the paper are similar to the previous works, such as specific methodologies or results. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). However, the comment does not provide specific examples or detailed reasoning to support the claim that the idea, coattention mechanism, and architecture are similar to those in the previous works. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment highlights a concern about the limited technical novelty of the paper, suggesting that the idea, coattention mechanism, and architecture are similar to previous works by Xing and Tsang (2022a, b). This feedback is 3 as it identifies a potential issue with the originality of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is rated as 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a gap in the analysis of GPTgenerated rumors, suggesting that there is no explanation for why these rumors are as difficult to detect as natural rumors. It implies that the authors should provide further analysis or solutions to address this issue. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but lack concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a gap in the analysis, questioning why GPTgenerated rumors are as difficult to detect as natural rumors, despite being written by humans. The comment suggests that further analysis or solutions should be proposed to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting rumors generated by GPT compared to natural rumors. It suggests that since artificial rumors are written by humans, they should be about the same difficulty as natural rumors, but the experimental results show otherwise. The comment implies that there is a gap in the analysis that needs to be addressed. However, it does not provide specific evidence or references to support this claim, making it 3. The authors would need to conduct further analysis or provide additional context to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the analysis of GPTgenerated rumors, specifically questioning why these rumors are as difficult to detect as natural rumors. It points out that artificial rumors are written by humans and should be about the same difficulty as natural rumors, but the experimental results suggest otherwise. This feedback is 3 as it highlights an area where the paper could be improved by providing further analysis or solutions. However, it lacks specific suggestions or guidance on how to address this issue, such as proposing additional experiments or methodologies. While it prompts the authors to consider a critical aspect of their work, the comment could be more helpful with more detailed guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 6, noting that the font size is a bit small. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending a specific font size or suggesting ways to improve the readability of the figure. Without explicit or implicit actions, the authors are left without a clear understanding of what steps to take to improve the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being small. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6, noting that the font size is too small. While this feedback is clear and points out a potential problem, it lacks actionable guidance on how the authors might address this issue, such as suggesting a specific font size or recommending ways to improve the readability of the figure. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what steps they might need to take to ensure a fair comparison. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in questioning the fairness of the comparison, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or improve the comparison. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive advice or suggestions for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment implies that the authors should consider alternative relationships and provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and explain alternative relationships. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the mono tonic relationship and its potential alternatives. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not provide specific examples or references to support the claim that other relationships might be more appropriate. The suggestion to explain this point is a request for clarification rather than a claim that requires verification. Therefore, the comment is considered 2, as it provides a suggestion for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to explore alternative relationships or explain the current relationship. The feedback is 3 as it points out a potential weakness in the paper\"s methodology but does not provide detailed advice on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the goal of the paper in the introduction and provides a specific example of a problem where the paper\"s results are irrelevant due to being already embarrassingly parallel. It also offers a suggestion for focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to make these changes or specify how to address the issues. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper in the introduction\" and provides specific examples of problems where the paper\"s results are irrelevant, such as samplingbased Bayesian methods and ERMbased distributed algorithms like Hogwild. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need for a clearer explanation of the paper\"s goal and a focus on problems where the loss function does not decompose as the sum of sample losses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s goal is not clear and suggests that the examples chosen do not convince the reader of the need for a lot of interprocess communication. The reviewer provides a specific example from the second paragraph, where samplingbased Bayesian methods are mentioned, and argues that the paper\"s results are already parallelizable, making them irrelevant. The reviewer also suggests focusing on problems where the loss function does not decompose as the sum of sample losses. While the comment provides a logical reasoning for the claim, it lacks specific references or detailed examples to fully substantiate the argument. Therefore, the comment is 4, as it offers a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s introduction, noting that the goal is not clearly explained. It provides a constructive suggestion by pointing out that the examples chosen do not convince the reader of the need for a lot of interprocess communication, particularly in the context of samplingbased Bayesian methods. The reviewer offers a clear direction for improvement by suggesting that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms. This feedback is actionable and provides a clear path for the authors to enhance the clarity and relevance of their paper. However, the comment could be more helpful if it included specific examples or suggestions for how to address these issues. Overall, the comment is 4, as it effectively guides the authors towards improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions that the hyperlinks for footnotes 3 and 4 do not seem to work. This provides a clear and direct action for the authors to take, which is to ensure that the hyperlinks are functional. The comment is explicit and concrete, giving the authors a straightforward task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is specific because it clearly identifies the issue with the hyperlinks not working, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the nonfunctionality of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable feedback that can help the authors ensure the functionality of their footnotes, which is important for reader comprehension and engagement. However, the comment lacks additional context or suggestions on how to resolve the issue, such as whether the hyperlinks should be reinserted or if there are alternative ways to reference the footnotes. While it provides a starting point for improvement, the feedback could be more comprehensive. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It specifically mentions the need for a better formalization of the architecture in section 2 and points out that the figure is misleading regarding the Label Embeddings. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to revise the discussion or what specific changes are needed. The action is implicit and somewhat vague, as the authors know they need to improve clarity but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, and provides specific feedback on the need for a better formalization of the architecture in section 2. It also points out that the figure is misleading regarding the Label Embeddings. This feedback is fully grounded as it explicitly mentions the section and provides specific details on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, due to its current lack of clarity. It provides specific feedback, such as the need for a better formalization of the architecture in section 2 and the issue with the figure regarding Label Embeddings. While the comment does not provide explicit references or detailed reasoning, the suggestions are based on logical observations and common sense, making the claim 3. The authors can infer the need for improvement but may require additional guidance to fully address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the discussion section, particularly in the modeling part, noting that it is currently unclear. It provides a detailed suggestion to improve clarity by recommending a better formalization of the architecture, specifically in section 2. The comment also points out a potential issue with the figure, suggesting that it might be misleading regarding the Label Embeddings. This feedback is clear and actionable, offering specific guidance on how the authors can enhance the clarity and accuracy of their discussion. However, it could be more helpful if it provided additional context or examples to further support the suggestions. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the description of the neural network in the section is hard to understand and suggests starting the section with the final paragraph to make it clearer. This provides a clear and direct action for the authors to take, which is to restructure the section to improve its clarity. The suggestion is concrete and actionable, as it specifies what needs to be done to enhance the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the description of the neural network is hard to understand and suggests starting the section with the final paragraph to clarify it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand, but it does not provide any specific examples, reasoning, or evidence to support this claim. The suggestion to start the section with the final paragraph implies that the later part of the section is clearer, but without further explanation, the authors may not fully understand the basis of this suggestion. Therefore, the comment is considered 1 as it lacks sufficient justification or evidence to support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the neural network, noting that it is hard to understand. It provides a clear suggestion to start the section with the final paragraph, which is said to clarify the description. This feedback is actionable and provides a direct way for the authors to improve the clarity of their draft. However, the comment could be more helpful if it offered additional guidance on how to restructure the section or what specific aspects of the neural network description are confusing. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and offers a concrete suggestion. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of training the model with attentionbased encdec training instead of CTC loss. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not specify which part of the paper discusses the model\"s training or limitations, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this alternative might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance on why this alternative might be beneficial or how it could be implemented. The authors are left with a general suggestion but without actionable feedback or detailed reasoning, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the necessity of having a column header as a separate type. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or simplify the division of tables. However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"line 247252,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of having a column header as a separate type in the tables, providing a clear direction for the authors to consider revising their approach. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the necessity of having a column header as a separate type. However, it does not provide any supporting evidence, reasoning, or examples to justify this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the division of tables into three types in Section 3, questioning the necessity of having a column header as a separate type. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation of their tables. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be revised. Therefore, it is rated as 2, as it provides some insight but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction on how to improve their work. The comment is explicit in its suggestion and provides concrete guidance on what additional attack methods to explore, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of attack methods in the paper, specifically mentioning that the methods are naive and suggesting the consideration of other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction on what additional attack methods to explore. However, the comment does not specify which part of the paper discusses the attack methods, making it weakly grounded. Despite this, the comment is specific in its suggestion to consider other attack methods, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which offers a clear and logical basis for the claim. The mention of specific papers provides a strong foundation for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of why the suggested attack methods are more appropriate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the attack methods used are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to consider, which gives the authors a clear direction for improvement. This feedback is actionable and provides a concrete suggestion for expanding the scope of the study, making it 5. However, the comment could be more helpful if it offered additional guidance on how to integrate these new attack methods or what specific aspects of the existing methods could be improved. Overall, the comment is 4, as it effectively directs the authors toward enhancing their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and \"image generation capabilities,\" but it does not specify which part of the paper discusses these topics. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment also lacks specificity, as it does not detail what specific issues with the mitigation methods or image generation capabilities are being addressed. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide specific suggestions or guidance on how the authors might address this problem or improve the image quality. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. The comment identifies a potential weakness but lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or mitigate the risk of unfairness. The action is implicit and vague, as the authors are left to infer that they need to consider these issues and possibly adjust their methodology or analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the fairness of comparisons, making it weakly grounded. The issue is clearly specified, as it addresses the potential risk of unfairness in the comparisons. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to support the claim about the potential leakage of information. While the concern is logical and based on common knowledge in the field, the lack of detailed evidence or references makes the claim 3. The authors would need to conduct further investigation or provide additional context to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. This feedback is important as it points out a critical issue that the authors should consider when evaluating their results. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or mitigate the risk of unfairness. While it identifies a potential problem, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what aspects of the paper could be revised in response. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, which is a clear issue for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or context to explain why this might be surprising or how it relates to the paper\"s content. Without any justification or references, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as depicted in Figure 1. However, it does not provide any context, explanation, or suggestions for why this might be surprising or how it relates to the paper\"s content. Without additional information or guidance, the authors are left without a clear understanding of what aspects of the paper need improvement or clarification. The comment lacks actionable feedback, making it difficult for the authors to address the issue effectively. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that using the minimal kmeans objective over multiple seeds might be more reasonable than the average of kmeans objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. While the suggestion is clear, the lack of explicit action or detailed instructions makes it 3. The authors can infer that they should consider using the minimal kmeans objective, but they may need to consult the references for further guidance on how to apply this suggestion.", "grounding_specificity_rationale": "The comment suggests a minor change in the use of the kmeans objective, specifically recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It provides references to support this suggestion, which is a clear and specific point. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the suggestion is specific, as it clearly outlines what needs to be changed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. These references offer a logical basis for the suggestion, as they discuss the properties of kmeans and the implications of different objective functions. However, the comment could be strengthened by providing more detailed reasoning or examples to further substantiate the claim. Therefore, the comment is 4, as it provides a strong foundation but lacks some specific details for full verification.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives with multiple seeds. It supports this suggestion with references to relevant literature, specifically Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja, which provide a basis for the claim. This feedback is actionable and offers a clear direction for enhancing the paper\"s methodology, making it 4. However, the comment could be more helpful if it included specific guidance on how to implement this change or if it discussed the potential implications of this shift. Overall, the comment is valuable and provides a solid foundation for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues regarding the uncertainty calibration process and the regularization term H. It suggests that the authors clarify the relationship between temperature calibration and uncertainty calibration, as well as the role of H in reducing entropy and its potential conflict with the paper\"s motivation for calibration. The comment explicitly requests clarification on these points, providing a clear action for the authors to take. Additionally, it highlights a specific contradiction in the paper\"s motivation and calibration process, offering a concrete suggestion for improvement. This feedback is explicit and provides detailed guidance on how the authors can address the issues, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) where the confusion arises regarding the relationship between temperature calibration and uncertainty calibration. It also references lines 133136, which discuss the paper\"s motivation regarding calibration. This provides clear guidance on where the authors need to address the confusion. The comment is specific in detailing the issue with the regularization term H and its impact on calibration, as well as the contradiction with the paper\"s motivation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It questions the apparent contradiction in the paper\"s presentation, suggesting that the authors clarify the relationship between these concepts. The comment also points out a potential conflict with the paper\"s motivation regarding calibration. While the reviewer provides a logical reasoning for the confusion and suggests a need for clarification, the comment lacks specific references or examples to fully substantiate the claim. This makes the claim 3, as it provides a basis for the critique but requires further elaboration for full verification. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a confusing aspect of the paper regarding the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It points out a contradiction in the paper\"s presentation, suggesting that the authors clarify this point. The comment also highlights a potential conflict with the paper\"s motivation for calibration, questioning the use of entropy reduction to increase confidence, which contradicts the goal of calibration. By providing specific areas for clarification and suggesting a potential contradiction, the comment offers actionable feedback that can help the authors improve their draft. However, it could be more helpful if it provided additional suggestions or examples to further guide the authors in addressing these issues. Overall, the comment is 4, as it effectively directs the authors\" attention to critical areas for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss the relationship, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the reference and discuss the context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not specify which part of the paper should include this reference or discuss the context, making it weakly grounded. The authors can infer that it pertains to the introduction or related work section, but this is not explicitly mentioned. The comment is specific in its suggestion to include a reference and discuss the context, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is closely related to the idea of unrolling, as proposed in \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" However, the comment does not provide specific examples or detailed reasoning to support why this reference is important or how it relates to the paper\"s context. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a critical oversight in the paper by pointing out a missing reference, \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context and situate the paper within the relevant literature. This feedback is valuable as it directs the authors to a key piece of literature that could enhance the paper\"s context and understanding. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference or discuss the differences between the proposed work and \"Lista.\" Overall, the comment is 4 as it highlights an important omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. This is a factual statement that does not require any supporting evidence or justification. It is a straightforward observation that the authors should address, but it does not provide any reasoning or context to explain why this is a significant issue. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable feedback that highlights a gap in the paper\"s presentation, which is important for the authors to address. By pointing out this omission, the comment provides a direct suggestion for improvement, allowing the authors to clarify and enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to define the FLOT cost matrix or suggested potential consequences of this omission. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the term \"connectivity\" as misleading because it does not reflect the structural connections between the brain and body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for alternative terminology. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the term \"connectivity\" as misleading, suggesting that it does not accurately reflect the structural connections between the brain and body. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the term \"connectivity\" as misleading because it does not accurately reflect the structural connections between the brain and body. This feedback is specific and identifies a potential issue with the terminology used in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the terminology. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, but it does not provide specific guidance on what details are missing or how to address them. The action is implicit, as the authors need to infer that they should review the \"Clarity, Quality, Novelty And Reproducibility\" section for guidance, but it lacks concrete details on how to improve the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which sections or parts of the paper are missing details, making it weakly grounded. The comment is specific in identifying the areas that need improvement, such as related work, experiments, and writing, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing, but it does not provide specific examples or references to support these claims. The comment suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, but without detailed guidance or examples, the authors may find it challenging to understand and address the issues effectively. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not polished and lacks details in related work, experiments, and writing. This feedback is clear and actionable, as it points out specific areas where the authors need to improve to make the paper more publishable. However, the comment could be more helpful if it provided specific examples or suggestions on how to address these issues, such as what details are missing or how to enhance the clarity of the writing. Despite this, the comment is 4 as it directs the authors\" attention to critical areas for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete guidance on how the authors should address the issue of comparing episodes with different lengths. It suggests that the authors should state how they handle these comparisons and mentions the specific issue of padding shorter sequences and the lack of a normalization factor. The comment also provides a clear explanation of why these decisions should be understood by readers without needing to check the code. This level of detail and specificity makes the action clear and actionable, allowing the authors to directly address the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the handling of comparisons between episodes with different lengths, such as the need to state how this is done and the lack of a normalization factor. Additionally, it provides a clear explanation of why these decisions should be understood by readers without needing to check the code. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths and mentions specific issues with the provided code. It provides a logical explanation of why the lack of a normalization factor of 1/T makes the distance increase with T and favors longer trajectories, which can be a good proxy for many Atari games but not necessarily for other domains. This reasoning is clear and supported by the observation of the code, making the claim 4. However, it could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed and actionable feedback on a specific issue in the paper, namely the handling of comparisons between episodes with different lengths. It points out a potential problem with the lack of a normalization factor of 1/T, which could lead to a bias towards longer trajectories. The reviewer suggests that the authors should clarify how they handle these comparisons and provides a clear explanation of why this is important. This feedback is valuable as it helps the authors understand the implications of their current approach and offers a concrete way to improve the clarity and robustness of their methodology. However, the comment could be more helpful if it included suggestions on how to address the issue or provided examples of how to implement the suggested changes. Overall, the comment is 4, as it guides the authors towards a specific area for improvement and provides a clear direction for enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention in SI 6.5 that the preprocessing is identical to that in Mnih et al. 7, but the evaluation is slightly different due to the absence of human starts. This provides a clear and direct action for the authors to take, as they are given specific instructions on what information to include in their supplementary information. The comment is explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to mention that the preprocessing is identical to that in Mnih et al. 7 but the evaluation is slightly different due to the absence of human starts. This provides clear guidance on what information should be included in the supplementary information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is slightly different from Mnih et al. 7 because no human starts are used. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples that would help the authors understand the basis of the claim or how it impacts the evaluation. Without additional context or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient support or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include in their supplementary information. It highlights a discrepancy between the preprocessing method mentioned in Mnih et al. 7 and the evaluation process in the current work, noting that no human starts are used in the evaluation. This feedback is clear and direct, offering a concrete way for the authors to enhance the transparency and comparability of their work. By addressing this point, the authors can better align their evaluation with the established methods in the field, potentially strengthening the credibility and reproducibility of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it guides the authors in improving their draft by highlighting a specific area for clarification."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. It explicitly states that the paper does not report any metrics for efficiency, which is a clear and direct action for the authors to take. However, the comment does not provide specific guidance on which metrics to report or how to measure efficiency, leaving some ambiguity in terms of how to implement the suggested action. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. It explicitly mentions \"efficiency,\" which provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the paper, namely, the reporting of metrics for efficiency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metrics that demonstrate the efficiency of the proposed method compared to previous work. This is a factual statement that does not require verification, as it is based on the absence of specific information in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that it does not report any metrics demonstrating the efficiency of the proposed method compared to previous work. This is a clear and actionable feedback that highlights an important area for improvement. However, the comment could be more helpful if it provided suggestions on which metrics to report or how to measure efficiency. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests the authors to provide more details about the statespace, whether it is finite or continuous, and to specify the space in which theta lies. It also suggests that the authors should be precise in their descriptions. This feedback is clear and direct, giving the authors a specific action to take: providing additional details about the statespace and the space of theta. The request is concrete, as it outlines exactly what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more details about the statespace, whether it is finite or continuous, and the space in which theta lies. The comment also suggests that the authors should be precise in their descriptions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement asking for additional details, which is a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors need to provide more details. It points out that the statespace is not clearly defined, whether it is finite or continuous, and questions the space in which theta lies. While the comment highlights a gap in the paper\"s clarity, it does not offer specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be clarified but without detailed instructions on how to improve the draft. Therefore, the comment is 3, as it provides a starting point for the authors to consider but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task and provides a rationale for this belief. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this belief or incorporate it into their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the choice of using object detection as the downstream task and expresses a personal belief that LiDARbased segmentation is the best choice. It also mentions that colorizationbased pretraining learns semantics and that object detection requires accurate locations and poses, particularly in benchmarks like KITTI and Waymo. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the choice of downstream task and the importance of accurate locations and poses, but it lacks grounding as it does not reference specific parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on a personal opinion rather than logical reasoning or external references, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, suggesting that colorizationbased pretraining learns semantics but lacks accuracy in location and pose, particularly in benchmarks like KITTI and Waymo. While the comment provides a perspective on the choice of downstream task, it lacks actionable feedback or suggestions for the authors to consider. It does not offer specific guidance on how the authors might address this issue or improve their work, leaving the authors without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. While the comment points out a potential issue, it does not provide explicit guidance on how to address this confusion. The authors are left to infer that they should clarify the notation or reword the description to avoid ambiguity, but the comment lacks concrete suggestions or examples of how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out potential confusion regarding the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their notation or reword the description to avoid ambiguity. However, the comment could be more helpful if it provided suggestions on how to address the confusion, such as proposing alternative notation or explaining the purpose of the dummy variable. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide specific guidance on which tasks to include or how they would enhance the paper. The action is implicit, as the authors need to infer that they should expand the benchmarking tasks, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies a potential improvement but does not provide explicit instructions on how to achieve it.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which part of the paper this recommendation pertains to, such as the experimental section or the results. This makes it difficult for the authors to identify the exact area where the suggestion should be applied. The comment is specific in its suggestion to include more benchmarking tasks, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide any specific examples or reasoning to support why these additional tasks would be beneficial or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific tasks to include or how they would enhance the paper. The feedback is 3 as it points out a potential weakness but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a confusion in Figure 1 regarding the reference to \"PointNet\" and provides a specific reference to a paper by Qi et al. that clarifies the issue. This feedback is clear and actionable, as it instructs the authors to correct the reference in Figure 1 to avoid confusion. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a specific reference to a paper by Qi et al. that clarifies the confusion. This level of detail helps the authors understand what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reference to \"PointNet\" in Figure 1 is confusing because it does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Qi et al., which clarifies the confusion. This provides a clear and specific example of the issue, making the claim 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing because it does not appear in the paper and there is another paper with the same name. By providing a specific reference to a paper by Qi et al., the comment offers a clear and actionable suggestion for the authors to correct the reference in Figure 1. This feedback is 5 as it guides the authors in making a specific and impactful improvement to their draft, enhancing its clarity and accuracy. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This raises a concern about the clarity of the presentation and suggests that it might be beneficial to clarify this aspect. The second part points out a minor issue with the line number 78, where \"on\" is unnecessary, and provides a correction. The first part of the comment is explicit and concrete, as it directly questions the authors about the optimality of the solution and suggests clarification. The second part is also explicit and provides a specific correction. Therefore, the comment is 5, as it provides clear and concrete guidance on both the theoretical and stylistic aspects of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 6\" and \"Line 78,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the optimality of the solution in Equation 6 and suggests clarifying this point. Additionally, it points out a minor issue with the line number 78, providing a correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the optimality of the solution in Equation 6, suggesting that it might be better to clarify this aspect. This raises a logical concern about the accuracy of the solution, but it lacks specific examples or references to support the claim. The second part points out a minor issue with the line number 78, where \"on\" is unnecessary, providing a direct correction. While the first part is 3 due to the logical reasoning, the second part is clear and actionable, making the overall comment 4. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment raises a critical question about the optimality of the solution in Equation 6, suggesting that it might be beneficial to clarify this aspect. This feedback is valuable as it prompts the authors to revisit and potentially clarify their theoretical framework, which could significantly impact the clarity and rigor of their work. Additionally, the comment points out minor formatting issues, such as unnecessary words in Line 78 and a correction in Line 132. These suggestions are actionable and can help the authors improve the presentation and clarity of their draft. However, the comment could be more helpful if it provided specific guidance on how to clarify the optimality of the solution or suggested alternative ways to address this concern. Overall, the comment is 4, as it identifies important areas for improvement and provides some actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks about the difference between the two. While the comment highlights an area for consideration, it does not provide explicit guidance or suggestions on how the authors should address this question or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of assuming a general Gaussian distribution and compare it to the isotropic Gaussian. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its inquiry about the difference between the two distributions, but without clear grounding, it is challenging for the authors to understand where to focus their attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on the difference between these two distributions. While the comment identifies a potential area for improvement or clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithm could be affected by this assumption. The feedback is 3 as it prompts the authors to consider the implications of their assumptions, but it lacks depth and actionable advice, leaving the authors with a general direction to explore without detailed guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, as it makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to include a discussion on the limitations of this choice. The comment is explicit and concrete, guiding the authors on exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment suggests that the authors should discuss the limitations of this choice, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that the authors should discuss the limitations of this choice. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that this choice is risky or assumptions are being made. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable piece of feedback. By pointing out this limitation, the comment encourages the authors to consider the implications of their decision and potentially address it in their paper. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects to focus on. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This feedback provides a clear and direct action for the authors to take, which is to justify their choice of using link prediction accuracy for early stopping. The comment is explicit and concrete, as it specifies what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use link prediction accuracy for early stopping, questioning why this choice was made over using average accuracy with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use link prediction accuracy for early stopping, suggesting that it might be more appropriate to use average accuracy with type accuracy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this might be the case. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the decision to use link prediction accuracy for early stopping, rather than considering average accuracy with type accuracy. This feedback is clear and actionable, as it prompts the authors to justify their choice and potentially reconsider their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It explicitly states that the authors should provide more details on how actual pruning was done. This feedback is clear and direct, giving the authors a specific action to take: to include more details on the pruning process. The comment is explicit and concrete, providing a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detail on how the ground truth of sensitivity is achieved and the actual pruning process. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the authors mention estimating a layer\"s sensitivity by pruning, but without providing details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more detailed information about the pruning process to enhance the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it suggested specific details or examples of what kind of information should be included. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not provide specific guidance on how the authors might improve their approach or incorporate more universal operator learning methods. The action is implicit and vague, as the authors are left to infer that they should explore more universal operator learning methods, but without concrete steps or suggestions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights the need for careful selection of basis functions, meshes, and stiffness matrix assembly, and notes that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It also suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. The comment provides some logical reasoning by comparing the proposed approach to specialized numerical solvers and operator learning methods. However, it lacks specific examples or references to support the claim about the accuracy of operator learning methods compared to specialized numerical solvers. This makes the claim 3, as it provides a general idea but requires further elaboration for full clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, suggesting that it relies heavily on FEniCS for solving linear/linearized systems of equations in FEM. It points out that while current operator learning methods may not match the accuracy of specialized numerical solvers, they offer more universality. However, the comment lacks specific suggestions or guidance on how the authors might improve their approach or incorporate more universal operator learning methods. While it highlights an important area for consideration, the feedback is 3 as it provides a direction for potential improvement but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues: the paragraph from L156166 is difficult to understand, and the figure is unclear. It suggests that there are bandit algorithms that plan to explore, such as the Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain. Additionally, it points out that the phrase \"Dashed lines indicate that the agent can plan ahead\" is vague. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what changes should be made. The authors are left to infer that they need to clarify the paragraph and the figure, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, such as the difficulty in understanding it and the unclear nature of the figure. The comment provides specific feedback on the need for clarification regarding bandit algorithms and the Gittins strategy, as well as the vagueness of the phrase \"Dashed lines indicate that the agent can plan ahead.\" This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and suggests that the figure is unclear. It provides specific examples of what is unclear, such as the mention of bandit algorithms and the Gittins strategy, as well as the vague nature of the phrase \"Dashed lines indicate that the agent can plan ahead.\" While the comment does not provide detailed reasoning or references to support these claims, it does offer clear examples of areas that need clarification. This makes the claim 3, as the authors can infer the need for improvement but may require additional context or examples to fully address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the text and figure in the paper. It highlights the difficulty in understanding the paragraph from L156166 and suggests that the figure is unclear, particularly regarding the phrase \"Dashed lines indicate that the agent can plan ahead.\" The comment provides actionable feedback by suggesting that there are bandit algorithms that plan to explore, such as the Gittins strategy, which could be used to clarify the text. Additionally, it recommends that the figure be improved to provide clearer explanations. While the comment identifies areas for improvement, it could be more helpful if it offered specific suggestions or examples of how to clarify the text or figure. Overall, the feedback is 4 as it provides clear guidance on how to enhance the clarity and understanding of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and suggests that the improvement over previously known results is limited to arbitrarily long inputs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to expand the applicability of their approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the bounds and their potential limitations, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the bounds are problematic or limit the applicability of the approach. Without specific examples or references, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. It questions the size of the inputs needed for improvement, suggesting that this could limit the practical use of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand the applicability of their approach. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general understanding of the concern but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what aspects of the performance they should focus on. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any details on what aspects of the performance should be considered or how the authors might address this question. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question about the performance of DVP on video with different lengths, which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any context, analysis, or suggestions on how the authors might address this question or what aspects of the performance should be considered. Without actionable feedback or guidance, the comment lacks depth and does not offer the authors a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for curiosity but does not effectively support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should clarify this in their draft. The action is implicit, as the authors need to infer that they should clarify the distinction between singletoken and multitoken cloze queries in their paper. However, the comment lacks concrete details on how to achieve this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"singletoken cloze queries\" and \"multitoken ones,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of clarity until reading the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the distinction between singletoken cloze queries and multitoken ones. It notes that this clarification is not clearly explained until the conclusion, which could be confusing for readers. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is 3 as it points out a potential area of improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses an opinion that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to 1. While it identifies a potential issue with the connection between sections and the theoretical analysis, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The comment lacks actionable details or concrete steps for the authors to take, such as recommending specific changes or improvements. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to 1. However, it does not specify which part of Section 2 is disconnected from the methodology or how the theoretical analysis is simplistic. This lack of specificity makes it difficult for the authors to identify the exact issues and address them effectively. Additionally, the comment does not provide a clear indication of where the connection between sections should be improved or how the theoretical analysis could be enhanced. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to 1. However, the comment does not provide specific examples or detailed reasoning to support these claims. The mention of 1 does not offer a detailed comparison or analysis of the theoretical analysis, leaving the authors without a clear understanding of how to address the issues raised. As a result, the claim is 1 due to the lack of supporting evidence or justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is somewhat simplistic and closely related to 1. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might improve the connection between these sections or enhance the theoretical analysis. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or additions are needed to strengthen their draft. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer actionable advice for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful, such as mostly for specular areas. While the comment implies that the authors should consider expanding their discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional discussion on the topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations where the losses are particularly helpful, such as mostly for specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the effectiveness of losses in certain situations, particularly for specular areas. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to discuss which situations the losses are particularly helpful, such as mostly for specular areas. However, it does not provide any specific reasoning, examples, or references to support why this discussion would be valuable or how it could enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful, such as mostly for specular areas. While the comment identifies a potential area for further exploration, it lacks specificity and does not provide actionable guidance on how the authors might expand their discussion. The suggestion is vague and does not offer concrete steps or examples for the authors to follow, making it 3. The feedback provides a direction for potential improvement but does not fully address the needs of the authors for actionable guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the lack of explanation for determining n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. It also notes that the answer is not found in reference 30. While the comment identifies a specific issue with the clarity of the algorithm, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to clarify the determination of n_t and the meaning of \"appropriate number,\" but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific area for clarification but does not provide detailed guidance on how to implement the change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of explanation for determining n_t and the ambiguity of the term \"appropriate number.\" The comment further notes that the answer is not found in reference 30, providing specific guidance on where to look for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the lack of explanation for determining n_t in Algorithm 2 and the ambiguity of the term \"appropriate number\" in line 225. It also notes that the answer is not found in reference 30. While the comment identifies a specific issue with the clarity of the algorithm, it does not provide detailed reasoning or evidence to support the claim that this is a significant issue. The lack of specific examples or references to substantiate the claim makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is not found in reference 30, which provides a clear and actionable suggestion for the authors to clarify this aspect of their algorithm. By highlighting a gap in the documentation and offering a specific direction for improvement, the comment is 4, as it guides the authors toward addressing a critical area of their draft. However, it could be more helpful if it provided additional context or suggestions on how to improve the explanation of n_t. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the reproducibility issue or what steps they should take to ensure their results are reproducible. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. Without explicit references to specific sections or parts of the paper, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of reproducibility are challenging or how the authors might improve it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code\"s availability is crucial. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. While it identifies a potential issue with the paper, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern or improve the reproducibility of their results. Without actionable feedback or specific recommendations, the comment does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not provide specific guidance or suggestions on how the authors might strengthen their evidence or improve their claims. The comment lacks actionable details, such as recommending additional experiments or data analysis that could support the claim. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in detailing what aspects of the experiments are insufficient or how the evidence could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the claim about the \"mixing time\" is not sufficiently supported by experiments. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the claim that \"in practice the mixing time is even better,\" stating that it is not sufficiently supported by experiments. This feedback highlights a potential weakness in the paper\"s evidence and suggests that the authors need to provide more robust experimental support to strengthen their claims. However, the comment lacks specific guidance on how to improve the experiments or what additional evidence is needed. While it identifies an area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, implying that the current representation of A as a single attribute could be expanded to include multiple attributes. However, the comment does not provide explicit guidance on how to implement this extension or what specific attributes should be included. The action is implicit and somewhat vague, as the authors need to infer the details of the extension themselves. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where A is currently defined. Without explicit references or detailed context, the authors may find it challenging to determine the exact area needing revision. The comment is specific in its suggestion to extend A to a vector form, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it could be implemented. Without such justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. This feedback is 3 as it identifies a potential enhancement to the current representation of A. However, it lacks specificity and does not provide guidance on how to implement this extension or what specific attributes should be included. The authors are left with a suggestion but without detailed instructions on how to apply it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the novelty of their method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed transductive method, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, it does not specify which part of the paper discusses the transductive method or how it is related to selftraining methods. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the method\"s novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is related to a common approach of incorporating unlabeled data in semisupervised methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses skepticism about the novelty of the proposed transductive method, suggesting that it is related to a common approach of incorporating unlabeled data in semisupervised methods. While it identifies a potential issue with the novelty of the method, it lacks specific details or examples to support this claim. The comment does not provide actionable feedback or suggestions for how the authors might address this concern or improve the novelty of their approach. Without actionable guidance, the comment is not helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should include these missing papers in their comparison, but it does not specify how to integrate them or what specific aspects should be covered. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison, mentioning that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is in, making it weakly grounded. The comment is specific in pointing out the missing papers, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, the comment does not provide specific examples or detailed reasoning to support why these papers are relevant or how their inclusion would improve the comparison. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing papers to enhance the depth and comprehensiveness of their comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate these papers or what specific aspects of the comparison should be expanded upon. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific guidance on how to modify the usage or what alternative terms might be more appropriate. The action is implicit, as the authors need to infer that they should be more cautious with the use of the word \"equivalent,\" but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the use of the word \"equivalent,\" suggesting a more cautious approach, especially when the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent,\" particularly when the equivalence is not verified. However, it does not provide specific examples or reasoning to support why this is a concern or how it affects the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"equivalent\" in the paper, particularly when the equivalence is not verified. It suggests a more cautious approach to using this term, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific guidance on how to address the issue or alternative terms that could be used. While it highlights an important area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the lack of detailed analysis of differences and similarities between the views, particularly in the context of clustering paraphrases of the word \"slip.\" While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The suggestion to conduct a more detailed analysis is implicit and lacks concrete steps on how to implement it. Therefore, the comment is 3, as it points out a specific area for improvement but does not offer detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the usefulness of other views and the lack of detailed analysis of differences between views. The comment is specific in detailing what needs to be addressed, such as a more detailed analysis of the different views and their differences. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the multiview clustering approach, particularly regarding the dominance of the paraphrase similarity view. It questions the usefulness of other views and lacks detailed analysis of their differences. The comment provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but it does not offer further analysis or comparisons. While the comment highlights a potential issue, it lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides some context but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the multiview clustering approach, particularly noting that the paraphrase similarity view consistently outperforms other views and their combinations. It questions the usefulness of the other views and highlights the need for a more detailed analysis of their differences and similarities. The comment provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but it lacks further analysis or discussion of other views. While the comment identifies a gap in the analysis, it could be more helpful if it offered suggestions on how to conduct a more comprehensive analysis or what specific aspects should be examined. Overall, the comment is 3 as it points out an area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests maintaining consistency in the typesetting of BertScore and BLEURT throughout the paper, recommending the use of either \"Bertscore\" or \"Bleurt\" consistently. This provides a clear and direct action for the authors to take, ensuring that the typesetting is uniform. The comment is explicit and concrete, giving the authors a straightforward path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the typesetting of BertScore and BLEURT throughout the paper, suggesting that consistency should be maintained. However, it does not specify which parts of the paper are affected by this inconsistency, making it weakly grounded. The comment is specific in its suggestion to maintain consistency, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that BertScore and BLEURT are inconsistently typeset throughout the paper, recommending consistency in the typesetting. However, the comment does not provide any specific examples or reasoning to support why this inconsistency is problematic or how it might affect the paper\"s clarity or professionalism. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a minor but noticeable inconsistency in the typesetting of BertScore and BLEURT throughout the paper. It suggests maintaining consistency in the typesetting to improve the paper\"s professionalism and readability. While the comment points out a specific issue, it does not provide detailed guidance on how to achieve consistency or why it is important. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with a general suggestion rather than a comprehensive plan for addressing the issue. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate this issue or what steps they should consider. The comment lacks specificity and does not offer any actionable advice, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or details about the Greek issue or how it relates to the paper. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for information, expressing interest in understanding whether other multilingual pretraining setups also struggle with Greek. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. While it identifies a potential area of concern, it does not provide any specific guidance or suggestions for the authors to address this issue. The comment lacks actionable feedback or detailed insights that could help the authors improve their draft. As a result, it is 2, as it provides a general idea but does not offer concrete steps for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the text in lines 293295, stating that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should address this issue by providing a clearer explanation or justification. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the text but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement. Without detailed justification or evidence, the claim remains 1, as it lacks the necessary support to help the authors understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text in lines 293295, noting that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification to address this issue. While the comment highlights a potential area of improvement, it lacks detailed guidance or specific suggestions on how to enhance clarity. The feedback is 3 as it points out a specific area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should consider using realworld datasets, it does not provide specific guidance on how to implement this change or which realworld datasets would be most appropriate. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the use of synthetic datasets or the outofdistribution setting, making it weakly grounded. The comment is specific in its suggestion to use realworld datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any specific reasoning or evidence to support why realworld datasets are more appropriate or why synthetic datasets are insufficient for the outofdistribution setting. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential limitation in the current experimental setup and provides a direction for improvement. However, the comment lacks specific guidance on which realworld datasets would be most suitable or how to incorporate them into the study. To be more helpful, the comment could include examples of realworld datasets or suggest specific criteria for selecting them. Overall, the feedback is 3 as it points out an area for enhancement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a vague explanation in the last paragraph of Section 3, specifically mentioning lines 207210. However, it does not provide explicit guidance on how to improve the explanation or what specific aspects need clarification. The comment consists of questions or comments, which imply that the authors should address the vagueness, but it does not offer concrete steps or suggestions on how to do so. As a result, the authors are left without a clear understanding of what actions to take to improve the draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific part of the paper, mentioning the last paragraph of Section 3 (lines 207210) on the single image case. This provides full grounding, allowing the authors to accurately identify the section being addressed. The comment also specifies the issue by noting that the explanations are vague, giving the authors a clear idea of what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and comments regarding the clarity of explanations, specifically mentioning the last paragraph of Section 3. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any suggestions or guidance on how to improve the clarity or what aspects of the explanation are unclear. This lack of actionable feedback limits the usefulness of the comment for the authors, as it does not offer concrete steps or examples to address the identified issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. While the comment implies that the current setup might be limiting, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should consider extending the model to multiple vehicles, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it prompts the authors to consider a potential extension but does not provide specific steps or suggestions for implementation.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about scalability, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the model\"s practicality. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the approach, specifically asking if it is feasible to extend the model to multiple trucks and drones. This feedback is valuable as it challenges the authors to consider the practical implications of their work and suggests a direction for potential future research. However, the comment does not provide specific guidance or suggestions on how to address this scalability issue, such as proposing methods or techniques for extension. While it prompts the authors to think about broader applicability, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not explicitly instruct the authors to make these changes. The comment implies that the authors should address this inconsistency, but it lacks concrete guidance on how to implement the suggested changes. The action is implicit and somewhat vague, as the authors know they need to address the inconsistency but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the number of biases in the paper, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not specify why this is a concern or what the implications are. The comment is fully grounded as it references a specific section of the paper, allowing the authors to accurately identify the part being addressed. However, it is underspecific because it lacks detailed explanation of the issue or suggestions for improvement. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the inconsistency in the number of biases in the paper, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, but it does not provide specific examples or references to support these claims. The comment lacks detailed reasoning or evidence to substantiate the assertion that the number of biases is confusing or incorrect. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper regarding the number of biases, particularly in the context of feedforward models described in section 3.4. It suggests that the resulting volume should be WxHx1 and that the bias should be a scalar, which is a clear and actionable point for the authors to address. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve this issue or if it pointed out the potential consequences of this inconsistency. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended and do not offer guidance on how the authors should address these issues in their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not specify which part of the paper these questions relate to, such as a particular section, figure, or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its questions about the impact of MC samples and network structure, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking about the impact of the number of MC samples on performance and the influence of network structure on this aspect. These questions are factual inquiries seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. While these questions are relevant and could help the authors explore important factors affecting their results, they do not provide specific guidance or suggestions on how to address these issues in the draft. The feedback lacks actionable advice or detailed insights that would enable the authors to improve their work. As a result, the comment is 3, as it identifies areas for further exploration but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This explicit suggestion provides clear guidance on what needs to be done to improve the paper. The authors are given a concrete task to enhance the readers\" understanding of the quality of the reconstruction. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include smoothed GT shapes, but without explicit references to the figures, the authors may find it challenging to pinpoint the exact sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\" understanding of the reconstruction quality. This is a logical suggestion based on the reviewer\"s understanding of the paper\"s content and the potential benefits of including these shapes. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this suggestion based on their own understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific action for the authors to take, which is to include smoothed GT shapes in Figures 3 and 5. This feedback is clear and actionable, as it provides a direct way for the authors to enhance the readers\" understanding of the quality of the reconstruction. By following this suggestion, the authors can improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it provided additional context or reasoning about why this inclusion would be beneficial. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of direct comparisons between the proposed approach and the baseline PRANC, specifically in terms of test accuracy, which is crucial for evaluating the improvement over the baseline. It suggests that the authors should include a direct comparison of test accuracy in their evaluation. While the comment explicitly states the action needed, it does not provide specific guidance on how to conduct this comparison or which metrics to use. The authors are aware of what needs to be done but may require additional information to fully implement the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, which is crucial for evaluating the improvement over the baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, which is crucial for evaluating the improvement over the baseline. The reviewer provides specific sections (3.4 and 3.5) where comparisons are made, but these comparisons are limited to training loss and the rank of possible solutions. The claim is 3 as it identifies a specific area where the comparison is lacking, but it could be strengthened by providing more detailed reasoning or examples of how test accuracy comparisons would enhance the evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons of test accuracy with the baseline PRANC. It highlights that while there are comparisons of training loss and the rank of possible solutions, these do not provide a comprehensive evaluation of the proposed approach\"s performance. The comment is clear and actionable, as it directs the authors to include a direct comparison of test accuracy, which is crucial for assessing the improvement over the baseline. This feedback is valuable as it guides the authors in enhancing the robustness and comprehensiveness of their evaluation, making the comment 4. However, it could be more helpful if it suggested specific methods or metrics for comparing test accuracy. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether EMAweighting is used for other baseline models in Table 3. It suggests that knowing whether all models being compared utilize the EMA benefits would ensure a fair comparison. While the comment does not explicitly instruct the authors to make this clarification, it is clear that the authors should address this issue to provide a more accurate comparison. The action is implicit but concrete, as the authors can directly infer that they need to clarify the use of EMAweighting across all models. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether EMAweighting is used for other baseline models, such as \"Supervised,\" and suggests that knowing this would ensure a fair comparison. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of EMAweighting in Table 3 for other baseline models. It suggests that knowing whether all models use EMA benefits would ensure a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how it impacts the fairness of the comparison. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the use of EMAweighting in Table 3 for other baseline models, such as \"Supervised,\" and suggests that knowing this would ensure a fair comparison. This feedback is clear and actionable, as it directs the authors to clarify a potential issue in their comparison methodology. By addressing this concern, the authors can improve the transparency and fairness of their results. However, the comment could be more helpful if it provided additional context or suggested how to implement this clarification. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. The comment also provides a presentation suggestion. While the action of questioning the hyperparameters and suggesting a presentation improvement is explicit, the comment lacks concrete guidance on how to address the issue of hyperparameters or how to present the results effectively. The authors know they need to investigate the hyperparameters and consider presentation suggestions, but the comment does not provide detailed steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion for presentation is specific, but the lack of grounding makes it challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. However, the comment lacks specific evidence or detailed reasoning to support the claim that the SCNN is \"lucky\" or to explain why the distance to the next best model is suspiciously large. Without additional context or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the SCNN\"s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. While the comment identifies a potential issue with the model\"s performance, it lacks specific guidance on how to address the concern about the hyperparameters or how to present the results effectively. The suggestion for presentation is a positive addition, but the overall feedback could be more actionable if it included detailed steps or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what aspects need clarification or how to improve the motivation. The comment lacks concrete details or suggestions on how the authors might address these issues, leaving the authors uncertain about the specific steps to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies specific areas of the experimental setup that are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the clarity and motivation of the experimental setup, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. While it points out a potential issue, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve the clarity of their experimental setup. The comment provides a starting point for the authors to consider, but it does not offer actionable steps or specific examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison of the model size (in terms of depth or number of parameters) to competing approaches. It also points out that the authors mention the number of hourglass modules but do not specify their size. This comment implies that the authors should provide more detailed information about the model size to facilitate a better comparison with competing approaches. While the action is implicit, it is clear and specific, guiding the authors on what additional information is needed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the model size to competing approaches, specifically mentioning the number of hourglass modules. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in asking for clarification on the size of the model, including the number of parameters or depth, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This comment is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This feedback is 3 as it identifies a gap in the paper\"s presentation, prompting the authors to provide more detailed information about the model size. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific aspects of the model size are relevant for comparison. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, stating that it does not provide better results compared to previous theoretical results. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the metric perspective analysis, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the metric perspective analysis is not better. The reference to Bartlett et al. (2017) provides some context, but it does not substantiate the claim. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, suggesting that it does not provide better results compared to previous theoretical results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential weakness, it does not offer actionable feedback or detailed advice on how to strengthen the paper\"s theoretical foundation or results. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests moving some visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also provides a concrete suggestion to condense the existing figures on the network architecture to make room for additional visual results. This feedback is clear and provides specific guidance on how the authors can improve their draft by enhancing the visual representation of their work. The action is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically mentioning the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also provides a suggestion to condense existing figures on the network architecture to accommodate these visual results. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the main paper and the supplementary material. The suggestion is specific, as it provides a clear direction for improving the paper by enhancing the visual representation of the results. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. The reviewer provides a concrete suggestion to condense existing figures on the network architecture to make room for these visual results. This feedback is clear and provides a specific action for the authors to take, making it 4. However, it could be strengthened by providing examples of the visual results that should be moved or more detailed guidance on how to condense the figures. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to move visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also offers a concrete suggestion to condense existing figures on the network architecture to make room for these visual results. This feedback is 5 as it not only identifies a specific area for improvement but also provides a detailed and actionable plan for enhancing the paper\"s visual representation and clarity. By following this advice, the authors can significantly improve the presentation and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. However, the reasoning provided gives the authors a clear understanding of the benefits of using WebQuestions, making the action somewhat explicit. The authors know what needs to be done but may need to infer the exact steps to implement the change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of dataset used in the study, specifically mentioning \"WebQuestionsSP\" and suggesting the use of \"WebQuestions (Berant et al., 2013) benchmark set.\" This provides full grounding as it explicitly mentions the dataset being discussed, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a change in dataset choice and provides a rationale for why this change would be beneficial, such as facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that WebQuestionsSP is not the most appropriate choice. While the suggestion is logical and based on common practices in the field, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the choice of dataset used in the study. It suggests using the WebQuestions benchmark set instead of WebQuestionsSP, reasoning that this choice would be more intuitive and facilitate direct comparison with mainstream QA research. This feedback is valuable as it offers a specific and logical alternative that could enhance the relevance and impact of the study. However, the comment could be more helpful if it included additional details on why WebQuestions might be a better fit or how it could improve the study\"s outcomes. Overall, the comment is 4 as it directs the authors to a more appropriate dataset choice, but it could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not explicitly instruct the authors to remove or modify these claims, nor does it provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to substantiate their claims, but they are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. However, the comment does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique of the claims, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. While the comment provides a logical argument questioning the desirability of sparsity, it lacks specific examples or references to support the claim. The suggestion to demonstrate the benefits or provide evidence of cost savings is a reasonable request, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. This feedback is 4 as it identifies a potential weakness in the paper\"s claims and offers a clear direction for improvement. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate the benefits or evidence of cost savings. Overall, the comment is 4 as it guides the authors towards a more substantiated argument, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically mentioning ImageNet derivatives. It explicitly states that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is important and that these results should be presented in the main paper. This provides a clear and direct action for the authors to take, which is to include additional results on these datasets. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks analysis or results on other datasets, specifically mentioning ImageNet derivatives. It implies that the authors should verify the effectiveness of their framework on ImageNet1k or ImageNet100 and include these results in the main paper. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the results or discussion sections where the current analysis is presented. The comment is specific in suggesting that additional results should be included, but it lacks full grounding as it does not directly reference a section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically mentioning ImageNet derivatives. It claims that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is important and that these results should be presented in the main paper. However, the comment does not provide specific examples or detailed reasoning to support why these datasets are crucial or how they would enhance the paper\"s impact. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the importance of these datasets themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by pointing out the lack of results on other datasets, specifically mentioning ImageNet derivatives. It suggests that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is crucial and should be included in the main paper. This feedback is clear and actionable, as it directs the authors to expand their analysis and present additional results that would enhance the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it provided specific suggestions on how to present these results or what aspects of the framework\"s effectiveness should be emphasized. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. This feedback provides a clear and explicit action for the authors to take, which is to ensure consistency in the terminology throughout the paper. The suggestion is concrete, as it specifies the action needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the inconsistency in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. It suggests that the authors should clarify this inconsistency or provide an explanation for treating them as models. However, the comment does not specify which sections of the paper this inconsistency occurs in, making it weakly grounded. The feedback is specific in identifying the issue with the inconsistent use of terms, but without explicit references to sections, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that BigFive and MBTI are initially mentioned as models to be extended but are later used as datasets, suggesting that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. The comment provides a logical reasoning for the inconsistency, which is a form of commonsense argument. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact sections where this inconsistency occurs, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. This feedback is clear and actionable, as it provides a straightforward suggestion for improving the consistency and clarity of the paper. By addressing this issue, the authors can enhance the coherence and accuracy of their presentation. Therefore, the comment is rated as 5, as it offers a specific and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the authors\" claim that the readability of RC datasets does not directly affect question difficulty, but it suggests that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment implies that the authors should consider these factors, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate this information into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of different features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the impact of dataset readability on question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the dependence on method or features for answer detection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges a claim made by the authors about the impact of dataset readability on question difficulty, stating that it depends on the method or features used for answer detection. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a claim made by the authors regarding the impact of dataset readability on question difficulty, stating that it depends on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it challenges the authors\" initial claim and suggests that their analysis might be limited in scope. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or expand their analysis. To be more helpful, the comment could offer examples of how different features might influence the results or suggest additional methods for exploring this dependency. Therefore, the comment is rated as 3, as it prompts the authors to consider a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically mentioning the need to address the repetition of explaining basic memory networks and the forward model. It also points out that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not provide specific guidance on how to improve the writing quality or what aspects of the related work should be expanded. The authors are left with a general understanding of what needs to be addressed but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not specify which sections of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing quality is being evaluated in general, but the lack of specific references or examples makes it difficult to pinpoint the exact parts needing improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work lacks pieces on more reinforcement learning tasks. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for improvement in the writing quality of the paper, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also points out a gap in the related work section, suggesting that more reinforcement learning tasks should be included. However, the comment lacks specific guidance or suggestions on how to address these issues, such as providing examples of how to improve the writing or what additional tasks should be included in the related work section. While it highlights areas for improvement, the feedback is 3 as it provides a general direction but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the notation and assumptions in the paper, specifically regarding the replacement of the first column of Qo with vo to form P\"o. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (termination) should be considered. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or modify their assumptions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo with vo to form P\"o, and it suggests that either Assumption 1 or Assumption 2 should be considered. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the notation and assumptions in the paper, specifically regarding the replacement of the first column of Qo with vo to form P\"o. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (termination) should be considered. However, the comment does not provide specific examples or detailed reasoning to support why these assumptions are relevant or how they impact the paper. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation and assumptions in the paper, specifically regarding the replacement of the first column of Qo with vo to form P\"o. It suggests that either Assumption 1 (finite length of an option) or Assumption 2 (termination) should be considered. This feedback is 3 as it points out a potential area for clarification or correction, but it lacks depth and does not provide detailed guidance on how the authors should address this issue. The comment could be more helpful with additional context or suggestions on how to resolve the identified problem. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the sequential relationship in a recurrent model. While the comment implies that the authors should explore these areas, it does not provide explicit guidance on how to identify or measure these improvements. The action is somewhat vague, as it does not specify which specific properties to focus on or how to assess them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the sequential relationship in a recurrent model. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in suggesting areas to explore for improvement, such as accuracy and the sequential relationship, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the sequential relationship in a recurrent model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these properties might be more relevant or how they could be improved. Without specific references or detailed explanations, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the sequential relationship in a recurrent model. This feedback is 3 as it provides a direction for the authors to explore alternative areas for improvement beyond FLOPs and inference time. However, the comment lacks specificity and does not offer detailed guidance on how to assess or measure these properties. To be more helpful, the comment could include examples or methods for evaluating these properties, making it more actionable for the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this assumption should be tested or how to address it. The comment lacks specificity and does not offer any concrete steps for the authors to follow, making it 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not specify which part of the paper this assumption is made in. The authors cannot confidently determine the exact section or part of the paper being addressed, making the comment weakly grounded. However, it is specific in questioning the validity of the assumption, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that d_e are good replacements for entity embeddings, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the assumption that d_e are good replacements for entity embeddings, questioning whether this assumption has been tested. This feedback is valuable as it prompts the authors to consider the validity of their approach and potentially conduct further testing or analysis. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the threshold values/ranges. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting specific steps to clarify or provide additional details. Without actionable guidance, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the clarity of the \"scoring function\" and the threshold values/ranges, but it does not specify which part of the paper this information is located in. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing what is unclear, namely, the derivation of the components of the scoring function and the threshold values/ranges. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the \"scoring function\" and the threshold values/ranges, but it does not provide any specific examples, references, or detailed reasoning to support the claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the derivation of the components of the \"scoring function\" and the threshold values/ranges. This feedback is clear and actionable, as it points out a gap in the clarity of the methodology section. By highlighting this issue, the authors are prompted to revisit and clarify these aspects, which could significantly improve the transparency and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify these components or offered examples of how to address the issue. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of their work might be affected by this inquiry. The comment lacks any explicit or implicit actions for the authors to take, leaving them without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or guidance on how the authors might address this question or what aspects of their work might be affected by it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of their work might be affected by it. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for consideration but does not offer substantial guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include more datasets with categorical features or employ onehot encoding, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Model Comparison\" and \"datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. The comment further specifies that the authors do not employ onehot encoding for this dataset, which could negatively impact performance for some models. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen selection of datasets is inadequate for a variety of reasons, specifically noting that only one dataset has categorical features, which are generally more challenging for deep learning models. The comment also points out that the authors do not employ onehot encoding for this dataset, which could negatively affect performance for some models. While the comment provides logical reasoning and common knowledge about the challenges posed by categorical features and the importance of onehot encoding, it lacks specific references or examples to fully substantiate the claim. This makes the claim 3, as it provides a basis for the critique but could be strengthened with additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it highlights a potential weakness in the paper\"s experimental setup and suggests a specific area for improvement. By addressing this issue, the authors can strengthen their claims about the thoroughness of their model comparison. However, the comment could be more helpful if it provided additional guidance on how to incorporate onehot encoding or other strategies to handle categorical features. Overall, the comment is 4, as it effectively directs the authors to a critical area for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses dissatisfaction with the choice of two IoT datasets, suggesting that they are unpopular and not wellsuited for benchmarking. It implies that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. However, the comment does not provide explicit guidance on how to make these changes or which specific datasets to consider. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their dataset choices, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of IoT datasets, noting that they are unpopular and not wellsuited for benchmarking. The reviewer suggests alternative datasets, such as wearable health or mobile activity recognition data, or sets from the UCI repository, providing clear guidance on what the authors should consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of two IoT datasets is \"unpopular\" and \"weird,\" suggesting that the datasets are not wellsuited for benchmarking. The reviewer provides reasoning by noting that the FlatCam Face dataset is relatively recent but not substantially followed, and the Headpose detection dataset was published in 2004 and is no longer widely used. This provides some logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these datasets are not suitable for benchmarking. The suggestion to consider better options, such as wearable health or mobile activity recognition data, adds some context but does not fully substantiate the initial claim. Therefore, the comment is 3, as it provides some reasoning but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets in Section 4, specifically the two IoT datasets mentioned. It points out that these datasets are not widely used and suggests that the authors should have considered better options for benchmarking, such as wearable health or mobile activity recognition data. This feedback is 3 as it highlights a specific area for improvement in the paper, namely the choice of datasets for benchmarking. However, the comment could be more helpful if it provided specific examples or guidance on how to select better datasets or what criteria to consider when choosing datasets for benchmarking. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they check the figures or provide a correction. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. This provides full grounding as it explicitly mentions the figures being addressed, allowing the authors to accurately identify the parts of the paper being discussed. The comment is also specific because it clearly specifies the issue of potential swapping, giving the authors a clear direction to investigate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. While this is a valid observation, it lacks actionable guidance or suggestions for the authors to address the issue. Without further explanation or context, the authors are left without a clear understanding of how to investigate or correct the potential error. Therefore, the comment is 2, as it identifies a potential issue but does not provide actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of dropout probes. It suggests that this aspect should be included in the discussion. While the comment implies that the authors should address this concern, it does not provide explicit guidance on how to incorporate this discussion or what specific points should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of dropout probes and their potential impact on sensitivity and the identification of causal roles. It raises a concern about the risk of false positives and suggests that this should be a substantial part of the discussion. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion section, but the lack of explicit mention of a section or specific part of the paper makes it difficult to pinpoint. The comment is specific in identifying the concern about false positives and suggesting their inclusion in the discussion, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential increase in false positives due to the use of dropout probes. It acknowledges the improvement in sensitivity and the identification of causal roles but suggests that this should be a substantial part of the discussion. The comment provides a logical reasoning for the concern, as it highlights the potential for false positives when using dropout probes. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the potential increase in false positives when using dropout probes to improve sensitivity and identify causal roles. It suggests that this aspect should be included in the discussion, which is a constructive and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to address this concern or integrate it into the discussion. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs further exploration and discussion."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the regret bound for the proposed minibatch method, stating that it is claimed to be in the appendix but not found in the supplementary material. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as whether they should clarify the location of the regret bound or provide it in the main text. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regret bound for the minibatch estimator,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of the regret bound in the supplementary material, despite the authors\" claim that it is there. The comment provides a clear reference to a specific external work, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which helps the authors understand the context of the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the regret bound for the minibatch method being in the appendix is not supported by the supplementary material. The reviewer provides a specific reference, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which could be used to verify the claim. However, the comment does not explicitly mention where in the supplementary material the regret bound is supposed to be found, which could make it slightly more difficult for the authors to address the issue. Despite this, the reference provides a clear direction for the authors to verify the claim, making the comment 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim the regret bound for the minibatch method is in the appendix but the reviewer did not find it in the supplementary material. This is a clear and actionable feedback that highlights a potential oversight or error in the paper\"s presentation. By pointing out this discrepancy, the comment provides the authors with a specific area to address, which could be crucial for ensuring the completeness and accuracy of their work. However, the comment could be more helpful if it suggested how the authors might resolve this issue or where the regret bound should be located. Overall, the comment is 4 as it directs the authors\" attention to a critical oversight, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a significant issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on which specific exploration methods should be discussed or compared, or how these comparisons could be made. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing what is missing, namely the discussion and comparison of these exploration methods, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support the claim that these methods are essential or relevant to the paper\"s focus. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss or compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of different exploration techniques. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should investigate these aspects and provide more details, but the lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. It provides clear guidance on what needs to be addressed, such as the need for more detailed information about hyperparameters and the importance of careful writing. However, the comment does not explicitly mention specific sections or lines of the paper, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies these issues, it does not provide specific examples or detailed reasoning to support the claims. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies several critical issues in the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. It provides specific questions and observations that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as providing examples of how to optimize inference or how to clarify the writing. Overall, the comment is 3 as it highlights areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this comparison or where the authors should focus their efforts to improve the method. The authors can infer that it relates to the comparison section or results, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the performance issue, but without clear references to the paper, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. However, the comment does not provide any supporting evidence, such as specific results or comparisons, to substantiate this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a valuable observation that highlights an area where the authors need to improve their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance their method. Without actionable feedback or detailed advice, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some subjective statements in the paper are inappropriate and recommends providing proofs and references to support the statements. It also points out that the image recovery performance is sensitive to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific proofs or references to include. The authors are left with a general understanding of what needs to be improved but lack concrete steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses subjective statements in the paper and suggests the need for proofs and references to support them. It also points out the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. However, the comment does not specify which parts of the paper contain these subjective statements or where the proofs and references should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections to address. The comment is specific in detailing what needs to be addressed, such as providing proofs and references, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some subjective statements in the paper are inappropriate and suggests the need for proofs and references to support them. It also highlights the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment provides some reasoning by mentioning the sensitivity of performance and the challenge of multiscale architecture design, but it lacks specific examples or references to substantiate the claims fully. This makes the claim 3, as it provides some support but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved. It points out subjective statements that lack supporting evidence and suggests the need for proofs and references to substantiate them. Additionally, it highlights the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment also mentions that models with skip connections could be regarded as using multiscale information implicitly, which is a relevant observation. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues. Overall, the feedback is 3 as it directs the authors to areas that need clarification or support, but it lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that the authors should consider comparing biases towards different languages/nationalities. While the comment suggests an area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the detailed analysis of different languages/nationalities and suggests an interesting observation to compare biases. The comment provides clear guidance on what could be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that there might be interesting observations comparing biases towards different languages/nationalities. However, the comment does not provide specific examples or detailed reasoning to support the claim that these comparisons would be interesting or necessary. The suggestion lacks concrete evidence or examples to substantiate the claim, making it 3. The authors would need to infer the potential significance of these comparisons, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It points out that biases towards different languages/nationalities might be different and suggests that there could be interesting observations comparing them. This feedback is 3 as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, it could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific observations might be interesting. Overall, the comment offers a direction for enhancing the analysis but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, the comment does not provide specific guidance on which properties to explore or how they might be incorporated into the approach. The action is implicit and somewhat vague, as the authors need to infer the specific properties to consider and how to integrate them into their design. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the methodology or approach section, but this inference is not explicit. The comment is specific in suggesting that other properties should be considered, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, the comment does not provide any specific reasoning, examples, or references to support why these additional properties are necessary or how they might enhance the approach. Without such evidence or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. This feedback is 3 as it identifies a potential area for improvement in the methodology or approach section of the paper. However, it lacks specificity and does not provide guidance on which properties to explore or how they might be incorporated into the design. The authors are left with a general suggestion but without detailed instructions on how to implement it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to address this expectation. The comment lacks specificity and does not provide any concrete steps or suggestions for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not specify which part of the paper this feedback pertains to, such as a particular section, table, or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment lacks specificity as it does not provide examples or detailed suggestions on how to expand the tasks or improve the importance of PE. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or references, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. While this feedback provides a general direction for the authors to consider, it lacks specificity and actionable guidance. It does not offer any detailed suggestions or examples of how to expand the tasks or improve the importance of PE. As a result, the comment is 3, as it gives the authors a broad idea of what to consider but does not provide the depth or detail needed for a comprehensive improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of the authors\" work with other papers focusing on semantic face editing, specifically mentioning the ability to achieve continuous control over attributes. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in identifying the need for elaboration on the differences between the authors\" work and these papers, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there are other works in the field of semantic face editing that achieve continuous control over attributes, and it suggests that the authors should elaborate on the differences between their work and these papers. However, the comment does not provide specific examples or references to these other works, making it difficult for the authors to understand the context or basis of the claim. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to support the assertion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment points out that there are other works in the field of semantic face editing that achieve continuous control over attributes. It suggests that the authors should elaborate on the differences between their work and these papers. This feedback is 3 as it highlights a potential area for improvement by pointing out the need for a more detailed comparison with existing literature. However, the comment lacks specific guidance on how to elaborate on the differences or what aspects should be emphasized, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. However, the comment does not explicitly instruct the authors to include this discussion or remove the zeroshot results. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations and questions the inclusion of zeroshot generation results. However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in its suggestion to include a discussion about fewshot demonstrations and questions the relevance of zeroshot results, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. However, the comment does not provide specific reasoning or evidence to support this claim, such as references to similar studies or discussions about the relevance of zeroshot results in the context of the paper. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities rather than being relevant to the main focus of the paper. It also suggests that a discussion about a set of fewshot demonstrations could be beneficial, offering a specific area for improvement. However, the comment lacks detailed guidance on how to integrate these suggestions into the paper or why they are important. While it points out a potential weakness, it could be more helpful with additional context or examples. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. However, the comment does not provide explicit instructions or guidance on how to compute the effective receptive field or what specific improvements should be expected. The action is implicit and somewhat vague, as the authors need to infer that they should compute the effective receptive field and compare it before and after applying the GS module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the GS module for propagating context information over different spatial locations and questions whether the effective receptive field is improved. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. However, the comment does not explicitly mention which part of the paper discusses the GS module or the effective receptive field, making it weakly grounded. The comment is specific in its inquiry about the effective receptive field and its improvement after applying the GS module, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. However, the comment does not provide detailed reasoning or evidence to support the claim that the effective receptive field is improved. The reference to 2 is a step towards verification, but it lacks specific examples or detailed explanations of how the effective receptive field is computed or improved. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. This feedback is 3 as it prompts the authors to consider a specific aspect of their work that could be improved or further explored. However, the comment lacks detailed guidance on how to compute the effective receptive field or what specific improvements might be expected. To be more helpful, the comment could provide more detailed instructions or examples on how to compute the effective receptive field and what improvements might be expected. Therefore, the comment is rated as 3, as it identifies an area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues contributing to the high time complexity of the proposed method. It points out the use of an itemoriented autoencoder, which may involve many users associated with a typical item, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps to reduce the time complexity. The authors are left to infer that they need to optimize the model or explore alternative approaches, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of high time complexity in the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues related to time complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment lacks specific examples or detailed reasoning to support these claims. While the reviewer identifies potential sources of high time complexity, the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some support but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several factors contributing to the high time complexity of the proposed method, including the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback is 3 as it points out specific areas where the authors might need to focus on to improve the efficiency of their approach. However, the comment lacks detailed suggestions or guidance on how to address these issues, such as proposing alternative methods or optimizations. While it highlights potential areas for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This feedback provides a clear and explicit action for the authors to take, as it directly instructs them to clarify the figures by specifying the types of autoencoders used. The suggestion is concrete, as it specifies what needs to be changed and how to make the figures more clear. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This feedback is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed in terms of clarity and detail regarding the types of autoencoders used. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of \"autoencoders.\" This is a subjective suggestion based on the reviewer\"s opinion that specifying the types of autoencoders used would enhance clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would improve clarity. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. It suggests that specifying \"pretrained solution encoders & solution decoders\" instead of \"autoencoders\" would enhance the clarity of the figures. This feedback is actionable and provides a clear direction for the authors to improve the presentation of their results, making it 4. However, it could be more helpful if it included examples of how this change would be beneficial or if it suggested other ways to enhance clarity. Overall, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also recommends removing the occlusion experiment as it does not seem relevant to the proposed method. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. The actions are clear, but the lack of specific instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific comparisons, such as with NeRFbased methods like Zero1to3 and pointe, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, noting that it does not seem to propose anything specific to occlusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several suggestions for improvements, such as recommending comparisons with specific methods like Zero1to3 and pointe, and questioning the relevance of the occlusion experiment. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the suggestions and how to address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement, including the need to compare the work with NeRFbased methods like Zero1to3 and pointe. This feedback is actionable and helps the authors understand what additional comparisons would strengthen their paper. However, the comment could be more helpful if it included specific guidance on how to conduct these comparisons or what aspects to focus on. Additionally, the comment questions the relevance of the occlusion experiment, which is a minor point. Overall, the comment is 4 as it offers clear directions for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide information about the computational requirements of the experiments, including the time taken and the hardware used. This request is clear and direct, giving the authors a specific action to take in terms of providing additional details about the computational aspects of their work. The comment is explicit and concrete, as it directly instructs the authors on what information to include, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the computation required to implement the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the time taken for the experiments and the hardware used, providing clear guidance on what additional details are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements of the experiments, specifically asking for details on the time taken and the hardware used. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide additional information about the computational requirements of their experiments. This includes details on the time taken for the experiments and the hardware used. By addressing this request, the authors can provide more context and transparency about their experimental setup, which is valuable for readers and reviewers. However, the comment could be more helpful if it suggested specific ways to present this information or highlighted the importance of this information for the readers. Overall, the comment is 4 as it directs the authors to include important details that enhance the comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of missing data on the model and its ability to leverage additional modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. While the comment is specific in its inquiry about the impact of missing data, it lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or justification, the claim remains 1, making it difficult for the authors to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It prompts the authors to consider whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. This question is relevant and could lead to valuable insights into the robustness and generalizability of the model. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or explore these questions further. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of verification of the stability of the OGEAug on OOD benchmarks, specifically on the DrugOOD dataset, where SPE is validated. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to verify the stability. The comment implies that the authors should conduct additional experiments or analyses to assess the stability of OGEAug on DrugOOD, but it does not offer concrete instructions or suggestions on how to implement these steps. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of verification of the stability of the OGEAug on OOD benchmarks, particularly on the DrugOOD dataset. It specifies that the authors should address this by validating the stability of their method on this dataset, where SPE is already validated. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the verification of stability on DrugOOD. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of their method, OGEAug, on OOD benchmarks such as DrugOOD, where another method, SPE, is validated. However, the comment does not provide specific examples or detailed reasoning to support why this is a concern or how it affects the paper\"s claims. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the authors\" work could be improved, namely the lack of verification of the stability of their method, OGEAug, on outofdistribution (OOD) benchmarks such as DrugOOD. It highlights that another method, SPE, is validated on this dataset, suggesting that the authors should conduct similar evaluations to ensure the robustness of their approach. However, the comment does not provide detailed guidance on how to perform these evaluations or what specific metrics or analyses should be used. While it points out a potential weakness, the feedback lacks depth and actionable suggestions, making it 3. The authors are given a direction to improve their work but are left to determine the exact steps to take, which limits the comment\"s usefulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments in the paper should be expanded to include multiple seed experiments, which would provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The suggestion is concrete, as it specifies the type of experiments that should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Single Seed Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, which are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests a solution by recommending multiple seed experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. While the claim is logical and makes sense, it lacks specific examples or references to support the assertion that multiple seed experiments would indeed provide a more robust evaluation. This makes the claim 3, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it points out a potential weakness in the current experimental setup and offers a straightforward solution to improve the study\"s reliability and validity. By addressing this issue, the authors can enhance the robustness and generalizability of their findings. Therefore, the comment is rated as 5, as it provides valuable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what alternative approaches they could consider. As a result, the authors are left without a clear direction for improvement, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the use of specific distributions (VMF and truncated normal) to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper discusses these distributions, making it weakly grounded. The comment is specific in questioning the motivation behind the choice of these distributions, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of specific distributions (VMF and truncated normal) to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these distributions are unclear or inappropriate. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It points out that the motivation behind this choice is unclear, which is a valid concern for the authors to address. However, the comment does not provide any suggestions or guidance on how the authors might clarify or justify their choice of distributions. While it identifies an area for improvement, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggestions for alternative approaches that could make the method more accessible. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the accessibility of the proposed method, specifically mentioning the requirement of a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this requirement, making it weakly grounded. The comment is specific in identifying the issue of accessibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential accessibility issue with the proposed method, noting that it requires an entire multiGPU setup for optimizations. This observation is relevant and could be helpful for the authors to consider when discussing the practical implications of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make their method more accessible. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. While the comment provides explicit suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions or what specific aspects to focus on when comparing the systems. The authors are given a clear direction but may need to infer the exact steps to take, making the comment 4.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to compare with another system and use Ref2 as a baseline, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The suggestion to use Ref2 as a baseline is not elaborated upon, leaving the authors without a clear understanding of the rationale behind the recommendation. Therefore, the comment is considered 2, as it provides some guidance but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. This feedback is clear and actionable, providing the authors with specific steps to enhance their work by including additional comparisons and baselines. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these comparisons or what specific aspects to focus on when evaluating the performance. Overall, the comment is 4 as it directs the authors towards meaningful improvements but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on how the quantitative results are obtained, specifically questioning what data is used for training, validating, and testing. This request provides a clear and direct action for the authors to take, which is to provide more detailed information about the data used in their experiments. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"quantitative results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how quantitative results are obtained, specifically asking for more detailed information about the data used for training, validating, and testing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the quantitative results are unclear. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the quantitative results in the paper. It questions the lack of detail on what data is used for training, validating, and testing, which is crucial information for understanding the experimental setup and results. This feedback is clear and actionable, as it provides a direct request for more detailed information, helping the authors to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested specific ways to present this information or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions might be at fault. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in questioning the model\"s performance but lacks grounding, as it does not reference a particular section or figure. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the model\"s performance in identifying true sources in the triangle dataset, but it does not provide any supporting evidence, reasoning, or references to justify why this might be the case. The lack of specific claims or references makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what assumptions might be at fault. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential area of concern but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what steps they could take to improve the generalizability of their approach. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach are limited to two views or how the generalizability to more views could be improved. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without too much difficulty. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without too much difficulty. This feedback is 3 as it points out a potential area for improvement in the generalizability of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their system. To be more helpful, the comment could provide examples of how other systems have successfully generalized to more views or offer suggestions on how to adapt the current approach to accommodate multiple views. Therefore, the comment is rated as 3, as it identifies an area for improvement but does not fully guide the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the user decoder\"s information usage, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The lack of context or explanation makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. This question highlights a potential gap in the paper\"s explanation or methodology, prompting the authors to clarify or justify their approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the discussion on the hyperparameter gamma is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment specifies what needs to be addressed, making it 5. The authors know exactly what information is missing and how to improve their draft by adding this discussion. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the discussion on arbitrary hyperparameter \u03b3,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely, the discussion on how to set the hyperparameter in practice for a given graph and analyzing its sensitivity. This provides clear guidance on what needs to be included, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the hyperparameter gamma is missing, which would make it difficult for researchers to follow. However, the comment does not provide any specific examples, reasoning, or references to support why this is a significant issue or how it affects the paper\"s comprehensibility. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the discussion on the hyperparameter gamma. It points out that this omission makes it difficult for researchers to follow the work, as it is crucial for understanding the practical application and sensitivity of the hyperparameter. By highlighting this gap, the comment provides clear and actionable feedback, encouraging the authors to include a discussion on setting the hyperparameter and analyzing its sensitivity. This feedback is valuable as it directs the authors to a specific area that needs improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of similar analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement this suggestion or specify how to design the controlled baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of different locations (layers) of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting ICL performance when ablating these heads. It implies that a controlled baseline should be established to ablate heads at different locations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for a controlled baseline to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that location is a confounding factor. The suggestion for a controlled baseline is clear, but the claim itself is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the model\"s performance, specifically the location of induction heads and FV heads within the model. It suggests that a controlled baseline should be established to ablate heads at different locations, which could help clarify the impact of these factors on ICL performance. This feedback is clear and actionable, providing the authors with a specific direction for improving their analysis and experimental design. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or discussed potential outcomes of such an analysis. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under the similarity measurement section, specifying that it should describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, namely to include a section on synonym identification that explains the approach to the multiplechoice task. The comment is explicit and concrete, offering a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"a section on synonym identification\" and specifies that it is missing under the \"similarity measurement\" section. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a section on synonym identification that explains the approach to the multiplechoice task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, specifically regarding the multiplechoice task. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence affects the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the significance of the missing section. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of a section on synonym identification under the similarity measurement section. It specifies that this section should describe how the multiplechoice task is approached, providing a clear and actionable suggestion for improvement. By highlighting this omission, the comment helps the authors understand where their draft needs to be strengthened, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to structure this section. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the comment implies that such an overview would be beneficial, it does not explicitly instruct the authors to include it or provide specific guidance on how to structure this overview. The action is implicit and somewhat vague, as the authors can infer the need for an overview but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, making it difficult for the authors to identify the exact sections that need revision. While the comment implies that the overview should be part of the introduction or methodology sections, this is not explicitly stated. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the parts of the paper that need this overview. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While this feedback highlights an area that could improve the paper\"s comprehensibility, it lacks specificity and actionable guidance. It does not specify which parts of the workflow or model should be included in the overview or how it would enhance the paper. This makes it 3, as it identifies a potential improvement but does not provide detailed instructions for implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3, stating that the expected quantities are scalars but are currently shown as a vector. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are currently shown as a vector. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 should be redefined because the expected quantities are scalars but are currently shown as a vector. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change that would necessitate evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the redefinition of Figure 3. It identifies a particular issue with the figure, noting that the expected quantities are scalars but are currently shown as a vector. This feedback is clear and direct, offering a concrete step for the authors to take to improve the clarity and accuracy of their figure. By addressing this issue, the authors can enhance the comprehensibility of their work. Therefore, the comment is 5, as it provides a clear and actionable direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific guidance on what aspects of the experimental setup need improvement or how to address these questions. The comment lacks explicit instructions or concrete details on how to enhance the experimental setup, leaving the authors uncertain about what actions to take. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not specify which part of the paper these ablation experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestion that the experiments deserve better setup, but it lacks grounding as it does not specify the exact sections or experiments being referred to. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific details or examples of what these questions are or how the experiments could be improved. This lack of specificity and actionable guidance makes it difficult for the authors to address the feedback effectively. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps or suggestions for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment implies that the authors should provide empirical evidence and clarify their explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence and clarify their explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about the usefulness of the proposed models for learning representations for lowfrequency words. It highlights the lack of empirical evidence to support this claim and suggests that the authors should provide such evidence. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion of the models\" utility and the results section. The authors can infer that it relates to the sections where these claims are made, but the comment does not provide explicit references. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have made a reasonable argument about the usefulness of their models for learning representations for lowfrequency words, but they lack empirical evidence to support this claim. The reviewer suggests that the authors should provide empirical evidence to test the hypothesis. Additionally, the comment notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment identifies a gap in the paper\"s evidence and explanation, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis, which is a clear and actionable suggestion. Additionally, the comment notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. This feedback is 4 as it provides the authors with a clear direction for improvement and highlights areas that need further clarification. However, it could be more helpful if it offered specific suggestions on how to provide the necessary evidence or clarify the explanation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the difficulty in understanding Figure 5 due to the clutter of lines. It suggests that the authors could report additional metrics like flops or model size to make the figure more concrete and easier to interpret. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the clarity of the figure and the report, ensuring a direct path to enhancing the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the difficulty in understanding the figure due to the clutter of lines and suggests reporting additional metrics like flops or model size to make the figure more concrete. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to understand due to the clutter of lines and suggests reporting additional metrics like flops or model size to make it more concrete. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to report additional metrics is a logical step to improve clarity, but without further elaboration, the comment remains 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the clutter of lines. It provides a clear suggestion for improvement by recommending that the authors report additional metrics such as flops or model size to make the figure more concrete and easier to interpret. This feedback is actionable and provides a direct path for the authors to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it included specific examples of how these additional metrics could be incorporated or how they might improve the figure. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that some details of the proposed method are missing, but it does not provide specific guidance on what these details are or how they should be addressed. The comment mentions \"questions section below,\" which implies that the authors should refer to a specific section for more information, but it does not explicitly instruct them to do so. Without concrete details or explicit actions, the authors are left without a clear understanding of what needs to be added or clarified. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some details of the proposed method are missing,\" but it does not specify which part of the paper these details are missing from. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in noting that details are missing, but without explicit references, it is weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, but it does not provide any specific examples or reasoning to support this claim. Without detailed information or references, the authors may find it challenging to understand what specific details are missing and how to address them. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting that some details of the proposed method are missing. However, it does not provide any further context, examples, or suggestions on what these details might be or how they could be addressed. Without additional guidance, the authors are left without a clear understanding of what specific information is lacking and how to improve their draft. This makes the comment 2, as it highlights a potential weakness but does not offer actionable feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 is confusing and lacks clarity regarding the meaning of the columns. It specifies that the issue is not addressed in either the text or the caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in Figure 4. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by noting that the columns in the figure are confusing and lack explanation in the text or caption. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing because it is not clear what the columns mean, and this is not explained in the text or caption. This is a factual observation rather than a subjective claim or suggestion, as it does not express an opinion or require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing because the meaning of the columns is not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the figure\"s content to improve its clarity and understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the figure, such as adding a caption or explaining the columns in the text. Overall, the comment is 4 as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be provided. While the comment implies that the authors should offer additional explanations, it does not explicitly instruct them to do so or provide specific guidance on what aspects to explain. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, comparing them to simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be given. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the explanations are needed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are indeed lower than expected. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, comparing them to simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be provided, which is a valid point. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the results or methodology should be explained further. While it identifies an area for improvement, it does not provide actionable steps or suggestions for the authors to enhance their draft. Therefore, the comment is 3, as it highlights a potential issue but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of an ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this lack. The action is implicit, as the authors need to infer that they should include an ablation analysis to better understand the performance gains. However, the comment lacks concrete details on how to conduct the analysis or what specific components should be analyzed. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper should include this analysis or provide guidance on how to conduct it. The authors can infer that the main paper is being referred to, but the lack of specific guidance makes it challenging to pinpoint the exact section needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the lack of an ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the absence of an ablation analysis, which makes it difficult to determine the source of the small performance gain. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to improve the clarity and robustness of their results. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation analysis or which components should be analyzed. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on what aspects of the experiments are lacking or how they could be improved. Without explicit guidance or concrete steps for the authors to take, the comment does not offer actionable feedback. The lack of specificity and direction makes it difficult for the authors to understand what needs to be addressed or how to improve their experiments. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in or provide any details on what aspects are lacking. This makes it difficult for the authors to identify the exact sections that need attention. The comment lacks both grounding and specificity, as it does not provide enough information to guide the authors in addressing the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue or improve the experiments. This lack of justification makes the claim 1, as it does not provide the necessary information for the authors to understand and address the concern.", "helpfulness_rationale": "The review comment identifies a concern with the CNN experiments, stating that they are not fully convincing. However, it does not provide any specific details or examples of what aspects of the experiments are lacking or how they could be improved. Without actionable feedback or suggestions, the authors are left without a clear path to address the issue. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the action is explicit, it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. The authors are given a clear direction to follow but are left to determine the exact steps and details of the comparison. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. The authors can infer that it relates to the results section or discussion, but this inference is not explicit. The comment is specific in suggesting a comparison with HateXplain models, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it could enhance the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a direction for the authors to enhance their work by comparing their results with existing literature. However, the comment lacks specificity and does not offer detailed guidance on how to conduct the comparison or what aspects to focus on. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific metrics or aspects to consider. Therefore, the comment is rated as 3, as it provides a general direction but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment implies that the authors should consider using the adaptive method, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method and justify its use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use of freezing, making it weakly grounded. The comment is specific in questioning the rationale behind the use of freezing and suggesting an alternative method, but it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be more appropriate or why freezing is not effective. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. This feedback is 3 as it prompts the authors to consider alternative methods and question the rationale behind their current approach. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement the adaptive method or why it might be more suitable. To be more helpful, the comment could include a detailed explanation of the adaptive method or specific examples of its benefits. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) that examines the robustness of the model by adding negation or changing entities in text. While the comment implies that such an analysis would be beneficial, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should perform a robustness analysis similar to existing work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting a method for evaluating robustness, but without explicit grounding, the authors may struggle to identify the exact section where this analysis should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness. While the comment provides a reference to existing work, it does not offer specific details or examples of how the analysis should be conducted or what aspects of robustness should be evaluated. This lack of detailed guidance makes the claim 3, as the authors would need to infer the exact steps to take based on the reference provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to evaluate the model\"s robustness by adding negation or changing entities in text. This feedback is 3 as it identifies a potential area for improvement and provides a specific reference for the authors to follow. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the analysis or what specific aspects of robustness should be evaluated. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of clarity regarding the computational cost of the proposed approach and suggests that the paper deserves a more comprehensive discussion on this topic. It also raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should provide a more detailed discussion on computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the computational cost in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically mentioning the lack of clarity regarding why the additional cost did not lead to \"significant delays in computation.\" It also questions whether the proposed approach becomes prohibitive in some settings. However, the comment does not explicitly mention which part of the paper discusses computational cost, making it weakly grounded. The authors can infer that it relates to the discussion on computational complexity, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding computational cost and the potential prohibitive nature of the approach. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding the computational cost of the proposed approach, questioning why the additional cost did not lead to \"significant delays in computation.\" It also expresses curiosity about whether the approach becomes prohibitive in some settings. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the significance of the computational cost and the potential impact on the approach. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement regarding the discussion of computational cost in the paper. It points out that while the paper mentions the additional cost, it does not provide a clear explanation of why this cost did not lead to significant delays in computation. This feedback suggests that the paper deserves a more comprehensive discussion on the computational complexity of the proposed approach. Additionally, the comment raises a question about whether the approach becomes prohibitive in certain settings, which is a valid concern that the authors should address. While the comment provides clear guidance on what needs to be improved, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to discuss computational complexity. Overall, the comment is 4 as it directs the authors to a specific area for improvement and raises an important consideration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide more explanation on how novel values in the test set are handled. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the clarity of the paper. The comment does not leave any ambiguity about the action required, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more explanation on how novel values in the test set are handled. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more explanation on how novel values in the test set are handled. This is a clear and actionable suggestion that can help the authors clarify their methodology and improve the clarity of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to handle novel values in the test set. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that similar methods have been proposed for multitask learning and suggests that they have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Similar methods have already been proposed for multitask learning,\" but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details on what needs to be addressed or improved regarding the discussion of these similar methods. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that similar methods have been proposed for multitask learning but are not discussed in the paper. However, it does not provide any specific examples or references to these methods, nor does it explain why their inclusion would be beneficial or relevant to the paper. Without detailed evidence or reasoning, the claim remains 1, as the authors are left without a clear understanding of the basis for the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out that similar methods have been proposed for multitask learning but are not discussed in the paper. This observation highlights a potential gap in the paper\"s literature review or discussion section. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the paper could be improved. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a missing element in the analysis of experimental results, specifically questioning why improvements in models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct a more detailed analysis of the experimental results to explain these observations. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area of improvement regarding the analysis of experimental results, specifically questioning the reasons behind the limited improvements in models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not specify which part of the paper this analysis is missing, making it weakly grounded. The comment is specific in its request for an indepth analysis of the experimental results, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of indepth analysis on experimental results, specifically why improvements in models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of indepth analysis of experimental results. It highlights a particular observation, namely the limited improvements in models on the offense detection dataset compared to the significant improvements on the coarse stereotype set. This feedback is 3 as it points out a gap in the analysis that the authors should address. However, it lacks detailed guidance on how to conduct this analysis or what specific aspects should be examined. To be more helpful, the comment could provide suggestions on how to analyze these results or what specific questions should be addressed. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to achieve this. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of hyperparameters and suggests that the baseline should be fully tuned with the same resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in its suggestion to ensure a fair comparison, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that this is an important consideration, it does not provide specific reasoning or evidence to support why this is necessary. The claim is 3 as it highlights a potential issue with the comparison, but it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive use of hyperparameters and the need for a fair comparison. It suggests that the baseline should be fully tuned with the same resources as the proposed method to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the validity of their results. However, the comment could be more helpful if it offered suggestions on how to achieve this fair comparison or provided examples of how to implement it. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to include standard deviations or any other statistical measures to enhance the significance of the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of standard deviations, which makes it difficult to judge the significance of the results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations. This is a critical piece of information as it affects the interpretation and reliability of the results. However, the comment does not provide any guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of standard deviations or other statistical measures to enhance the significance of the results. Without actionable advice, the comment is limited in its usefulness to the authors. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a weakness in the analysis by pointing out the lack of theoretical support for the existence and smoothness of the solution of SDE (2a)(2d), as well as the guarantees of the discretization in time and space. While the comment identifies specific areas that need further development, it does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to strengthen the theoretical foundation of their analysis, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3, as it points out a specific area for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical work on sampling and particlebased optimization methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of theoretical support for the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This provides clear guidance on what the authors need to address in their analysis. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is weak due to the lack of theoretical support for the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. However, the comment does not provide specific references or examples to substantiate these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the theoretical foundation of the paper by pointing out the lack of theoretical support for the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This feedback is valuable as it highlights an area that requires further development to strengthen the paper\"s theoretical underpinnings. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as references to relevant literature or methods for establishing the theoretical guarantees. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or what specific steps to take to enhance realism. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper discusses the generated images or the results, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited realism, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer concrete steps or examples for the authors to enhance the realism of their generated images. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not explicitly instruct the authors to make this correction or provide guidance on how to incorporate this information into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the correction in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement about Cycle Consistency loss and provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This explanation is logical and provides a clear correction to the original claim, making the comment 4. However, it could be strengthened by providing specific references or examples to support the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper\"s description of Cycle Consistency loss, pointing out that the statement is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This feedback is clear and actionable, as it guides the authors to correct their understanding and presentation of the Cycle Consistency loss. However, the comment could be more helpful if it included specific suggestions on how to incorporate this correction into the paper or provided additional context to enhance the authors\" understanding. Overall, the comment is 4, as it offers valuable insights for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is explicit and provides a concrete action for the authors to take, which is to clarify the terminology or rephrase the text to avoid confusion. The comment is 5 as it directly guides the authors on how to improve their draft by addressing a specific issue with terminology. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used in the paper, specifically the term \"hyperspectral.\" It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is fully grounded as it explicitly mentions the term \"hyperspectral\" and provides a clear explanation of its correct usage. The comment is specific in detailing what is wrong with the current usage of the term, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a clear definition of hyperspectral imaging as the imaging technique that obtains the spectrum for each pixel in the image of a scene. This explanation is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing examples or references to further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, pointing out that the term \"hyperspectral\" is confusing. It provides a clear explanation of what hyperspectral imaging entails, which is the imaging technique that obtains the spectrum for each pixel in the image of a scene. This feedback is actionable as it guides the authors to clarify their terminology or rephrase the text to avoid confusion. However, the comment could be more helpful if it suggested alternative terminology or provided examples of how to improve the clarity of the text. Overall, the comment is 4 as it directs the authors to address a specific issue with their terminology, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the w/o perception module, and the questionable significance of the improvements based on the sample size. While the comment identifies these issues, it does not provide specific guidance or suggestions on how the authors should address them. The lack of actionable steps or detailed advice makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the role of visual information and the effectiveness of the knowledgegraph memory and visualdriven reasoning. It specifically mentions Table 10, which compares the performance of w/o perception module and w perception, and highlights the lack of explicit verification of the effectiveness of visual information. The comment also questions the significance of the improvements based on the sample size of 1000 users. While the comment does not explicitly mention the exact part of the paper being addressed, it is clear that it pertains to the results and discussion sections. The authors can infer that it relates to the experimental results and the ablation study, but the comment lacks explicit grounding. However, it is specific in detailing the issues with the effectiveness of visual information and the questionable significance of the improvements. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the effectiveness of visual information and the ablation study, questioning the significance of the improvements based on the sample size. It points out that the ablation study does not explicitly verify the effectiveness of the visual information, and the implementation details of the w/o perception module are unknown. The comment also questions the significance of the improvements based on the sample size of 1000 users. While the reviewer provides some reasoning and examples, such as the comparison of w/o perception module and w perception, the claim could be strengthened with more detailed evidence or references to support the assertion about the questionable significance of the improvements. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of explicit verification of the effectiveness of visual information and the ablation study. It points out that the ablation study does not provide clear evidence of the effectiveness of the knowledgegraph memory and visualdriven reasoning. Additionally, the comment questions the significance of the improvements based on the sample size of 1000 users, suggesting that the results may not be statistically significant. This feedback is valuable as it highlights areas where the paper could be strengthened and provides specific examples of where the authors need to improve their analysis and presentation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional guidance on how to improve the paper. Overall, the comment is 4 as it identifies weaknesses and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening, as it does not cite or compare previous works on Lasso screening, such as Ren et al.\"s paper. The comment explicitly instructs the authors to cite and compare these previous works, providing a clear and concrete action for them to take. This feedback is actionable because it gives the authors a specific task to perform, which is to include relevant citations and comparisons to enhance the paper\"s credibility and comprehensiveness. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of citation and comparison to previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about Transfer Lasso showing the best accuracy in feature screening is not supported by citing or comparing it with previous works on Lasso screening, such as Ren et al.\"s paper. The comment provides a specific reference to a previous work, which could be used to substantiate the claim. However, the comment does not include direct comparisons or detailed reasoning about why the cited work is relevant or how it supports the claim. This makes the claim 3, as it provides a basis for the assertion but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening. It points out that the paper does not cite or compare previous works on Lasso screening, such as Ren et al.\"s paper, which could provide a more comprehensive understanding of the topic. By suggesting that the authors include these references, the comment offers a clear and actionable feedback that would enhance the paper\"s credibility and comprehensiveness. This feedback is valuable as it directs the authors to a relevant area for improvement, making the comment 4. However, it could be more helpful if it provided additional context or suggestions on how to integrate these references effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation used for results, specifically questioning what \"%p\" stands for in the context of the paper\"s claims about the improvement on CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights a specific area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results\" and specifically questions the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This provides clear guidance on where the authors need to clarify their notation, making it easy for the authors to identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, namely the unclear meaning of \"%p.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of notation in the paper, specifically regarding the meaning of \"%p\" in the context of the claim about the improvement on CIFAR10. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify what \"%p\" might stand for or why it is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation in the paper, specifically questioning the meaning of \"%p\" in the context of the claim about the improvement on CIFAR10. This feedback is clear and actionable, as it points out a potential source of confusion for readers. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered alternative ways to express the results. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a specific action by suggesting that the title should be clarified to avoid confusion. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft by making a specific change to the title. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying it to distinguish between machine and human reading comprehension. While the comment identifies a potential issue with the title, it does not provide specific examples or detailed reasoning to support why the title is ambiguous or how it could be clarified. The suggestion is based on common knowledge about the terms \"reading comprehension\" and \"readability,\" but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the title of the paper, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the title. By addressing this issue, the authors can enhance the precision of their work and better communicate their focus on machine comprehension. However, the comment could be more helpful if it offered additional guidance on how to rephrase the title or provided examples of how to clarify the distinction. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative metrics they should use. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their choice of metrics. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the human evaluation section. The comment is also specific because it clearly specifies the issue with the use of TSS and suggests that this choice weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an automatic metric (TSS) instead of a human metric weakens the convincingness of the human evaluation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is problematic or how it affects the evaluation. Without specific details or references, the claim remains 1, as the authors are left without guidance on how to address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the human evaluation process, specifically questioning the use of an automatic metric (TSS) instead of a human metric for evaluating style control. This feedback highlights a gap in the evaluation methodology, suggesting that the choice of metrics could impact the credibility of the evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it points out a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the lack of confidence intervals and the evaluation on standard datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. It also notes that the evaluation is only conducted on two standard datasets in the RNP community. The comment provides references to relevant literature, such as 1 DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, 2 Controlling Selection Bias in Causal Inference, AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022, which could be used to support the claim. However, the comment lacks specific examples or detailed reasoning about why these references are relevant, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation being limited to only two datasets, which are standard in the RNP community. It provides references to relevant literature, such as 1 DiversitySensitive Conditional Generative Adversarial Networks, ICLR 2019, 2 Controlling Selection Bias in Causal Inference, AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models, TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022, which could be used to support the claim. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as recommending the inclusion of confidence intervals or evaluating on additional datasets. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While the comment explicitly asks for training losses, it does not provide specific guidance on how to obtain or analyze these losses. The action is implicit, as the authors need to infer that they should include training losses in their analysis, but it is concrete because the direction is clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for training losses, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the results. Without such context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While it identifies a potential issue, it lacks specificity and does not provide guidance on how to address the concern or what aspects of the training process might be unstable. The request for training losses is a logical step to take, but without further context or suggestions, the comment remains 3. The authors are given a direction to explore, but the feedback could be more comprehensive and actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the paper\"s claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claims. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s claim about the strength of the proposed BC loss, specifically mentioning the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specificity by identifying the issues, it lacks full grounding as the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper overstates the strength of the proposed BC loss by suggesting that geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed explanations or references to substantiate the assertion that these elements are indeed the same concept. Without explicit evidence or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the paper\"s claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are essentially the same concept from different viewpoints. This feedback is 3 as it identifies a potential overstatement in the paper\"s claims. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. The comment could be more helpful if it offered actionable advice or examples to support the critique. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of sample size on training speed and potentially adjust their comparisons accordingly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the training of RegMixup, specifically mentioning that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with sample size and its impact on training speed and comparison fairness. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. The comment provides a logical reasoning for the claim, explaining that the increased sample size could affect the training speed. However, it lacks specific examples or references to support the assertion about unfair comparison, making the claim 3. The authors would need to further investigate the impact of sample size on training speed and comparison fairness to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. This feedback is 3 as it points out a specific area where the authors might need to address the impact of sample size on training efficiency and fairness of comparison. However, the comment lacks detailed guidance on how the authors should adjust their methodology or analysis to account for this issue, which would make it more actionable. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue or what alternative approaches they might consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the implications of using focal loss in regression tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or the regression tasks, making it weakly grounded. The comment is specific in identifying the issue with the use of focal loss in regression tasks and the potential impact on accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the claim is not 5 due to the lack of detailed evidence or examples. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore alternative approaches. The feedback is 3 as it highlights a potential weakness in the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of scalability they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit references or detailed context, the authors may find it challenging to identify the exact area being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors should investigate this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies an important aspect that the authors should consider, it does not provide any specific guidance or suggestions on how to address this issue. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer actionable insights or suggestions for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of the proposed technique across tasks with varying reasoning requirements. While the comment implies that additional datasets should be included, it does not provide specific guidance on which datasets to use or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors may infer that it relates to the experimental results or the conclusion, but this inference is not explicit. The comment is specific in its suggestion to include more datasets, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, the comment does not provide any specific reasoning or evidence to support why these datasets are particularly relevant or why including them would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it provides a specific direction for enhancing the paper by expanding the experimental evaluation. However, it lacks detailed guidance on which datasets to include or how to incorporate them into the analysis, which could limit its effectiveness. The comment highlights an important aspect of generalizability that the authors should consider, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide more implementation details of the proposed methods, which are currently lacking. It specifies that these details should be included in Section 4.1. This direct and concrete guidance gives the authors a clear understanding of what needs to be done to address the concern. The comment provides specific instructions on where to include the additional information, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4.1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of implementation details of the proposed methods, which is a clear and specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details in the paper is a significant issue, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples or reasoning to support why this is a concern or how it affects the paper\"s comprehensibility or reproducibility. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for reproducibility and understanding of the work. It provides a clear and actionable suggestion by specifying that these details should be included in Section 4.1. This feedback is valuable as it guides the authors on what needs to be addressed to improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance or examples of what specific implementation details should be included. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the paper, noting that there is no empirical evaluation and no comparison with other methods. It emphasizes the lack of practical value and suggests that the paper is not suitable for publication at NeurIPS. While the comment identifies a critical area for improvement, it does not provide specific guidance on how to address these issues or what kind of empirical evaluation or comparisons should be included. The authors are left with a general understanding of what needs to be improved but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it points out a significant problem but lacks detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation and comparison with other methods, noting that the paper does not provide a practical value for its contributions. It also critiques the theoretical contributions, stating that the paper is not suitable for publication at NeurIPS due to the absence of empirical evidence. However, the comment does not specify which part of the paper lacks empirical evaluation or comparisons, making it weakly grounded. The feedback is specific in identifying the absence of empirical evaluation and the lack of practical value, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. The reviewer suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The claim is 3 as it points out a significant gap in the paper\"s evaluation and provides a logical argument for why empirical evaluation is crucial. However, the comment could be strengthened by providing specific examples of other methods or theoretical papers that have successfully addressed similar issues, which would enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that there is no empirical evaluation or comparison with other methods, which makes it unclear what the practical value of the contribution is. It suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. While the comment highlights a critical gap in the paper, it does not provide specific guidance on how to address this issue or what kind of empirical evaluation or comparisons should be included. The feedback is 3 as it points out a significant weakness but lacks detailed suggestions for improvement, leaving the authors with a general understanding of what needs to be improved but without actionable steps to take."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in the manuscript regarding the use of \"P\" as both a probability and a cumulative distribution function. It explicitly states that this inconsistency leads to confusion, but it does not provide specific guidance on how the authors should address this issue. The comment does not offer suggestions for redefining \"P\" or revising the equations to clarify their usage. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line in the text (L44) in the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the confusion caused by the use of \"P\" as both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"P mostly represents a probability but sometimes for a cumulative distribution function,\" which leads to confusion. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion. Without detailed examples or references, the claim remains vague and lacks sufficient evidence to be 5. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \"P\" in the manuscript, noting that it is sometimes used to represent a probability and sometimes a cumulative distribution function, which can lead to confusion. This feedback is clear and actionable, as it points out a potential source of ambiguity that the authors should address. By highlighting this issue, the comment provides a concrete direction for the authors to improve the clarity of their manuscript. However, it could be more helpful if it suggested ways to resolve the confusion, such as recommending the use of different symbols or providing clearer explanations. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of artificial patterns in analysis and ablation studies instead of natural spurious correlations. It suggests that the community is not fully aware of how neural networks learn natural rare spurious correlations. However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or improve their analysis. The feedback lacks actionable details, leaving the authors without a clear path to follow. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the use of artificial patterns in analysis and ablation studies instead of natural spurious correlations. It suggests that the community is not fully aware of how neural networks learn natural rare spurious correlations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the use of artificial patterns versus natural spurious features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of artificial patterns in analysis and ablation studies instead of natural spurious correlations. It suggests that the community is not fully aware of how neural networks learn natural rare spurious correlations. However, the comment lacks specific examples or references to support the claim that most analysis and ablation studies use artificial patterns. The reasoning is based on the author\"s knowledge, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of artificial patterns in analysis and ablation studies instead of natural spurious correlations. It suggests that the community is not fully aware of how neural networks learn natural rare spurious correlations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, the feedback is vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a concern but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRMRL 1 and asks whether the algorithms can be applied in more general tasks. While the comment implies that the authors should consider expanding the scope of their work, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not specify which part of the paper discusses the limitations to navigation problems or the potential applications in general tasks. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestion to explore broader applications, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is limited to navigation problems or that combining RL and planning has already been discussed in PRMRL. The reference to PRMRL provides some context, but the comment does not explain how this relates to the current work or why it is relevant. Therefore, the claim is 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRMRL 1 as a related work and suggests that the algorithms could be applied in more general tasks. This feedback is 3 as it points out a potential limitation of the paper\"s scope and suggests a direction for future work. However, it lacks specific guidance on how the authors might expand their work to address this limitation or what specific areas they should explore. The comment could be more helpful with additional details or suggestions on how to apply the algorithms in broader tasks. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be wellsuited for 1NN if they are not close to a spherical Gaussian. It also offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. While the comment implies that the authors should consider this suggestion, it does not explicitly instruct them to make this change. The action is concrete, as it provides a clear direction for improvement, but it is somewhat implicit because it does not explicitly instruct the authors to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the suitability of feature spaces for 1NN and offers a potential solution by recommending individual standardization of feature dimensions. This provides a clear direction for improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that feature spaces may not be wellsuited for 1NN if they are not close to a spherical Gaussian distribution. It suggests that individual standardization of feature dimensions could address this issue. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that feature spaces are not wellsuited for 1NN. This makes the claim 3, as the authors would need to further investigate the claim to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be wellsuited for 1NN if they are not close to a spherical Gaussian distribution. It offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. This feedback is clear and actionable, as it identifies a potential weakness in the methodology and provides a concrete suggestion for improvement. However, the comment could be more helpful if it included additional context or examples to further explain the implications of this observation. Overall, the comment is 4 as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the proposed \"contrastive gap,\" which is central to the work. It suggests that while an intuitive example is provided, the setting of this example is less convincing, and a formal definition is still missing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap to enhance the clarity of their work. However, it does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to define it. The action is implicit and somewhat vague, as the authors can infer the need for a definition but may not know how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of a clear definition and the less convincing nature of the example provided. The comment is specific in detailing what needs to be addressed, namely, the need for a formal definition and a more convincing example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" has never been defined clearly, despite being central to the work. It provides a specific example of an \"idealized\" dataset to demonstrate the concept, but the setting of this example is less convincing. The comment suggests that a clear, formal definition is still lacking. While the comment identifies a specific issue with the lack of definition, it does not provide detailed reasoning or evidence to fully substantiate the claim. The authors may find it challenging to address the issue without additional context or examples. Therefore, the comment is 3, as it highlights a gap but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the \"contrastive gap,\" which is central to the work. It highlights that while an example is provided, the setting of this example is less convincing, and a formal definition is still missing. This feedback is valuable as it points out a significant gap in the paper\"s clarity and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to define the contrastive gap or provided examples of how to improve the example. Overall, the comment is 4 as it directs the authors to a critical area needing attention but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional baselines, such as those mentioned in the related work section, would enhance the paper. It also acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment does not provide explicit instructions on how to include these additional baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing any remaining unclear parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. It also mentions that the authors explained why the chosen baseline makes sense. However, the comment does not specify which part of the paper this suggestion pertains to, such as the related work section or the experimental setup. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional baselines and asking for clarification on testing, but it lacks grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. However, it does not provide specific reasoning or evidence to support the claim that including these baselines would enhance the paper. The comment lacks detailed justification or examples of how these additional baselines would improve the study, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests including additional baselines in the paper, such as those mentioned in the related work section, which could enhance the study\"s comprehensiveness. It acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment lacks specificity in terms of which baselines should be included or how they would improve the paper. Additionally, the question about testing beforehand is not fully addressed, leaving the authors with incomplete guidance. While the comment provides some direction, it could be more helpful with more detailed suggestions or examples. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This comment explicitly instructs the authors to ensure consistency in notation, which is a clear and direct action. However, it does not provide specific guidance on how to achieve this consistency, such as suggesting which notation to use or where to make the change. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by pointing out the discrepancy in notation between the text and the figure, where the task loss is referred to as L_task in the text but L_class in figure 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This observation is factual and does not require any supporting evidence or reasoning. It is a straightforward statement of a typographical error or inconsistency, which is easily verifiable by the authors themselves. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This is a clear and specific observation that highlights a potential source of confusion for readers. By pointing out this inconsistency, the comment provides the authors with a straightforward action to take: ensure consistency in notation throughout the paper. However, the comment does not offer additional guidance or suggestions on how to address this issue, such as recommending a specific notation or explaining why consistency is important. While it provides a clear direction for improvement, the lack of additional context or suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this limitation or what specific aspects they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in questioning the depth of the network in the graph case, but it lacks grounding as it does not reference a specific section or figure. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It prompts the authors to consider whether this is also the case in their work. However, the comment does not provide any specific guidance or suggestions on how the authors might address this limitation or improve their method. It lacks actionable feedback and does not offer insights into potential improvements or areas for further exploration. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the work would be more convincing if it were also evaluated in machine translation, as this would provide a more comprehensive assessment of the proposed method. However, the comment does not provide specific guidance on how to implement this evaluation or what aspects of machine translation should be considered. The action is implicit and somewhat vague, as the authors can infer the need for additional evaluation but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning the use of answer generation and summarization as conditional generation tasks. It suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation or the proposed method, making it weakly grounded. The comment is specific in suggesting an additional evaluation method to enhance the work\"s credibility, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work\"s evaluation is limited because it only uses answer generation and summarization, which are more akin to opendomain generation rather than closedomain generation like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This claim is 3 as it provides a logical reasoning based on the nature of the tasks and their relationship to opendomain and closedomain generation. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are more akin to opendomain generation rather than closedomain generation like machine translation. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the evaluation of the proposed method. By addressing this point, the authors could strengthen the credibility and applicability of their work. However, the comment could be more helpful if it included specific guidance on how to conduct the machine translation evaluation or what aspects of machine translation would be most relevant. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for full comprehensiveness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dropping rate and the number of masks generated for the dropout technique. While it does not explicitly instruct the authors to provide this information, the question is clear and specific, allowing the authors to understand what additional details are needed. The action is implicit but concrete, as the authors know exactly what information is required to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and references the response letter, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what information is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the dropping rate and the number of masks generated for the dropout technique. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout technique, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the clarity and completeness of their explanation. By addressing this question, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific aspects of the dropout technique might be affected by the lack of this information. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper does not provide information about the type of GPUs used and the inference time during testing. This feedback is clear and direct, instructing the authors to include this information in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the missing details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a critical piece of information that could impact the reproducibility and reliability of the results. By pointing out this omission, the comment provides clear and actionable feedback that would help the authors improve their draft. However, the comment could be more helpful if it suggested how to include this information or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of equation 2. It suggests that only neighboring nodes are attended to, which implies that the authors should clarify this aspect. While the comment does not explicitly instruct the authors to make this clarification, it is clear that addressing this issue would help improve the clarity of the paper. The action is implicit but concrete, as the authors know exactly what needs to be clarified. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether each node can attend to its own lowerlevel representation, based on the description of equation 2. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the functionality of nodes in the context of equation 2, specifically whether each node can attend to its own lowerlevel representation. The comment is based on the description of equation 2, which suggests that only neighboring nodes are attended to. However, it does not provide specific evidence or references to support this claim, making it 3. The authors would need to clarify or provide additional information to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the functionality of nodes in the context of equation 2, questioning whether each node can attend to its own lowerlevel representation. This is a relevant and detailed inquiry that prompts the authors to clarify a potential misunderstanding or oversight in their work. By addressing this question, the authors can enhance the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the feedback is 4 as it directs the authors\" attention to an important aspect of their work that needs clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including the results of the bottomup method 9 on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. The comment provides a specific action to take, which is to include the results in the tables and conduct the evaluation on the MS Coco dataset. This is a clear and direct instruction, making the comment 5. The authors know exactly what needs to be done to improve their draft based on the feedback provided.", "grounding_specificity_rationale": "The comment suggests including the results of the bottomup method 9 on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. It provides specific examples of what should be included, making the comment fully grounded as it explicitly mentions the tables and datasets. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results from the bottomup method and the evaluation on the MS Coco dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the results of a specific method, the bottomup method 9, on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset to assess its performance in easy (nonoccluded) settings. The comment provides a specific example of a method that has outperformed others, which is a logical and verifiable claim. However, it lacks detailed reasoning or references to support the claim that including these results would be beneficial or necessary. The suggestion is 4 due to the logical basis but could be strengthened with additional justification or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by suggesting the inclusion of results from the bottomup method 9 on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset, particularly in easy (nonoccluded) settings. These suggestions are clear and actionable, offering the authors a concrete way to enhance the comprehensiveness and relevance of their results. By following these suggestions, the authors can strengthen their paper by providing additional context and comparisons, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim of using an \"annotation guideline\" and suggests that it may be an overstatement. It provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve their claim. The action is implicit and vague, as the authors are left to infer that they need to clarify or substantiate their claim about using an annotation guideline. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim and references a specific example from the TACRED slot filling guidelines. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the complexity of annotation guidelines in the IE domain and provides an example to illustrate the depth of true guideline understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that the paper makes use of an \"annotation guideline\" by pointing out that the guidelines in the IE domain are complex and were curated by linguists. It provides a specific example from the TACRED slot filling guidelines to illustrate the depth of these guidelines. This provides a clear and detailed explanation of the claim, making it 5. The authors are given a concrete example and reasoning to support the critique, allowing them to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper\"s claim of using an \"annotation guideline.\" It points out that the guidelines in the IE domain are complex and were curated by linguists, providing a specific example from the TACRED slot filling guidelines. This feedback is valuable as it highlights a gap in the paper\"s understanding of the depth and complexity of annotation guidelines. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provide additional context. Overall, the comment is 4 as it directs the authors to consider the depth of their claim and provides a specific example for reference, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors did not address the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what specific weaknesses should be considered or how they should be addressed. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of discussion on the weaknesses of the proposed model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the absence of a discussion on weaknesses, but it lacks grounding as it does not provide a clear reference to the part of the paper where this discussion should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on what weaknesses should be addressed or how to improve the discussion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by pointing out that they did not discuss the possible weaknesses of the proposed model. This feedback is clear and actionable, as it directs the authors to consider and address potential limitations or drawbacks of their model. However, the comment could be more helpful if it provided examples of what these weaknesses might be or suggested ways to address them. Overall, the comment is 4 as it highlights an important aspect for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. While the comment implies that more work on GLN should be included, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate this information. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, it does not specify which part of the paper the introduction of related work is located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in suggesting that more information on GLN should be included, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, the comment does not provide specific examples or references to support the claim that the introduction is insufficient or how GLN should be discussed. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s introduction, noting that the discussion of related work is insufficient. It suggests that more information on GLN should be provided to reflect the advantages or differences of the proposed method compared to BGLN. This feedback is clear and actionable, as it directs the authors to expand their discussion on GLN to enhance the paper\"s comprehensiveness and clarity. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this information effectively. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the use of dropout rates in the paper. It questions why only one dropout rate is used for Moon\"s approach, while Variational dropout has inputoutput and recurrent dropout parameters. This comment implies that the authors should clarify or justify their choice of using a single dropout rate for Moon\"s approach. However, it does not explicitly instruct the authors to make this clarification or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation or justification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the use of dropout rates in the paper, questioning why only one dropout rate is used for Moon\"s approach, while Variational dropout has inputoutput and recurrent dropout parameters. This provides full grounding as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the use of dropout rates and suggests a potential inconsistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters for Variational dropout. This raises a logical question about the consistency and effectiveness of the dropout rates used in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s results. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the use of dropout rates in the paper. It questions why only one dropout rate is used for Moon\"s approach, while Variational dropout has inputoutput and recurrent dropout parameters. This feedback highlights a potential area for improvement in terms of methodological consistency and could prompt the authors to justify or clarify their choices. However, the comment does not provide detailed guidance or suggestions on how to address this issue, such as recommending specific changes or additional analyses. While it points out a discrepancy, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the current approach of using ProtPainter for binder design is empirical and lacks optimization and validation. It implies that the authors should consider further optimization and validation of the conformation estimation process. However, the comment does not provide explicit guidance on how to achieve this optimization or validation, nor does it specify which aspects of the process need improvement. The action is implicit and somewhat vague, as the authors can infer the need for optimization and validation but lack concrete steps on how to implement these changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of binder design, specifically mentioning ProtPainter and its empirical conformation estimation. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design and recommends further optimization and validation. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current approach is empirical or lacks optimization. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the binder design process, where the current approach using ProtPainter is described as empirical and lacks optimization and validation. This feedback is 3 as it points out a potential weakness in the methodology and suggests that further optimization and validation are needed. However, the comment lacks specific guidance or suggestions on how to achieve this optimization or validation, which would make it more actionable. The authors are left with a general understanding of what needs improvement but without detailed steps to address it. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it implies that additional evaluation is needed, it does not explicitly instruct the authors to conduct these evaluations or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors can infer the need for more evaluation but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, nor does it provide detailed guidance on what specific aspects of the evaluation should be expanded upon. The authors can infer that it relates to the evaluation section, but the lack of explicit mention of a section or specific elements makes it weakly grounded. The comment is specific in suggesting additional evaluation scenarios, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. However, the comment does not provide any specific reasoning, examples, or references to support why these scenarios are particularly important or why additional evaluation would be valuable. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, particularly on CIFAR10 in both full label and lower label scenarios. While it identifies a specific area where additional analysis could be conducted, it lacks detailed guidance or suggestions on how to conduct this evaluation or what specific aspects should be examined. The comment provides a general direction for improvement but does not offer actionable steps or specific examples, making it 3. The authors are given a direction to consider but are left to determine the specifics of the evaluation themselves. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions the counterintuitive placement of the discussion about the iterative algorithm, suggesting that it should be addressed earlier in the paper. Second, it points out the lack of reference to Laplacian eigenmaps in the paper, which was not cited in the introduction. These comments provide explicit actions for the authors to take, such as reorganizing the discussion to make it more logical and ensuring that references to Laplacian eigenmaps are included. The feedback is clear and concrete, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses two specific issues: the placement of the discussion about the iterative algorithm, which is considered counterintuitive, and the lack of reference to Laplacian eigenmaps in the paper. It also mentions a figure, but the specific figure is not specified. While the authors can infer that the comment pertains to the discussion section or the introduction, the lack of explicit reference to a specific figure makes the comment weakly grounded. The comment is specific in detailing what needs to be addressed regarding the iterative algorithm and the reference to Laplacian eigenmaps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the placement of the discussion about the iterative algorithm, suggesting that it is counterintuitive to place it at the end. This claim is 3 as it provides a logical reasoning for the placement, but it lacks specific examples or references to support the claim fully. Second, it points out the absence of a reference to Laplacian eigenmaps in the paper, which was not cited in the introduction. This is a factual statement that does not require verification. Therefore, the comment is 4, as it provides some justification for the first claim but lacks detailed support for both claims.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it questions the placement of the discussion about the iterative algorithm, suggesting that it is counterintuitive to place it at the end. This feedback provides a clear and actionable suggestion for reorganizing the discussion to make it more logical. Second, it points out the absence of a reference to Laplacian eigenmaps in the paper, which was not cited in the introduction. This feedback is specific and actionable, guiding the authors to include relevant references to enhance the paper\"s comprehensiveness. Overall, the comment is 4 as it provides clear guidance on how to improve the paper, making it a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2.1 is unnecessary because it discusses Batch Normalization and Conditional Batch Normalization (CBN), which are general techniques. It also suggests that the description of the proposed methodology is independent of the choice of model and that the time spent on the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and use the time spent on ResNet to enhance the motivation for CBN, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses Section 2.1, specifically mentioning the inclusion of Batch Normalization and Conditional Batch Normalization (CBN) techniques. It also suggests that the description of the proposed methodology is independent of the choice of model and that the time spent on ResNet could be better used to provide greater motivation and intuition for the proposed CBN approach. This provides full grounding as the authors can accurately identify the section being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of Section 2.1 and the use of ResNet time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2.1 is unnecessary because Batch Normalization and Conditional Batch Normalization are general techniques, and the description of the proposed methodology is independent of the choice of model. The reviewer suggests that the time spent on ResNet could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment provides a logical argument for the redundancy of Section 2.1, it lacks specific examples or references to support the claim that the description of the proposed methodology is independent of the choice of model. This makes the claim 3, as it provides a basis for the argument but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Section 2.1, suggesting that the inclusion of Batch Normalization and Conditional Batch Normalization (CBN) techniques is general and does not justify the specific description of the proposed methodology. It also suggests that the time spent on ResNet could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment points out a potential issue with the current structure of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is 3 as it highlights a potential area for improvement but does not provide detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix in equation (1) and how it relates to the expectation of sparsity. While the comment highlights a potential inconsistency, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or revise their assumptions regarding sparsity and conditioning. However, the comment lacks concrete details on how to implement this clarification or revision, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying by a dense projection matrix and its implications for sparsity, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. While it does not contain an explicit claim, it poses a logical question that requires the authors to clarify their assumptions or provide additional context. The comment does not make a subjective judgment or suggest a specific change, so it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. While it identifies a potential inconsistency, it does not provide specific guidance or suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 2, as it provides some insight but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It also provides a reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should revisit and possibly revise their statement about initialization, it does not explicitly instruct them to do so or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should make a more careful statement and consider the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"initialization\" and references a specific work by Kunstner, Hennig, and Balles (2019), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about initialization should be more carefully stated, referencing a specific work by Kunstner, Hennig, and Balles (2019) as a source of evidence. This provides a clear and specific reference to support the claim, making it 5. The reviewer\"s reasoning is based on the relevance of the reference to the topic of initialization and the potential impact on the statement about NGD being a discretization of NGF. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It provides a specific reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is valuable as it directs the authors to a specific area for improvement and offers a reference that could enhance their understanding of the topic. However, the comment could be more helpful if it provided additional context or guidance on how to address the issue or incorporate the reference into the paper. Overall, the comment is 4 as it provides a clear direction for improvement but lacks depth in its suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. First, it highlights the lack of clarity regarding how named entities were extracted from the datasets, which is an explicit action for the authors to address. Second, it suggests that an Englishproofreading would significantly improve the readability of the paper, providing a concrete action for the authors to take. However, the comment does not specify which parts of the paper need proofreading or how the proofreading should be done. While the actions are clear, the lack of detailed guidance on proofreading limits the level of concreteness. Therefore, the comment is 4, as it provides explicit actions but lacks full detail on execution.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the extraction of named entities from the datasets and the need for Englishproofreading to improve the paper\"s readability. However, it does not specify which part of the paper discusses the extraction of named entities, making it weakly grounded. The comment is specific about the need for clarity in the extraction process and the potential benefits of Englishproofreading, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is not clear how named entities were extracted from the datasets and suggests that Englishproofreading would significantly improve the paper\"s readability. However, the comment does not provide any specific examples, detailed reasoning, or references to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the clarity of how named entities were extracted from the datasets and the need for Englishproofreading to enhance the paper\"s readability. While the comment highlights important issues, it lacks detailed guidance or suggestions on how to address these concerns. For example, it does not specify which parts of the paper need clarification or how the Englishproofreading should be conducted. This limits the comment\"s helpfulness, as it provides some insight but does not fully support the authors in making the necessary improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. However, the comment does not provide specific guidance on how to address this issue, such as recommending a particular section or suggesting a specific format for defining these variables. The action is implicit and somewhat vague, as the authors can infer that they need to address the formatting inconsistency but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296\" and \"Line 302,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point highlights a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a formatting inconsistency regarding the use of L and E, suggesting that they should be defined in the immediate vicinity and that their usage should be consistent. This feedback is specific and actionable, as it points out a potential issue that could affect the clarity and readability of the manuscript. By addressing this inconsistency, the authors can improve the overall quality of their draft. However, the comment could be more helpful if it provided examples of how to define L and E or suggested a specific section where this should be addressed. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct additional comparisons, it does not provide specific guidance on which models or techniques to include or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these comparisons should be made. This lack of grounding makes it difficult for the authors to identify the exact area needing improvement. The comment is specific in its suggestion to include more comparisons, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support the claim that these additional comparisons would be beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies a potential area for improvement by recommending additional comparisons that could enhance the manuscript\"s comprehensiveness and depth. However, the comment lacks specific guidance on which models or techniques to include, making it somewhat limited in its usefulness. To be more helpful, the comment could provide examples or references to specific models or techniques that could be compared, offering the authors a clearer path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and concrete, providing the authors with clear instructions on how to improve the draft. The reviewer identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity ensures that the authors know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections for grammatical errors and punctuation in the manuscript, such as \"Despite of being compact\u00e2\u0080\u009d > \u00e2\u0080\u009cDespite being compact\u00e2\u0080\u009d,\" \"We refer multiway arrays\u00e2\u0080\u009d > \u00e2\u0080\u009cWe refer to multiway arrays\u00e2\u0080\u009d,\" \"HPFN to a even deeper ConAC\u00e2\u0080\u009d > \u00e2\u0080\u009cHPFN to an even deeper ConAC\u00e2\u0080\u009d,\" and \"Effect of the modelling mixed temporalmodality features.\" > I\"m not sure what this means, it\"s not grammatically correct.\" These corrections are clearly identified and specify what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of corrections for grammatical errors and punctuation, which are factual statements without any claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and actionable, helping the authors to improve the clarity and professionalism of their draft. The reviewer identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity is beneficial for the authors, as it allows them to make direct improvements to their manuscript. However, the comment could be more helpful if it provided additional context or suggestions for how to address these issues in the broader context of the paper. Overall, the comment is 4, as it provides clear guidance for improving the manuscript."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what changes are needed. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not specify which part of the paper these equations are located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in questioning the accuracy of the equations but lacks grounding as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any context, explanation, or guidance on why this is a concern or how it affects the paper\"s content or analysis. Without additional information or suggestions for improvement, the authors are left without actionable feedback. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the comparison and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or experiment. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison between different design approaches, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or detailed explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a comparison between sequential design and combinational design, implying that the proposed method may perform better in pure combinational logic without registers. This is a valuable suggestion as it could provide additional insights into the effectiveness of the method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. While it identifies an interesting area for exploration, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. While it prompts the authors to provide this information, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to include the performance of the baseline in their draft. However, the comment lacks concrete guidance on how to present this information or what specific details should be included. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. This provides clear guidance on what additional information the authors should include in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or additional information, as it seeks to understand the performance of a specific baseline in terms of a particular metric. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance of a baseline, LDA+LSTM, in terms of the topic switch percent metric. This feedback is 3 as it prompts the authors to provide additional information that could enhance the comprehensiveness of their experimental results. However, the comment lacks depth and does not offer suggestions on how to present this information or what specific aspects of the performance should be highlighted. To be more helpful, the comment could include guidance on how to analyze and present the results of this baseline, such as suggesting specific metrics or methods for comparison. Therefore, the comment is rated as 3, as it identifies an area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of mention of TD3GA in the main paper. It also suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and emphasize the comparison to TD3GA in their paper. However, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of mention of TD3GA in the main paper and the need for a comparison to TD3GA to support the central claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, particularly due to the absence of mention of TD3GA in the main paper. The reviewer suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that TD3GA is crucial for understanding the synergies. The suggestion to include a comparison to TD3GA provides a direction for improvement, but the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention TD3GA, which is crucial for understanding these synergies. It also highlights a central claim that using onpolicy RL better fits the DQD framework and suggests that the comparison to TD3GA should be central to this claim. This feedback is clear and actionable, as it provides a specific area for improvement by recommending the inclusion of TD3GA in the paper. However, the comment could be more helpful if it offered additional guidance on how to effectively integrate TD3GA into the analysis or discussion. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"confident\" in the context of the paper, suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential issue and suggests a possible action, it does not explicitly instruct the authors to rephrase or clarify the term. The action is implicit and somewhat vague, as the authors need to infer the exact change needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific phrase, \"ceterus paribus convexity,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \"confident\" and suggesting that it might refer to model confidence or human interpretability. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim or suggest why the clarification is necessary. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential area of confusion, it does not provide specific suggestions or guidance on how to rephrase or clarify the term. This limits the usefulness of the feedback, as the authors may still struggle to address the issue without additional direction. Therefore, the comment is 3, as it highlights a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the novelty of their work or address the limitations mentioned. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not specify which part of the paper discusses these findings or where the novelty is limited. The authors may have an idea of where the novelty is being discussed, but the comment lacks explicit references to specific sections or results. Additionally, the comment does not provide detailed guidance on how to enhance the novelty or address the limitations mentioned. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. The reviewer provides a logical reasoning that taskspecific finetuning generally increases confidence for a specific task while potentially reducing generalizability. However, the comment lacks specific examples or references to support the claim that the novelty is limited. While the reasoning is plausible, the absence of detailed evidence or examples makes the claim 3, as the authors may need to further explore the literature or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interesting findings of the work but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. The reviewer provides a logical explanation that taskspecific finetuning generally increases confidence for a specific task while potentially reducing generalizability. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty of their work or address the limitations mentioned. While it identifies an area for improvement, the feedback is vague and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the applicability of adversarial prediction accuracy, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the paper could be improved to better explain the relevance of adversarial prediction accuracy. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the authors should provide more details about the experiment setup and explore the effects of varying the number of InContext Examples. However, while the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information about the number of different sets of incontent examples used and the reliance on a single dataset, which limits the generalizability of the results. These points are wellsupported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation section of the paper, including the lack of transparency in the experiment setup and the reliance on a single dataset. It points out specific areas that need improvement, such as the absence of information about the number of different sets of incontent examples used and the need to explore the effects of varying the number of InContext Examples. This feedback is valuable as it highlights potential weaknesses in the experimental design and suggests ways to enhance the comprehensiveness and generalizability of the results. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues, such as recommending additional datasets or methods for evaluating the results. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors can infer that they need to include more references to related work, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not specify which part of the paper this feedback pertains to, such as the introduction or discussion section, making it weakly grounded. The comment is specific in identifying the need for additional attention to related work, but without explicit grounding, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, the comment does not provide any reasoning, evidence, or justification for why these specific references are relevant or how they would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. While this feedback highlights the need for more comprehensive referencing, it lacks specific guidance on how to incorporate these references or what aspects of the related work should be addressed. The comment provides a general direction but does not offer actionable steps or detailed suggestions, making it 3. The authors are aware of the need for additional references but may need to seek further guidance to effectively integrate them into their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not provide specific guidance on how to incorporate these aspects or what algorithmic details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their focus on algorithmic details, but they lack concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what specific algorithmic aspects should be addressed or how they should be incorporated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper is limited after the concept of Blackwell winner is proposed. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. This feedback highlights a potential area for improvement in the paper, indicating that the authors might have overlooked an important aspect of their work. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these algorithmic aspects or what specific improvements are needed. While it identifies a potential weakness, it does not offer actionable advice or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. While the comment implies that the authors should conduct more systematic comparisons, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Zemel et al. (2013)\" and \"the present paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparisons with this work could be improved by making them more systematic with respect to the tuning of each method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons should be more systematic or how they could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand and address the suggestion effectively. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with Zemel et al. (2013) could be made more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and actionable suggestion for enhancing the paper\"s analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the feedback is 4 as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this connection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection to properties of universal kernels and references a specific chapter for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This provides a clear and specific reference to external literature that could support the claim, making the comment 4. However, the comment could be strengthened by including a brief explanation of why this connection is relevant or how it could impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This feedback is 3 as it prompts the authors to consider a potential connection that could enhance their work. However, the comment lacks depth and does not provide specific guidance on how to explore this connection or why it might be relevant. To be more helpful, the comment could include a more detailed explanation of the potential benefits or implications of this connection. Therefore, the comment is rated as 3, aligning with a score of 3."}
