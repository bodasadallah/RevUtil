{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the adopted baseline models. First, it points out that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. Second, it mentions that the authors do not compare with other domain adaptation methods, such as those cited in Section 8. The comment provides explicit actions for the authors to take, such as including comparisons with Campos et al. (2020) and other domain adaptation methods. These actions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the adopted baseline models and the comparison with Campos et al. (2020) and other domain adaptation methods. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies the issues with the adopted baseline models, including the lack of comparison with Campos et al. (2020) and other domain adaptation methods. Additionally, it provides a clear suggestion for improvement by recommending the inclusion of comparisons with these works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adopted baseline models are weak and lacks comparisons with relevant works. It specifically mentions the absence of comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would improve the paper. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the significance of these comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the adopted baseline models. First, it points out that the authors do not compare their work to Campos et al. (2020), which also uses feedback in QA tasks. This lack of comparison limits the paper\\'s scope and makes it difficult for readers to understand the novelty and significance of the proposed approach. Second, the comment notes that the authors do not compare with other domain adaptation methods, such as those cited in Section 8. This lack of comparison with relevant literature limits the paper\\'s comprehensiveness and makes it challenging for readers to assess the paper\\'s contribution. The comment provides clear and actionable feedback, suggesting that the authors should include comparisons with Campos et al. (2020) and other domain adaptation methods. This feedback is valuable as it guides the authors in improving the comprehensiveness and novelty of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a clarification about the input used in the Lample et al. Bi-LSTM-CRF model, specifically mentioning that it is word embeddings. It also questions the figure, asking whether it shows KNs in the source language or in English, as the mentions have been translated to English. The authors have acknowledged the issue and stated they will correct the figure. While the comment provides explicit actions for the authors to take, such as clarifying the input and addressing the figure, it lacks detailed guidance on how to implement these changes. The authors know what needs to be done but may require additional information to fully execute the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the input used in the Lample et al. Bi-LSTM-CRF model and questioning the figure regarding the language of the mentions. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a clarification about the input used in the Lample et al. Bi-LSTM-CRF model and questions the figure regarding the language of the mentions. The authors have acknowledged the issue and stated they will correct the figure, indicating that the comment is mostly verifiable. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, which could be improved with additional context or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides specific and actionable feedback by suggesting that the authors clarify the input used in the Lample et al. Bi-LSTM-CRF model, specifically mentioning that it is word embeddings. Additionally, it raises a question about Figure 3, asking whether it shows KNs in the source language or in English, as the mentions have been translated to English. The authors have acknowledged the issue and stated they will correct the figure, indicating a commitment to addressing the feedback. This level of detail and acknowledgment makes the comment highly helpful, as it guides the authors in making necessary improvements to their draft. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or what aspects of these claims need further analysis. Without explicit guidance on which claims to focus on or how to conduct the analysis, the authors are left without a clear understanding of what actions to take. The comment lacks both specificity and directness, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that certain claims in the paper would benefit from more in-depth analysis, but it does not specify which claims are being referred to or what aspects of these claims need further analysis. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need attention. Without clear references to specific sections, tables, or figures, the comment is not grounded. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that certain claims in the paper would benefit from more in-depth analysis, but it does not provide any specific examples or reasoning to support this claim. Without detailed justification or references, the authors are left without guidance on which claims need further analysis or how to conduct it. This lack of evidence or reasoning makes the claim unverifiable, as it does not provide the authors with a clear path to improve their work. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or what aspects of these claims need further analysis. Without specific guidance or examples, the authors are left without actionable feedback on how to improve their work. The comment lacks depth and clarity, making it difficult for the authors to effectively address the feedback. Therefore, it is rated as barely helpful, as it provides a general suggestion but does not offer sufficient detail or direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, including asking for clarification on the pooling method used for embedding features (line 397) and addressing the clarity of Equation (7) in line 472. It specifies what needs to be clarified or defined, such as whether E_i represents the type or identity of AC i, and suggests that the LHS of equation (7) should be a conditional probability. These actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (397 and 472) where improvements are needed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and the interpretation of Equation (7). It provides detailed guidance on what the authors should address, making the feedback actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and observations regarding the presentation of the model. It seeks clarification on the pooling method used for embedding features and questions the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i. The comment also points out a potential issue with the interpretation of the LHS of equation (7) as a conditional probability. While the comment raises valid points, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors would need to infer the implications of these questions and make the necessary clarifications themselves. Therefore, the comment is somewhat verifiable, as it provides some guidance but requires additional context or evidence to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397), which is crucial for understanding the model's architecture. Additionally, it questions the clarity of Equation (7) in line 472, pointing out potential confusion regarding whether E_i represents the type or identity of AC i. The comment suggests that both aspects need to be defined, providing a clear and actionable feedback on how to improve the clarity and precision of the presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the comprehensibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for empirical evidence, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, the comment does not provide any specific evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. This feedback is specific and actionable, as it directs the authors to include additional data or results that would strengthen their claims. However, the comment could be more helpful if it provided examples of what kind of evidence would be most effective or how to present it. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more analysis and comments should be provided on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also expresses disagreement with the authors\\' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The reviewer provides specific examples and reasoning, such as the DeiT-B models not outperforming DeiT-T in APTOS2019 and not outperforming DeiT-S on multiple datasets. This feedback is explicit and provides concrete guidance on what the authors should address, making it highly actionable. The authors are given clear instructions on how to improve their analysis and presentation of the results, ensuring they know exactly what needs to be done to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) and critiques the authors\\' viewpoint regarding the similarity of benefits between CNNs and ViTs. The reviewer provides specific examples and reasoning, such as the DeiT-B models not outperforming DeiT-T in APTOS2019 and not outperforming DeiT-S on multiple datasets, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a claim that the authors\\' viewpoint regarding the similarity of benefits between CNNs and ViTs from increased model capacity is incorrect. The reviewer provides specific examples and reasoning, such as the DeiT-B models not outperforming DeiT-T in APTOS2019 and not outperforming DeiT-S on multiple datasets, which supports the claim. Additionally, the reviewer compares this with the consistent improvements observed in CNNs. This detailed justification makes the claim mostly verifiable, as it provides clear reasoning and examples to support the critique. However, it could be strengthened by referencing specific studies or works that demonstrate the differences between CNNs and ViTs in terms of model capacity. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed critique of the authors' viewpoint regarding the similarity of benefits between CNNs and ViTs from increased model capacity. It specifically addresses the performance trends in Figure 3, pointing out that the DeiT-B models do not outperform DeiT-T in APTOS2019 and do not outperform DeiT-S on multiple datasets. The reviewer also highlights that CNNs can provide consistent improvements in model capacity, except on the ISIC2019 dataset. This feedback is clear and actionable, offering specific examples and reasoning to support the critique. By providing detailed insights into the performance trends and suggesting areas for improvement, the comment is highly helpful, as it empowers the authors to address potential weaknesses in their analysis and presentation. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. The reviewer suggests that the authors should discuss the relationship between their proposed method and ResNeSt, as this could provide a clearer understanding of the novelty. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to discuss the relationship with ResNeSt. While the action is implicit, it is concrete in terms of what needs to be addressed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, suggesting that it is too similar to other attentional modules proposed in previous works. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. However, the comment does not explicitly mention which part of the paper discusses the proposed method or the attentional modules, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of discussion on the relationship between the proposed method and ResNeSt. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules proposed in previous works. It provides references to specific works ([1, 2, 3]) and mentions ResNeSt as a related structure. However, the comment lacks detailed reasoning or specific examples of how the proposed method is similar to these other works, making it somewhat verifiable. The mention of ResNeSt provides some context, but the lack of detailed comparison or analysis limits the thoroughness of the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. The comment provides a clear direction for improvement by suggesting that the authors should discuss the relationship between their proposed method and ResNeSt, which could enhance the paper's novelty and differentiation. However, the comment could be more helpful if it offered specific suggestions on how to discuss this relationship or provided examples of how the proposed method differs from ResNeSt. Overall, the comment is mostly helpful as it highlights a potential area for improvement and provides a clear direction for the authors to enhance the novelty of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the implicit call to the Witness oracle is confusing. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the concept, provide an alternative explanation, or offer specific steps to improve the clarity of the text. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in terms of the issue it addresses, it lacks grounding as it does not provide a clear reference to the part of the paper where this confusion occurs. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the implicit call to the Witness oracle is confusing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the implicit call to the Witness oracle is confusing. However, it does not provide any suggestions or guidance on how the authors might clarify this concept or improve the clarity of the text. Without actionable advice or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential issue but does not offer actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not explicitly instruct the authors to do so or suggest specific alternative methods. The action is implicit and somewhat vague, as the authors can infer that they need to improve their methodology but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the authors\\' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in its critique of the methodology and the need for improvement, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' methodology for reproducing a well-known result, questioning the need for this observation to be made again using a \"coarse\" methodology. The reviewer provides a logical reasoning by referencing the common knowledge that language models inherit biases from their training corpora, which has been observed in various models like word2vec, BERT, and ChatGPT. This reasoning supports the claim that the observation is not novel and could be more effectively addressed with a more sophisticated methodology. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue, which would enhance its verifiability. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment critiques the authors' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a 'coarse' methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might improve their approach or what alternative methods they could use. This limits the comment's helpfulness, as it provides some insight but does not offer actionable feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the distinction between training the proposed method with weak supervision and semi-supervised training. It provides a specific suggestion to rename the column in Table 1 and proposes a more detailed approach to specify the data used for training. This feedback is clear and provides concrete steps for the authors to take, making it highly actionable. The authors know exactly what changes need to be made to improve the clarity of their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors clarify the distinction between weak supervision and semi-supervised training, and provides a specific suggestion for renaming the column. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the distinction between training with weak supervision and semi-supervised training, particularly in Table 1. It provides a specific example of how the proposed framework row in Table 1 refers to the semi-supervised version of the method, recommending a renaming of the column. The reviewer also offers a suggestion for a more detailed approach to specify the data used for training. While the comment is based on a logical reasoning and provides specific suggestions, it lacks explicit references or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could be strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the clarity of the paper by distinguishing between training with weak supervision and semi-supervised training. It specifically references Table 1 and offers a specific recommendation to rename the column and provide more detailed information about the data used for training. This feedback is valuable as it helps the authors to better organize and present their results, making the paper more accessible and understandable. The comment is detailed and actionable, aligning with a score of 5, indicating that it is highly helpful for the authors to improve their draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific weakness in the paper, namely the limited consideration of datasets in the experiments section. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. The comment provides concrete examples of relevant works and datasets, giving the authors clear direction on how to improve their experimental evaluation. This feedback is explicit and provides detailed guidance on what actions to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the limited consideration of datasets in the experiments, particularly those from Federated learning benchmarks. The comment suggests relevant works for the authors to consider, such as FedProx and FedMAX, providing clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s main weakness is the limited consideration of datasets in the experiments section, specifically mentioning CIFAR-10 and suggesting the inclusion of datasets from Federated learning benchmarks like LEAF. The reviewer provides references to specific works, FedProx and FedMAX, which are relevant to the field and could serve as examples for the authors to consider. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples of how these datasets and works would enhance the paper\\'s comprehensiveness. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experimental evaluation, which is only conducted on the CIFAR-10 dataset. It suggests that the authors should expand their evaluation to include datasets from Federated learning benchmarks, such as LEAF, and references specific works like FedProx and FedMAX for guidance. This feedback is clear and actionable, providing the authors with a concrete direction to improve the comprehensiveness of their experimental evaluation. By addressing this issue, the authors could enhance the significance and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting by balancing the unlabeled data, as is done in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (EMNLP 2018). The comment provides a specific reference to a similar study, which gives the authors a clear direction on how to improve their approach. It also explains the rationale behind the suggestion, making it explicit and concrete. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of unlabeled data from the Amazon review dataset, specifically mentioning the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced.\" This provides full grounding as it explicitly references a specific part of the paper. The comment also specifies the issue by noting that this balance is impractical in real-world applications and suggests using a more convincing setting as in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper. This level of detail and specificity allows the authors to clearly understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data used in the study is perfectly balanced, which is impractical in real-world applications. The reviewer suggests using a more convincing setting, referencing the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (EMNLP 2018), which directly samples unlabeled data from millions of reviews. This provides a specific example of a more realistic approach. However, the comment could be strengthened by providing more detailed reasoning or evidence on why the perfectly balanced unlabeled data is impractical and how the suggested approach addresses this issue. While the reference to the He et al. paper provides some support, the claim could be more robust with additional justification. Therefore, the comment is mostly verifiable, as it offers a logical suggestion but lacks full justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of unlabeled data in the study, noting that the unlabeled data is perfectly balanced, which may not reflect real-world scenarios. It suggests using a more convincing setting, such as the one described in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (EMNLP 2018), which involves sampling unlabeled data from millions of reviews. This feedback is clear and actionable, as it provides a specific reference for the authors to consider when addressing the issue of data imbalance. By suggesting a more realistic approach, the comment offers valuable guidance for improving the study\\'s applicability and relevance. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusing description of the MFDA setting in the Method Section, specifically mentioning the use of \"single target domain with sparse labels\" and the labeling of the target distribution p_T(x, y) with label observation. It also questions the notation for the target domain \\u03c7 and references the original MFDA paper (Yue et al., 2021a) for clarification. The reviewer points out that the problem setting description differs significantly from the original paper, leaving the authors with a clear action to address the confusion. However, the comment does not provide specific guidance on how to resolve the issue or what changes should be made. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section\" and references the \"MFDA paper (Yue et al., 2021a)\", allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the confusing description of the MFDA setting, particularly regarding the labeling of the target domain and the use of unlabeled data in source domains. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the MFDA setting description in the Method Section. It points out that the description is confusing, particularly regarding the labeling of the target domain and the use of unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) to provide context and questions the consistency of the problem setting description. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the original paper provides some context, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a confusing description of the MFDA setting in the Method Section, specifically regarding the labeling of the target domain and the use of unlabeled data in source domains. It references the original MFDA paper (Yue et al., 2021a) for clarification, highlighting a discrepancy in the problem setting description. This feedback is clear and actionable, as it points out a specific area of confusion that the authors need to address to improve the clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion or offered alternative ways to clarify the description. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights several issues with the paper, including the perceived incremental contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It also suggests that the paper should introduce MedRetriever and KGRAG. However, the comment does not provide explicit instructions on how to address these issues or what specific changes should be made. The authors are left to infer that they need to review and possibly expand their literature review and methodology sections to include these references and algorithms. While the comment identifies areas for improvement, it lacks concrete guidance on how to implement these changes, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the perceived incremental nature of the contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It specifically mentions the combination of GraphRAG and GraphCare, as well as the need to introduce MedRetriever and KGRAG. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the issues are related to the methodology and literature review sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, such as the need for additional citations and the inclusion of specific algorithms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the article is incremental and consists of a combination of GraphRAG and GraphCare, without providing specific examples or references to support this claim. It also mentions that many key baselines were not cited and that essential RAG algorithms should have been introduced, such as MedRetriever and KGRAG. However, the comment lacks detailed reasoning or evidence to substantiate these claims, making it difficult for the authors to understand and address the issues effectively. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the points.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies several issues with the paper, including the perceived incremental nature of the contribution, the lack of citation of key baselines, and the omission of essential RAG algorithms. It suggests that the paper should introduce MedRetriever and KGRAG, which are commonly used algorithms in the field. However, the comment lacks specific guidance on how to address these issues or what changes should be made to the paper. While it points out areas for improvement, it does not provide detailed feedback or actionable steps for the authors to take, making it somewhat helpful. The authors are left to infer that they need to review and possibly expand their literature review and methodology sections, but without concrete suggestions, the comment remains somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning Baidu's work. It suggests that this work uses the triplet loss and reports results on a dataset similar to Webface, with the VRF achieving 98.65% on LFW, which is better than the result in Table 3 of the paper. While the comment identifies a gap in the literature and provides a specific reference, it does not explicitly instruct the authors to include this reference or discuss it in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this reference and discussing its implications. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the experiment of face recognition and references a specific work by Baidu. It also provides a link to a dataset results page, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it details the missing reference and provides a comparison with the results in Table 3, suggesting that the VRF achieves better performance. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning Baidu's work. It provides a link to a dataset results page, which supports the claim by offering a specific example of a relevant reference. However, the comment could be strengthened by providing more detailed reasoning or examples of why this reference is important or how it could impact the paper's results. The mention of Baidu's work and the link to the dataset results page provide some support, but the claim is not fully verifiable due to the lack of detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's literature review by pointing out that some state-of-the-art references are missing, specifically mentioning Baidu's work on face recognition. It provides a specific reference and highlights that this work uses the triplet loss and reports results on a dataset similar to Webface, achieving a higher accuracy on LFW compared to the results in Table 3 of the paper. This feedback is valuable as it directs the authors to include a relevant and potentially impactful reference in their work, which could enhance the comprehensiveness and credibility of their literature review. However, the comment could be more helpful if it suggested how the authors might integrate this reference into their paper or discussed the implications of this comparison. Overall, the comment is mostly helpful as it provides clear guidance on improving the paper's literature review, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to \"cite the source appropriately\" regarding the rock-paper-scissors example, which is inspired by a previous work. This provides a clear and direct action for the authors to take, ensuring they give proper credit to the original source. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to cite the source appropriately. This provides clear guidance on what needs to be done to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by a previous work and suggests citing the source appropriately. However, the comment does not provide any specific references or examples of previous work that the example is inspired by, nor does it explain why this is important to cite. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the rock-paper-scissors example, noting that it is inspired by previous work. It provides a clear and actionable suggestion for the authors to cite the source appropriately. This feedback is helpful as it guides the authors to ensure proper attribution and acknowledges the influence of prior work, which is essential for academic integrity and credibility. However, the comment could be more helpful if it provided specific examples of previous work or detailed guidance on how to cite the source. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides an explicit suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) as an example. This feedback is concrete and provides a clear action for the authors to take, which is to explore the averaging approach as an alternative to using the embedding of the first subword token as the verb embedding. The authors know exactly what action to take and how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) as an example. This provides clear guidance on how to address the issue, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides a specific reference to a source (Hewitt and Manning, 2019) that discusses averaging over subword representations. This provides a clear and verifiable basis for the claim that averaging is a common practice in certain cases. The reference to the source adds credibility and supports the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that averaging over subword representations is a common practice, as exemplified by a reference to Hewitt and Manning (2019). This feedback is actionable and offers a concrete alternative to the current approach of using the embedding of the first subword token as the verb embedding. By suggesting this alternative, the comment helps the authors enhance their methodology and potentially improve the performance or interpretability of their model. However, the comment could be more helpful if it included a discussion on why averaging might be beneficial or how it could be implemented. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve or expand upon their experimental setup or results. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"experiments\" and \"CATER,\" but it does not specify which part of the paper these experiments are discussed in or how they relate to the main claims or findings. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in describing the comprehensive nature of the experiments, including architectural mismatches and cross-domain imitation, but it does not provide detailed guidance on what aspects of these experiments need improvement or clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment consists solely of factual statements about the experiments, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. This feedback provides insight into the thoroughness of the experimental validation, which is valuable information for the authors. However, the comment lacks specific suggestions or guidance on how the authors might improve or expand upon their experimental setup or results. While it offers some insight into the strengths of the study, it does not provide actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a positive aspect but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions. While the comment provides valuable information, it lacks actionable guidance on how the authors should utilize this information to improve their draft. Therefore, the comment is somewhat actionable, as it provides some insight but does not offer clear instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the bounded noise assumption and its limitations in stochastic optimization literature, referencing specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this critique pertains to, such as a particular section or discussion. This makes it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing the limitations of the bounded noise assumption and suggesting relevant works for further exploration, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide detailed reasoning or analysis to support why this assumption is restrictive or how the referenced works address this limitation. While the references are specific, the lack of detailed justification or explanation makes the claim somewhat verifiable. The authors would need to read the referenced works to fully understand the context and implications of the claim, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. This feedback is somewhat helpful as it directs the authors to relevant literature that could inform their work. However, the comment does not offer specific guidance on how to incorporate these references or what aspects of the bounded noise assumption could be improved. Additionally, it lacks detailed suggestions on how the authors might address the limitations of the bounded noise assumption in their own research. While it provides a starting point for further exploration, the feedback could be more actionable and comprehensive to be rated as highly helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It explicitly asks whether \"100 steps\" refers to 100 sampled strategies. This question provides a clear and direct action for the authors to clarify the meaning of \"100 steps\" in their draft. The comment is explicit and concrete, as it directly instructs the authors to provide clarification on the terminology used. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the meaning of \"100 steps\" in the context of the search models comparison in section 5.1. It asks whether \"100 steps\" refers to 100 sampled strategies, providing a clear and direct inquiry for clarification. This feedback is actionable as it prompts the authors to clarify their terminology, which is essential for ensuring the clarity and understanding of their work. However, the comment could be more helpful if it suggested how the clarification might impact the analysis or interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to address a specific point of confusion, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the reason why their proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO. It also requests an explanation of the theoretical technique difference between DMLCBO and these works. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the theoretical differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and references specific previous works, SUSTAIN and MRBO, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed algorithm, which is its failure to achieve the same convergence rate as previous works using the double momentum technique. The comment also suggests that the authors discuss the reason for this difference and the theoretical technique difference between DMLCBO and the referenced works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which use the double momentum technique. The reviewer provides references to these works and suggests that the authors discuss the reason for this difference and the theoretical technique difference between DMLCBO and the referenced works. While the comment identifies a potential issue, it lacks specific details or examples to fully substantiate the claim. The references to SUSTAIN and MRBO provide some context, but the comment could be strengthened with more detailed reasoning or evidence to support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works using the double momentum technique. It suggests that the authors discuss the reason for this difference and the theoretical technique difference between DMLCBO and the referenced works. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve their draft. By addressing this point, the authors can enhance the theoretical foundation of their work and potentially strengthen their claims. Therefore, the comment is rated as highly helpful, as it offers detailed and constructive guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the scalability aspect, but it lacks concrete steps or recommendations on how to mitigate the potential scalability problem. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the modulator, which is a specific element of the paper, providing a clear reference to the part of the paper being discussed. It also raises a concern about scalability and the potential need for tedious hyperparameter tuning for diverse training data. This provides a specific issue for the authors to address, making the comment fully grounded. However, it does not specify how the authors should address the scalability issue or suggest potential solutions. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the modulator, noting that it is heuristically designed and suggesting that there might be scalability concerns. It raises a concern about the need for tedious hyperparameter tuning for diverse training data, which is a valid point that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or strategies for improving scalability. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the use of untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their OOD experiments. It also implies that the authors should ideally compare their method with those class of methods. While the comment explicitly states the actions to take, it does not provide detailed guidance on how to integrate this information into the paper or what specific comparisons to make. The authors are given a clear direction but may need to infer the exact implementation details. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Regarding the OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al., and place their method in context. Additionally, it implies that the authors should ideally compare their method with those class of methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention untrained neural networks, such as the deep image prior by Ulyanov et al., in the context of their OOD experiments. It provides a logical reasoning by pointing out that untrained networks have been shown to be effective in solving inverse problems across a wide class of images. This reasoning supports the claim that mentioning untrained networks would be beneficial. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper's OOD experiments by suggesting that the authors mention untrained neural networks, such as the deep image prior by Ulyanov et al. (CVPR 2018), in the context of their work. This is a constructive suggestion as it provides a relevant comparison that could enhance the paper's context and understanding of the results. The comment also implies that the authors should ideally compare their method with those class of methods, which could further strengthen the paper's contribution. However, the comment could be more helpful if it provided specific guidance on how to integrate this information or what aspects of the comparison would be most beneficial. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more detailed.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the first two sections of the paper, noting that the author stacked a number of previous approaches but failed to explain each method clearly. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide explicit guidance on how to address these issues or suggest specific changes to improve clarity. The authors are left to infer that they need to clarify the explanations, but the lack of concrete suggestions makes it difficult to know exactly what actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" This level of detail helps the authors understand what needs to be addressed in these sections. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with the clarity of the paper, particularly in the first two sections. It provides examples of unclear statements, such as the \"trivial\" conversion of stacked LSTM to sequential LSTM and the sentence \"our lower hierarchical layers zoom in time.\" However, the comment does not provide detailed reasoning or examples to support why these statements are unclear or how they could be improved. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the exact issues from the examples provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the clarity of the paper, particularly in the first two sections. It points out that the author stacked a number of previous approaches but failed to explain each method clearly. The comment provides examples of unclear statements, such as the 'trivial' conversion of stacked LSTM to sequential LSTM and the sentence 'our lower hierarchical layers zoom in time.' This feedback is clear and actionable, as it directs the authors to clarify these sections and provides specific examples of what needs to be addressed. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the explanations. Overall, the comment is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the goal of the paper, specifically regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that the authors should clarify whether their claim is that this is a foundation model or a proof of concept, and if it is the latter, to justify a future useful application. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the goal of the paper, specifically mentioning the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the introduction or methodology sections where the goal and comparison are discussed. The authors can infer the relevant parts, but the comment lacks explicit grounding. The specificity is clear as it specifies what needs to be addressed regarding the goal and comparison. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of comparison with existing DAS earthquake detectors and the need for justification regarding the benefit of the authors\\' method against these existing approaches. The reviewer suggests that the paper should clarify whether it claims to be a foundation model or a proof of concept and, if the latter, to justify a future useful application. While the comment identifies a gap in the paper, it lacks specific examples or references to existing DAS earthquake detectors, making it somewhat verifiable. The authors would need to conduct additional research or provide more detailed information to fully address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if the latter, to justify a future useful application. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the lack of comparison and justifying the potential utility of their method. However, the comment could be more helpful if it offered suggestions on how to conduct the comparison or what aspects of the existing methods should be considered. Overall, the comment is mostly helpful, as it guides the authors toward a clearer and more comprehensive presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights similarities between the current analysis and prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a detailed critique of the analysis, comparing it to prior works and suggesting that the results are not surprising due to similarities with existing studies. It references specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in detailing the similarities and comparisons with prior works, providing a clear basis for the critique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar analyses are present in prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This provides a logical basis for the claim, as it references existing literature and studies that have explored similar topics. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a strong foundation but lacks some specific details for full verification.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the analysis, noting that similar analyses are present in prior works. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This feedback is somewhat helpful as it highlights a potential gap in the originality of the analysis and suggests that the results may not be particularly surprising. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the originality of their work. As it stands, the comment provides a basis for reflection but lacks actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on two issues: the accuracy of the claim about the Walkman algorithm being solved by ADMM and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. The first point is fully grounded as it explicitly mentions the second paragraph of the \"Related Work\" section, allowing the authors to accurately identify the part of the paper needing revision. The second point is also fully grounded, as it refers to the first paragraph of Section 3. The comment is specific in detailing what needs to be addressed in each case, providing clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the inaccuracies in the claim about the Walkman algorithm being solved by ADMM and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. This detailed guidance helps the authors understand what needs to be revised or clarified in their draft. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims. The first claim is that the statement \"However, these works are all based on the simple SGD for decentralized optimization\" is inaccurate because the Walkman algorithm is solved by ADMM, with two versions. This claim is somewhat verifiable as it provides a specific reference to the Walkman algorithm and its solution by ADMM, but it lacks detailed reasoning or examples to fully substantiate the claim. The second claim is that the reference for the \"it\" in the first paragraph of Section 3 is unclear. This is a factual observation that does not require verification. Therefore, the overall verifiability of the comment is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two distinct issues. First, it corrects a factual error by pointing out that the Walkman algorithm is solved by ADMM, not SGD, and provides a detailed explanation of the two versions of the solution. This feedback is valuable as it helps the authors ensure the accuracy of their claims in the \"Related Work\" section. Second, the comment identifies a lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3, suggesting that the authors need to clarify this reference. This feedback is clear and actionable, guiding the authors to improve the clarity and accuracy of their draft. Overall, the comment is mostly helpful as it provides specific guidance on correcting factual errors and improving clarity, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more experimental results to demonstrate the effectiveness of their proposed method, referencing specific works ([1, 2, 3]) as examples. This feedback is explicit, as it directly instructs the authors to expand their experimental section. The suggestion is also concrete, as it provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental results to demonstrate the effectiveness of the proposed method, referencing specific works ([1, 2, 3]) as examples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include more experimental results to demonstrate the effectiveness of their proposed method, referencing specific works ([1, 2, 3]) as examples. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, indicating that including additional experimental results would strengthen the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how these specific works relate to the proposed method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental results to demonstrate the effectiveness of their proposed method. It provides a clear and actionable suggestion by referencing specific works ([1, 2, 3]) as examples of additional experimental results that could be included. This feedback is valuable as it guides the authors on how to enhance the robustness and comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it offered additional guidance on how to integrate these examples or what specific aspects of the proposed method should be emphasized in the additional experiments. Overall, the comment is mostly helpful, as it provides clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that more information is needed on the translation and filtering methodology used to create the Arabic climate change QA dataset. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the process. The comment specifies what needs to be addressed, making it explicit and concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of details regarding the filtering process used to create the Arabic climate change QA dataset. It specifies that more information on the translation and filtering methodology is needed to assess the dataset quality. However, it does not explicitly mention which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, which is the lack of information on the filtering process. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking. This is a factual statement that does not contain an opinion, judgment, or suggestion. It does not require verification or evidence, as it is a straightforward observation. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the importance of providing more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to include additional details that would enhance the transparency and credibility of their work. However, it could be more helpful if it suggested specific aspects of the methodology that should be elaborated upon or provided examples of how this information could be integrated into the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take, suggesting that the \"Related Work\" section should be expanded to include a more comprehensive overview of existing methods and their limitations. It specifies the types of methods that should be discussed, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This feedback is concrete, as it outlines specific areas for improvement and provides examples of relevant methods. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be improved, such as providing a more comprehensive overview of existing methods and their limitations, and suggesting specific types of methods to include, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail helps the authors understand exactly what needs to be addressed in the \"Related Work\" section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"Related Work\" section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The comment provides examples of specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which should be included to better position SSMs. This provides a clear and specific rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Related Work\" section, noting that it lacks details and suggesting ways to enhance it. It provides a clear and actionable feedback by specifying the types of methods that should be included, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This guidance helps the authors understand what additional information is needed to provide a comprehensive overview of the field. However, the comment could be more helpful if it included specific examples or references to these methods, which would further assist the authors in implementing the suggested improvements. Overall, the comment is mostly helpful as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors might improve it. Without concrete examples or detailed suggestions, the authors are left without a clear understanding of what changes to make or how to address the issues. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or what specific issues need to be addressed. Without this level of detail, the authors cannot confidently determine which sections to focus on for improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a subjective observation about the writing being unclear, but it does not provide any specific examples or reasoning to support this claim. Without detailed feedback or evidence, the authors are left without guidance on how to improve the clarity of their writing. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the writing in the paper is unclear, but it does not provide specific examples or suggestions for improvement. This lack of detail makes it difficult for the authors to understand which parts of the writing are unclear and how to address these issues. Without actionable feedback or guidance, the comment does not effectively assist the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to take to improve the experiment or the explanation. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the synthetic experiment in a non-separable case and asks for an explanation of how the data distribution illustrated in Figure 1 can be inseparable from the network model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model. This feedback highlights a potential issue that the authors need to address, as it questions the validity of the experiment. However, the comment lacks specific guidance or suggestions on how to resolve this issue or improve the experiment. While it identifies a problem, it does not provide actionable steps or detailed feedback, making it somewhat helpful. The authors are left with a general understanding of the problem but without clear direction on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the efficiency or whether there are alternative methods to consider. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the pairwise matching are inefficient or how they can be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the assertion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it provides a general insight but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this idea or whether it should be considered a significant contribution. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the idea of adding a method on top of other methods to improve transferability, but it does not specify which part of the paper this suggestion is related to. The authors cannot confidently determine which section or method this comment pertains to, making it weakly grounded. The comment is specific in suggesting that this approach is good but not significant, providing a clear direction for the authors to consider. However, without explicit grounding, the comment is not fully actionable. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach is not significant. Without specific reasoning or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any further explanation or guidance on why this approach is not considered a significant contribution. The comment lacks depth and actionable feedback, leaving the authors without specific insights or suggestions for improvement. As a result, the comment is not helpful, as it does not offer meaningful guidance or constructive feedback that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, implying that the authors should reconsider the phrasing. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. While the first part is somewhat vague, it does provide a clear direction for the authors to consider revising their language. The second part is explicit and concrete, offering specific suggestions for improvement. However, the overall comment lacks detailed guidance on how to tone down the statement or how to address the grammatical errors, making it somewhat actionable. Therefore, the comment is rated as mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the line number '34' and the specific statement about the neural network memorizing critical points. This allows the authors to accurately identify the part of the paper being addressed. Additionally, the comment is specific because it provides clear feedback on the phrasing of the statement and suggests ways to improve the method section, such as compressing it and correcting grammatical errors. The mention of plurals and articles provides specific guidance on what needs to be checked. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point consists of two parts. The first part suggests toning down a statement about the neural network memorizing critical points, which is a subjective claim that requires no verification. The second part provides specific feedback on the method section, suggesting it could be compressed and corrected for grammatical errors. This part is mostly verifiable as it provides clear guidance on how to improve the method section, but it lacks detailed examples or references to support the grammatical corrections. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a mix of feedback. It suggests toning down a statement about the neural network memorizing critical points, which is a specific and actionable suggestion for improving the clarity of the text. Additionally, it offers feedback on the method section, suggesting it could be compressed and corrected for grammatical errors, particularly regarding plurals and articles. This feedback is clear and provides the authors with concrete steps to improve their draft. However, the comment could be more helpful if it included specific examples of grammatical errors or suggested ways to compress the method section. Overall, the comment is mostly helpful as it offers actionable advice for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors\\' claim of parameter efficiency and asks for clarification on the experimental setup, specifically why the authors switched the types of BPE vocabulary. While the comment identifies areas for improvement and raises specific questions, it does not provide explicit guidance on how the authors should address these issues or what changes they should make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with Megatron and questions the overrating of this comparison. It also raises a specific question about the experimental setup, particularly the switch in BPE vocabulary types. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the comparison and experimental setup sections. The authors can infer that it relates to these parts, but the comment lacks explicit grounding. The specificity is clear as it identifies the issue with the comparison and the question about the experimental setup. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also raises a question about the experimental setup, specifically the switch in BPE vocabulary types. While the comment provides some reasoning by comparing the performance of Megatron and COCO-LM with other approaches, it lacks detailed justification or references to support the claim about overrating. The question about the experimental setup adds depth but does not fully substantiate the initial claim. Therefore, the comment is somewhat verifiable, as it provides some reasoning but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the authors' claim of parameter efficiency and asks for clarification on the experimental setup, specifically why the authors switched the types of BPE vocabulary. While the comment identifies a potential issue with the comparison and raises a relevant question, it lacks detailed guidance on how the authors should address these concerns or improve their analysis. The feedback is somewhat helpful as it points out areas for improvement but could be more comprehensive and actionable to be fully beneficial for the authors.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific example from the histogram in Figure 3, where the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features with ResNet-50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should improve the analysis or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should strengthen their analysis or provide additional context. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of convincing analysis and provides a specific example from the histogram in Figure 3. The comment further clarifies the hypothesis about the GS-P-50 model and suggests that additional context might improve the analysis. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific example from the histogram in Figure 3, where the GS-P-50 model has a smaller class selectivity score, indicating that it shares more features with ResNet-50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the observation indicating that GS-P-50 learns better representation. While the reference to [1] and [2] provides some context, it does not fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a detailed explanation using the histogram in Figure 3, highlighting the GS-P-50 model's smaller class selectivity score, which implies that it shares more features with ResNet-50. The reviewer also hypothesizes that additional context might allow the network to reduce its dependency. However, the comment could be more helpful if it offered suggestions on how the authors might strengthen their analysis or provide additional context. Overall, the comment is somewhat helpful as it points out a potential weakness but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including [R1], [R2], and [R3], which employ feature replay for continual learning. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to strengthen their conclusions. The feedback is somewhat actionable as it highlights a potential weakness but lacks detailed instructions on how to improve it. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific claims about the paper\\'s conclusions, such as the belief that continuous learning with unlabeled data accumulates noise. It also provides references to external works, including [R1], [R2], and [R3], which offer potential explanations for the observed results. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including [R1], [R2], and [R3], which employ feature replay for continual learning. This provides some support for the claim by offering examples of alternative approaches. However, the comment lacks detailed reasoning or specific evidence to fully substantiate the claim. The references provided are relevant but do not directly address the specific claim about the conclusions being unconvincing. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s conclusions, noting that some claims are not convincing. It provides a detailed critique by pointing out a potential limitation in the exploration of combination methods and references several works, including [R1], [R2], and [R3], which employ feature replay for continual learning. This feedback is valuable as it directs the authors to consider alternative approaches and provides specific examples of relevant literature. However, the comment could be more helpful if it offered suggestions on how to strengthen the paper\\'s conclusions or provided additional guidance on addressing the identified issue. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a starting point for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific in its suggestion that some aspects might be hardware and software dependent, but without explicit references or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be influenced by specific hardware or software configurations. However, the comment does not provide any specific examples, references, or guidance on how the authors might address this issue or what implications it might have for their work. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific in its suggestion that some aspects might be hardware and software dependent, but without explicit references or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be influenced by specific hardware or software configurations. However, the comment does not provide any specific examples, references, or guidance on how the authors might address this issue or what implications it might have for their work. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide explicit guidance on how the authors might address the lack of novelty or what specific aspects of the paper could be improved to enhance its originality. The feedback lacks actionable steps or concrete suggestions for the authors to consider, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items. However, it does not specify which part of the paper this critique applies to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer supports this claim by noting that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the paper lacks originality. The mention of different penalty coefficients for users and items does not provide enough context or explanation to fully support the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it lacks depth and does not provide specific suggestions on how the authors might enhance the originality of their work. The feedback is vague and does not offer actionable guidance on how to address the lack of novelty or improve the paper's contribution. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies specific issues with the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma in the equation. The reviewer suggests clarifying these points. The comment provides explicit actions for the authors to take, such as clarifying the description and the equation, which are concrete and actionable. However, it does not specify how to address the potential numerical instability issue, which could be addressed with additional guidance. Overall, the comment is mostly actionable due to its clear and concrete suggestions for improvement.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Sec. 4.2,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issues with the description and equation, particularly the absence of the term r^q and the unclear meaning of sigma. The comment also raises concerns about potential numerical instability due to the use of sigmoid activations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q and the unclear meaning of sigma. The reviewer suggests clarifying these points and raises a concern about potential numerical instability due to the use of sigmoid activations. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim about numerical instability. The suggestion to clarify the equation is clear, but the lack of detailed justification for the numerical instability concern makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the description in Section 4.2 regarding the use of the question to learn attention on image features. It points out a discrepancy between the description and the equation, specifically mentioning the absence of the term r^q, which is the question representation, and the unclear meaning of sigma in the equation. The reviewer suggests clarifying these points, which is a clear and actionable suggestion. Additionally, the comment raises a concern about potential numerical instability due to the use of sigmoid activations, which could be addressed with additional guidance. While the comment provides valuable feedback on improving the clarity and accuracy of the paper, it could be more helpful if it offered suggestions on how to address the numerical instability issue. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides clear guidance, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the paper, stating that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or improve the paper. Without specific suggestions or directions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and its incremental contribution. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or specific sections where the ENCODE part is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment lacks specific examples or detailed reasoning to support the claim that the decomposition part is a significant contribution. The mention of [10] provides some context, but without further elaboration, the claim remains somewhat verifiable. The authors would need to investigate the reference [10] and the specific aspects of the ENCODE part to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment identifies a specific issue with the paper\\'s formatting, it does not provide any guidance or suggestions on how the authors might address this problem or improve the paper. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of reduced whitespace in the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. However, it does not specify which sections or parts of the paper are affected, making it weakly grounded. The comment is specific in detailing the issue with the formatting, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This claim is supported by the observation that these issues could lead to a violation of the 9-page paper limit, which is a clear and logical reasoning. However, the comment lacks specific examples or references to substantiate the claim further, making it somewhat verifiable. The authors would need to address the issue of excessive whitespace to ensure compliance with the page limit, but the lack of detailed evidence or examples makes the claim less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment highlights a critical issue that could impact the paper's acceptability, it lacks actionable guidance or suggestions on how the authors might address this problem or improve the paper's formatting. The feedback is somewhat helpful as it points out a specific area for improvement, but it does not provide detailed advice or examples on how to resolve the issue, leaving the authors with limited actionable information. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not specify which sections or parts of the paper are lacking in detail or clarity. The authors may infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue of limited technical details and formulations, but it lacks grounding as it does not specify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. This feedback highlights an area where the authors might need to provide more depth or clarity to better communicate the novelty of their work. However, the comment lacks specific suggestions or guidance on how to enhance the technical details or formulations, which would make it more actionable. While it points out a potential issue, it does not offer concrete steps or examples for the authors to follow, limiting its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can differ across datasets. It suggests that the paper lacks cross-dataset experiments to test the generalization of the work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these cross-dataset experiments or what specific datasets should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk in methods that exploit relationships between action units and the need for cross-dataset experiments to test generalization. The comment is specific in detailing what is missing in the paper, namely, cross-dataset experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that methods exploiting relationships between action units can have different correlations across datasets, using examples of AU6 and AU1 to illustrate this point. It suggests that the paper lacks cross-dataset experiments to test the generalization of the work. While the claim is based on logical reasoning and provides specific examples, it lacks detailed references or specific datasets to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the assertion but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential risk in methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of AU6 and AU1, emphasizing the need for cross-dataset experiments to test the generalization of the work. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a method to address it. However, the comment could be more helpful if it offered additional guidance on how to conduct these cross-dataset experiments or which datasets to use. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that over-parametrization leads to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that supports the benefits of over-parametrization in supervised learning of deep neural networks. However, the comment does not explicitly instruct the authors to address this claim or provide a specific action to take. The suggestion to include references to theoretical work is implicit and somewhat vague, as it does not specify which references to include or how to incorporate them into the paper. Therefore, the comment is somewhat actionable, as it provides a direction for the authors to consider but lacks concrete guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the claim that over-parametrization leads to overfitting and worse performance, providing references to theoretical work that support the benefits of over-parametrization in supervised learning of deep neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim about over-parametrization and its impact on performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of over-parametrization in supervised learning of deep neural networks. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific examples or detailed explanations of the theoretical work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment challenges a claim about over-parametrization and its impact on performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of over-parametrization in supervised learning of deep neural networks. This feedback is valuable as it encourages the authors to reconsider their assumptions and potentially revise their claims. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or address the challenge to the claim. Overall, the comment is mostly helpful as it prompts the authors to consider alternative perspectives and provides a direction for further exploration.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the experimental comparison, suggesting that the proposed method was pre-trained before fine-tuning, which may not be the case for the compared methods. It implies that the authors should ensure that the compared methods were also pre-trained or initialized with similar models. The comment provides a clear action for the authors to take, which is to clarify the pre-training conditions of the compared methods. This guidance is explicit and concrete, allowing the authors to address the issue directly. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, specifically noting that the proposed method was pre-trained before fine-tuning, while the compared methods may not have been initialized with the same or similar pre-trained models. This provides clear guidance on what needs to be addressed in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair due to differences in pre-training between the proposed method and the compared methods. The reviewer provides a specific example from Table 1, where the proposed method without SSL performs inferior to most compared methods. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically noting that the proposed method was pre-trained before fine-tuning, while the compared methods may not have been initialized with the same or similar pre-trained models. This observation is important because it could affect the fairness of the comparison. The comment provides a clear and actionable suggestion for the authors to ensure that the compared methods were also pre-trained or initialized with similar models. This feedback is valuable as it helps the authors address a potential weakness in their experimental setup, potentially leading to a more robust and fair comparison. However, the comment could be more helpful if it offered additional guidance on how to achieve this or provided examples of how to implement this suggestion. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using better meta-data embeddings for zero-shot learning on the CUB dataset, referencing a specific table and paper for comparison. It provides a concrete action by recommending a specific table and paper to refer to, and it also includes a follow-up update that thanks the authors for their response. This feedback is explicit and provides clear guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that better meta-data embeddings options are available and references a specific table and paper for comparison. The comment is specific in detailing what needs to be addressed, namely the use of \"attribute\" meta-data and the potential improvement with better embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of \"attribute\" meta-data for zero-shot learning on the CUB dataset is good for fair comparison but implies that better meta-data embeddings are available. It references a specific table and paper for comparison, providing a logical basis for the claim. However, the comment lacks detailed reasoning or specific examples of how the proposed method would perform with better meta-data embeddings, which could strengthen the argument. Therefore, the claim is mostly verifiable, as it provides a clear direction for improvement but could be more robust with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a specific suggestion for improvement by recommending the use of better meta-data embeddings for zero-shot learning on the CUB dataset. It references a specific table and paper for comparison, offering a clear direction for enhancing the performance of the proposed method. The comment is actionable and provides a concrete way for the authors to improve their results, making it highly helpful. However, it could be more helpful if it included more detailed guidance on how to implement the suggested changes or if it discussed the potential impact of these improvements. Overall, the feedback is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks a discussion on using moment matching instead of quantile regression for distributional reinforcement learning (DRL). It specifically mentions a relevant literature source, Nguyen-Tang et al. (AAAI\u201921), which discusses moment matching. The comment implies that the authors should include this discussion when presenting various approaches to DRL. While the action is explicit, it is somewhat vague because it does not provide detailed guidance on how to integrate this discussion into the paper. The authors know they need to address the lack of discussion on moment matching, but the comment does not specify exactly how to do so, such as which sections to include this information in or how to structure the discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 22-30, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion on using moment matching instead of quantile regression for DRL, referencing a specific literature source (Nguyen-Tang et al. AAAI\u201921). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression for DRL, referencing a specific source (Nguyen-Tang et al. AAAI\u201921). This claim is somewhat verifiable as it provides a specific reference to a relevant literature source, which could help the authors understand the point better. However, the comment lacks detailed reasoning or examples to explain why moment matching is a more suitable approach or why it should be discussed in the paper. The authors would need to explore the referenced literature to fully understand the claim, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the discussion of distributional reinforcement learning (DRL). It points out that the paper lacks a discussion on using moment matching instead of quantile regression, referencing a relevant literature source (Nguyen-Tang et al. AAAI\u201921). This feedback is valuable as it highlights an area where the paper could be improved by providing a more comprehensive overview of DRL approaches. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve the novelty of their work. Without actionable suggestions or explicit directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may infer that it relates to the interpretation of predictions or model interpretation, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the approach are considered limited or how the authors might address this critique. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the approach is limited, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. While it identifies a potential issue with the novelty of the work, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the critique or enhance the originality of their approach. Therefore, the comment is barely helpful, as it points out a concern but does not offer constructive feedback or actionable steps for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should clarify how well the assumptions underlying PCA are met. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to enhance the paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or evidence regarding the assumptions of PCA. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should clarify how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the novelty and assumptions of PCA, it lacks grounding, as it does not reference specific parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions of PCA are met in the context of the paper. While the reference provides a starting point for the authors to consider, the lack of detailed analysis or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the authors should clarify how well the assumptions underlying PCA are met. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address these concerns or enhance the significance of their results. The feedback is somewhat helpful as it points out a potential weakness in the paper's methodology, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should clarify how well the assumptions underlying PCA are met. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to enhance the paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or evidence regarding the assumptions of PCA. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should clarify how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the novelty and assumptions of PCA, it lacks grounding, as it does not reference specific parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions of PCA are met in the context of the paper. While the reference provides a starting point for the authors to consider, the lack of detailed analysis or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the authors should clarify how well the assumptions underlying PCA are met. While the comment identifies a potential area"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluative framework is limited in scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. It raises questions about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment identifies a potential limitation, it does not provide explicit guidance on how the authors should address this issue. The feedback is vague and lacks concrete suggestions for improvement, leaving the authors uncertain about how to expand the scope of their framework. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluative framework, specifically mentioning the limitations in scope, which is restricted to three Question-Answering tasks and two language models. It raises questions about the method\\'s applicability to other reasoning or generation tasks and more advanced models like vicunna or alpaca. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation framework. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the limitations of the framework and suggesting potential areas for expansion. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, specifically mentioning the consideration of only three Question-Answering tasks and two language models. The reviewer questions the method\\'s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. This claim is somewhat verifiable as it provides a specific critique of the scope of the evaluation framework, but it lacks detailed examples or references to support the claim fully. The authors would need to further explore the limitations of their framework to address this feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the evaluative framework, specifically noting that it is restricted to only three Question-Answering tasks and two language models. This feedback highlights a potential scope issue, suggesting that the method's applicability may be limited. The comment raises questions about the method's generalizability to other reasoning or generation tasks and more advanced models like vicunna or alpaca, which is a valid concern. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their evaluation. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is problematic because it implies negative rates, which is not the case. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. While the comment explicitly states the issue and provides a clear suggestion for improvement, it does not offer specific guidance on how to implement the suggested changes. The authors know what needs to be done but may need to infer the exact steps to take, such as how to create a second y-axis or which alternative visualization would be more accurate. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that it implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. This provides clear guidance on how to improve the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is \"a bit awkward\" because it implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use a second y-axis or another visualization provides some guidance, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the clarity and accuracy of the figure. By addressing this issue, the authors can improve the presentation of their results and make their work more comprehensible. However, the comment could be more helpful if it included additional guidance on how to implement the suggested changes or provided examples of alternative visualizations. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and offers a clear direction for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left without any actionable steps or concrete advice on what aspects of the algorithm's complexity could be enhanced. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the algorithm needs improvement or what aspects of complexity should be addressed. This lack of specificity makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment does not provide any guidance on how to improve the complexity of the algorithm, leaving the authors without a clear understanding of what changes to make. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific guidance or suggestions on how to achieve this improvement. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what aspects of the algorithm's complexity could be enhanced or how to make those improvements. This lack of specificity and actionable guidance makes the comment barely helpful, as it does not effectively support the authors in improving their draft.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It also points out that this is not consistent with the author\\'s experience, suggesting that the baseline models may not be properly regularized. The reviewer further asks if dropout is applied to the hidden states in addition to the embeddings. While the comment identifies a potential issue and provides a specific question for the authors to consider, it does not explicitly instruct them to address this concern or provide guidance on how to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization of their models and possibly clarify the statement in the supplemental section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for LM compared to the GAN model, suggesting that this is not consistent with the author\\'s experience. The comment further asks if dropout is applied to the hidden states in addition to the embeddings, providing a clear direction for the authors to investigate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. 2014, which suggests that the baseline models may not be properly regularized. The comment also asks if dropout is applied to the hidden states in addition to the embeddings, which could be relevant to the discussion. While the comment provides a specific example and a question for the authors to consider, it lacks detailed reasoning or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about a statement in the supplemental section D.4, questioning the necessity of smaller architectures for LM compared to the GAN model to avoid overfitting. It provides a counterexample from Zaremba et al. 2014, suggesting that the baseline models may not be properly regularized. The reviewer also asks if dropout is applied to the hidden states in addition to the embeddings, which is a relevant question for the authors to consider. While the comment identifies a potential issue and provides a specific question for the authors to address, it could be more helpful if it offered suggestions on how to investigate and resolve the issue. Overall, the comment is somewhat helpful as it prompts the authors to reconsider their approach and provides a direction for further exploration.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise. It also recommends including empirical results. While the comment implies that the authors should make the introduction more concise and incorporate empirical results, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the conciseness and include empirical results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which part of the main part or the introduction is being addressed, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and include empirical results, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve this. The authors are left with a general idea of what needs to be addressed but without actionable steps or examples. This makes the comment somewhat helpful, as it points out a potential issue but does not fully support the authors in making the necessary improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any explicit or implicit actions for the authors to take to clarify the technical contribution or address the standard nature of the analysis. The comment lacks guidance on how the authors might improve their draft to make the technical contribution more clear or distinctive. As a result, the authors are left without a clear understanding of what changes are needed to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is being addressed or provide details on what aspects of the technical contribution are unclear. This lack of specificity makes it difficult for the authors to identify the exact areas needing improvement. Additionally, the comment does not provide any guidance on how to clarify the technical contribution or address the standard nature of the analysis. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors are left without guidance on how to address the issue or improve their technical contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's technical contribution, noting that most of the analysis is standard. This feedback is valuable as it highlights a potential weakness in the paper's originality and suggests that the authors may need to clarify or enhance their technical contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the technical contribution. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment does not provide specific guidance on how to reproduce these features or what aspects of the previous models need to be replicated. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization approach used in the LN models and compares it to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment does not specify which part of the paper discusses the regularization or the LN models, making it weakly grounded. The suggestion to reproduce the main features of previous models is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the regularization approach applied to the LN models, noting that it differs from previous models. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment lacks specific examples or references to the previous models, such as Pillow et al., which would provide more context and support for the claim. Without detailed references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, the comment could be more helpful if it offered suggestions on how to reproduce the features or what aspects of the previous models are crucial to replicate. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including some failure cases and related discussion would be beneficial. However, it does not provide explicit guidance on which specific failure cases to include or how to structure the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add failure cases and discuss them, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including some failure cases and related discussion, but it does not specify which part of the paper this feedback pertains to. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in its suggestion to include failure cases and discuss them, but it lacks grounding as it does not specify the exact sections or parts of the paper where this information should be added. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including some failure cases and related discussion, but it does not provide any specific reasoning, examples, or references to support why this would be beneficial. Without additional context or justification, the authors may find it challenging to understand the value of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that including some failure cases and related discussion would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific failure cases to include or how to structure the discussion. This limits the usefulness of the feedback, as the authors may not know how to implement the suggestion effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the variable \\u03b5 should be introduced when discussing equation (11) in Section 4.1, as it is not used in equation (10). This provides a clear and direct action for the authors to take, which is to introduce \\u03b5 in the appropriate section. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the use of \\u03b5 in equations (10) and (11), suggesting that introducing \\u03b5 when discussing equation (11) might improve clarity. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the variable \\u03b5 is not used in equation (10) but is used in equation (11). It proposes that introducing \\u03b5 when discussing equation (11) might improve clarity. While the comment identifies a potential issue with the use of \\u03b5, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to introduce \\u03b5 is a logical step to enhance clarity, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the variable \\u03b5 in equations (10) and (11) in Section 4.1. It suggests that introducing \\u03b5 when discussing equation (11) might improve clarity. This feedback is clear and actionable, as it provides a specific recommendation for enhancing the clarity of the text. By addressing this suggestion, the authors can improve the coherence and understanding of their work. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim regarding evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion of evolutional dropout, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. The comment implies that these limitations should be discussed explicitly. However, the claim lacks specific examples or references to support the comparison between evolutional dropout and Batch Normalization, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and points out its limitations, particularly in only increasing the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation, suggesting that these limitations should be discussed explicitly. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper's discussion of evolutional dropout. However, it could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be addressed. Overall, the comment offers a clear direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution should be described or how to enhance the description. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the contribution without being given concrete steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the author should add more description about the contribution of the paper, but it does not specify which part of the paper this contribution is discussed in or what aspects of the contribution need more description. This lack of specificity makes it difficult for the authors to identify the exact sections that need revision. The comment is not grounded because it does not provide any explicit references to specific parts of the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the author should add more description about the contribution of the paper, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution need more description or how to enhance the description. This lack of detail makes it difficult for the authors to understand the exact areas that require improvement and how to address them effectively. As a result, the comment is barely helpful, as it provides a general suggestion without actionable feedback. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in section 4, the term \"X\" should be a multiset instead of a set, as it is currently defined. The reviewer provides a rationale for this suggestion, explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent the graph with repeated vertex or edge labels. This feedback is explicit and provides a clear action for the authors to take, which is to revise the definition of \"X\" to reflect a multiset. The suggestion is concrete, as it specifies the change needed and its rationale, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current definition of \"X,\" suggesting that it should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a rationale for this suggestion, making the comment detailed and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that in section 4, the term \"X\" should be a multiset instead of a set, as it is currently defined. The reviewer provides a rationale for this claim by explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent graphs with repeated vertex or edge labels. This explanation is logical and provides a clear reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the definition of 'X' in section 4, suggesting that it should be a multiset rather than a set. The reviewer provides a rationale for this suggestion, explaining that including the multiplicities of labels in the graph is necessary for the histogram to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and actionable, as it guides the authors to make a specific change to improve the accuracy and clarity of their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or if it pointed out other potential issues in the section. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations. The feedback lacks explicit instructions or concrete steps for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this critique pertains to, such as a specific section or equation. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the derivation\\'s reliance on classical learning theory-based bounds and suggests the need for Bayesian considerations, but without explicit references or examples, it remains weakly grounded. Therefore, the comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback highlights a potential limitation in the authors\\' approach and suggests that incorporating Bayesian considerations could improve the validity of the bounds. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh->en ChatGPT and GPT-4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment explicitly identifies the need for significance testing, it does not provide detailed guidance on how to conduct this testing or which specific tests to use. The authors are left with a clear action to take but without explicit instructions on how to execute it, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of significance testing to support claims of method differences. The comment provides a detailed example of a claim that lacks supporting evidence, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh->en ChatGPT and GPT-4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. While the comment provides a logical argument for the need for significance testing, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could be strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, noting that the authors discuss differences between methods but do not provide significance testing to support these claims. It provides a specific example, mentioning line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer points out that the difference between zh->en ChatGPT and GPT-4 is minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. This feedback is clear and actionable, as it highlights a critical gap in the paper's methodology and provides a specific example of where significance testing is needed. However, the comment could be more helpful if it offered suggestions on how to conduct the significance testing or which specific tests to use. Overall, the comment is mostly helpful, as it effectively guides the authors in addressing a significant weakness in their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. It implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a potential issue, it does not explicitly instruct the authors to conduct ablation studies or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the potential regularization effects influencing the improvements observed in the teacher\\'s performance. It explicitly mentions the case where the student distills knowledge to the teacher, which is a clear reference to a specific part of the paper. The comment is specific in detailing the concern about the potential regularization effects and suggests the need for proper ablation studies to verify the distillation effect. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. The reviewer provides a logical reasoning by pointing out that the fine-tuning on GLUE without validation early-stopping usually has very high variances. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct further analysis or experiments to fully address the concern, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that the improvements in the teacher\\'s performance are due to distillation rather than regularization effects. It points out that the fine-tuning without early-stopping could lead to high variances, suggesting that proper ablation studies are needed to verify the distillation effect. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to substantiate their claims. However, the comment could be more helpful if it provided specific guidance on how to design and execute these ablation studies. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve their contribution. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions might be necessary. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the paper\\'s contribution and the proposed model, suggesting they appear limited and incremental. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution or model are perceived as limited or incremental. Without specific references to sections, figures, or tables, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the perceived limitations or improve the contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses an opinion that the paper's contribution appears limited and that the proposed model is incremental. However, it does not provide any specific feedback, suggestions, or examples to support this opinion or guide the authors on how to enhance their contribution or model. Without actionable advice or detailed insights, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment expresses an opinion that the paper's contribution appears limited and that the proposed model is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve their contribution. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions might be necessary. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution or model are perceived as limited or incremental. Without specific references to sections, figures, or tables, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the perceived limitations or improve the contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses an opinion that the paper's contribution appears limited and that the proposed model is incremental. However, it does not provide any specific feedback, suggestions, or examples to support this opinion or guide the authors on how to enhance their contribution or model. Without actionable advice or detailed insights, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment expresses an opinion that the paper's contribution appears limited and that the proposed model is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve their contribution. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or additions might be necessary. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion that the paper\\'s contribution appears limited and that the proposed model is incremental. However"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their model. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining of Transformer-M on QM9, highlighting that it performs poorly on most tasks other than homo, lumo, and gap. This is a clear and specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Despite this, the comment is specific in detailing the problem with the model\\'s performance and its implications for the paper\\'s claims. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as demonstrated by Transformer-M\\'s performance on QM9. The reviewer provides a specific example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the paper\\'s claim of Transformer-M being a general-purpose neural network model. This claim is somewhat verifiable as it provides a specific example of negative transfer, but it lacks detailed reasoning or references to support the general claim about negative transfer. The authors would need to further explore and substantiate the claim to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the supervised pretraining of Transformer-M on QM9, specifically noting that it performs poorly on most tasks other than homo, lumo, and gap. This observation challenges the claim that Transformer-M is a general-purpose neural network model. The comment provides a specific example of negative transfer, which is a valuable insight for the authors to consider. However, the feedback could be more helpful if it offered suggestions on how to address this issue or improve the model's generalizability. Overall, the comment is somewhat helpful as it highlights a critical area for improvement but lacks detailed guidance for the authors to implement the suggested changes.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the supervised pretraining of Transformer-M on QM9, specifically noting that it performs poorly on most tasks other than homo, lumo, and gap. This observation challenges the claim that Transformer-M is a general-purpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their model. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer, but without specific guidance, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining of Transformer-M on QM9, highlighting that it performs poorly on most tasks other than homo, lumo, and gap. This is a clear and specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Despite this, the comment is specific in detailing the problem with the model\\'s performance and its implications for the paper\\'s claims. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as demonstrated by Transformer-M\\'s performance on QM9. The reviewer provides a specific example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the paper\\'s claim of Transformer-M being a general-purpose neural network model. This claim is somewhat verifiable as it provides a specific example of negative transfer, but it lacks detailed reasoning or references to support the general claim about negative transfer. The authors would need to further explore and substantiate the claim to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed critique of the experimental evaluation, specifically focusing on the ablation study and the comparison on CIFAR. It highlights that the paper claims a distinction in the \"picking\" step, but this aspect is not ablated, and the comparison on CIFAR is not convincing. The reviewer suggests that the continual learning literature has extensive experiments on CIFAR and that the paper should compare to more approaches, ideally using the same setup as in the DEN paper to ensure fairness and correctness. While the comment identifies specific areas for improvement, it does not explicitly instruct the authors on how to address these issues, such as suggesting specific ablation studies or comparisons. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments and comparisons, but they may not know exactly how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1,\" \"Ablations 2.1.1,\" \"Experiments on CIFAR,\" \"2.2.1,\" and \"2.2.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study and the comparison on CIFAR, providing clear guidance on what needs to be addressed. The comment is specific in detailing the need for additional ablation studies and comparisons to ensure fairness and correctness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several concerns about the experimental evaluation, specifically regarding the ablation study and the comparison on CIFAR. It claims that the paper\\'s claim about the \"picking\" step is not ablated, and the comparison on CIFAR is not convincing due to the limited number of approaches compared (only DEN) and the unclear evaluation of DEN. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. While the comment provides specific examples and suggestions for improvement, it lacks detailed reasoning or references to support the claim that the comparison is not convincing. The feedback is mostly verifiable as it provides a clear direction for improvement but could be strengthened with more detailed justification or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides detailed feedback on the experimental evaluation, specifically focusing on the ablation study and the comparison on CIFAR. It highlights that the paper claims a distinction in the 'picking' step but does not provide an ablation study to support this claim. Additionally, the comparison on CIFAR is deemed unconvincing due to the limited number of approaches compared (only DEN) and the unclear evaluation of DEN. The reviewer suggests that using the same setup as in the DEN paper would make the comparison more convincing. This feedback is clear and actionable, offering specific areas for improvement and guidance on how to enhance the experimental evaluation. However, it could be more helpful if it provided additional suggestions or examples for the ablation study. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to improve their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It suggests that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between the proposed method and a previous work, [10], regarding computation time and search space. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this comparison is made in, making it weakly grounded. The authors can infer that it relates to the comparison section or the results, but this is not explicitly stated. The comment is specific in detailing the issue of information loss in the output, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. The claim is somewhat verifiable as it provides a logical reasoning for the observed difference in computation time and output information. However, the comment lacks specific references or examples to support the claim fully, making it somewhat verifiable. The authors would need to further investigate the comparison between ancestral graphs and DAGs to fully understand the implications of this claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It points out that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. This observation is insightful and provides a clear comparison that the authors might consider in their work. However, the comment does not offer specific suggestions or guidance on how the authors could address this issue or improve the performance of their method. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It points out that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between the proposed method and a previous work, [10], regarding computation time and search space. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this comparison is made in, making it weakly grounded. The authors can infer that it relates to the comparison section or the results, but this is not explicitly stated. The comment is specific in detailing the issue of information loss in the output, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. The claim is somewhat verifiable as it provides a logical reasoning for the observed difference in computation time and output information. However, the comment lacks specific references or examples to support the claim fully, making it somewhat verifiable. The authors would need to further investigate the comparison between ancestral graphs and DAGs to fully understand the implications of this claim. Therefore, the comment is rated as 3:"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify the distinction between the two methods. While the comment identifies specific areas of confusion and requests clarification, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions, questioning the differences between anchor-based regression and RepPoints in RetinaNet, and suggesting that the authors clarify this problem. The comment provides a clear rationale for the need for clarification, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet. It references other works, such as ATSS, to suggest that the regression methods may not significantly influence the results. The reviewer questions the motivations behind RepPoints and suggests that the authors clarify the differences between the two methods. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claim. The authors would need to provide additional information or evidence to fully address the reviewer\\'s concerns. Therefore, the comment is somewhat verifiable, as it provides a basis for further investigation but requires more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about the definitions in Table 1 regarding the differences between anchor-based regression and RepPoints in RetinaNet. It also questions the motivations behind RepPoints, suggesting that the authors clarify this problem. The comment provides a logical basis for the concern, referencing other works like ATSS that have demonstrated the insensitivity of regression methods. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and motivations, which are crucial for the paper's coherence and understanding. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft by addressing specific areas of confusion.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on whether the Fourier modes are real or complex numbers. This is a clear and direct action for the authors to take, as it provides a specific area of ambiguity that needs to be addressed. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fourier modes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification on whether the Fourier modes are real or complex numbers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the nature of Fourier modes (real or complex), which is a factual inquiry. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it provides a specific request for clarification regarding the nature of Fourier modes (real or complex). This feedback is valuable because it helps the authors ensure that their presentation of Fourier modes is accurate and consistent with the mathematical concepts they are using. By addressing this point, the authors can improve the clarity and rigor of their work. However, the comment could be more helpful if it included additional context or examples to further guide the authors in understanding the implications of this clarification. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to correct a specific error in their manuscript by replacing \"Fig. 5.1\" with \"Fig. 1\" on line 205. It also provides a concrete action for the authors to take, which is to include the label \"\\label\" after the \"\\caption\" in their LaTeX code. This guidance is clear and direct, allowing the authors to easily identify the necessary changes and implement them. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the incorrect reference to Fig. 5.1 instead of Fig. 1 and provides a concrete action for the authors to take, which is to correct the label in their LaTeX code. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction regarding a typographical error in the manuscript, specifically identifying a mismatch between the reference number and the actual figure caption. The comment provides a clear and specific correction, \"Fig. 1 instead of Fig. 5.1,\" and offers a solution by suggesting the use of the label \"\\label\" after \"\\caption\" in LaTeX. This feedback is straightforward and verifiable, as it relies on a simple observation and a direct correction. Therefore, the comment is fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the manuscript, namely a typographical mistake in the reference to a figure. It provides a clear and actionable correction, instructing the authors to replace \"Fig. 5.1\" with \"Fig. 1\" on line 205. Additionally, it offers a practical suggestion to include the label \"\\label\" after \"\\caption\" in their LaTeX code, which would solve the issue. This feedback is direct, specific, and actionable, enabling the authors to correct the error and improve the accuracy and clarity of their manuscript. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness by providing concrete examples of the proposed components. It specifically mentions the Element-level Graph Pre-training and its focus on core elements, but it does not provide explicit guidance on how to conduct these studies or what specific aspects to include in the case studies. The comment implies that the authors should include case studies to support their claims, but it lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of the proposed components, specifically mentioning the Element-level Graph Pre-training. It provides a specific example of a case study from \"Graph pre-training for AMR parsing and generation.\" This feedback is fully grounded as it explicitly mentions the Element-level Graph Pre-training and references a specific example, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a method for enhancing the paper\\'s effectiveness by including case studies and error studies. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness by providing concrete examples of the proposed components. It mentions a specific example from \"Graph pre-training for AMR parsing and generation,\" which supports the claim. However, the comment lacks detailed reasoning or specific examples of how case studies and error studies would improve the paper, making it somewhat verifiable. The addition of specific examples or detailed reasoning would strengthen the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that discussing case studies and error studies could enhance the paper's effectiveness by providing concrete examples of the proposed components. It specifically mentions the Element-level Graph Pre-training and its focus on core elements, but it lacks detailed guidance on how to conduct these studies or what specific aspects to include. The comment provides a specific reference to a related work, 'Graph pre-training for AMR parsing and generation,' which could serve as an example. While the feedback identifies a potential improvement area, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, as it offers a direction for enhancement but lacks comprehensive detail.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This feedback is explicit and provides a clear action for the authors to take, which is to define the notation \"cal P\" with a subscript in the same section where it is first used. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the notation \"cal P\" with a subscript is used without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of definition for the notation \"cal P\" with a subscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"cal P\" with a subscript is used several times without being defined in the same section. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward statement of a potential issue in the paper, but it lacks depth or context, making it difficult for the authors to fully understand the significance of the claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"cal P\" with a subscript being used without being defined in the same section. This is a clear and actionable feedback that highlights a potential confusion for readers who might not be familiar with the notation. By pointing out this issue, the comment provides the authors with a specific area to address, which could improve the clarity and accessibility of their draft. However, the comment could be more helpful if it suggested how the authors might define the notation or provided an example of how to do so. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, including correcting a spelling error in \"known\" to \"know\" at line 148, defining \"\\u03b3_0^{***}\" at line 156, and specifying the meaning of the colors in Figure 1. These actions are clear and concrete, giving the authors a straightforward path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (l148, l156, and Figure 1), allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, such as correcting the spelling error, defining \"\\u03b3_0^{***}\", and specifying the meaning of the colors in Figure 1. This level of detail provides clear guidance on how to improve the draft, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of three separate comments, each addressing specific issues in the paper. The first comment suggests a correction in spelling, which is a factual statement and does not require verification. The second comment requests a definition for \"\\u03b3_0^{***}\", which is also a factual request for clarification. The third comment is a request for specification of the meaning of the colors in Figure 1, which is another factual request for clarification. Since these comments are factual and do not express opinions, judgments, or suggestions that require verification, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying three distinct issues in the draft. It corrects a spelling error, requests a definition for \"\\u03b3_0^{***}\", and suggests specifying the meaning of the colors in Figure 1. Each of these points is clear and directly addresses areas where the draft can be improved, offering the authors concrete steps to enhance their work. However, the comment could be more helpful if it provided additional context or suggestions for how to make these improvements. Overall, the feedback is mostly helpful as it guides the authors in making necessary corrections and clarifications, but it could be more comprehensive with additional guidance. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or what changes might be necessary. The comment is implicit in its request for clarification, and the authors would need to infer the actions required to improve their draft. As a result, the comment is somewhat actionable, as it identifies areas for clarification but lacks concrete instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the questions being raised about the rationale behind certain design choices, such as the separate timbre encoder module and the input of SADTW. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the rationale behind certain design choices in Figure 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationale behind certain design choices in Figure 1, specifically regarding the separate timbre encoder module and the input of SADTW. While it identifies areas for clarification, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider and potentially clarify their design choices, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the writing or presentation being jumbled at times, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the writing or presentation, nor are there suggestions for specific sections or areas that need clarification. Without actionable advice or specific feedback, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"writing\" and \"presentation,\" but it does not specify which parts of the paper are jumbled or unclear. This lack of grounding makes it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its critique of the writing and presentation being jumbled, but without explicit references to sections, it is not fully grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a subjective opinion about the writing and presentation being jumbled, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to specific sections, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion about the writing and presentation being jumbled at times, but it does not provide any specific examples or suggestions for improvement. This lack of detail and actionable feedback makes it difficult for the authors to understand where the issues lie or how to address them. Without actionable guidance, the comment does not contribute significantly to the authors\\' efforts to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should investigate the computational complexity and power demand of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and power demand, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support the claim about computational complexity or power demand. The reasoning is based on the reviewer\\'s imagination and speculation, which makes the claim somewhat verifiable. The authors would need to conduct further analysis to address this concern, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises an important question about the computational complexity of the method compared to other methods, such as emerging convolutions. It also speculates on the potential power demand if the method were to be used on a mobile device, which is a relevant consideration for practical applications. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a critical aspect of the work, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider an important aspect of their work but does not fully guide them in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the authors\\' claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. However, the comment does not provide explicit guidance on how the authors should correct this error or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to revise their claim based on the reference provided. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of their paper being addressed. It also specifies the issue by pointing out a claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads, which is incorrect according to Wang et al., 2023. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a statement about the attention patterns of certain heads in the base IOI circuit is incorrect, referencing a specific section of a previous work, Wang et al., 2023. This provides a clear and specific reference to support the claim, making it fully verifiable. The authors are given a clear basis for revising their understanding or presentation of these attention patterns. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the authors\\' claim about the attention patterns of certain heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the incorrectness of the claim. This feedback is valuable as it directs the authors to a source that can help them correct their understanding or presentation of these attention patterns. However, the comment could be more helpful if it provided additional context or guidance on how to address the error or incorporate the findings from Wang et al., 2023, into the paper. Overall, the comment is mostly helpful as it highlights a critical area for improvement but lacks depth in its suggestions for resolution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the vagueness of the comment about RNNs and suggests a reference for further clarification. It also critiques the reinforcement learning analogy, suggesting that it is out of place and recommending that generalization capabilities be better illustrated with examples from later in the paper. While the feedback is specific and provides clear guidance on how to improve the draft, it does not explicitly instruct the authors to make these changes. The action is implicit but concrete, as the authors can infer the necessary modifications. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L15,\" \"L16,\" and \"L18,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the comment about RNNs being vague and suggests a reference for further clarification. Additionally, it critiques the reinforcement learning analogy and recommends that generalization capabilities be better illustrated with examples from later in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides a specific critique of the comment about RNNs being vague, suggesting a reference for further clarification. It also critiques the reinforcement learning analogy, stating that it is out of place and recommending that generalization capabilities be better illustrated with examples from later in the paper. The comment is mostly verifiable as it provides a reference for further clarification and offers a specific suggestion for improvement. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the draft. It identifies a vague comment about RNNs and suggests a reference for further clarification, which is helpful for the authors to improve the clarity of their discussion. Additionally, it critiques the reinforcement learning analogy, noting that it seems out of place and recommends that generalization capabilities be better illustrated with examples from later in the paper. This feedback is clear and provides the authors with concrete steps to enhance the clarity and effectiveness of their draft. However, the comment could be more helpful if it offered additional suggestions or examples for improving the analogy or generalization discussion. Overall, the comment is mostly helpful, as it guides the authors in making specific improvements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that every kernel can be described by a feature space parameterized by a neural network, noting that this is not true for infinite-dimensional RKHSs like the RBF kernel. It suggests that the authors should clarify this limitation. While the comment identifies a specific issue and implies that the authors should address it, it does not provide explicit guidance on how to clarify this point or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, particularly noting the limitation for infinite-dimensional RKHSs like the RBF kernel. The comment suggests that the authors should clarify this limitation, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, specifically questioning the assertion that every kernel can be described by a feature space parameterized by a neural network. It provides a specific example, the RBF kernel, which is known to have an infinite-dimensional RKHS, making it impossible to represent with a finite-width neural network. This critique is supported by logical reasoning and a reference to common knowledge in the field, making the claim mostly verifiable. However, the comment could be strengthened by providing additional examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that every kernel can be described by a feature space parameterized by a neural network. It provides a counterexample, the RBF kernel, which has an infinite-dimensional RKHS, making it impossible to represent with a finite-width neural network. This feedback is valuable as it highlights a potential misunderstanding or misrepresentation in the paper. By pointing out this limitation, the comment encourages the authors to clarify their claims and provide a more accurate representation of the capabilities of neural networks in representing kernel functions. However, the comment could be more helpful if it suggested ways to address this issue or provided additional context. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not well-positioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. The reviewer suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a literature review and how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s positioning in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the well-known nature of the key idea and providing examples of previous works, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. The reviewer provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. This provides some support for the claim by referencing specific examples, but the comment could be strengthened by offering more detailed reasoning or references to further substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed method's positioning in the literature, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and 'score-interpolation,' which use this property. This feedback is somewhat helpful as it highlights a potential lack of novelty in the proposed method and suggests that the authors should conduct a thorough literature review to address this issue. However, the comment could be more helpful if it provided specific guidance on how the authors might differentiate their work or what aspects of the literature they should focus on. Overall, the comment offers a starting point for the authors to consider, but it lacks depth and actionable suggestions, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution is limited because there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need to be improved. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the technical contribution is limited, specifically mentioning that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the technical contribution are lacking or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited because there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the technical contribution of the paper, specifically noting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. This feedback is clear and actionable, as it highlights a critical area for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might enhance their technical contribution or what aspects of the typical model could be explored. Despite this, the comment is mostly helpful as it directs the authors' attention to a key area for improvement. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilon-greedy and identical to BRP-NAS. The comment further states that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies specific issues with the approach, it does not provide explicit guidance on how the authors should address these concerns or improve their work. The feedback lacks actionable steps or suggestions for the authors to take, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific components of the approach, such as the weak predictors used (MLP, Regression Tree, and Random Forest) and the sampling strategy (epsilon-greedy and similar to BRP-NAS). It also references Table 2 in Appendix C to show the similarity in results between the proposed WeakNAS and BRP-NAS. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific in detailing what is not novel and how the results compare to existing work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the components of the approach are not novel, as they are similar to existing methods like MLP, Regression Tree, and Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilon-greedy and identical to BRP-NAS. The comment provides references to specific works ([2, 3, 7]) and cites BRP-NAS [5] to support its claim. This level of detail and evidence makes the claim mostly verifiable, as it provides a clear basis for the assertion. However, it could be strengthened by more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the novelty of the approach, noting that the weak predictors used (MLP, Regression Tree, and Random Forest) have been used before for NAS performance prediction. It also points out that the sampling strategy is similar to epsilon-greedy and identical to BRP-NAS, suggesting that the results of the proposed WeakNAS are almost the same as BRP-NAS. The comment provides references to specific works ([2, 3, 7] and BRP-NAS [5]) to support its claims. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their approach. While it highlights areas for improvement, it does not offer concrete steps or recommendations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It first asks for clarification on how the precision, recall, and F1-score were calculated for the 4-class classification of breast density. This is a direct request for additional information. Additionally, it suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection. The comment further recommends providing AUC results for comparisons, which is another explicit action. These actions are clear and concrete, giving the authors a specific path to follow for improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of precision, recall, and F1-score for the 4-class classification of breast density, and it also refers to the comparison of model performance using AUC with sensitivity and specificity at different operating points for breast cancer detection. This provides clear guidance on what aspects of the paper need clarification or improvement. The comment is specific in detailing what needs to be addressed, such as the calculation methods and the inclusion of AUC results for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the calculation of precision, recall, and F1-score for the 4-class classification of breast density and suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection. The comment provides a logical basis for the claim by referencing common practices in the field, which supports the suggestion that AUC results should be included for comparison. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by asking for clarification on how the precision, recall, and F1-score were calculated for the 4-class classification of breast density. It also suggests that researchers typically report AUC with sensitivity and specificity at different operating points for breast cancer detection, and it recommends providing AUC results for comparisons. This feedback is clear and constructive, offering the authors a direct path to improve their draft by aligning their reporting with common practices in the field. The comment is highly helpful as it not only identifies areas for clarification but also provides guidance on how to enhance the presentation of results, making it easier for the authors to improve their work. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset creation is optional and mentions that the Kialo dataset is well-studied and cleaner than the dataset created in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset, specifically mentioning the Kialo dataset and its cleanliness compared to the dataset created in the paper. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in pointing out the comparison between the Kialo dataset and the one created in the paper, suggesting that the latter can be additional data to learn from. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the dataset created in the paper with the Kialo dataset, suggesting that the latter is cleaner and more suitable for the authors\\' needs. However, the comment does not provide specific evidence or reasoning to support why the Kialo dataset is more suitable or cleaner. The mention of \"no automatic processes exist to construct it\" provides some context but does not substantiate the claim. Without detailed justification or examples, the claim remains somewhat verifiable, as it lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the creation of the dataset is optional and highlights the availability of the Kialo dataset, which is well-studied and cleaner than the dataset created in the paper. It suggests that the created dataset can be additional data to learn from, which is a useful observation. However, the comment lacks actionable guidance or specific suggestions on how the authors might use this information to improve their work. While it provides some insight into the dataset creation process, it does not offer detailed feedback or constructive advice that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable suggestions.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges that the creation of the dataset is optional and mentions the Kialo dataset as a well-studied and cleaner alternative. However, it does not provide any explicit or implicit actions for the authors to take regarding the dataset creation. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset, mentioning the Kialo dataset as a well-studied and cleaner alternative. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in pointing out the comparison between the Kialo dataset and the one created in the paper, suggesting that the latter can be additional data to learn from. However, without explicit references to the paper, the authors may find it challenging to pinpoint the exact sections needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the dataset created in the paper with the Kialo dataset, suggesting that the latter is cleaner and more suitable for the authors\\' needs. However, the comment lacks specific evidence or reasoning to support why the Kialo dataset is more suitable or cleaner. The mention of \"no automatic processes exist to construct it\" provides some context but does not substantiate the claim. Without detailed justification or examples, the claim remains somewhat verifiable, as it lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the creation of the dataset is optional and highlights the availability of the Kialo dataset, which is well-studied and cleaner than the dataset created in the paper. It suggests that the created dataset can be additional data to learn from, which is a useful observation. However, the"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also critiques the cross-layer modification and the limited improvement observed in the ablation study. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the critique of the cross-layer modification and the limited improvement observed, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment lacks specific examples or references to support the claim that the cross-layer modification does not bring much insight or that the improvements are negligible. The reasoning is based on general observations and lacks detailed evidence or analysis, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel and questioning the significance of the cross-layer modification. It also points out that the ablation study results, specifically the limited improvement observed in the self-cross attention, suggest that the main improvements come from using a na\u00efve transformer rather than the proposed modification. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it identifies areas for concern, it does not provide actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, the comment is somewhat helpful, as it highlights potential weaknesses but does not fully support the authors in addressing them.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment does not specify which part of the paper discusses the Transformer or the ablation study, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the critique of the cross-layer modification and the limited improvement observed, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study. However, the comment lacks specific examples or references to support the claim that the cross-layer modification does not bring much insight or that the improvements are negligible. The reasoning is based on general observations and lacks detailed evidence or analysis, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the use of the Transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the cross-layer modification and the limited improvement observed in the ablation study, suggesting"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the authors\\' claim that there is no research on joint error for UDA, suggesting that this problem has been studied in previous works, such as \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019. The reviewer explicitly instructs the authors to discuss this work and illustrate the relationship between it and the proposed method, as well as why their method is better. This feedback provides a clear and specific action for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the authors\\' claim about the lack of research on joint error for UDA and suggests discussing this previous work to clarify the relationship between it and the proposed method. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in previous works, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019. The reviewer provides a specific reference to support their claim, making it fully verifiable. This level of detail and evidence allows the authors to understand and address the critique effectively. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' claim about the lack of research on joint error for UDA, pointing out that this problem has been studied in previous works, such as \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019. The reviewer suggests that the authors discuss this work and illustrate the relationship between it and their proposed method, as well as why their method is better. This feedback is highly helpful as it provides a clear and actionable suggestion for the authors to address a potential oversight in their paper and improve its comprehensiveness. By correcting this oversight, the authors can enhance the clarity and impact of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of dataset size on their results and potentially adjust their comparison accordingly. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison and suggesting that the superior performance may be due to the dataset size, rather than the method itself. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods is unfair due to the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. The reviewer provides a specific example, mentioning GEM, which uses only 20M unlabeled data. This provides some logical reasoning and a specific example to support the claim, making it somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to further substantiate the claim about the impact of dataset size on accuracy. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. This feedback is somewhat helpful as it identifies a potential issue with the comparison and provides a rationale for why the results might be biased. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparison. To be more helpful, the comment could include recommendations for alternative methods or datasets to ensure a fair comparison. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the need for a new curriculum learning method for text graphs, suggesting that existing methods could be applied. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of existing methods should be considered. The comment lacks concrete details on how to justify the need for a new method or how to improve the discussion of the research gap. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Section 1,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the need for a new curriculum learning method for text graphs and questions why existing methods cannot be applied. The comment provides clear guidance on what needs to be addressed, namely, the justification for a new method and the discussion of the research gap. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the need for a new curriculum learning method for text graphs is not justified, as existing methods could be applied. However, the comment does not provide specific examples or references to existing methods that could be applied or why they are not suitable for text graphs. This lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's discussion of curriculum learning methods, specifically questioning the need for a new method for text graphs. It points out that existing methods could be applied, suggesting that the research gap is not adequately addressed. However, the comment lacks specific guidance or suggestions on how the authors might justify the need for a new method or how to improve the discussion of the research gap. While it highlights an important area for consideration, the feedback is somewhat helpful as it prompts the authors to reflect on their methodology and the applicability of existing work. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful but incomplete in its guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This action is explicit and provides a clear direction for the authors to follow. It also offers concrete guidance on how to implement this change, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method. The authors can infer that it relates to the domain adaptation section, but this inference is not explicit. The comment is specific in its suggestion to use pre-trained models and compare transfer parts, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This claim is based on the observation that pre-trained models can overcome domain-shift problems in the NLP field. However, the comment lacks specific references or examples to support the claim that these models are indeed effective in this context. While the suggestion is logical, the lack of detailed evidence or references makes it somewhat verifiable, as the authors would need to conduct further research to fully understand and apply the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for all methods. This suggestion is based on the observation that these models can overcome domain-shift problems in the NLP field. By comparing the efficacy of the transfer parts instead of the simplest n-gram features, the authors can potentially enhance the performance and robustness of their methods. The comment is specific and provides a concrete direction for improvement, making it highly helpful for the authors to enhance their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This action is explicit and provides a clear direction for the authors to follow. It also offers concrete guidance on how to implement this change, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method. The authors can infer that it relates to the domain adaptation section, but this inference is not explicit. The comment is specific in its suggestion to use pre-trained models and compare transfer parts, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This claim is based on the observation that pre-trained models can overcome domain-shift problems in the NLP field. However, the comment lacks specific references or examples to support the claim that these models are indeed effective in this context. While the suggestion is logical, the lack of detailed evidence or references makes it somewhat verifiable, as the authors would need to conduct further research to fully understand and apply the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for all methods. This suggestion is based on the observation that these models can overcome domain-shift problems in the NLP field. By comparing the efficacy of the transfer parts instead of the simplest n-gram features, the authors can potentially enhance the performance and"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority to competitors. The comment implies that a quantitive comparison on the final outputs could be more convincing. While the action is implicit, it is clear that the authors need to address this issue by providing a comparison of final outputs. The suggestion is concrete, as it specifies what needs to be done to improve the evaluation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the quantitive evaluation results only reflect middle outputs and suggests that a comparison on final outputs would be more convincing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\\'s superiority to competitors. The reviewer implies that a comparison on the final outputs would be more convincing, but the comment lacks specific examples or references to support this claim. While the suggestion is logical, it requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the quantitive evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It points out that Figure 4 illustrates the comparison of final results with a single data sample, suggesting that the current evaluations are not convincing enough to confirm ModelAngelo's superiority to competitors. The comment implies that a comparison on the final outputs would be more convincing. While the feedback highlights a potential weakness in the evaluation, it does not provide specific suggestions or guidance on how to address this issue or improve the evaluation. The comment is somewhat helpful as it points out a gap in the evaluation but lacks detailed actionable advice, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, and the fixed radius with different scales. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed explanations and examples to clarify these aspects. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lacks in detail about the techniques\" and provides specific examples of areas where the paper is unclear, such as the sparsification process, generating landmarks on the edge, deciding the number of landmarks, and achieving shape invariance. This level of detail allows the authors to accurately identify the parts of the paper that need improvement. However, the comment does not specify which sections or figures are affected, which would make it fully grounded. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of unclear aspects, such as the sparsification process and the generation of landmarks on the edge, along with questions about the number of landmarks, image features, and shape invariance. While the comment identifies several areas that need clarification, it does not provide specific references or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of these details and how they might impact reproducibility. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's lack of detail, making it difficult for readers to reproduce the results. It specifically points out the sparsification process, which is crucial for extracting landmark features, and questions the generation of landmarks on the edge, the number of landmarks used, the type of image features, and the fixed radius with different scales. These are all critical aspects that need clarification to ensure the reproducibility of the results. However, the comment could be more helpful if it provided suggestions or examples on how to address these issues, such as recommending specific references or methods for clarification. Overall, the comment is mostly helpful as it highlights important areas for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores could introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they might need to consider alternative approaches or metrics to mitigate these biases. However, the lack of specific suggestions or examples makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED for determining chunk significance, specifically mentioning the potential issue of basing eviction decisions purely on utility scores. However, it does not specify which part of the paper discusses this approach, making it weakly grounded. The comment is specific in identifying the potential bias introduced by favoring recent chunks, which could lead to premature evictions of valuable chunks. However, without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the utility-based approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential issue, it lacks specific examples or references to support the claim of potential biases. The reasoning is based on logical inference, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the utility-based approach used in FIITED for determining chunk significance. It highlights the concern that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. This feedback is somewhat helpful as it points out a potential weakness in the methodology, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The comment provides a starting point for the authors to consider, but it could be more helpful with additional details or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the first paragraph of the Introduction, stating that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a specific issue with the introduction, it does not provide explicit guidance on how the authors should revise or restructure this paragraph. The action is implicit and somewhat vague, as the authors can infer that they need to reorganize the introduction to better align with the paper\\'s focus, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, which is that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. This claim is somewhat verifiable as it provides a logical reasoning based on the focus of the paper, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact parts of the introduction that are not aligned with the paper\\'s focus, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. This feedback is clear and actionable, as it directs the authors to revise their introduction to better align with the paper\\'s focus on drift detection. However, the comment could be more helpful if it provided suggestions on how to integrate the DNN introduction with the drift focus or offered examples of how to make the introduction more relevant. Overall, the comment is mostly helpful as it highlights a significant issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how different parts of the framework contribute to the final result, particularly in the experimental section. It suggests that the authors should include quantitative experiments and comparisons between algorithms, as well as more detailed explanations of the presented ones. The comment provides specific actions, such as conducting quantitative experiments and comparisons, and offering detailed explanations, which are explicit and concrete. This guidance gives the authors clear direction on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the clarity of how different parts of the framework contribute to the final result, specifically mentioning the lack of quantitative experiments and comparisons between algorithms. It also requests more detailed explanations of the presented algorithms. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental section and the result section. The feedback is specific in detailing what is missing or unclear, such as the need for quantitative experiments and detailed explanations. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding how different parts of the framework contribute to the final result, despite showing promising visual stimuli results. The reviewer suggests that quantitative experiments and comparisons between algorithms are missing, and more detailed explanations are needed. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's clarity regarding the performance of different parts of the framework and their contribution to the final result. It points out the lack of quantitative experiments and comparisons between algorithms, which is crucial for understanding the framework's effectiveness. The comment also suggests that more detailed explanations are needed for the presented algorithms, which would enhance the paper's comprehensiveness. By highlighting these areas for improvement, the comment provides clear and actionable feedback that can help the authors strengthen their draft. However, it could be more helpful if it offered specific suggestions or examples of how to conduct these experiments or provide detailed explanations. Overall, the comment is mostly helpful, as it guides the authors towards improving the clarity and robustness of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and mentions specific examples of previous works that have been evaluated on this set. Additionally, it recommends comparing the paper to other approaches where corresponding publications are available. These actions are clear and provide specific guidance on how the authors can improve their draft by ensuring a more comprehensive comparison with existing works. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the \"official COOC leader board,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as comparing the results on the official COOC leader board and the blind test set, and suggesting that the paper should at least compare to other approaches where corresponding publications are available. This provides detailed feedback on how the authors can enhance their work. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should compare its results on the official COOC leader board, specifically on the blind test set, and suggests that the paper should at least compare to other approaches where corresponding publications are available. The comment provides a specific reference to the COOC leader board and mentions previous works that have won the challenge and been evaluated on the blind challenge set. This provides some justification for the claim, but it could be strengthened by including more detailed reasoning or examples of why these comparisons are important. Therefore, the comment is somewhat verifiable, as it offers a basis for the claim but lacks full detail and specific references to support the suggestion fully.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the paper's comparison with related work. It highlights that the paper should compare its results on the official COOC leader board, specifically on the blind test set, which is a more rigorous and standardized evaluation method. The comment also references specific examples of previous works that have won the challenge and been evaluated on the blind challenge set, providing a benchmark for the authors to follow. Additionally, it suggests that the paper should at least compare to other approaches where corresponding publications are available, which is a valuable piece of advice for ensuring a comprehensive comparison. This feedback is clear, actionable, and provides the authors with a concrete path to improve their draft, making it highly helpful. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. While the comment implies that the authors should provide more context or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms used. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of the term \"wrong\" and suggests clarifying what is meant by \"good,\" \"bad,\" or \"wrong\" explanations before using these concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the term \"wrong\" used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a \"good,\" \"bad,\" or \"wrong\" explanation before using these concepts. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the term 'wrong' used in the paper, specifically in the context of L248. It suggests that the authors clarify what is meant by a 'good,' 'bad,' or 'wrong' explanation before using these concepts. This feedback is somewhat helpful as it identifies a potential area of confusion for the reader and provides a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to clarify these terms or provided examples of what constitutes a good or bad explanation. Overall, the comment provides a starting point for the authors to address, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It suggests that this comparison is necessary to prove the superiority of the schema searched by the author\\'s method (ELF) over the schema in Mid Vision Feedback (MVF). While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct this comparison or what specific metrics or experiments should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"experimental demonstration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experimental demonstration of the contribution points, particularly the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by stating that the absence of this comparison does not prove the superiority of the schema searched by the author\\'s method (ELF) over the schema in Mid Vision Feedback (MVF). However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact comparison that should be made to address the issue, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a specific area where the authors can enhance their paper by providing a more comprehensive comparison. By suggesting the inclusion of this comparison, the comment offers a clear direction for improvement, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to conduct this comparison or what specific metrics should be used. Overall, the comment effectively directs the authors to a critical area for enhancement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It raises a question about whether the current work is merely an extension or introduces novel contributions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. The action is implicit and vague, as the authors are left to infer that they need to demonstrate originality or provide a clear distinction from the referenced work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which part of the paper these similarities are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in questioning the originality of the work, but it lacks grounding as it does not point to specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the article\\'s reasoning and writing logic bear similarities to a previous study, raising concerns about originality. However, the comment does not provide specific examples or detailed comparisons to substantiate this claim. Without concrete evidence or references to the previous study, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. This feedback is somewhat helpful as it highlights an important aspect of originality that the authors should consider. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. To be more helpful, the comment could provide examples of where the similarities are most apparent or offer suggestions on how to demonstrate originality. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy in the discussion regarding regret and the method\\'s performance. It questions whether the regret cannot be sublinear, given the subsequent proof of T^{1/2} regret. The comment explicitly asks if the prediction error over the entire horizon T cannot be sublinear, providing a clear and direct action for the authors to clarify their discussion. This feedback is explicit and concrete, guiding the authors on how to address the issue by revising their explanation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion regarding regret and the method\\'s performance, questioning whether the regret cannot be sublinear despite the subsequent proof of T^{1/2} regret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the consistency of the discussion regarding regret and the method\\'s performance. It points out a discrepancy between the claim that regret cannot be sublinear and the subsequent proof of T^{1/2} regret. The comment suggests that the discussion might be unclear, implying that the authors should clarify whether the prediction error over the entire horizon T cannot be sublinear. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to address the question and provide additional context or evidence to fully understand and respond to the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the discussion regarding regret and the method\\'s performance. It questions whether the regret cannot be sublinear, given the subsequent proof of T^{1/2} regret. This feedback is clear and actionable, as it prompts the authors to clarify their discussion and ensure consistency in their claims. By addressing this point, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the discrepancy. Overall, the comment is mostly helpful as it guides the authors towards a more precise and coherent discussion, but it could be further enhanced with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. However, the comment does not explicitly instruct the authors to include such a discussion or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the importance of learning long-range dependencies and suggests a discussion about this, particularly regarding the encoding of locality in the graph structure. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. However, the comment lacks specific examples or references to support the claim that learning long-range dependencies is not fully required or that the truth lies somewhere in between. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It notes that the paper provides examples of this happening, such as in the visualizations in Table 3, but questions whether it is fully required. The reviewer suggests that there should be a discussion about this, especially regarding the encoding of locality in the graph structure. This feedback is mostly helpful as it identifies a potential area for improvement and provides a clear direction for the authors to address. However, it could be more helpful if it offered specific suggestions or examples of how to discuss this topic. Overall, the comment is actionable and provides valuable insights for the authors to consider, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It suggests that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. However, the comment does not provide specific guidance on how to address these issues or improve the draft. The authors are left to infer that they need to clarify the definition of $e_l$ and possibly revise the theoretical results to address the exponential dependence on $M$. While the comment highlights potential areas for improvement, it lacks explicit and concrete actions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\", \"Corollaries 1, 2, and 3\", \"Theorem 4\", and \"Figure 1\", allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the definition of $e_l$ and the exponential dependence on the diameter $M$ of the domain of data, as well as the potential weakness of the proposed approaches. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two main concerns: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It claims that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The mention of \"Figure 1\" provides some context, but the lack of detailed explanation or references limits the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some support but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two specific issues: the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, as well as Theorem 4. It points out that the results have a weakness in terms of the required feature size increasing exponentially with $M$, which may affect the performance as shown in Figure 1. The comment provides a clear explanation of the issue and suggests that the exponential dependence on $M$ affects the constant factor of the required feature size. However, it could be more helpful if it offered suggestions on how to address these issues or improve the theoretical results. Overall, the comment is mostly helpful as it highlights important areas for improvement but lacks detailed guidance on how to make those improvements.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the potential issue of oversmoothing in addition to oversquashing and vanishing/exploding gradients, which are known issues with deep graph networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or incorporate it into their analysis. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the poor long-range modeling ability of DGNs and attributes it to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the issues with DGNs but lacks grounding, as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not provide specific references, examples, or detailed reasoning to support these claims. The mention of oversmoothing is made in the context of very deep graph networks, but without further elaboration, the authors may find it challenging to understand the relevance and impact of this claim. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It provides a reference to a relevant paper, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,\" which could help the authors understand the context and implications of these issues. However, the comment lacks specific guidance or actionable suggestions on how the authors might address these challenges or incorporate this knowledge into their work. While it highlights an important area for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not offer detailed guidance on implementation or analysis.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the problem. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is weakly grounded because it does not provide explicit references to specific parts of the paper, and it is not specific enough to guide the authors on how to address the issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. As a result, it is barely helpful, as it provides a general observation but does not offer actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a suggestion for improvement or a point that needs clarification. Without any actionable advice or direction, the authors are left without a clear understanding of how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the consideration of finer grouping for quantization instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. The authors may have to infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in questioning the choice of quantization granularity, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of per-tensor and per-channel. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be beneficial or why the current approach is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the question and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of quantization granularity, specifically why finer grouping is not considered instead of per-tensor and per-channel. While it identifies a potential area for improvement, the comment lacks depth and does not provide any suggestions or reasoning to support the need for finer grouping. Without additional context or guidance, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it points out a potential area for consideration but does not offer actionable advice or insights.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"For training we used an epsilon-greedy ...,\" suggesting that there might be epsilon-greedy exploration on top of the proposed strategy. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the meaning. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilon-greedy ...,\" providing a clear indication of what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilon-greedy ...,\" without making any subjective claims or judgments. It does not express an opinion, suggest changes, or request additions. Therefore, it is a factual statement that does not contain a claim, aligning with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilon-greedy ...,\" suggesting that there might be epsilon-greedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue. The feedback lacks actionable advice or detailed explanations, making it difficult for the authors to effectively improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which are not commonly used in existing ML accelerators. It implies that the proposed methodology might have limited implications. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors could address this issue or explore alternative implications. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential limitations of the proposed methodology regarding dynamic precision control during training, specifically mentioning that it might only show meaningful performance gains on bit-serial accelerators. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in identifying the potential limitations and suggesting that the proposed methodology might have limited implications due to the common use of bit-parallel fixed-point numbers in existing ML accelerators. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which are not commonly used in existing ML accelerators. This claim is somewhat verifiable as it provides a logical reasoning based on the current state of ML accelerators. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the proposed methodology, specifically that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which are not commonly used in existing ML accelerators. This observation is relevant and provides a critical perspective on the applicability of the proposed methodology. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or explore alternative implications. While it highlights an important consideration, it does not offer specific steps or insights for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a specific issue with Equation 12, noting that it is confusing and questioning the origin of the reward at each trial. It suggests that one of the r_i values might be taken from Equation 11, and it recommends explaining the network model in Section 4.2 using equations to improve clarity. The reviewer provides references to relevant literature and a specific paper for further guidance. This feedback is explicit in identifying the problem and suggesting a solution, and it provides concrete steps for the authors to take. However, it could be more actionable if it included specific examples or detailed explanations of how to address the confusion. Overall, the comment is mostly actionable, as it provides clear guidance on what needs to be improved and how to do so, but it could be more detailed.\", 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation 12, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the origin of the reward at each trial and suggesting that one of the r_i values might be taken from Equation 11. Additionally, it provides a specific suggestion for improvement by recommending that the network model be explained in Section 4.2 using equations. The comment also includes references to relevant literature, which further supports the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation 12 is confusing and questions the origin of the reward at each trial. It suggests that one of the r_i values might be taken from Equation 11 and recommends explaining the network model in Section 4.2 with equations to improve clarity. The comment provides references to relevant literature, which could help the authors understand the context and potential solutions. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the confusion in Equation 12. While the references are a step towards verification, they do not fully address the issue of confusion. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Equation 12, noting that it is confusing and questioning the origin of the reward at each trial. It suggests that one of the r_i values might be taken from Equation 11 and recommends explaining the network model in Section 4.2 using equations to improve clarity. The comment provides references to relevant literature, which can be beneficial for the authors to consider when addressing the issue. However, the feedback could be more helpful if it included specific examples or detailed guidance on how to clarify the equation or explain the network model. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a starting point for addressing the confusion, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of novelty in the idea and points out that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the lack of novelty or improve the originality of their work. Without specific suggestions or directions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the idea and points out that both the new metric and method are relatively straightforward. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not provide specific references to sections or figures, and it is not specific about what aspects of the new metric or method are considered straightforward. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that both the new metric and method are relatively straightforward. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific references, comparisons, or detailed explanations, the authors are left without a clear understanding of the basis for these assertions. As a result, the claim is unverifiable, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the limitations of the novelty of the idea, stating that both the new metric and method are relatively straightforward. However, it does not provide any constructive feedback or suggestions on how the authors might address these limitations or enhance the originality of their work. Without actionable advice or specific guidance, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding. It also recommends using a notation table to clarify the use of symbols. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps for better understanding and the use of a notation table to clarify the use of symbols. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or subsection. This makes it difficult for the authors to identify the exact area needing improvement. While the comment provides some guidance on what needs to be addressed, it lacks full grounding, as the authors cannot confidently determine the exact part of the paper being discussed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to clarify the use of symbols. While the comment provides a logical suggestion for enhancing clarity, it lacks specific examples or references to support the claim. The authors are left to infer the exact improvements needed, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the model description, suggesting that presenting the generative process in separate steps would enhance understanding. It also recommends using a notation table to clarify the use of symbols, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided examples of how the generative process could be broken down or detailed further. Overall, the feedback is mostly helpful as it guides the authors on how to improve their draft, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, the comment does not specify what aspects of the motivation should be improved or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the importance of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to clarify the importance of the work, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the motivation section. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights that the trade-off between head and tail categories is not fully investigated for the baselines, suggesting that changing hyper-parameters in Decouple [Kang et al.] could improve tail accuracy. The comment concludes by recommending that the authors address these issues and continue their work for future submission. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance comparison of the proposed approach with Decouple [Kang et al.] and highlights the trade-off between head and tail categories. It suggests that the paper is not yet ready for submission to ICLR due to the lack of investigation into the trade-off for the baselines. The comment is fully grounded as it explicitly mentions \"Table 5\" and references \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as investigating the trade-off for the baselines and suggesting a potential improvement in Decouple [Kang et al.]. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also suggests that the trade-off between head and tail categories has not been fully investigated for the baselines, and provides a specific example of how Decouple [Kang et al.] could improve tail accuracy by adjusting hyper-parameters. However, the comment lacks detailed evidence or references to support the claim about the proposed approach's performance compared to Decouple [Kang et al.], making it somewhat verifiable. The authors would need to conduct further analysis or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's performance, noting that the proposed approach does not outperform or is even worse than a baseline method, Decouple [Kang et al.]. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that adjusting hyper-parameters in Decouple [Kang et al.] could improve tail accuracy. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to investigate the trade-off for the baselines and potentially enhance the paper's submission to ICLR. However, the feedback could be more helpful if it included specific recommendations or examples of how to address these issues. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" While the comment identifies areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide concrete steps to enhance the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weak supervision\" and provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the evaluation of weak supervision and provides examples of unrealistic elements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of weak supervision could be improved by questioning the realism of the evaluated tweets. It provides specific examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This provides a clear and detailed explanation of the issue, making the claim mostly verifiable. However, it could be strengthened by referencing specific studies or examples of realistic evaluations to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation of weak supervision, suggesting that the evaluation could be enhanced by considering the realism of the evaluated tweets. It provides detailed examples of unrealistic prompts and generated tweets, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the unrealistic generation of authors with \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This feedback is clear and actionable, offering the authors a concrete direction to improve the evaluation of weak supervision. However, the comment could be more helpful if it suggested specific ways to assess the realism of the tweets or provided examples of more realistic evaluations. Overall, the comment is mostly helpful, as it provides valuable insights and actionable suggestions for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors might infer that it relates to the discussion of the proposed model's performance or its comparison with other models, but this inference is not explicit. The comment is specific in its suggestion to compare with a particular existing work, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This claim is somewhat verifiable as it provides a specific reference to an existing work that could be used for comparison. However, the comment lacks detailed reasoning or explanation on why this comparison would be beneficial or how it would enhance the proposed model's performance. The authors would need to infer the potential benefits of such a comparison, making the claim somewhat verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests a specific comparison that the authors could make to enhance the evaluation of their proposed model. By comparing their model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16), the authors could provide a more comprehensive understanding of their model's performance and its advantages. This feedback is clear and actionable, offering a concrete way for the authors to improve their draft by expanding their comparative analysis. However, the comment could be more helpful if it provided additional context or reasoning on why this comparison is important. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an odd design choice of trimming questions after the first 10, given that the question model is a bag of words and encoding longer sequences is not expensive. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their design choice. The comment lacks actionable guidance, leaving the authors without a clear direction for revising their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the design choice of trimming questions after the first 10, noting that it seems odd given the nature of the question model. The comment provides a clear rationale for this concern, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, given that the question model is a bag of words and encoding longer sequences is not expensive. The reviewer provides a logical reasoning by pointing out the inconsistency between the design choice and the nature of the question model. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact reasoning behind the claim, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design choice of trimming questions after the first 10, noting that the question model is a bag of words and encoding longer sequences is not expensive. This observation raises a valid concern about the efficiency and effectiveness of the design. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their design choice. While it highlights a potential area for improvement, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). This is a direct request for the authors to provide an explanation or definition of this equation, which is a clear and explicit action. The comment does not require the authors to infer any additional steps or actions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation (2), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\", providing a clear direction for the authors to address this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification on the meaning of a specific equation in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a direct request for clarification regarding the meaning of a specific equation in the paper, specifically Equation (2). While it identifies a gap in the paper's clarity, it does not provide any suggestions or guidance on how the authors might address this issue or improve the draft. The comment lacks actionable feedback or context that could help the authors enhance their work. Therefore, it is rated as barely helpful, as it points out a potential area of confusion but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly instructs the authors to correct the color of two lines in the supplementary material, specifying that they should be in green. It provides specific references to the lines in question, such as L502, L507, and L509, and indicates the corresponding sections or elements, such as SuppMat, Table 4, and Algorithm 1. This level of detail and specificity makes it clear and actionable for the authors to make the necessary changes. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and references, such as L502, L507, and L509, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be corrected, namely the color of the lines, which should be changed from red to green. This provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point consists of a factual statement about the need to correct the color of specific lines in the supplementary material. It provides explicit references to the lines in question, such as L502, L507, and L509, and specifies the changes needed, such as changing the color from red to green. This level of detail and specificity makes the comment fully verifiable, as it provides clear guidance on what needs to be corrected. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment is highly helpful as it provides specific and actionable feedback by identifying errors in the color of lines in the supplementary material. It clearly specifies the lines that need to be corrected, such as L502, L507, and L509, and indicates the corresponding sections or elements, such as SuppMat, Table 4, and Algorithm 1. This level of detail and specificity empowers the authors to make the necessary corrections, ensuring that their draft is accurate and consistent. The feedback is clear and actionable, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that important references are missing, specifically mentioning GFF and EfficientFCN as examples. It encourages the authors to include a comprehensive comparison with these works. The comment provides specific references for the authors to consider, making the action clear and concrete. The authors know exactly what needs to be done to improve their draft, which is to include these references and conduct a comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GFF\" and \"EfficientFCN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, which is the inclusion of these references for a comprehensive comparison. The comment is specific in detailing the need for a comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF and EfficientFCN as examples. The reviewer provides explicit references to these works, which are well-known in the field of semantic segmentation. This provides clear and specific evidence supporting the claim, making it fully verifiable. The references to GFF and EfficientFCN, along with the detailed information provided, offer a strong basis for the authors to understand the need for inclusion and comparison. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a critical issue by pointing out that important references are missing from the paper. It specifically mentions GFF and EfficientFCN as examples of relevant work that should be included for a comprehensive comparison. This feedback is actionable and provides clear guidance on what the authors need to do to improve their draft. By suggesting specific references and comparisons, the comment offers valuable insights that can significantly enhance the paper\\'s depth and relevance. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references into the manuscript. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer suggests that the paper would be more convincing if the authors could provide experimental results to support the performance of their algorithms. While the comment implies that the authors should conduct experiments to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide experimental results to validate their algorithms. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\alpha$. The reviewer suggests that the paper would be more convincing if the authors could provide experimental results to support the performance of their algorithms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer provides a specific example of the issue, stating that $\\alpha$ can be as small as $1/k^2L^2$, which could lead to numerical instability even for moderate sizes of $n$, $k$, and $L$. The reviewer suggests that the paper would be more convincing if the authors could provide experimental results to support the performance of their algorithms. While the comment provides a logical reasoning and a specific example, it lacks detailed references or additional evidence to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could be strengthened with more detailed support.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific concern about the practical performance of the proposed algorithms, particularly regarding the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer points out that this could lead to numerical instability, especially for small values of $\\alpha$, which can be as small as $1/k^2L^2$. The comment suggests that the paper would be more convincing if the authors could provide experimental results to support the performance of their algorithms. This feedback is clear and actionable, as it highlights a potential weakness in the paper and provides a specific suggestion for improvement. However, it could be more helpful if it included additional guidance on how to conduct these experiments or what specific results should be expected. Overall, the comment is mostly helpful, as it effectively directs the authors to address a critical issue and improve the robustness of their claims.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, particularly when applied to large-scale datasets like ImageNet. It explicitly asks if there is a solution to address this scalability issue, which is a clear and direct action for the authors to take. The comment also implies that the practical contribution of the paper could be significantly reduced if this issue is not addressed. This feedback provides a concrete action for the authors to consider, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the scalability issue of the proposed NC measure, specifically mentioning the use of the whole training and test datasets as input. It raises a concern about the method\\'s applicability to large-scale datasets like ImageNet, which is a specific and relevant aspect of the paper. However, the comment does not explicitly mention which part of the paper discusses the NC measure or scalability, making it weakly grounded. Despite this, the comment is specific in detailing the scalability issue and suggesting a potential solution. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large-scale datasets like ImageNet. The reviewer suggests that this scalability issue could significantly reduce the practical contribution of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about scalability. While the concern is valid, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the concern but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the scalability of the proposed NC measure, specifically questioning how it can be learned and applied to large-scale datasets like ImageNet. This is a critical point that the authors should address to ensure the practical applicability of their work. The comment provides a clear and actionable suggestion for the authors to consider, which is to address the scalability issue. However, it could be more helpful if it offered potential solutions or strategies for addressing this concern. Overall, the comment is mostly helpful as it directs the authors' attention to a significant limitation of their work and suggests a direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly states that the proposed PSA method requires more computation than baselines and suggests that the comparison of computation complexity should be included in the experiment part. This provides a clear and direct action for the authors to take, which is to include a comparison of computation complexity in their experiments. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'algorithm 1' and 'feeding forward,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the PSA method requires more computation than baselines and suggests including a comparison of computation complexity in the experiment part. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. This claim is somewhat verifiable as it provides a specific observation about the computational requirements of the PSA method compared to baselines. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as specific calculations or references to other studies. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some support but requires additional details to be fully convincing.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computational complexity involved, specifically mentioning the calculation of flipped previous layer outputs into the current layer in Algorithm 1. This feedback is actionable as it suggests that the authors should include a comparison of computation complexity in their experiments. By addressing this concern, the authors can provide a more comprehensive analysis of their method's efficiency. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or provided examples of similar studies for reference. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific issues and suggestions for improvement. It explicitly mentions that the fonts in figures 1 and 2 should be larger, and it provides examples of elements that are too small. Additionally, it suggests clarifying the \"CTRL\" long form explanation and improving the font size in figure 2. These suggestions are clear and provide concrete guidance on how the authors can enhance their draft. The comment also highlights the lack of details in the comparison with other state-of-the-art Transformer designs, suggesting that a table would better emphasize the data. This feedback is actionable because it gives the authors specific steps to take to improve their draft, making it a highly actionable comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 1,\" \"figure 2,\" and specific elements like \"V_mem,\" \"Th_i,\" and \"U_i^t,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as the font sizes and the \"CTRL\" long form explanation. The comment is specific in detailing the issues with font sizes and the need for clarification, providing clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of observations and suggestions for improvement, such as recommending larger fonts and clarifying the \"CTRL\" long form explanation. However, it does not contain any claims or opinions that require verification. The comments are descriptive and provide specific feedback on the draft, but they do not make subjective judgments or assertions that need substantiation. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the draft, focusing on both the visual elements and the content of the figures. It highlights issues with font sizes, suggesting that certain elements, such as \"V_mem,\" \"Th_i,\" and \"U_i^t,\" are too small and recommending that the \"CTRL\" long form explanation be clarified. Additionally, it points out that the font in figure 2 is too small. Furthermore, the comment identifies a lack of details in the comparison with other state-of-the-art Transformer designs, suggesting that a \"table\" manner would better emphasize the data for readers to justify the improved accuracy. This feedback is clear and provides the authors with specific steps to improve their draft, making it mostly helpful. However, it could be more helpful if it included suggestions on how to present the data in a table format or additional details on the comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA is a bit better than FP according to the results in Table 1.\" This feedback is explicit and provides a clear action for the authors to take, which is to include \"ATA\" in the comparison. The suggestion is concrete, as it specifies what needs to be added to the comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that the proposed method should be compared to \"ATA\" in addition to \"+LFP.\" This provides clear guidance on what needs to be addressed in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA is a bit better than FP according to the results in Table 1.\" This claim is based on the observation that \"ATA\" is better than \"FP\" in terms of results, as indicated in Table 1. The reviewer provides a logical reasoning by referencing specific results from Table 1, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks some depth in its explanation.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the comparison in Table 2, suggesting that the proposed method should be compared to 'ATA' in addition to '+LFP' in the leave one out setting. This feedback is clear and actionable, as it provides a direct suggestion for improvement by including a more relevant comparison. By addressing this point, the authors can enhance the comprehensiveness and validity of their results. However, the comment could be more helpful if it explained why including 'ATA' is important or how it would strengthen the comparison. Overall, the comment is mostly helpful as it guides the authors towards a specific improvement, but it could be more comprehensive with additional context or reasoning.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multi-head attention. It also asks for clarification on the split arrow in Figure 2 and whether the same vectors are used for keys and values. While the comment does not explicitly instruct the authors to provide these definitions, it clearly indicates what information is missing and how it could be improved. The authors can infer that they need to clarify these details to enhance the readers\\' understanding. However, the comment lacks specific guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the split arrow in the figure and the lack of mathematical definition for multi-head attention. The comment is specific in detailing what needs to be addressed, such as clarifying the use of the same vectors for keys and values. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the lack of mathematical definition in the architectural details of the model, specifically regarding multi-head attention. It also asks for clarification on the split arrow in Figure 2. While the comment identifies areas where the paper could be improved, it does not provide specific reasoning or evidence to support the need for these clarifications. The request for a formal definition of multi-head attention and the split arrow in Figure 2 is clear, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved, namely the lack of mathematical definition in the architectural details, particularly regarding multi-head attention. It also raises a question about the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. This feedback is clear and actionable, as it provides the authors with specific areas to address to enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to provide the necessary mathematical definitions or clarified the use of the split arrow in the figure. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the presentation of the paper is difficult for the reviewer to follow, but it does not provide any specific guidance or suggestions on how the authors might improve the presentation. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the presentation need improvement. As a result, the authors are left without any actionable steps to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the presentation of the paper is difficult to follow, but it does not specify which part of the paper is problematic or provide any details on what aspects of the presentation are unclear. This lack of specificity makes it challenging for the authors to identify the exact areas that need improvement. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point states that the presentation of the paper is difficult to follow, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed information or context, the authors may find it challenging to understand the basis of the reviewer\\'s difficulty in following the presentation. As a result, the claim is unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses difficulty in following the presentation of the paper, but it does not provide any specific examples or suggestions for improvement. This lack of detail makes it challenging for the authors to understand where the presentation is unclear or how to address the issue. Without actionable feedback or guidance, the comment does not contribute significantly to the authors\\' efforts to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. While the comment implies that these actions should be taken, it does not provide specific guidance on how to integrate these references or what aspects of the comparison should be emphasized. The authors can infer the need for these additions, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. However, the comment does not specify which part of the paper these suggestions should be addressed in, making it weakly grounded. The comment is specific in its recommendations for including and comparing relevant works and discussing differences, but without explicit grounding, the authors may struggle to identify the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. While the comment provides a logical basis for the suggestions, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors are left to infer the relevance of these works and the potential benefits of including them, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by suggesting that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. This feedback is actionable and provides specific references for the authors to consider, which can significantly enhance the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it included detailed guidance on how to integrate these references or what aspects of the comparison should be emphasized. Overall, the comment is mostly helpful as it offers clear directions for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between meta solvers and centralized RL, referencing a specific paper for context. This provides a clear and direct action for the authors to take, which is to address the distinction between these concepts. The comment also offers a specific example of a relevant paper, \"Learning to communicate with deep multi-agent reinforcement learning,\" which helps the authors understand how to approach the clarification. Therefore, the comment is highly actionable, as it provides explicit and concrete guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking the authors to clarify the difference between these concepts and provides a reference to a specific paper, \"Learning to communicate with deep multi-agent reinforcement learning,\" which helps the authors understand the context and potential approach to addressing the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between meta solvers and centralized RL, referencing a specific paper for context. While the comment provides a reference to a relevant paper, it lacks detailed reasoning or specific examples to fully substantiate the claim. The authors are left to infer the nature of the difference between meta solvers and centralized RL, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, specifically noting that the meta solvers seem to be centralized controllers. It provides a clear and actionable suggestion for the authors to clarify this distinction, referencing a specific paper for context. This feedback is valuable as it helps the authors address a potential misunderstanding in their work and provides a concrete reference for further explanation. However, the comment could be more helpful if it offered additional guidance on how to effectively clarify the distinction or provided specific examples of how the clarification could be implemented. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement and provides a starting point for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" in line 285, specifically asking if \"chunk\" is still considered sequential information. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the meaning of \"non-sequential information\" and \"chunks\" in their draft. However, the comment lacks concrete details on how to resolve the confusion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"non-sequential information such as chunks,\" questioning whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific phrase in the text, \"non-sequential information such as chunks.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this phrase, which could potentially improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address the confusion. Overall, the comment is mostly helpful as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the discrepancy between Equation 9 and Figure 1, suggesting that the output patches might not be cropped parts of the input image but just masked versions with most pixels black. It also points out that Figure 1 might be misleading and suggests that zooming on the region of interest using bilinear sampling could provide better results. This feedback is clear and provides a direct action for the authors to address the discrepancy and improve the clarity of their figures. The suggestion is concrete, as it specifies the issue and offers a potential solution. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or just masked versions with most pixels black. Additionally, it suggests that zooming on the region of interest using bilinear sampling could provide better results. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the discrepancy between Equation 9 and Figure 1, questioning the nature of the output patches. It provides a clear and direct claim that the output patches might not be cropped parts of the input image but just masked versions with most pixels black, suggesting that Figure 1 is misleading. The reviewer also offers a potential solution by suggesting that zooming on the region of interest using bilinear sampling could provide better results. This feedback is well-supported by logical reasoning and a specific suggestion, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy between Equation 9 and Figure 1, questioning the nature of the output patches and suggesting that Figure 1 might be misleading. It provides a clear and actionable suggestion by pointing out that zooming on the region of interest using bilinear sampling could provide better results. This feedback is valuable as it helps the authors clarify their presentation and potentially improve the accuracy of their figures. However, the comment could be more helpful if it included additional context or examples to further substantiate the claim. Overall, the comment is mostly helpful, as it guides the authors in addressing a critical issue and improving the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the technical novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to differentiate their work from the previous papers, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not specify which part of the paper these comparisons are based on, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity in detailing what aspects of the paper need to be improved or differentiated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). However, the comment does not provide specific examples or detailed reasoning to support the claim that the idea, co-attention mechanism, and architecture are similar to those in the previous works. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). It highlights that the idea, co-attention mechanism, and architecture of the current paper are quite similar to those in the previous works. This feedback is somewhat helpful as it points out a potential weakness in the paper's originality. However, the comment lacks specific suggestions or guidance on how the authors might differentiate their work or improve its novelty. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct a fair comparison by comparing CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback is clear and provides a specific action for the authors to take, making it highly actionable. The comment also explains why the current comparison is unfair, providing a rationale for the suggested change. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of fairness in the comparison between CPEF and PMEF, suggesting that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of the pre-training module design. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Figure 3 is unfair because PMEF lacks a pre-training module, while CPEF does. The reviewer suggests comparing CPEF with another pre-trained model, such as ExpertBert, to ensure fairness. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a potential solution. However, it lacks specific references or examples of how the comparison could be made more fair, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison presented in Figure 3, where CPEF is compared with PMEF. It points out that PMEF lacks a pre-training module, which makes the comparison unfair. The reviewer suggests a more fair comparison by recommending the inclusion of another pre-trained model, such as ExpertBert, to showcase the advantage of CPEF\\'s innovative pre-training module design. This feedback is clear and actionable, providing the authors with a specific direction for improving the fairness of their comparison. By addressing this issue, the authors can enhance the credibility and robustness of their findings. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. While the comment implies that the authors should explore additional attack methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider other attack methods and where to find examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the attack methods used in the paper, specifically mentioning that they are naive and suggesting the consideration of other classical attack methods in NLP. It provides examples of papers to refer to for inspiration. However, the comment does not specify which part of the paper discusses the attack methods, making it weakly grounded. The authors can infer that it relates to the methodology section, but this is not explicitly mentioned. The comment is specific in suggesting alternative attack methods and providing references, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment lacks detailed reasoning or evidence to support why the current attack methods are naive or why other methods should be considered. The suggestion to check specific papers provides a direction for the authors to explore, but without further justification, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the attack methods used are naive. It suggests that the authors should consider other classical attack methods in NLP, providing specific examples of papers to refer to for inspiration. This feedback is clear and actionable, offering the authors a direction for improving their methodology. However, the comment could be more helpful if it provided additional guidance on how to integrate these new attack methods or what specific aspects of the current methods are considered naive. Despite this, the feedback is mostly helpful as it directs the authors to a potential area for enhancement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises two issues regarding the uncertainty calibration process and the regularization term H. It suggests that the authors clarify the relationship between temperature calibration and uncertainty calibration, as well as the role of H in reducing entropy and its potential conflict with the paper's motivation for calibration. The comment explicitly requests clarification on these points, providing a clear action for the authors to take. Additionally, it highlights a specific contradiction in the paper's motivation and calibration process, offering a concrete suggestion for improvement. This feedback is explicit and provides detailed guidance on how the authors can address the issues, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions specific lines (155-160) where the confusion arises regarding the relationship between temperature calibration and uncertainty calibration. It also references lines 133-136, which discuss the paper's motivation regarding calibration. This provides clear guidance on where the authors need to address the confusion. The comment is specific in detailing the issue with the regularization term H and its impact on calibration, as well as the contradiction with the paper's motivation. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It questions the apparent contradiction in the paper's claims and suggests that the authors clarify this point. The comment provides a logical reasoning by pointing out the inconsistency between the claim that temperature calibration is independent of uncertainty calibration and the subsequent discussion that both are required for calibration. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the reviewer's concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a confusing aspect of the paper regarding the relationship between temperature calibration and uncertainty calibration, as well as the role of the regularization term H. It points out a contradiction in the paper's claims and suggests that the authors clarify this point. The comment also highlights a potential issue with the paper's motivation for calibration, noting that reducing entropy (which is against the paper's motivation) could lead to overconfidence in the predictions. By providing specific points of confusion and suggesting areas for clarification, the comment offers actionable feedback that can help the authors improve their draft. However, it could be more helpful if it provided additional suggestions or examples to further guide the authors in addressing these issues. Overall, the comment is mostly helpful, as it identifies key areas for improvement and provides some direction for the authors to follow.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss the relationship, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the reference and discuss the context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not specify which part of the paper should include this reference or discuss the context, making it weakly grounded. The authors can infer that it relates to the introduction or related work section, but this is not explicitly mentioned. The comment is specific in suggesting that the paper should address the relationship with \"Lista,\" but it lacks detailed guidance on how to do so. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is closely related to the idea of unrolling, as proposed in \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" However, the comment does not provide specific examples or detailed reasoning to support why this reference is important or how it relates to the paper\\'s content. The lack of detailed justification or references makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical oversight in the paper by pointing out a missing reference to 'Lista,' which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and 'Lista' to provide context and clarify the relationship between the two. This feedback is valuable as it guides the authors to include a relevant reference and address the context of their work, which can enhance the paper's comprehensiveness and credibility. However, the comment could be more helpful if it provided specific suggestions on how to discuss the similarities and differences or where in the paper this discussion should be included. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about Algorithm 2, specifically questioning whether it is possible to update one node based on results from multiple connected nodes. It also notes that \"avg\" is computed but not used, and asks for clarification on the variables \"j' and i'\". The authors\\' response addresses some concerns but does not fully address the initial questions. The comment provides explicit actions for the authors to clarify their algorithm and explain the variables, but it lacks concrete details on how to implement these actions. The authors are given a direction but not fully guided on how to execute it, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the algorithm, such as the unclear update process for nodes and the use of \"avg,\" as well as questions about the variables \"j' and i'.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the update process for nodes based on results from multiple connected nodes. It also questions the use of \"avg\" and the meaning of \"j' and i'.\" While the comment identifies areas of confusion, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors\\' response addresses some concerns but does not provide additional context or evidence to fully verify the claims. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed explanation or references to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several concerns about Algorithm 2, specifically questioning the update process for nodes based on results from multiple connected nodes. It also notes that 'avg' is computed but not used, and asks for clarification on the variables 'j' and 'i''. While the comment identifies areas of confusion and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The response from the authors indicates that some concerns have been addressed, but the initial feedback remains incomplete. Therefore, the comment is somewhat helpful, as it provides some insight into areas that need clarification but does not fully guide the authors in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete guidance on how the authors should address the issue of comparing episodes with different lengths. It suggests that the authors should state how they handle these comparisons and mentions the specific issue of padding shorter sequences and the lack of a normalization factor. The comment also provides a clear explanation of why this is important and how it affects the comparison of trajectories. This level of detail and specificity gives the authors a clear understanding of what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the handling of comparisons between episodes with different lengths, suggesting that the authors should state how they handle this and providing a specific example of padding shorter sequences by replicating the last state. Additionally, it highlights the lack of a normalization factor of 1/T, which affects the comparison of trajectories and favors longer ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should state how they handle comparisons between episodes with different lengths and provides specific examples of the issues with the current approach. It references the provided code and explains the lack of a normalization factor of 1/T, which affects the comparison of trajectories and favors longer ones. This provides a clear and detailed explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by including specific references or examples from the literature to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the handling of comparisons between episodes with different lengths in the paper. It points out that the authors pad shorter sequences by replicating the last state and lack a normalization factor of 1/T, which can lead to a bias towards longer trajectories. This feedback is clear and actionable, as it provides a specific suggestion for improvement by recommending that the authors clarify their approach and include the normalization factor. The comment also explains why this is important for readers to understand without needing to check the code, which is a valuable contribution. However, the comment could be more helpful if it offered additional suggestions or examples on how to implement these changes. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies several issues with figures 1 to 3, including small text, unclear explanations of inputs and outputs, and captions that are not self-contained. It suggests that the authors should make these figures more readable and understandable. However, the comment does not provide specific guidance on how to improve the figures, such as recommending the use of larger fonts, clearer labels, or more detailed captions. While the action is implied, the lack of concrete details makes it vague, leaving the authors uncertain about how to address the issues effectively. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with these figures, such as the small text, unclear explanations of inputs and outputs, and captions that are not self-contained. The comment further specifies the need to link these figures to certain parts of the main text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that figures 1 to 3 are difficult to parse due to small text, unclear explanations of inputs and outputs, and captions that are not self-contained. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies specific issues with figures 1 to 3, noting that the texts are too small, the inputs and outputs are not clearly explained, and the captions are not self-contained. It also points out that it is difficult to link these figures to certain parts of the main text. This feedback is somewhat helpful as it highlights areas where the figures could be improved for clarity and comprehension. However, the comment could be more helpful if it provided suggestions or examples on how to address these issues, such as recommending the use of larger fonts or clearer labels. Overall, the comment provides a starting point for improvement but lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. It provides a specific example of GDSS, which is a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This provides clear guidance on what needs to be done to improve the draft, making the action explicit and concrete. The authors know exactly which models to compare and where to find a suitable baseline, ensuring high actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. The comment further provides a specific example of GDSS and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the continuous diffusion model should be compared as a baseline in Table 3, based on its superior performance in Table 2. The reviewer provides a specific example of GDSS, a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential improvement in the paper by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3. It provides a specific example of GDSS, a continuous diffusion model, and references recent work [2] that proposes a conditional molecule generation framework using classifier guidance based on GDSS. This feedback is clear and actionable, offering the authors a concrete suggestion for enhancing the comparison and analysis in their paper. By following this advice, the authors can improve the comprehensiveness and relevance of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include a comparison against the state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a clear and direct action for the authors to take, as it provides a specific and concrete suggestion for enhancing the paper. The comment does not leave any ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. This makes it difficult for the authors to identify the exact section where this comparison should be added. The comment is specific in its suggestion but lacks grounding, as it does not point to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a logical suggestion based on the field\\'s standards and practices, as these loss functions are commonly used in biometric verification. However, the comment does not provide specific references or examples of how these functions are typically used or why they are relevant to the paper\\'s focus. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the relevance and importance of these loss functions on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of a comparison against state-of-the-art loss functions used in face/iris verification. It specifically mentions examples like Center-Loss, A-Softmax, AM-Softmax, and ArcFace, which are widely used in the field. This feedback is valuable as it directs the authors to a specific area where their work could be enhanced, offering a concrete way to strengthen the paper\\'s contribution and relevance. However, the comment could be more helpful if it provided additional context or reasoning on why these loss functions are particularly relevant or how their inclusion could impact the paper\\'s findings. Despite this, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a confusion in Figure 1 regarding the reference to \"PointNet\" and provides a specific correction by referencing a different paper. It directs the authors to a specific paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which clarifies the reference. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" in Figure 1, providing a direct correction by referencing a different paper. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reference to \"PointNet\" in Figure 1 is confusing because it does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which clarifies the reference. This provides a clear and specific justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that the name does not appear in the paper and suggesting a potential confusion with another paper. It provides a clear and actionable correction by referencing a different paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which clarifies the reference. This feedback is highly helpful as it guides the authors in correcting a potential source of confusion in their paper, ensuring that readers are directed to the correct reference. The comment is specific and actionable, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs, ideally with error bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations, and suggests that the models are small, making it necessary to provide statistics. The comment provides clear and concrete guidance on how to improve the presentation of the results, specifying the actions needed to address the issue. This level of detail and specificity makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results comparing standard- vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation of these results, suggesting that the results should be presented as a mean over many runs with error bars. The comment further explains that the plotted curves are from single runs and might be subject to significant fluctuations, and it emphasizes the need to provide statistics due to the small models. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs with error bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. While the comment provides a logical argument for the need to present results with error bars and statistics, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but could be strengthened with additional evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific issue with the presentation of results comparing standard- vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs with error bars, which is a common practice to ensure statistical significance and reliability. The comment also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and emphasizes the need to provide statistics due to the small models. This feedback is detailed and constructive, offering the authors a clear path to improve the presentation and analysis of their results. Therefore, the comment is rated as highly helpful, as it provides valuable guidance for enhancing the quality and rigor of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the need to describe the CUDA version and the PyTorch version. This feedback is clear and direct, as it specifies exactly what additional information is required to improve the draft. The authors know exactly how to address this feedback by providing the requested details, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This feedback is fully grounded as it explicitly mentions the need for additional details about the experimental setup. However, it does not specify what aspects of the experimental environment should be described in more detail, such as hardware specifications or software configurations. This lack of specificity reduces the comment to a fully grounded but under-specific category. Therefore, the comment aligns with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The reviewer claims that different versions of the experimental environment can impact training and inference speeds. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of different versions. This makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand the implications of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for more detailed description of the experimental environment, such as the CUDA and PyTorch versions. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the transparency and reproducibility of the experimental setup. By addressing this feedback, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it included additional context or examples of how different versions of these tools might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a specific area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the paper\\'s strength for ICLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the paper to address this concern or what specific aspects need attention. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses doubt about the paper\\'s strength for ICLR, but it does not specify which part of the paper is being evaluated or what specific issues are causing this doubt. Without any grounding or specificity, the authors cannot determine which aspects of the paper need improvement or clarification. This lack of detail makes the comment not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses doubt about the paper\\'s strength for ICLR, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references, the authors are left without guidance on how to address the concern or improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses doubt about the paper\\'s strength for ICLR, but it does not provide any specific feedback, suggestions, or examples to help the authors understand what aspects of the paper need improvement or clarification. Without actionable guidance or detailed critique, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the experiments in the paper should be run multiple times to improve reproducibility, which is a common issue in deep reinforcement learning (RL). It references a recent suggestion for a community effort towards reproducibility and provides a specific reference [a] for further reading. While the comment implies that the authors should consider running multiple experiments and reporting statistics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the reproducibility issue by running multiple experiments. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the experiments in the paper should be run multiple times to improve reproducibility, which is a common issue in deep reinforcement learning (RL). It references a recent suggestion for a community effort towards reproducibility and provides a specific reference [a] for further reading. However, the comment does not specify which part of the paper should be addressed regarding the experiments or the reproducibility issue. The authors can infer that it relates to the experimental section, but this inference is not explicit. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that deep RL experiments should be run multiple times to improve reproducibility, citing a recent suggestion for a community effort towards reproducibility. It references a specific paper [a] that discusses the issue of reproducibility in deep RL. While the comment provides a logical reasoning for the claim, it lacks detailed examples or specific guidance on how to implement this suggestion. The reference to the Henderson et al. paper adds some verifiability, but the comment could be strengthened with more detailed examples or a more comprehensive discussion of the issue. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could be improved with additional details.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a critical issue in deep reinforcement learning (RL) experiments, namely the need for reproducibility and the significance of improvements. It suggests that the experiments should be run multiple times to address this issue, which is a common concern in the field. The comment references a recent suggestion for a community effort towards reproducibility and provides a specific paper [a] for further reading. This feedback is valuable as it highlights a significant area for improvement in the paper and offers a concrete reference for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to implement the suggestion or examples of how other studies have addressed this issue. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement and provides a starting point for addressing it.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. It suggests that the results imply that better NMT systems are also better at idiomatic translations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methods. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs random data is similar for most language and score combinations. This provides clear guidance on what needs to be addressed, namely the need for the methods to be more idiom-specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed upweighing and KNN methods have a similar impact on idiomatic vs random data for most language and score combinations, suggesting that the methods are not idiom-specific. This claim is somewhat verifiable as it provides a logical reasoning based on the observation of similar impacts in Figure 3. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the data or methodology to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. It suggests that the results imply that better NMT systems are also better at idiomatic translations. While the comment identifies a potential issue with the methods' specificity, it lacks detailed guidance or suggestions on how the authors might address this concern or improve their methods. The feedback is somewhat helpful as it points out a potential limitation, but it could be more actionable with specific recommendations or examples. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of direct comparisons between the proposed approach and the baseline PRANC, specifically in terms of test accuracy. It highlights that while there are comparisons of training loss and the rank of possible solutions, these do not provide a comprehensive evaluation of the proposed approach. The comment explicitly suggests that a direct comparison of test accuracy is necessary to determine if the approach is indeed an improvement over the baseline. This feedback is clear and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of direct comparisons of test accuracy between the proposed approach and the baseline PRANC, despite comparisons of training loss and the rank of possible solutions. The comment provides specific sections where these comparisons are mentioned, which helps the authors understand the context. However, it lacks detailed reasoning or examples to fully substantiate the claim that the lack of test accuracy comparisons is problematic. The mention of specific sections provides some support, but the claim could be strengthened with more detailed justification or references to why test accuracy is crucial for evaluating the proposed approach. Therefore, the comment is somewhat verifiable, as it provides some support but could be strengthened with additional evidence or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the baseline PRANC in terms of test accuracy. It highlights that while there are comparisons of training loss and the rank of possible solutions, these do not provide a comprehensive evaluation of the proposed approach's effectiveness. The comment is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to fully assess the improvement over the baseline. This feedback is valuable as it guides the authors in enhancing the robustness and comprehensiveness of their evaluation, making the comment mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the improvement of the proposed method over existing RL methods is not impressive, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the proposed method could be improved. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique pertains to, such as the results section or a specific experimental comparison. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the improvement are not impressive or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the existing RL methods or the proposed method\\'s improvements, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is unverifiable, as it lacks the necessary justification or evidence to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the improvement of the proposed method over existing RL methods, stating that it is not impressive. However, it does not provide any specific details, examples, or suggestions on how the authors might enhance the method or address the perceived lack of improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of their work need improvement or how to make it more impactful. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a critique about the improvement of the proposed method over existing RL methods, stating that it is not impressive. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their method. Without specific guidance or suggestions on how to enhance the method or provide more impressive results, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique pertains to, such as the results section or a specific experimental comparison. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the improvement are not impressive or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvement of the proposed method over existing RL methods is not impressive, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the existing RL methods or the proposed method\\'s improvements, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is unverifiable, as it lacks the necessary justification or evidence to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the improvement of the proposed method over existing RL methods, stating that it is not impressive. However, it does not provide any specific details, examples, or suggestions on how the authors might enhance the method or address the perceived lack of improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of their work need improvement or how to make it more impactful. Therefore, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the improvement of the proposed method over existing RL methods, stating that it is not impressive. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their method. Without specific guidance or suggestions on how the authors might enhance the method or provide more impressive results, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the improvement of the proposed method over"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a plot of the model illustration, a pseudo-code table, or a code repository to clarify the model design and facilitate reproducibility. The suggestion is clear and concrete, as it specifies the exact actions the authors need to take to address the issue of unclear model design. This level of detail and specificity makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of unclear model design, specifically mentioning the fragmentation or absence of details regarding the model architecture and learning process. It suggests providing a plot, pseudo-code table, or code repository to clarify these aspects. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the methodology or results sections where the model design is discussed. The suggestion to demonstrate integrated details for reproducibility is clear and specific, providing a concrete action for the authors to take. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details regarding the model architecture and learning process. The reviewer suggests providing a plot, pseudo-code table, or code repository to clarify these aspects. However, the comment lacks specific examples or references to support the claim that Neurochaos Learning is not well-known, which could strengthen the justification for the need to demonstrate integrated details. While the suggestion is logical, the lack of detailed evidence or references makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration for full clarity.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the model design, noting that the model architecture and learning details are fragmented or missing. It provides actionable suggestions for improvement, such as providing a plot of the model illustration, a pseudo-code table, or a code repository, to enhance transparency and facilitate reproducibility. This feedback is clear and constructive, offering the authors a straightforward path to address the identified weakness and improve the clarity and reproducibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to present the model details effectively. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning and its impact on large networks trained in distributed settings. It highlights the potential necessity of finding global top Q values of the metric over the average of gradients, which could affect acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper discusses pruning or distributed training, making it weakly grounded. The issue is clearly specified, as it points out a potential problem with the current approach. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors do not mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is somewhat verifiable as it points out a potential issue that could affect the acceleration techniques like quantization and sparsification. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could break a significant portion of acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning and its impact on large networks trained in distributed settings. It highlights the potential necessity of finding global top Q values of the metric over the average of gradients, which could affect acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper discusses pruning or distributed training, making it weakly grounded. The issue is clearly specified, as it points out a potential problem with the current approach. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors do not mention the necessity of finding global top Q values of the metric over the average of gradients. This could potentially break a significant portion of acceleration techniques like quantization and sparsification. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could break a significant portion of acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they check the figures or provide a correction. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. This provides full grounding as it explicitly mentions the figures being addressed, allowing the authors to accurately identify the parts of the paper being discussed. The comment is also specific because it clearly specifies the issue of potential swapping, giving the authors a clear direction to investigate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the figures in Figs 1 and 2, questioning whether they have been swapped by mistake. This is a straightforward statement of fact without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the figures in Figs 1 and 2, suggesting that they may have been swapped by mistake. While this observation is important for the authors to address, the comment lacks actionable guidance or suggestions on how to verify or correct the issue. It does not provide any context or reasoning to support the claim, nor does it offer any advice on how the authors might investigate or resolve the potential error. As a result, the comment is barely helpful, as it identifies a potential issue but does not provide actionable feedback for the authors to improve their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out issues with the paper formatting, specifically mentioning that it does not follow the NeurIPS formatting style, the abstract font size being too large, and the bottom page margins being altered. It suggests that fixing the paper style would provide more space and allow the NLP experiments to be included in the main body of the paper. While the comment identifies specific formatting issues and suggests a potential solution, it does not provide explicit instructions on how to correct the formatting or where to include the NLP experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the formatting issues and integrate the NLP experiments. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses specific formatting issues, such as the NeurIPS formatting style, font size, and page margins. It provides explicit references to the abstract font size and bottom page margins, allowing the authors to accurately identify the parts of the paper being discussed. The comment also suggests a potential solution by mentioning that fixing the paper style would provide more space and allow the NLP experiments to be included in the main body. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style. It specifies issues with the abstract font size and bottom page margins, suggesting that fixing these issues would provide more space and allow the NLP experiments to be included in the main body. While the comment provides specific examples of formatting issues, it lacks detailed reasoning or references to support the claim that these issues are significant or detrimental to the paper's presentation. The suggestion to include NLP experiments in the main body is a logical inference but lacks explicit justification. Therefore, the comment is somewhat verifiable, as it provides some evidence but could benefit from more detailed reasoning or references to fully substantiate the claim.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific formatting issues with the paper, such as not following the NeurIPS formatting style, the size of the abstract font, and the alteration of bottom page margins. It suggests that fixing these issues would provide more space and allow the NLP experiments to be included in the main body of the paper. This feedback is clear and actionable, as it provides the authors with a specific area to address and an improvement that could enhance the paper's presentation and content. However, the comment could be more helpful if it offered suggestions on how to correct the formatting issues or provided examples of how to integrate the NLP experiments. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a potential solution, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a significant issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on which specific exploration methods should be discussed or compared, or how the authors might structure this discussion. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing what is missing, namely the discussion and comparison of these exploration methods, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support the claim that these methods are essential or relevant to the paper\\'s focus. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of related work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which exploration methods should be discussed or how they might be compared. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile is confusing and proposes adding an extra pair of brackets around the term or defining the bracketed term separately if there is enough space. This feedback provides a clear and explicit action for the authors to take, which is to make a specific change to the definition or provide additional explanation. The suggestion is concrete, as it specifies what needs to be done to improve the clarity of the definition. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential issue with the definition and provides a concrete suggestion for improvement by adding an extra pair of brackets or defining the bracketed term separately. This level of detail helps the authors understand what needs to be addressed and how to improve the clarity of the definition. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of the quantile is confusing and proposes a potential improvement by adding an extra pair of brackets or defining the bracketed term separately. However, the comment does not provide any specific reasoning or examples to support why the definition is confusing or how the suggested changes would clarify it. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile. It provides a clear and actionable suggestion by suggesting a potential improvement, such as adding an extra pair of brackets or defining the bracketed term separately. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and understanding of their work. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on the importance of this clarification. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should vary across multiple HS datasets when evaluated in a cross-data setting. Additionally, it proposes another interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. While the comment identifies a redundancy and suggests an alternative focus, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for revision but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the redundancy of RQ1 and suggests an alternative focus for analysis, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. It also mentions the impact on RQ2 & RQ3 t-sne plots. However, the comment does not specify which part of the paper discusses RQ1 or where the alternative analysis should be included. While it provides a clear suggestion for improvement, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should vary across multiple HS datasets when evaluated in a cross-data setting and proposes another interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. The comment provides a reference to support the suggestion, which is a helpful addition. However, the claim could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is mostly verifiable, as it offers a logical basis for the claim but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a redundancy in the RQ1 mentioned in the paper, suggesting that it does not provide additional information for the audience. It proposes an alternative focus, which is to analyze how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 t-sne plots. This feedback is valuable as it offers a constructive suggestion for improving the paper by providing a more meaningful and relevant research question. However, the comment could be more helpful if it included specific guidance on how to incorporate this analysis or if it provided examples of how to conduct such an analysis. Overall, the comment is mostly helpful as it directs the authors to a more impactful area of investigation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a 'fix' of [12], rather than a new PIC approach. It provides a specific action by suggesting the authors mention the existing work by [12] in the introduction. This feedback is clear and concrete, giving the authors a direct path to improve their draft by addressing the need for clarification. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for clarity in the introduction regarding the proposed solution being a 'fix' of [12] rather than a new PIC approach. The comment provides a clear action for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the authors must clarify in the introduction that the proposed solution is a 'fix' of [12], rather than a new PIC approach. The comment provides a specific suggestion for clarification, which is a logical and reasonable request. However, it lacks detailed reasoning or references to support why this clarification is necessary or how it would impact the paper's clarity. The claim is somewhat verifiable as it points out a specific area for improvement but could be strengthened with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the clarity of the introduction. It identifies a specific issue with the authors' description of their proposed solution, noting that it should be clarified as a 'fix' of [12] rather than a new PIC approach. The comment offers a specific recommendation by suggesting the authors mention the existing work by [12] in the introduction. This feedback is clear and actionable, guiding the authors on how to enhance the clarity and accuracy of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC (HRAC-G4RL) and whether G4RL requires HRAC\\'s regularization in the latent space. While the comment implies that the authors should provide an explanation for this combination, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to justify the combination, but it lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\\'s regularization in the latent space. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the rationale behind the combination, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\\'s regularization in the latent space. This question is a request for clarification and does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information to understand the methodology better. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC, specifically asking why G4RL requires HRAC\\'s regularization in the latent space. This question prompts the authors to provide a clear explanation of their methodology, which is valuable for improving the clarity and understanding of their work. However, the comment does not offer suggestions or guidance on how to address this issue or improve the draft. While it identifies a gap in the paper, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple suggestions and observations. It explicitly requests comparisons with specific NeRF-based methods, such as Zero-1-to-3 and point-e, which provides clear actions for the authors to take. Additionally, it questions the relevance of the occlusion experiment, suggesting that it may not be necessary if the method does not propose anything specific to occlusion. While the comment does not explicitly instruct the authors to remove the occlusion experiment, the suggestion is clear and actionable. The authors know exactly what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific comparisons, such as with NeRF-based methods like Zero-1-to-3 and point-e, which allows the authors to accurately identify the parts of the paper being addressed. It also questions the relevance of the occlusion experiment, providing a clear specification of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several requests for comparisons with specific methods, such as Zero-1-to-3 and point-e, and a suggestion to remove the occlusion experiment. These requests are based on the reviewer\\'s knowledge of existing methods and their relevance to the paper\\'s approach. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or why the occlusion experiment is irrelevant. The lack of specific examples or references makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several actionable suggestions for improvement. It explicitly requests comparisons with specific NeRF-based methods, such as Zero-1-to-3 and point-e, which can help the authors situate their work within the broader context of related methods. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it may not be necessary if the method does not propose anything specific to occlusion. This feedback is clear and provides the authors with a direction for refining their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or address the relevance of the occlusion experiment. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the discussion on the hyperparameter gamma is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment specifies what needs to be addressed, making it highly actionable. The authors know exactly what information is missing and how to improve their draft by adding this discussion. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the discussion on arbitrary hyperparameter \u03b3,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely, the discussion on how to set the hyperparameter in practice for a given graph and analyzing its sensitivity. This provides clear guidance on what needs to be included, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on the hyperparameter gamma is missing, which would make it difficult for researchers to follow. However, the comment does not provide any specific examples, reasoning, or references to support why this is a significant issue or how it affects the paper\\'s comprehensibility. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the discussion on the hyperparameter gamma. It points out that this omission makes it difficult for researchers to follow the work, as it is crucial for understanding the practical application and sensitivity of the hyperparameter. By highlighting this gap, the comment provides clear and actionable feedback, encouraging the authors to include a discussion on setting the hyperparameter and analyzing its sensitivity. This feedback is valuable as it directs the authors to a specific area that needs improvement, making the comment mostly helpful. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of similar analyses. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the methodology section, such as confusing model architecture descriptions and inconsistent notation. It points out a particular inconsistency with the notation of $v^p_{t-1}$ and labels ($l_0$, $l_{t-1}$). While the comment highlights areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the notation and descriptions, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Methodology section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the model architecture description, noting inconsistencies in notation and the confusion caused by the labels. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the methodology section is confusing due to inconsistent notation and misleading label descriptions. The reviewer provides specific examples, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the initial impression of a sequence of tokens being generated as labels, which is not the case. This provides clear reasoning and specific examples to support the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies specific issues with the methodology section, such as confusing model architecture descriptions and inconsistent notation. It provides detailed examples, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the initial impression of a sequence of tokens being generated as labels, which is not the case. This feedback is actionable and provides clear guidance on how to improve the clarity and consistency of the methodology section. By addressing these issues, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the descriptions. Overall, the comment is mostly helpful, as it effectively directs the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. This feedback is clear and provides a direct action for the authors to take, namely to give more attention to prompt design and its implications. The comment is explicit and concrete, offering a clear path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table. While the authors can infer that it relates to the discussion of prompts or the introduction of MenatQA, the lack of explicit grounding makes it difficult for them to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. The comment highlights the importance of discussing how to design prompts effectively. However, it does not provide specific examples, references, or detailed reasoning to support why this is a critical aspect or how it could be improved. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the significance of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement, suggesting that more emphasis should be placed on prompt design. It highlights the importance of discussing how to design prompts effectively, given that different prompts can result in varying performance outcomes. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their paper. By addressing this suggestion, the authors can improve the depth and relevance of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the condition \\u03b7\\u2265C_0 in Proposition 6.1 seems too strong, given that the signal-to-noise ratio \\u03b7 is typically a small value. It recommends that the authors clarify this condition and compare it with that in Section 4, where the model is correct. While the comment explicitly states the need for clarification and comparison, it does not provide specific guidance on how to clarify the condition or what aspects of the comparison should be emphasized. The action is somewhat explicit but lacks detailed instructions on execution, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Proposition 6.1' and 'Section 4', allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the condition \\u03b7\\u2265C_0 seems too strong and suggests clarifying it and comparing it with the condition in Section 4. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the condition \\u03b7\\u2265C_0 in Proposition 6.1 seems too strong, given that the signal-to-noise ratio \\u03b7 is typically a small value. The reviewer suggests that the authors clarify this condition and compare it with that in Section 4, where the model is correct. While the comment provides a logical reasoning based on the typical nature of the signal-to-noise ratio, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the condition \\u03b7\\u2265C_0 in Proposition 6.1, noting that the signal-to-noise ratio \\u03b7 is typically a small value. It suggests that the authors clarify this condition and compare it with that in Section 4, where the model is correct. This feedback is somewhat helpful as it points out a potential weakness in the paper and provides a direction for improvement by suggesting a comparison with another section. However, the comment could be more helpful if it offered specific suggestions on how to clarify the condition or what aspects of the comparison should be emphasized. Overall, the comment provides a basis for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential issue with the condition \\u03b7\\u2265C_0 in Proposition 6.1, noting that the signal-to-noise ratio \\u03b7 is typically a small value. It suggests that the authors clarify this condition and compare it with that in Section 4, where the model is correct. While the comment explicitly states the need for clarification and comparison, it does not provide specific guidance on how to clarify the condition or what aspects of the comparison should be emphasized. The action is somewhat explicit but lacks detailed instructions on execution, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Proposition 6.1' and 'Section 4', allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the condition \\u03b7\\u2265C_0 seems too strong, given that the signal-to-noise ratio \\u03b7 is typically a small value. The comment suggests clarifying this condition and comparing it with that in Section 4, where the model is correct. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the condition \\u03b7\\u2265C_0 in Proposition 6.1 seems too strong, given that the signal-to-noise ratio \\u03b7 is typically a small value. The reviewer suggests clarifying this condition and comparing it with that in Section 4, where the model is correct. While the comment provides a logical reasoning based on the typical nature of the signal-to-noise ratio, it lacks specific examples or references to support the claim fully. This makes the claim"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the legends of Tables 1, 2, and 3 longer and to clarify whether the numbers represent % errors or % correct (assuming MNIST and CIFAR are the respective datasets). This feedback is clear and direct, providing specific guidance on how to improve the clarity of the tables. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the legends, suggesting that they should be longer and clarify whether the numbers represent % errors or % correct, particularly in the context of MNIST and CIFAR datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends of Tables 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, particularly in the context of MNIST and CIFAR datasets. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change that would require justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the legends in Tables 1, 2, and 3. It suggests that the legends should be longer and clarify whether the numbers represent % errors or % correct, particularly in the context of MNIST and CIFAR datasets. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and accuracy of the tables. By addressing this issue, the authors can enhance the readability and understanding of their results, making the comment mostly helpful. However, it could be more helpful if it included examples of how to clarify the legends or suggested alternative phrasing. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the concept of energy should be refreshed in Section 5.2, where it is used several times, and provides a specific suggestion on how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement these suggestions, such as specific examples or references to related literature. The authors know what needs to be done but may need additional information to fully execute the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as refreshing the concept of energy in Section 5.2 and providing hints on how to interpret it. Additionally, it mentions the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and should be refreshed in Section 5.2, where it is used several times. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for revisiting the concept of energy and clarifying the peak in Figure 5, it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable as it highlights areas for improvement but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the presentation of the concept of energy in the paper. It suggests that the concept should be refreshed in Section 5.2, where it is used several times, and provides a specific suggestion on how to interpret it. Additionally, it points out that the concept of peak in Figure 5 is not described, which is another area for improvement. The comment is clear and actionable, offering specific guidance on how the authors can enhance their draft by providing additional context and clarification. This feedback is mostly helpful as it provides clear directions for improvement, allowing the authors to make significant enhancements to their work. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a specific action by suggesting that the title should be clarified to avoid confusion. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft by making a specific change to the title. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the ambiguity in the title and suggesting a clearer distinction between machine and human reading comprehension. However, it lacks specific examples or references to support the claim, which could make it more robust. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the title of the paper, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the title. By addressing this issue, the authors can enhance the precision of their work and better communicate their focus on machine comprehension. However, the comment could be more helpful if it offered additional guidance on how to rephrase the title or provided examples of clearer titles in the field. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It explicitly states that the claim is incorrect and provides a detailed explanation of why the CLT does not guarantee Gaussianity in a non-asymptotic regime or for a finite linear combination of arbitrary random variables. This feedback is explicit and provides concrete details on how the authors can correct their understanding or presentation of the CLT. The authors are given a clear and actionable path to improve their draft by addressing the inaccuracies in their claim. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, which is that the authors\\' assertion about the Central Limit Theorem (CLT) is incorrect. The comment provides detailed reasoning and examples to support the claim, explaining why the CLT does not guarantee Gaussianity in a non-asymptotic regime or for a finite linear combination of arbitrary random variables. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, stating that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This critique is supported by logical reasoning and specific references to the limitations of the CLT, making the claim mostly verifiable. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific claim in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It critiques the claim by explaining that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a detailed explanation of the error in their understanding or presentation of the CLT. By correcting this misunderstanding, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the claim to align with the correct understanding of the CLT. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the lack of confidence intervals and the evaluation on standard datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. It also mentions that the evaluation is only conducted on two standard datasets in the RNP community. While the comment provides references to relevant literature, it does not offer specific examples or detailed reasoning to support the claim that the lack of confidence intervals is a significant issue. The references provided are general and do not directly address the specific concerns raised in the comment. Therefore, the claim is somewhat verifiable, as it provides some support but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the absence of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation being limited to only two datasets, which are standard in the RNP community. The comment provides references to relevant literature, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, ICLR 2019, [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pre-trained language models, TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations, NeurIPS 2022, which could serve as a basis for further exploration and improvement. However, the comment could be more helpful if it offered specific suggestions on how to incorporate confidence intervals or additional datasets to strengthen the paper's claims. Overall, the comment is somewhat helpful as it highlights important areas for improvement but lacks detailed guidance on implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of scalability they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references or detailed context, the authors may find it challenging to identify the exact area being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors should investigate this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies an important aspect that the authors should consider, the comment lacks specificity and actionable guidance. It does not provide any suggestions on how the authors might address this issue or what specific aspects of scalability they should focus on. Without additional context or direction, the authors may find it challenging to determine how to improve their draft in response to this feedback. Therefore, the comment is barely helpful, as it highlights a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRM-RL [1] and asks whether the algorithms can be applied in more general tasks. While the comment implies that the authors should consider expanding the scope of their work to more general tasks, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not specify which part of the paper discusses the limitations to navigation problems or the potential applications in more general tasks. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its suggestion to explore broader applications, it lacks grounding as it does not explicitly mention the relevant parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is limited to navigation problems or that combining RL and planning has already been discussed in PRM-RL. The reference to PRM-RL provides some context, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. While the comment identifies a potential limitation and provides a reference for further exploration, it lacks specific guidance or actionable suggestions on how the authors might expand their work to address this limitation. The feedback is somewhat helpful as it points out an area for improvement but does not offer detailed advice or examples on how to achieve this expansion. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be well-suited for 1-NN if they are not close to a spherical Gaussian. It also offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. While the comment implies that the authors should consider this suggestion, it does not explicitly instruct them to make this change. The action is concrete, as it provides a clear direction for improvement, but it is somewhat implicit because it does not explicitly instruct the authors to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the suitability of feature spaces for 1-NN and offers a potential solution by recommending individual standardization of feature dimensions. This provides the authors with a clear understanding of what needs to be addressed in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that feature spaces may not be well-suited for 1-NN if they are not close to a spherical Gaussian distribution. It suggests that individual standardization of feature dimensions could address this issue. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that feature spaces need to be close to a spherical Gaussian for 1-NN performance. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific observation about the feature spaces used in the paper, suggesting that they may not be well-suited for 1-NN if they are not close to a spherical Gaussian distribution. It offers a potential solution by recommending that feature dimensions be individually standardized to address this issue. This feedback is clear and actionable, as it identifies a potential weakness in the methodology and provides a concrete suggestion for improvement. However, the comment could be more helpful if it included additional context or examples to further explain the importance of this issue and the benefits of the suggested solution. Overall, the comment is mostly helpful as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the meaning of \\u0394 in the statement of Lemma 5. This is a direct and specific request for information, providing the authors with a clear action to take. By asking for clarification, the comment guides the authors to address a specific issue in their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification about the meaning of \\u0394 in the statement of Lemma 5. This provides the authors with a clear understanding of what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification about the meaning of \\u0394 in the statement of Lemma 5. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, asking for clarification about the meaning of \\u0394 in the statement of Lemma 5. This is a specific and direct request that helps the authors understand and address a potential confusion in their draft. By providing this feedback, the reviewer is guiding the authors to improve the clarity and comprehensibility of their work, which is beneficial for enhancing the draft. However, the comment could be more helpful if it included additional context or suggestions on how to resolve the issue. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including the results of the bottom-up method [9] on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. The comment provides a specific action to take, which is to include the results in the tables and conduct the evaluation on the MS Coco dataset. This is a clear and direct instruction, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft based on the feedback provided.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including the results of the bottom-up method [9] on the crowdpose dataset in the tables and evaluating the performance of the method on the standard MS Coco dataset. It also mentions a potential drop in performance in easy (non-occluded) settings. While the comment does not explicitly mention specific sections or tables, it provides enough context for the authors to understand the parts of the paper being addressed. The suggestion to include the results in the tables and evaluate on the MS Coco dataset is specific, giving the authors clear guidance on what to include. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including the results of a specific method, the bottom-up method [9], on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset to assess its performance in easy (non-occluded) settings. While the comment provides a suggestion for improvement, it does not contain any claims or opinions that require verification. It is a request for additional information or evaluation, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests including the results of a specific method, the bottom-up method [9], on the crowdpose dataset in the tables. It also recommends evaluating the performance of the method on the standard MS Coco dataset to assess its performance in easy (non-occluded) settings. This feedback is clear and actionable, providing the authors with specific steps to enhance the comprehensiveness and robustness of their results. By following this suggestion, the authors can improve the verifiability and completeness of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim of using an \"annotation guideline\" and suggests that it may be an overstatement. It provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve their claim. The action is implicit and vague, as the authors are left to infer that they need to clarify or substantiate their claim about using an annotation guideline. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"annotation guideline\" claim and references a specific example from the TACRED slot filling guidelines. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the complexity of annotation guidelines in the IE domain and provides an example to illustrate the depth of true guideline understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the paper makes use of an \"annotation guideline\" by pointing out that the guidelines in the IE domain are complex and were curated by linguists. It provides an example from the TACRED slot filling guidelines to illustrate the depth of these guidelines. However, the comment lacks specific references or detailed examples to fully substantiate the claim that the paper's prompts do not fully capture the depth of true guideline understanding. While the reasoning is logical, the lack of detailed evidence makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration for full clarity.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential overstatement in the paper's claim of using an 'annotation guideline,' noting that the guidelines in the IE domain are complex and were curated by linguists. It provides a specific example from the TACRED slot filling guidelines to illustrate the depth and complexity of these guidelines. The comment highlights that the paper's prompts may not fully capture the depth of true guideline understanding. This feedback is clear and actionable, as it directs the authors to consider the complexity of annotation guidelines and potentially revise their claim or provide more detailed justification. However, the comment could be more helpful if it offered suggestions on how to address this issue or provide additional context. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what implications it might have for their work. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the implications of having an original CAD model associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper this question relates to or what implications it might have. Without clear grounding or detailed guidance, the authors cannot effectively address the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific scenario related to the original CAD model and spatially-varying BRDF maps. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of having an original CAD model associated with spatially-varying BRDF maps. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what implications it might have for their work. The comment lacks actionable feedback or specific advice, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not offer actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time to support their claim. This action is clear and direct, providing the authors with a specific task to perform. The comment also specifies what type of figure is needed, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first question,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to plot a figure showing the decline in accuracy of a predictor over time to support the claim. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evidence of the motivation is not direct and proposes a specific action to support the claim by plotting a figure showing the decline in accuracy of a predictor over time. This is a logical suggestion based on the problem described in the paper, which is the accuracy decline due to long-term and continuous usage. However, the comment does not provide specific examples or references to support the claim that the evidence is not direct, making it somewhat verifiable. The authors would need to infer the basis of the claim, which is a limitation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s motivation, noting that the evidence is not direct. It provides a clear and actionable suggestion by recommending that the authors plot a figure showing the decline in accuracy of a predictor over time to support their claim. This feedback is detailed and constructive, offering a concrete way for the authors to strengthen their paper. However, it could be more helpful if it included additional guidance on how to interpret or analyze the data in the figure. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the definition and calculation of excessive risk, specifically in terms of expectation. It asks for clarification on how to calculate excessive risk and whether the values are comparable across different groups. While the comment identifies areas that need further explanation, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific information or calculations need to be clarified. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 103\" and references Figures 3 and 7, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the definition of excessive risk, how it is calculated, and whether the values are comparable across different groups. The reviewer also asks for clarification on the optimal solution \u03b8* and its relation to the loss function. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definition and calculation of excessive risk, specifically in terms of expectation. It points out that the optimal solution \u03b8* is not the optimal solution for the loss function w.r.t. data of group a, which could lead to negative values for excessive risk. The reviewer also questions the comparability of excessive risk values across different groups and asks for clarification on why excessive risk is a good representation for fairness. While the comment raises valid concerns, it lacks specific examples or references to support the claim about the possibility of negative values or the comparability of excessive risk values. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several important questions about the definition and calculation of excessive risk, specifically in terms of expectation. It points out potential issues with the calculation of excessive risk, such as the possibility of negative values and the comparability of values across different groups. The comment also questions whether excessive risk is a good representation for fairness. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to clarify their methodology and consider alternative representations of fairness, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It suggests that the authors should clarify the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment implies that the authors should address these aspects, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the introduction or motivation section, but this is not explicitly mentioned. The comment is specific in detailing the issues with the motivation and potential applications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the motivation is unclear. The suggestion to clarify potential applications or benefits is a logical extension of the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a gap in the paper, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out a potential weakness in the paper but does not provide detailed advice on how to improve it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for examples of \"unreliable neighbors\" in lines 170 to 171. This request provides a clear and direct action for the authors to take, which is to include specific examples to clarify the concept of \"unreliable neighbors.\" The comment is explicit and concrete, giving the authors a straightforward task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly requests examples of \"unreliable neighbors,\" providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, specifically asking for examples of \"unreliable neighbors\" in lines 170 to 171. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it explicitly requests examples of \"unreliable neighbors\" in lines 170 to 171. This feedback provides a specific direction for the authors to improve their draft by clarifying the concept of \"unreliable neighbors.\" By addressing this request, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to identify or define \"unreliable neighbors\" or provided examples from the literature. Overall, the comment is mostly helpful as it guides the authors towards improving their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the paper\\'s approach, which is to use known causal relationships between features. It highlights that prior knowledge is not always available and might be inaccurate for specific subpopulations, leading most researchers to focus on mining causal relationships from data automatically. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of prior knowledge and explore alternative approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the practicality of using known causal relationships between features, as it acknowledges that prior knowledge is not always available and might be inaccurate for specific subpopulations. However, it does not specify which part of the paper discusses this approach or where the authors might need to address this concern. The authors can infer that it relates to the methodology or discussion sections, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on what aspects of the paper need to be revised or improved to address the concern about practicality. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the practicality of using known causal relationships between features, noting that prior knowledge is not always available and might be inaccurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that prior knowledge is inaccurate or unavailable. The reasoning is based on general observations about the field, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's approach, which is the reliance on known causal relationships between features. It points out that prior knowledge is not always available and might be inaccurate for specific subpopulations, which is a common challenge in many research fields. The reviewer suggests that most researchers focus on mining causal relationships from data automatically, implying that the proposed approach might be impractical. While the comment highlights a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the practicality of their work. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or whether it requires any changes to the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what needs to be done. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contrastive learning framework are similar to SimCLR or what implications this similarity has for the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework is the same as SimCLR, which is a relevant observation. However, it does not provide any further context, analysis, or suggestions on how this observation might impact the paper or what implications it has for the authors. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that splitting Table 4 and 5 into separate tables would improve readability, as it would allow for easier comparison of measures. The action is clear and concrete, as it specifies which tables need to be split and how they should be formatted. This provides the authors with a direct and actionable way to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into separate tables for each measure. This feedback is detailed and actionable, providing a clear path for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that splitting Table 4 and 5 into separate tables would improve readability by allowing easier comparison of measures. This is a logical suggestion based on the reviewer\\'s understanding of the data presentation and the potential benefits of clearer organization. However, the comment does not provide specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is mostly verifiable, as it offers a reasonable suggestion but lacks detailed justification or evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that the tables be split into separate tables for each measure, the reviewer offers a clear and practical way to enhance the clarity and organization of the data presentation. This feedback is valuable as it directly addresses a potential issue in the manuscript and provides a straightforward solution. However, the comment could be more helpful if it included additional suggestions or examples of how to implement this change effectively. Overall, the comment is mostly helpful, as it guides the authors in making a significant improvement to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. While the comment implies that the authors should conduct more systematic comparisons, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Zemel et al. (2013)\" and \"the present paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparisons with this work could be improved by making them more systematic with respect to the tuning of each method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons should be more systematic or how they could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand and address the suggestion effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with Zemel et al. (2013) could be made more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and actionable suggestion for enhancing the paper's analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove the scalability properties. This is a clear and direct action that provides the authors with a specific task to perform. The comment also specifies what needs to be done, making it highly actionable. The authors know exactly how to address the feedback by estimating the time complexity, which is a concrete step towards improving the scalability analysis of the learning algorithm.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is estimating the time complexity to prove the scalability properties. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be estimated to prove the scalability properties. However, the comment does not provide any reasoning, examples, or references to support why this estimation is necessary or how it would impact the scalability. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be estimated to prove the scalability properties. This feedback is clear and actionable, providing the authors with a concrete step to take in order to enhance the scalability analysis of their learning algorithm. By estimating the time complexity, the authors can demonstrate the scalability of their approach, which is a critical aspect for practical applications. However, the comment could be more helpful if it offered additional guidance on how to estimate the time complexity or provided examples of similar approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion around equation (10) is very brief and not well-explained. However, it does not provide any explicit or implicit actions for the authors to take to improve this section. There is no guidance on how to expand or clarify the discussion, nor are there suggestions for what specific aspects need more explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment does not specify what is unclear or missing in the discussion around this equation, making it under-specific. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is very terse and not clearly explained. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues with the discussion, making it difficult to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the discussion around equation (10), noting that it is very brief and not well-explained. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity and depth of their discussion. However, the comment could be more helpful if it provided suggestions on how to enhance the explanation or what specific aspects need further elaboration. Overall, the comment is mostly helpful as it highlights a specific area for improvement but lacks detailed guidance for the authors to fully address the issue.', 'helpfulness_label': '4'}"}
