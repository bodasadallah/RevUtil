{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation is correct, implying that the current method is flawed. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise the description of HIERENC. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, noting that using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. This provides clear guidance on what needs to be addressed in the description of HIERENC. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that using the average of all instantiations of context filled by every possible entity in the vocabulary is a poor idea because only one instantiation is correct. The reviewer provides a logical reasoning by questioning the validity of averaging multiple instantiations, which could introduce noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact issue and potential improvements from the reviewer\"s reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation is correct, implying that the current method is flawed. This feedback is clear and actionable, as it provides a specific area for improvement and highlights a potential weakness in the methodology. However, the comment could be more helpful if it offered suggestions on how to clarify the description or alternative approaches to consider. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper uses integrated gradients for attribution measurement, which has been studied in existing papers. It also mentions the proposal of postprocessing steps to filter out \"falsepositive\" neurons. However, the comment suggests that the paper does not demonstrate the importance of these postprocessing steps. The reviewer proposes an ablation study as a potential solution to address this issue. While the action is explicit, the comment does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be included. The authors know they need to conduct an ablation study, but the comment lacks concrete instructions on how to execute it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the use of integrated gradients for attribution measurement and the proposal of postprocessing steps to filter out \"falsepositive\" neurons. It suggests that the paper does not demonstrate the importance of these postprocessing steps and recommends an ablation study. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in suggesting an ablation study to address the lack of demonstration of the importance of the postprocessing steps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of postprocessing steps to filter out \"falsepositive\" neurons, despite using integrated gradients for attribution measurement. The reviewer suggests that an ablation study may be needed to address this issue. However, the comment lacks specific examples or references to support the claim that the importance of these steps is not demonstrated. While the suggestion for an ablation study is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the use of integrated gradients for attribution measurement has been studied in existing papers. It also points out the proposal of postprocessing steps to filter out \"falsepositive\" neurons but suggests that the paper does not demonstrate the importance of these steps. The reviewer recommends conducting an ablation study to address this issue. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper\"s methodology and results. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear direction for enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the proposed method of matching the head of noun phrases. The comment implies that the authors should clarify how they handle situations where the head word is not a pronoun. While the action is implicit, it is clear that the authors need to address this issue, and the comment provides a specific area for clarification. However, the comment does not offer concrete guidance on how to implement this clarification, such as suggesting specific examples or methods to handle the situation. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment raises a specific question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the proposed method of matching the head of noun phrases. It explicitly mentions the method and the specific scenario where the head word is not a pronoun, providing full grounding. The comment is also specific as it clearly identifies the issue and suggests a need for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the method proposed by the authors for identifying antecedents, specifically when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. While the comment identifies a specific area of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is 3, as it points out a potential weakness but requires more detailed explanation or references to be fully substantiated.", "helpfulness_rationale": "The review comment raises a specific question about the method proposed by the authors for identifying antecedents, particularly when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. This feedback is clear and actionable, as it prompts the authors to clarify their method and consider alternative approaches to address the identified issue. However, the comment could be more helpful if it provided suggestions on how to handle these situations or offered examples of how the method could be improved. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional baselines, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this extension is discussed in, making it difficult for the authors to identify the exact section that needs further development. The comment is specific in suggesting additional baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support why these additional baselines are necessary or how they would enhance the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a vague suggestion without sufficient evidence or explanation.", "helpfulness_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment identifies a potential area for improvement by suggesting additional baselines, it lacks specific guidance on how these baselines should be incorporated or what benefits they might offer. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to demonstrate that something, such as attention in a seq2seq multitask learning (MTL) model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism to improve its performance. While the comment implies that the authors should investigate the reasons for failure and make necessary changes, it does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the difficulty of demonstrating that attention in a seq2seq multitask learning model is not working and suggests that the value lies in understanding why it fails and making changes to the attention mechanism. However, it does not specify which part of the paper this discussion pertains to, making it weakly grounded. The comment is specific in its suggestion to understand why attention fails and make changes to the mechanism, but without grounding, the authors cannot confidently identify the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something, such as attention in a seq2seq multitask learning model, is not working, but the value lies in understanding why it fails and making changes to the attention mechanism. While the comment provides a logical reasoning for why understanding the reasons for failure is valuable, it lacks specific examples or references to support the claim. The suggestion to change the attention mechanism is vague and does not provide a clear path for the authors to follow. Therefore, the comment is 3, as it offers a general insight but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges the difficulty in demonstrating that attention in a seq2seq multitask learning model is not working, but it emphasizes the importance of understanding why it fails and making changes to the attention mechanism to improve its performance. This feedback highlights a critical aspect of the paper\"s analysis and suggests a direction for improvement. However, the comment lacks specific guidance or actionable steps for the authors to take to address this issue. While it identifies a valuable area for exploration, it does not provide detailed suggestions or examples, making it 3. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is only on an extremely lowresource regime, which is not the only case where data augmentation is used in realworld applications. Additionally, it notes that sentence classification is an easier task and suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. While the comment highlights areas for improvement, it does not provide explicit guidance on how to strengthen the experiments or expand the scope of the proposed method. The authors are left to infer that they need to broaden the experimental settings and demonstrate the method\"s applicability to other NLP tasks. However, the lack of specific instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is only on an extremely lowresource regime, which is not the only case where data augmentation is used in realworld applications. Additionally, it notes that sentence classification is an easier task and suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the issues relate to the experimental section, but this inference is not explicit. The comment is specific in detailing the weaknesses and potential improvements, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak, given the paper\"s length, and suggests that the setting is only on an extremely lowresource regime, which is not the only case where data augmentation is used in realworld applications. The reviewer also notes that sentence classification is an easier task and implies that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. While the comment provides some reasoning and examples, such as the mention of sentence classification being an easier task, it lacks specific references or detailed explanations to fully substantiate the claim. This makes the claim 3, as it provides some support but requires further elaboration for the authors to fully understand and address the issues.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is only on an extremely lowresource regime, which is not the only case where data augmentation is used in realworld applications. Additionally, it notes that sentence classification is an easier task and suggests that the proposed augmentation method has potential for use in more NLP tasks, which were not demonstrated. While the comment highlights areas for improvement, it does not provide specific suggestions or guidance on how to strengthen the experiments or expand the scope of the proposed method. The feedback is 3 as it points out weaknesses but lacks actionable advice, leaving the authors to infer the necessary steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or what aspects of these claims need further analysis. Without explicit guidance on which claims to focus on or how to conduct the analysis, the authors are left without a clear understanding of what actions to take. The comment lacks both specificity and directness, making it 1.", "grounding_specificity_rationale": "The comment suggests that certain claims in the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or provide any context about what these claims are. Without specific references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims need more indepth analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that certain claims in the paper would benefit from more indepth analysis, but it does not provide any specific examples or reasoning to support this claim. Without detailed explanations or references to the claims in question, the authors are left without guidance on which claims need further analysis or why they are insufficient. This lack of specificity and justification makes the claim 1.", "helpfulness_rationale": "The review comment suggests that certain claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any guidance on what aspects of these claims need further analysis. Without specific examples or detailed feedback, the authors are left without actionable steps to improve their draft. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of constituent parse as knowledge and suggests that the term \"knowledge\" might be misleading. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the model generalizes to different knowledge, specifically questioning the representation of substructure as a sequence of words and the use of the term \"knowledge.\" It provides a specific critique by suggesting that the term \"knowledge\" might be misleading, as it is typically used to refer to world or external knowledge rather than syntax or semantics. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or example, making it weakly grounded. The feedback is specific in detailing the issue with the term \"knowledge,\" but without grounding, it is challenging for the authors to pinpoint where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to world or external knowledge rather than syntax or semantics. The reviewer provides a specific critique by pointing out the potential confusion in terminology. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to explore the implications of this critique and potentially provide additional context or evidence to address it fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the generalization of the model and the representation of substructure as a sequence of words. It questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to world or external knowledge rather than syntax or semantics. This feedback is valuable as it points out a potential misunderstanding or misinterpretation of the term \"knowledge\" in the context of the paper. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify or redefine the term \"knowledge\" to align with its intended use. Overall, the comment is 3 as it identifies a potential issue but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It suggests that the authors should provide a better understanding of the gap between the performance of the clustering approach and the oracle GAP for PPDBClus. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance gap, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"nouns\" and \"parts of speech,\" allowing the authors to accurately identify the specific areas being addressed. It also specifies the issue by questioning the generalizability of the clustering approach and the performance gap between TWSI and PPDBClus. The comment is specific in detailing what needs to be addressed, such as understanding the gap in performance and clarifying the generalizability claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable to all parts of speech. The comment provides a logical reasoning based on the observed performance gap, suggesting that the authors should provide a better understanding of this gap. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable. This feedback is 3 as it identifies a specific area of concern and highlights a potential inconsistency in the paper\"s claims. However, the comment could be more helpful if it provided suggestions on how the authors might address these issues or improve the generalizability of their approach. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point challenges the claim that there is no corresponding set of tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly instruct the authors to include these references or to address the claim in their draft. While the action is implied, it lacks concrete guidance on how to implement the correction. The authors are left to infer that they should incorporate the references provided, but without detailed instructions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment challenges a claim about the absence of corresponding tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly mention which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or conclusion section, but this inference is not direct. The comment is specific in identifying the claim as false and providing references to support this, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges a claim by providing references that support the existence of corresponding tools for the reinforcement learning setting. This provides a clear and specific counterpoint, making the claim 5. The references used are external sources that can be verified, adding robustness to the claim. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper, specifically questioning the assertion that there is no corresponding set of tools for the reinforcement learning setting. By providing references from the submitted paper and external sources, the comment offers a clear and factual correction, which is valuable for the authors to consider. This feedback is actionable as it directs the authors to include these references or address the claim in their draft, thereby enhancing the accuracy and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these references effectively. Overall, the comment is 4, as it provides a clear correction and guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) whether the proposed method is fairly compared with other methods, and (2) whether the proposed technique promotes existing Class incremental semantic segmentation methods. While the questions imply that the authors should address these concerns, they do not provide explicit guidance on how to do so. The authors are left to infer that they need to justify the fairness of their comparison and demonstrate the novelty of their technique in the context of existing methods. However, the comment lacks concrete suggestions or detailed instructions on how to address these issues, making the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions regarding the proposed method: (1) whether it is fairly compared with other methods, and (2) whether it promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions relate to, such as specific sections or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions, but without clear grounding, it is challenging for the authors to address the issues effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two questions regarding the fairness of comparison and the promotion of existing methods. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the proposed method. The first question asks whether the method is fairly compared with other methods, which is a valid concern for the authors to address. The second question inquires about the promotion of existing Class incremental semantic segmentation methods, which could be an important aspect to consider for the authors. However, the comment does not provide specific guidance or suggestions on how the authors might address these questions or improve their draft. While it identifies areas for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written in a concise manner due to space limitations and could have benefited from a slower development to make it easier to read. While the comment implies that the authors should consider expanding the section for clarity, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should expand the section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is \"tersely written\" and could have benefited from a slower development for an easier read. This level of detail allows the authors to understand what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is written in a concise manner due to space limitations, which could have benefited from a slower development for an easier read. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or improvements needed. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 4, noting that it is written in a concise manner due to space limitations. It suggests that the section could have benefited from a slower development to make it easier to read. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might expand or clarify the section. This limits the usefulness of the feedback, as the authors are left to infer the nature of the improvements needed. Therefore, the comment is 3, as it points out a potential issue but does not provide detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed method. It also highlights the absence of performance comparison. This feedback is clear and direct, providing the authors with a specific action to take: include a comparison with the method proposed in 1 and perform a performance comparison. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lack of comparison with a highly relevant method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a comparison with a method proposed in 1 and the lack of performance comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should include a comparison with a highly relevant method, specifically mentioning 1 and its proposed method. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison with a highly relevant method, specifically mentioning 1 and its proposed method. It highlights the importance of including a comparison with this method, as it could enhance the paper\"s comprehensiveness and provide a more robust evaluation of the proposed approach. However, the comment could be more helpful if it provided specific suggestions on how to conduct the comparison or what aspects should be emphasized in the comparison. Overall, the feedback is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment identifies specific issues, it does not provide explicit guidance on how to address these problems or improve the results. The authors are left to infer that they need to enhance the performance of their models or provide a more detailed explanation of the baseline models. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method with two models, noting that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses the pipeline method or the baseline models, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the results and the lack of introduction for baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method with two models does not yield better average results for both XVNLI and MaRVL, and that the baseline models are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipeline style method, noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models in the experiments are not well introduced, which is a critical aspect for readers to understand the context and performance of the study. However, the comment lacks actionable suggestions or guidance on how to improve the method or introduce the baseline models more effectively. While it highlights important areas for improvement, the feedback is 3 as it provides a starting point for the authors to address these issues but does not offer detailed steps or examples for implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not explicitly instruct the authors to do so or suggest specific alternatives. The action is implicit and somewhat vague, as the authors can infer that they need to improve their methodology but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in its critique of the methodology and the need for improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, referencing the common knowledge that language models reproduce the biases of the corpora on which they are trained. However, the comment lacks specific examples or references to support the claim that the methodology is \"coarse\" or that the observation needs to be made again. This makes the claim 3, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" methodology for reproducing a wellknown result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might improve their approach. The feedback is 3 as it points out a potential weakness in the methodology, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It also points out that Theorems 1 and 2 prove the relationship between GCL and a clearer community structure, but the connection between degree bias and this relationship is not intuitive. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what kind of explanations are needed. The authors are left to infer that they should provide more detailed explanations or examples to clarify the relationship between degree bias and the community structure. Therefore, the comment is 3, as it highlights a need for clarification but lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment addresses the need for more explanations regarding how a small degree of bias can be achieved from a clear community structure. It specifically mentions Theorems 1 and 2, which are referenced in the paper, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment also specifies what needs to be addressed, namely the lack of intuition in the relationship between degree bias and the community structure. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which prove the relationship between GCL and a clearer community structure, but questions the intuition behind the connection between degree bias and this relationship. While the comment highlights a potential gap in the paper, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the nature of the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which prove the relationship between GCL and a clearer community structure, but points out that the connection between degree bias and this relationship is not intuitive. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples to clarify the relationship between degree bias and the community structure. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided specific examples of what kind of explanations are needed. Overall, the comment is 4, as it effectively guides the authors towards enhancing the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. While the comment implies that the authors should provide additional clarification, it does not explicitly instruct them to do so or specify how much detail is required. The action is implicit and somewhat vague, as the authors know they need to clarify the notation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the notation and the split between \"static\" and temporal features, specifically mentioning \"S\" and \"Xt.\" This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation and the need for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation and the split between \"static\" and temporal features are confusing, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or references leaves the claim 3, as it requires the authors to infer the exact nature of the confusion and the need for additional information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, noting that it is confusing and requires more information than is provided in the paper. It specifies what needs to be clarified, namely the definitions of \"S\" and \"Xt,\" which is a clear and actionable suggestion for the authors to improve the clarity of their notation. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested alternative ways to clarify the notation. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a claim in section 2 of the paper and questions its validity, stating that it is true but not an advantage. The reviewer suggests that a model capable of handling only a single time series data is almost useless. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2\" and refers to a specific claim about INRs operating on a perdatainstance basis. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim\"s validity and suggests that a model capable of handling only a single time series data is almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"INRs operate on a perdatainstance basis\" is true but not an advantage. The reviewer provides a logical reasoning by suggesting that a model capable of handling only a single time series data is almost useless. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the notion of a model\"s usefulness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in section 2 of the paper and questions its validity, suggesting that it is true but not an advantage. The reviewer provides a logical reasoning by pointing out that a model capable of handling only a single time series data is almost useless. This feedback is clear and actionable, as it prompts the authors to reconsider the significance of this claim and potentially revise their draft to address this concern. However, the comment could be more helpful if it offered suggestions on how to reframe or support the claim or provided alternative perspectives. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with largescale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a more realistic condition or method to characterize the benefit of large learning rates. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the required condition on the learning rate, noting that it is not scalable and may lead to unreasonably large learning rates when working with largescale datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in identifying the issue with the scalability of the condition and the potential problem with large learning rates. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and unrealistic. The reviewer provides a logical reasoning by stating that in practice, step sizes do not grow with the sample size, which could lead to unreasonably large learning rates when dealing with largescale datasets. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide more detailed evidence or examples to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. This observation is relevant and could help the authors reconsider their assumptions or approach. However, the comment lacks detailed guidance or suggestions on how to address this issue or improve the scalability of the condition. While it points out a potential problem, it does not provide actionable steps or alternative solutions for the authors to consider. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting, as in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, by directly sampling unlabeled data from millions of reviews. This is an explicit suggestion that provides a concrete action for the authors to take, which is to replicate the approach used in the referenced work. The comment also explains why this is necessary, citing the impracticality of the perfectly balanced unlabeled data in realworld applications. This level of detail and specificity makes the comment 5, as it gives the authors a clear and concrete path to follow for improving their draft.", "grounding_specificity_rationale": "The comment addresses the use of unlabeled data in the Amazon review dataset, specifically mentioning the Blitzer version. It suggests that the authors should use a more convincing setting, as in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, by directly sampling unlabeled data from millions of reviews. This provides a clear and specific reference to a related work, allowing the authors to identify the part of their paper that needs improvement. The comment is fully grounded as it references a specific dataset and suggests a method from a relevant study. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or method. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data in the Amazon review dataset is impractical in realworld applications. It suggests that the authors should use a more convincing setting, as in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, by directly sampling unlabeled data from millions of reviews. The claim is supported by logical reasoning, as it points out the impracticality of perfectly balanced data in realworld scenarios and provides a specific reference to a related work that addresses this issue. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear rationale but lacks some depth in its explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of unlabeled data in the Amazon review dataset, specifically noting that the data is perfectly balanced, which may not reflect realworld scenarios. It suggests that the authors should consider a more convincing setting, as in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, by directly sampling unlabeled data from millions of reviews. This feedback is clear and actionable, as it provides a specific method for the authors to improve the practicality of their approach. By referencing a related work, the comment offers a concrete suggestion for enhancing the draft. However, it could be more helpful if it included additional context or examples to further explain the implications of this suggestion. Overall, the comment is 4, as it guides the authors towards a more realistic and practical approach."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in 3. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could take to improve their sampling method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) on line 130. It also compares this issue to sampling from the leverage score in 3. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically Equation (10) and the reference to 3. The comment is specific because it clearly details the problem with sampling from the DPP and compares it to a similar issue with the leverage score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in 3. The reviewer provides a logical comparison, suggesting that sampling from the DPP might be more challenging than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the comparison is relevant, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in 3. This feedback is 3 as it identifies a potential weakness in the sampling method and provides a relevant comparison. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve their sampling method. As it stands, the comment provides a starting point for the authors to consider, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the lack of experiments on the POMDP problem with nonconvex value functions, specifically mentioning examples like surveillance in museums with thresholded rewards and privacy preserving data collection. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments should be conducted. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experiments on the POMDP problem with nonconvex value functions, particularly in the context of the examples provided. The reviewer questions why there are no experiments on these settings, even in a simulated context, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiments are not useful. The absence of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. This feedback is 3 as it identifies a gap in the experimental validation of the paper\"s claims. However, it lacks specific suggestions or guidance on how the authors might conduct these experiments or what additional experiments would be beneficial. The comment provides a direction for improvement but does not offer detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions that this limitation prevents the use of single deep neural networks on homomorphically encrypted data. While the comment emphasizes the need for further research, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this limitation further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need to study noise accumulation and its impact on the use of single deep neural networks on homomorphically encrypted data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that it is important to study the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a critical issue. Without specific examples, references, or logical reasoning, the claim remains 1. The authors are left without guidance on how to address this issue or why it is significant, making the comment difficult to act upon. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a critical limitation in the study, specifically the impact of noise accumulation in the context of homomorphic encryption on sequential ensembling. It emphasizes the importance of studying this effect, which is a relevant and insightful observation. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or what steps they could take to improve their work. While it identifies a significant area for further exploration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with previous results in a stronglyconvex concave case, the authors should use standard regularization tricks. While the comment implies that the authors should incorporate these tricks, it does not explicitly instruct them to do so or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should use regularization tricks and how to apply them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using standard regularization tricks to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors might infer that it relates to the comparison or analysis section, but this inference is not explicit. The comment is specific in its suggestion to use regularization tricks, but it lacks grounding as it does not specify the exact part of the paper where this comparison is made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using standard regularization tricks to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why these tricks are necessary or how they would improve the comparison. Without additional context or justification, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using standard regularization tricks to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the comment identifies a potential improvement by suggesting the use of regularization tricks, it lacks specificity and does not provide detailed guidance on how to implement these tricks or what specific aspects of the comparison would benefit from their use. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and present their solutions in the paper. It also mentions that the citation seems disordered. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to deal with the different types of inputs or how to organize the citations. The action is somewhat implicit and vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests presenting solutions in the paper. It also mentions that the citation seems disordered. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting the need to discuss different types of inputs and the organization of citations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and presents this as a valuable addition to the paper. It also mentions that the citation seems disordered, which is a factual observation. However, the comment does not provide specific examples or detailed reasoning to support why discussing different types of inputs is valuable or how the citation should be organized. This lack of detailed justification makes the claim 3, as the authors would need to infer the significance of the suggestion and the nature of the disordered citations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the authors discuss how to handle different types of inputs, such as biomedical signals or speech. This is a valuable suggestion as it highlights a gap in the current discussion and provides a direction for enhancing the paper\"s comprehensiveness. Additionally, the comment notes that the citation seems disordered, which could be addressed to improve the paper\"s organization. While the comment provides actionable feedback, it could be more helpful if it offered specific suggestions or examples on how to handle different types of inputs or how to organize the citations. Overall, the comment is 4 as it directs the authors to an important area for improvement and provides a clear direction for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment implies that the authors should address this in their draft, it does not provide explicit guidance on how to discuss or acknowledge the issue. The action is implicit and somewhat vague, as the authors need to infer that they should include a detailed discussion of this tradeoff. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of the ICLHAR on accuracy scores, specifically mentioning the drop from 70.4 to 55.6 on TRIP. However, it does not specify which part of the paper discusses the ICLHAR or the accuracy scores, making it weakly grounded. The comment is specific in detailing the issue with the ICLHAR\"s impact on accuracy, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It specifically mentions a drop in accuracy scores from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment highlights a critical point, it does not provide specific guidance on how to address this issue or what aspects of the discussion should be expanded. This limits the comment\"s helpfulness, as it provides a clear direction but lacks depth and actionable suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The authors are left without clear instructions on where to focus their efforts or how to correct the identified problems. As a result, the comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment highlights severe writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper contain these issues, making it difficult for the authors to identify the exact areas needing improvement. Without specific references or examples, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address the feedback. Without concrete evidence or references, the claim remains 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights important areas for improvement, it lacks depth and detail, making it 2. The authors are left with a general understanding of the problem but without clear steps to correct it. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. It points out that backpropagation is widely accepted as biologically implausible. However, the comment does not provide specific guidance on how the authors should address this issue or improve the statement. The feedback lacks actionable details, such as suggesting alternative ways to express the biological implausibility or providing evidence to support the claim. As a result, the authors are left without a clear understanding of what changes to make to strengthen the statement. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, citing the widespread acceptance of backpropagation as biologically implausible. This claim is supported by common knowledge and general understanding in the field, making it 3. However, the comment could be strengthened by providing specific references or examples to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This feedback is 3 as it points out a common misunderstanding or lack of clarity in the paper. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or improve the statement. Without actionable advice or examples, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific NLP tasks to explore. The comment implies that the authors should expand their analysis to other tasks, but it lacks concrete details or actionable steps on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on contrastive learning in code search tasks and suggests that it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper discusses the proposed method or how it could be expanded to other tasks. The authors might infer that the discussion on the method\"s application is relevant, but the comment lacks explicit grounding. It is specific in identifying the need for broader exploration but does not provide detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant as it highlights an area where the authors could expand their analysis to enhance the generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as recommending particular NLP tasks to explore or providing examples of how the method could be applied. While it points out an important area for improvement, the feedback could be more actionable and comprehensive to be considered 5. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative terminology or providing a rationale for why the term \"certificate\" is being used in this context. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors clarify the terminology and ensure that it is understood in the intended context. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing alternative terminology or providing a detailed explanation of the term \"certificate\" in the context of the paper. While it highlights an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include real data, as barycenters have applications in various realworld problems. While the comment implies that the authors should consider including real data in their experiments, it does not provide explicit instructions on how to do so or what specific realworld problems to address. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include real data, indicating that the current focus on toy data is limiting. However, it does not specify which part of the paper discusses the experiments or where the authors should make these changes. This lack of explicit grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in suggesting the inclusion of real data, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and proposes expanding them to include real data, where barycenters can be used. However, the comment does not provide specific examples or references to support the claim that real data would be more relevant or beneficial. The suggestion is based on a general observation about the potential applications of barycenters, but without detailed reasoning or evidence, it remains somewhat vague. Therefore, the comment is categorized as 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that the experiments are limited to toy data. It suggests that the authors should expand their experiments to include real data, as barycenters have applications in various realworld problems. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and applicability of their work. By addressing this suggestion, the authors can significantly improve the impact and generalizability of their findings. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. While the comment implies that the authors should consider this reformulation, it does not explicitly instruct them to make this change or explain how it would affect the motivation of Algorithm 1. The action is implicit and somewhat vague, as the authors need to infer the need for this reformulation and understand its implications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. The reviewer provides a logical reasoning by suggesting a reformulation that could affect the motivation of the algorithm. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to explore the suggested reformulation to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1 by suggesting that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation unclear. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify or reframe their approach. By suggesting a potential reformulation, the comment provides a concrete direction for the authors to improve the clarity and motivation of their work. However, the comment could be more helpful if it included additional suggestions or examples to further guide the authors in addressing this issue. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific claim about the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this observation is related to, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be valuable for the authors to consider. However, the comment lacks depth and does not offer actionable advice or suggestions on how the authors might incorporate this insight into their work. It does not provide specific guidance on how to address this observation or its implications for the paper\"s content or analysis. As a result, the comment is 3, as it offers a potential area for exploration but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. The first comment instructs the authors to make the captions more descriptive, which is a clear and direct action. The second comment requests a better explanation of the \"scramble network,\" again providing a specific and actionable suggestion. Both comments are concrete and provide clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses two separate issues: the need for more descriptive captions and the explanation of the \"scramble network.\" While it does not explicitly mention specific sections or figures, the authors can infer that these issues pertain to the figures and captions throughout the paper. The comment is specific in detailing what needs to be addressed, such as making the captions more descriptive and providing a better explanation of the \"scramble network.\" However, the lack of explicit section references makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate comments, each addressing a specific issue with the paper. The first comment suggests that the captions are not descriptive enough, making it difficult for readers to understand the figures without referring to the text. The second comment requests a better explanation of the \"scramble network.\" While these suggestions are logical and reasonable, they do not contain any specific claims or references that would require verification. The comments are based on the authors\" subjective experience and observations, which are common in peer review. Therefore, the comments are considered \"No,\" as they do not contain claims that require verification.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. The first suggestion is to make the captions more descriptive, which is a clear and actionable point. This feedback helps the authors understand the need to enhance the clarity of their figures, making it easier for readers to interpret them without having to search through the text. The second suggestion is to explain the \"scramble network\" better, which is also a direct and constructive piece of advice. By addressing these specific areas, the authors can significantly improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided examples or further guidance on how to make the captions more descriptive or explain the \"scramble network.\" Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It asks why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. However, the comment does not explicitly instruct the authors to include such an explanation or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"images used in this paper sample,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. The comment clearly specifies what needs to be addressed, namely, the rationale behind this particular dimension of difficulty. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that the choice is not wellmotivated and asks why this particular dimension of difficulty is interesting. However, the comment lacks specific reasoning or evidence to support why this choice is not wellmotivated or why the dimension of difficulty is interesting. The absence of detailed justification or examples makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while more difficult tasks are interesting, the authors should provide a rationale for why this particular dimension of difficulty is interesting. This feedback is 3 as it prompts the authors to clarify their reasoning and potentially enhance the motivation for their experimental setup. However, it lacks depth and does not offer specific guidance on how to address the issue or improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it does not provide explicit guidance or suggestions on how the authors might address this issue or what steps they should take to explore this further. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the impact of periodicity on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment does not explicitly mention a specific part of the paper, it is clear that it relates to the experimental results and the comparison between models. The authors can infer that it pertains to the results section or the comparison between models, but the comment lacks explicit grounding. The specificity is clear as it questions the extent of periodicity\"s impact on the results and suggests a potential solution. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then asks if adding periodicity to the spectral kernel would allow it to capture these results at a similar level to the explicitly compositional model. While the comment raises an interesting question, it lacks specific evidence or references to support the claim that the results are solely due to periodicity. The suggestion to add periodicity to the spectral kernel is a logical inference but lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for inquiry but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships and that in all experiments except Experiment 1b, the relationships involve periodicity. The reviewer then suggests that adding periodicity to the spectral kernel might allow it to capture these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the impact of periodicity on their results and suggests a potential avenue for further investigation. However, the comment could be more helpful if it provided specific guidance on how to explore this issue or what experiments might be necessary to address it. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the goal of the paper, specifically regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors should clarify whether their claim is that this is a foundation model or a proof of concept, and if it is the latter, to justify a future useful application. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically mentioning the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It suggests that the authors clarify whether their claim is that this is a foundation model or a proof of concept and, if it is the latter, to justify a future useful application. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the introduction or methodology sections where the goal and comparison are discussed. The authors can infer the relevant parts, but the comment lacks explicit grounding. The specificity is clear as it specifies what needs to be addressed regarding the goal and comparison. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the claim that the paper presents a foundation model. The reviewer suggests that the authors clarify whether their claim is a foundation model or a proof of concept and, if the latter, to justify a future useful application. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that there are other DAS earthquake detectors or that the comparison is necessary. The suggestion to clarify the claim is logical, but the comment could be strengthened with more detailed reasoning or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s goal and methodology. It points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the claim that the paper presents a foundation model. The comment suggests that the authors clarify whether their claim is a foundation model or a proof of concept and, if the latter, to justify a future useful application. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the lack of comparison and justification. However, the comment could be more helpful if it offered suggestions on how to conduct the comparison or what future applications could be explored. Overall, the comment is 4, as it effectively guides the authors in enhancing the clarity and robustness of their claims."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. While the comment implies that the authors should consider this limitation and potentially address it, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about the potential for extension, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a purely factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the limitation of using triplets or a sliding window of length 3 in the approach. It prompts the authors to consider whether this is a fundamental limitation or if an extension to longer subsequences is feasible. This feedback is valuable as it challenges the authors to think about the scope and potential improvements of their work. However, the comment does not provide specific guidance or suggestions on how to address this limitation or extend the approach, which could enhance its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: first, it asks for clarification on the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. Second, it points out that the paper lacks related work, despite the subject matter being closely related. While the comment explicitly requests clarification on the term and highlights the need for related work, it does not provide specific guidance on how to address these issues. The authors are left with a general understanding of what needs to be clarified or added, but without detailed instructions on how to implement these changes. Therefore, the comment is 3, as it identifies specific areas for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for clarification on the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. Additionally, it points out the lack of related work, which is a specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. It also points out the absence of related work, suggesting that the subject matter is closely related to existing work. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed justification or evidence makes the claim 3, as it provides a basis for inquiry but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two important points. First, it asks for clarification on the term \"sequence of episodes,\" which is crucial for understanding the context and methodology of the paper. This feedback is valuable as it prompts the authors to provide a clear definition or explanation, ensuring that readers can follow the discussion. Second, the comment points out the absence of related work, suggesting that the subject matter is closely related to existing research. This observation highlights a potential gap in the paper\"s literature review, which the authors should address to strengthen their argument for novelty. While the comment identifies areas for improvement, it could be more helpful if it provided specific suggestions or examples of related work to consider. Overall, the comment is 4 as it directs the authors to clarify their terminology and address a potential oversight in their literature review."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this distinction. The authors may infer that it pertains to the discussion or results sections, but this is not explicitly mentioned. The comment lacks specificity in terms of what needs to be addressed, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While this is a valid point, the comment lacks specificity and does not provide detailed guidance on how the authors should make this distinction or why it is important. Without actionable advice or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and clarity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. While it identifies a specific issue with the clarity of the proof, it does not provide explicit guidance on how the authors should address this problem. The comment lacks concrete suggestions or actions for the authors to take, such as recommending ways to improve the clarity of the proof or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the theorem is buried in the appendix and its proof is not clear enough. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and suggests that the authors should clarify or improve the clarity of the proof. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative ways to present the proof or suggesting improvements to enhance its clarity. As a result, the feedback is 3, as it highlights a critical area for improvement but does not fully support the authors in making the necessary changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific feedback on two issues: the accuracy of the claim about the Walkman algorithm being solved by ADMM and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. The first point is fully grounded as it references specific sections of the paper (Page 2, second paragraph in Related Work) and provides a clear correction. The second point is also fully grounded, as it references a specific section (Section 3, first paragraph) and highlights a lack of clarity. Both points are specific, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the claims about the Walkman algorithm and the lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of two claims. The first claim challenges the accuracy of a statement about the Walkman algorithm being solved by ADMM, referencing a specific paper (Mao et al., 2020) as evidence. This provides a clear and specific reference, making the claim 4. The second claim questions the clarity of a reference in Section 3, noting that \"it\" lacks a clear reference. While this part of the comment lacks specific examples or references, it is still 3 due to the general nature of the critique. Therefore, the overall verifiability of the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues. First, it corrects a claim about the Walkman algorithm being solved by ADMM, referencing a specific paper (Mao et al., 2020) as evidence. This feedback is valuable as it helps the authors ensure the accuracy of their claims in the related work section. Second, it points out a lack of clarity regarding the reference for the \"it\" in the first paragraph of Section 3, suggesting that the authors need to provide a clearer reference. This feedback is clear and actionable, guiding the authors to improve the clarity and accuracy of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment identifies a potential issue with the analysis, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete suggestions on which specific approaches to include or how to conduct the additional comparisons. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically mentioning that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which sections or figures are affected. The comment is specific in pointing out the lack of comparison with other NAS approaches, which is a clear issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. However, the comment does not provide specific examples or references to support the claim that these other approaches are relevant or necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the analysis on BRPNAS could be improved by pointing out that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a broader range of NAS approaches. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these additional approaches or what aspects of the analysis should be expanded. Overall, the comment is 4 as it highlights a potential weakness in the analysis and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for these additions but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity in detailing what specific aspects of the experiment results should be enriched or how the thresholds should be varied. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, the comment does not provide specific examples or references to support the claim that these additions are necessary or would improve the results. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion, leaving the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the experiment results could be enriched: the inclusion of attacks with different strengths and the exploration of how different thresholds affect detection performance. This feedback is clear and actionable, providing the authors with concrete steps to enhance their experimental analysis. By suggesting these additions, the comment offers valuable guidance on how to improve the robustness and comprehensiveness of the results. However, it could be more helpful if it provided examples or detailed suggestions on how to implement these changes. Overall, the comment is 4 as it directs the authors\" attention to important aspects of their work that need further exploration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to expand the method\"s applicability. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not specify which part of the paper discusses the method\"s applicability or how it is currently limited to digit or text images. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its critique of the method\"s applicability, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the proposed method, specifically questioning whether it can be used on natural images like CIFAR10, which have broader realworld applications. This feedback highlights an important aspect of the method\"s potential impact and suggests that the authors should consider expanding the scope of their experiments to include more diverse datasets. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to demonstrate the method\"s applicability to natural images. While it identifies a potential limitation, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to reorganize the prompts or what specific changes should be made. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve the organization of the prompts. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the prompts are not wellorganized and that sentences squeeze together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Tables 6 and 7 are not wellorganized, with sentences squeezing together. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address. However, the comment could be more helpful if it offered suggestions on how to reorganize the prompts or provided examples of better organization. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is clear and direct, providing the authors with a specific action to take: to clarify the figures and ensure that all modules are labeled correctly. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figures are not clear due to confusion in the relation of subfigures and the absence of labels for certain modules, such as CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is based on the observation of the figures and the lack of clarity in labeling, which is a subjective assessment. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to address the issues raised by making the figures clearer and labeling the modules correctly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that they are not clear and providing examples of confusion and missing labels. By pointing out these specific areas of concern, the comment offers actionable feedback that can help the authors improve the clarity and accuracy of their figures. However, the comment could be more helpful if it provided suggestions on how to clarify the figures or what specific changes should be made. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights questionable design choices, specifically mentioning the use of perplexity as a measure of retaining semantic information after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not provide explicit guidance on how to control these factors or what specific actions should be taken to improve the design choices. The action is implicit and somewhat vague, as the authors need to infer that they should address the control of domain drift, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses \"some questionable design choices,\" specifically mentioning the use of perplexity as a measure of retaining semantic information after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not specify which part of the paper these design choices are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the control of domain drift, providing clear guidance on the issue. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of retaining semantic information after finetuning, questioning how factors like domain drift are controlled. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that perplexity is an appropriate measure or that domain drift is not adequately controlled. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of retaining semantic information after finetuning, suggesting that there may be aspects of domain drift that are separate from catastrophic forgetting. It questions how these factors are controlled, implying that the authors should address this issue. While the comment highlights a potential weakness in the methodology, it does not provide specific guidance or suggestions on how to control domain drift or improve the measure of semantic information retention. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with a general direction to explore without detailed guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors might address this concern or what steps they could take to improve the dataset size or coverage. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the dataset or find a way to ensure its comprehensiveness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of dataset size, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. It also questions the adequacy of the dataset to cover varied domains, given that LLMs are typically trained on trillions of tokens. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about dataset size and its implications for capturing diverse user traits and topics. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer provides a logical reasoning by comparing the dataset size to the scale of typical LLM training data, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific examples or references to support the claim about the dataset\"s sufficiency, making it 3. The authors would need to conduct further analysis or research to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains, which is a valid point. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as expanding the dataset or exploring alternative methods to ensure comprehensiveness. While it identifies a potential weakness, the feedback could be more helpful with actionable advice or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the work, noting that it only uses binary features and questioning the applicability of the method to real and categorical features. While the comment highlights an area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this limitation. The action is implicit, as the authors need to infer that they should consider the applicability of their method to real and categorical features. However, the comment lacks concrete details on how to implement this change, making it vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions the applicability of the method to real and categorical features. However, it does not specify which part of the paper discusses the use of binary features or how the authors should address the applicability to real and categorical features. This makes it difficult for the authors to identify the exact section that needs revision. The comment is weakly grounded because it does not provide specific guidance on where to find this information, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work only uses binary features. However, the comment does not provide any supporting evidence, examples, or references to justify why the method might not be applicable to other types of features. Without specific reasoning or references, the claim is difficult for the authors to address, making it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the work, noting that the method only uses binary features and questioning its applicability to real and categorical features. This feedback is 3 as it points out an area where the authors might need to expand their work to make it more comprehensive. However, the comment lacks specific suggestions or guidance on how the authors could address this limitation, such as exploring the use of real or categorical features. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors might improve it. Without concrete examples or detailed suggestions, the authors are left without a clear understanding of what changes are needed. The comment lacks explicit or implicit actions, making it 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or what specific issues need to be addressed. Without explicit references to sections, figures, or specific points, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding the nature of the unclear points, making it difficult for the authors to understand what needs to be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples or reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed feedback or evidence, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they might be clarified. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to improve their draft. This lack of detail and specificity makes the comment 2, as it does not effectively support the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors use other metrics, such as BERTScore, to evaluate the results. While the action is explicit, it does not provide specific guidance on how to incorporate these metrics or what aspects of the results they should evaluate using BERTScore. The suggestion is concrete in terms of the action to take, but the lack of detailed instructions on implementation makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or specific tables or figures. Without explicit references to the sections or elements being addressed, the authors may find it challenging to determine where to apply this suggestion. Additionally, the comment lacks specificity regarding what aspects of the results should be evaluated using BERTScore or how this metric should be incorporated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning, examples, or references to support why BERTScore would be a better choice or how it would improve the evaluation. Without such justification, the claim is not verifiable, as it lacks the necessary evidence or explanation to be understood or acted upon by the authors. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. While this is a specific and actionable suggestion, it does not provide any context or reasoning as to why BERTScore might be a better choice or how it could improve the evaluation. The comment lacks depth and does not offer detailed guidance on how to implement this suggestion, leaving the authors with a vague idea of what to do but no clear path forward. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making the necessary changes. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific areas where the paper could be improved: the discussion of scalability bounds and the lack of clarity regarding memory requirements and computational complexity. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to expand their discussion on scalability and provide more detailed analysis of memory requirements and computational complexity. However, the lack of specific suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Scalability Bounds\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the lack of discussion on the upper limits of scalability and the absence of a clear discussion on memory requirements and computational complexity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the upper limits of FedDES\"s scalability and lacks a clear discussion of memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on scalability bounds and the absence of a clear discussion on memory requirements and computational complexity. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to expand the discussion or what specific aspects of scalability and computational complexity should be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the impact of the base node, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the topic. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential area for clarification but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer implies that the authors should clarify or justify this choice, but the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or justification for the direction of the arrow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer implies that the main purpose of the figure is to influence n^(i), but the current direction of the arrow is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this direction is problematic or how it affects the understanding of the figure. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). This feedback highlights a potential inconsistency or confusion in the figure, which could impact the reader\"s understanding of the main purpose of the figure. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the figure. While it identifies a potential area for clarification, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. While the comment points out the lack of definition for abbreviations, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to define all abbreviations used in the paper, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3, as it highlights a specific area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that many abbreviations lack definition and provides a specific example of \"AR\" standing for domain adaptation tasks and algorithms. This level of detail and specificity makes it clear what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and causes confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any additional context, reasoning, or examples to support why this is a significant issue or how it affects the clarity of the paper. Without further elaboration or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many abbreviations lack definition and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it highlights a concrete area where the authors can improve the clarity of their work by defining abbreviations. However, the comment could be more helpful if it suggested how the authors might define these abbreviations or provided examples of how to do so. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it does not provide explicit guidance or suggestions for the authors to follow. The comment implies that the authors should consider other technical aspects when using advantage, but it does not specify what these aspects might be or how they should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it does not explicitly mention a specific part of the paper, the authors can infer that it relates to the methodology or analysis section. The comment is specific in questioning the technical basis for using advantage, which provides some guidance on what needs to be addressed. However, the lack of explicit mention of a section or part of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. It acknowledges that using advantage is more common in practice but seeks clarification on other technical aspects that might influence this choice. The comment does not make a claim or express an opinion, as it is purely inquisitive. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it seeks clarification on other technical aspects that might influence this choice. This feedback is 3 as it prompts the authors to consider additional factors in their analysis, but it lacks depth and does not provide specific guidance or suggestions for improvement. The authors are left with a general question that requires further exploration, making the comment 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the setting of Unsupervised Online Adaptation, noting that it seems contradictory because the training set requires annotations, which implies supervision. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the description. The feedback lacks actionable details, leaving the authors uncertain about what changes to make or how to clarify the description. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the Unsupervised Online Adaptation setting, noting that it seems contradictory because the training set requires annotations, which implies supervision. This provides clear guidance on what needs to be addressed in the description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with annotations, which implies supervision. However, the comment does not provide specific examples or detailed reasoning to support this claim. The lack of detailed evidence or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of the Unsupervised Online Adaptation setting, noting that it seems contradictory because the training set requires annotations, which implies supervision. This feedback highlights a specific area where the authors might need to clarify or reframe their description to accurately reflect the unsupervised nature of the adaptation process. However, the comment lacks depth and does not provide detailed guidance on how to address this issue or improve the description. While it points out a potential problem, it does not offer actionable suggestions or examples for the authors to follow. Therefore, the comment is 3, as it provides a starting point for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the fairness of the performance comparison in Table 1, specifically noting that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This comment implies that the authors should consider adjusting the comparison to ensure fairness, but it does not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should address the fairness of the comparison, and it is somewhat vague because it does not provide specific guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to differences in sample weights used by VINS compared to other baselines. The reviewer provides a specific observation about the sample weights, which supports the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the comparison is unfair due to differences in sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential weakness in the evaluation methodology that the authors should address. By pointing out this discrepancy, the comment provides a concrete direction for improvement, allowing the authors to enhance the fairness and validity of their results. However, the comment could be more helpful if it suggested how to adjust the comparison or provided examples of how to address the issue. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results are presented in a convoluted manner, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. It also questions the reason for presenting the results in this way. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the presentation of results. The action is implicit and vague, as the authors are left to infer that they need to clarify or reorganize the results to address the safety violations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and specifies the issue with the presentation, particularly regarding the disregard of safety violations in the first 1000 episodes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details what needs to be addressed, namely, the convoluted presentation and the need to clarify the reason for presenting the results in this manner. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard the safety violations of the agent in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support the claim that the presentation is convoluted or why the safety violations are disregarded. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard the safety violations of the agent in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should provide a clearer explanation or justification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the presentation of results. While it highlights a potential weakness, it does not offer concrete steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific guidance or suggestions on how to improve the allocation of Figure 1 or the editing of the main paper. The authors are left with a vague understanding of what needs to be addressed, making it difficult to know how to implement the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not specify which part of the main paper needs editing or how the allocation of Figure 1 could be improved. This lack of specificity makes it difficult for the authors to understand exactly what needs to be addressed. The comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific enough to provide actionable guidance. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment lacks specificity and does not provide detailed guidance on how to improve the allocation of Figure 1 or the editing of the main paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out an area for improvement but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the planbased method requiring manual design based on the ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans based on Table 2. The comment suggests that the proposed method may be difficult to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue and provides some insight, it does not offer explicit guidance or suggestions on how the authors might address this concern or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the need for manual design based on the ground truth, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the planbased method or the learned plan methods, making it weakly grounded. The authors can infer that it relates to the methodology section, but the lack of explicit references or specific sections makes it challenging to pinpoint. The comment is specific in detailing the issue with the planbased method and its generalizability, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on the ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors are left to infer the implications of these statements, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the planbased method, noting that it requires manual design based on the ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, suggesting potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. This feedback is clear and actionable, as it highlights a critical limitation of the method and provides a specific area for improvement. However, the comment could be more helpful if it offered suggestions on how to address this limitation or alternative approaches to consider. Overall, the comment is 4 as it directs the authors\" attention to a significant weakness in their methodology and encourages them to explore potential solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to strengthen their conclusions. The feedback is 3 as it highlights a potential weakness but lacks detailed instructions on how to improve it. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific claims about the paper\"s conclusions, such as the belief that continuous learning with unlabeled data accumulates noise. It also provides references to external works, including R1, R2, and R3, which offer potential explanations for the observed results. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that some conclusions are not convincing and provides a specific example of a claim that is not supported by evidence. It suggests that the results might come from limited exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. This provides some support for the claim by offering examples of alternative approaches. However, the comment lacks detailed reasoning or specific evidence to fully substantiate the claim. The references provided are relevant but do not directly address the specific claim about the conclusions being unconvincing. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some claims are not convincing. It provides a detailed critique by pointing out a potential limitation in the exploration of combination methods and references several works, including R1, R2, and R3, which employ feature replay for continual learning. This feedback is valuable as it directs the authors to consider alternative approaches and provides specific examples of relevant literature. However, the comment could be more helpful if it offered suggestions on how to strengthen the paper\"s conclusions or provided additional guidance on addressing the identified issue. Overall, the comment is 4 as it highlights a critical area for improvement and provides a solid foundation for further exploration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended, leaving the authors without guidance on how to address them. Without specific suggestions or directions, the authors are left to infer potential actions, such as conducting further analysis or providing additional context. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions about the accuracy of the ground truth and the significance of the differences, but without clear references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any guidance or suggestions on how the authors might address these concerns or improve their analysis. The questions are openended and lack actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, it does not provide specific guidance on how to address this issue or suggest alternative wording. The authors are left without clear instructions on how to improve the phrasing or tone of their writing. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of exaggerated wording in the conclusion, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" This provides some grounding as it refers to a specific part of the paper, but it does not specify which sections or sentences are overly exaggerated. The comment is specific in identifying the issue of flamboyant word choice, but without explicit references to sections, it is weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, the comment does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant. This feedback is 3 as it points out a potential issue with the writing style that could affect the clarity and professionalism of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as recommending alternative phrasing or tone. Without actionable advice, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues and suggestions for improvement. It highlights the need for more explanations regarding bit operations other than 11, specifically mentioning Fig. 5a. It also questions the handling of DVS input when the input is in aer format. Additionally, it suggests that analyzing energy consumption would make the paper more solid, referencing a specific reference 15. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the figure, such as the strangeness of the presentation and the need for more explanations. Additionally, it raises questions about the handling of DVS input when the input is in aer format and suggests analyzing energy consumption as in reference 15. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several issues and suggestions for improvement, but it does not contain any claims that require verification. The comment is descriptive and provides specific feedback on the paper\"s content, such as the need for more explanations regarding bit operations and the handling of DVS input. It also suggests that analyzing energy consumption would strengthen the paper. However, it lacks any subjective opinions, judgments, or requests for changes that would require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific feedback on the paper, identifying several areas for improvement. It highlights the need for more explanations regarding bit operations other than 11, specifically mentioning Fig. 5a, and suggests that providing additional context would enhance the paper\"s clarity. Additionally, the comment questions the handling of DVS input when the input is in aer format and suggests that analyzing energy consumption would make the paper more solid, referencing a specific reference 15. This feedback is clear and actionable, offering the authors concrete steps to improve their draft. However, it could be more helpful if it provided detailed guidance on how to address these issues or specific examples of what additional explanations or analyses might be beneficial. Overall, the comment is 4, as it provides valuable insights and suggestions for enhancing the paper\"s quality and rigor."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance input information but notes that many MLMs can already perform object detection tasks independently. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance input information, but notes that many MLMs can already perform object detection tasks independently. However, the comment does not specify which part of the paper discusses these approaches or where the authors might address these concerns. The authors can infer that it relates to the introduction or discussion sections, but the lack of explicit references makes it weakly grounded. The comment is specific in its critique of the approach and its potential lack of innovation, but the absence of grounding makes it difficult for the authors to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance input information but notes that many MLMs can already perform object detection tasks independently. However, the comment lacks specific examples or references to support the claim that the approach is not innovative or that many MLMs can already perform object detection tasks. The reasoning is somewhat vague and lacks detailed evidence, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance input information but notes that many MLMs can already perform object detection tasks independently. While the comment identifies a potential issue with the novelty of the approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. The feedback is 3 as it points out a potential weakness in the paper\"s contribution, but it does not provide actionable steps or detailed advice for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these additional experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed guidance on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in detailing the concerns and suggestions for further experimentation, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not adequately address these issues. The authors are left with a general concern about the model\"s generalization performance, but without concrete evidence or examples, it is difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It highlights a specific area of concern regarding the training of similar nodes or graphs with features that converge excessively, potentially discarding unique features. The comment also questions the effectiveness of positive sample selection without introducing perturbation noise and suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or address the concerns raised. The feedback is 3 as it points out a potential weakness in the current experimental setup but could be more actionable with detailed guidance or examples."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or where in the paper they should be addressed. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations/social norms (e.g., physical/psychological safety) in the main paper. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the lack of clarity but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, noting that the types of situations/social norms (e.g., physical/psychological safety) are not clear. This feedback is valuable as it highlights a potential gap in the paper\"s clarity, which could impact the reader\"s understanding. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as providing examples or clarifications. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include more baselines for comparison and test more domains. It also points out that the choices of weighting and learning density functions are not strongly motivated and requests stronger empirical results. This feedback is clear and provides specific actions for the authors to take, such as expanding the baselines and testing on additional domains. The comment is explicit and concrete, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"more baselines to be compared\" and \"more domains to be tested,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the current choices of weighting and learning density functions, which are not strongly motivated. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include more baselines and test more domains, and it questions the motivation behind the choices of weighting and learning density functions. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for more baselines to be compared and more domains to be tested, which is a constructive suggestion for improving the comprehensiveness of the study. It also points out that the choices of weighting and learning density functions are not strongly motivated, which is a valid concern. However, the comment could be more helpful if it provided specific examples of alternative baselines or domains that could be tested, or if it offered suggestions on how to strengthen the motivation for the current choices. Overall, the feedback is 4 as it highlights areas for improvement but could be more detailed and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies specific issues with the figure, it does not provide explicit guidance on how to address these ambiguities or clarify the symbols. The authors are left to infer that they need to improve the clarity of the figure and possibly investigate the issue of information redundancy. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that some symbols are not explained clearly and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references leaves the claim 3, as the authors would need to infer the nature of the ambiguity and the potential redundancy or interference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a specific area for improvement in the paper\"s presentation and raises a relevant question that could impact the understanding of the methodology. However, the comment could be more helpful if it provided suggestions on how to clarify the symbols or address the potential redundancy and interference. Overall, the comment offers some guidance but lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their results. The action is implicit and vague, as the authors are left to infer that they should consider including other kernel types or discuss the implications of the current limitation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the paper regarding the assumption of a subgaussian spectrum for kernels, particularly mentioning the exclusion of Matern kernels due to their polynomial decay spectrum. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the potential restriction of the results, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s results are limited because the authors assume a subgaussian spectrum for kernels, which is reasonable for popular Gaussian kernels but excludes other popular kernels like Matern kernels. The reviewer provides a logical reasoning for the claim, explaining that the assumption is valid for Gaussian kernels but not for Matern kernels, which decay polynomially. This reasoning is clear and provides a basis for understanding the limitation. However, the comment could be strengthened by providing specific examples or references to Matern kernels to further substantiate the claim. Therefore, the comment is 4, as it offers a logical explanation but lacks detailed examples or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment highlights that this limitation could restrict the applicability of the results. While it points out a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their results. The feedback is 3 as it raises an important consideration but lacks depth and actionable advice, leaving the authors with a general understanding of the limitation but no clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide specific guidance on how to simplify the writing or which parts of the paper are particularly challenging to follow. The authors are left with a general idea of what needs to be improved but lack concrete steps or examples to follow. As a result, the comment is 3, as it identifies a problem but does not offer detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which parts of the paper are particularly challenging to follow or provide examples of where the writing is unclear. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to simplify the writing or what specific changes should be made. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand which parts of the writing are problematic or how to address them. Without detailed feedback or evidence, the claim remains 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the writing, noting that it is difficult to follow in many places. However, it lacks actionable guidance or suggestions on how to simplify the writing or improve its clarity. Without detailed feedback or examples, the authors are left with a general understanding of the problem but no clear path to address it. This makes the comment 3, as it points out a potential area for improvement but does not provide the necessary depth or specificity to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is explicit, it is somewhat vague as it does not specify which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The authors are given a clear direction to improve their work, but the lack of specific guidance on the number or types of datasets limits the level of detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper discusses the method or the datasets used, making it weakly grounded. The comment is specific in its suggestion to test on more datasets, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any specific reasoning, examples, or references to support why more datasets are necessary or how they would improve the evaluation. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. While this is a logical and constructive suggestion, it lacks specificity and does not provide guidance on which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The comment identifies a potential area for improvement but does not offer actionable advice or detailed feedback, making it 3. The authors are given a direction to improve their work, but the lack of specific guidance limits the comment\"s effectiveness. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the distinction between the two normalization techniques. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the difference between Online Normalization and Batch Normalization, particularly their bias and unbiased nature. It raises a question about why Online Normalization is unbiased and Batch Normalization is biased, which is a clear and specific point. However, the comment does not explicitly mention which part of the paper discusses these normalization techniques, making it weakly grounded. Despite this, the comment is specific in detailing the issue, so it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It suggests that the authors clarify why Online Normalization is unbiased and Batch Normalization is biased. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the question effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It points out a potential confusion regarding why Online Normalization is unbiased and Batch Normalization is biased. While the comment identifies a specific area of confusion, it does not provide any actionable feedback or suggestions for the authors to address this issue. Without additional guidance or insights, the authors may find it challenging to improve their draft based on this comment. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that overparametrization leads to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that supports the benefits of overparametrization in supervised learning of deep neural networks. However, the comment does not explicitly instruct the authors to address this claim or provide a specific action to take. The suggestion to include references to theoretical work is implicit and somewhat vague, as it does not specify which parts of the paper should be revised or how to incorporate these references. Therefore, the comment is 3, as it provides a direction for the authors to consider but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the claim that overparametrization leads to overfitting and worse performance, providing references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or detailed explanations of how the referenced work supports the argument, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges a claim about overparametrization leading to overfitting and worse performance, suggesting that it is not universally true. It provides references to theoretical work that support the benefits of overparametrization in supervised learning of deep neural networks. This feedback is valuable as it encourages the authors to reconsider their assumptions and potentially revise their claims. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these references or address the challenge to the claim. Overall, the comment is 4 as it prompts the authors to consider alternative perspectives and provides a direction for further exploration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include more game environments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not specify which part of the paper discusses the experiments or which game environment is being used. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not provide any specific reasoning, examples, or references to support why more experiments are necessary or how they would improve the study. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary to provide a broader perspective or validation of the findings. While the comment highlights an important area for improvement, it lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. This limits the usefulness of the feedback, as it provides a general direction but does not offer detailed suggestions for implementation. Therefore, the comment is 3, as it points out a critical area for enhancement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing an exhaustive list of items in memory for recognition judgments. It questions the practicality of such a list and suggests that it might be difficult to test concrete predictions with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to find a way to address the feasibility of the exhaustive list. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the feasibility of implementing an exhaustive list of items in memory for recognition judgments. It provides a logical reasoning about the difficulty of implementing such a list and testing concrete predictions with simulations. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenge of implementing an exhaustive list and testing predictions, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of implementing an exhaustive list of items in memory for recognition judgments. It questions the practicality of such a list and suggests that it might be difficult to test concrete predictions with simulations. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that such a list is impractical or untestable. The authors are left to infer the basis of the concern, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing an exhaustive list of items in memory for recognition judgments, questioning the practicality of such a list and the difficulty in testing concrete predictions with simulations. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. The feedback is 3 as it points out a potential weakness in the paper, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the experimental comparison, suggesting that the proposed method was pretrained before finetuning, which may not be the case for the compared methods. It implies that the authors should ensure that the compared methods were also pretrained or initialized with similar models. The comment provides a clear action for the authors to take, which is to clarify the pretraining and initialization of the compared methods. This guidance is explicit and concrete, allowing the authors to address the issue directly. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, specifically noting that the proposed method was pretrained before finetuning, while the compared methods may not have been initialized with the same or similar pretrained models. This provides clear guidance on what needs to be addressed in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to differences in pretraining between the proposed method and the compared methods. The reviewer provides a specific example from Table 1, where the proposed method without SSL performs inferior to most compared methods. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically noting that the proposed method was pretrained before finetuning, while the compared methods may not have been initialized with the same or similar pretrained models. This observation is important because it could affect the fairness of the comparison. The comment provides a clear and actionable suggestion for the authors to ensure that the compared methods were also pretrained or initialized with similar models. This feedback is valuable as it helps the authors address a potential weakness in their experimental setup, potentially leading to a more robust and fair comparison. However, the comment could be more helpful if it offered additional guidance on how to achieve this or provided examples of how to implement the suggested change. Overall, the comment is 4, as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for zeroshot learning on the CUB dataset, referencing a specific table and paper for comparison. It provides a concrete action by recommending a specific table and paper to refer to, and it also includes a followup update that thanks the authors for their response. This feedback is explicit and provides clear guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that better metadata embeddings options are available and references a specific table and paper for comparison. The comment is specific in detailing what needs to be addressed, namely the use of \"attribute\" metadata and the potential improvement with better embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison but implies that better metadata embeddings are available. It references a specific table and paper for comparison, providing a logical basis for the claim. However, the comment lacks detailed reasoning or specific examples of how the proposed method would perform with better metadata embeddings, which could strengthen the argument. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending the use of better metadata embeddings for zeroshot learning on the CUB dataset. It references a specific table and paper for comparison, offering a clear direction for enhancing the performance of the proposed method. The comment is actionable and provides a concrete way for the authors to improve their results, making it 5. However, it could be more helpful if it included more detailed guidance on how to implement the suggested changes or if it discussed the potential impact of these improvements. Overall, the feedback is 4, as it offers a clear path for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the nature of the contribution regarding ECE_sweep is not clearly described, specifically mentioning that it amounts to autotuning a hyperparameter. The reviewer suggests that the paper should be upfront about its contribution. While the comment identifies a specific issue with the clarity of the contribution, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the contribution regarding ECE_sweep, specifically mentioning the need for a more explicit description of how it is used to choose the number of bins. It also notes that this approach is not fundamentally different from other estimators. The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarity of the contribution regarding ECE_sweep. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the nature of the contribution with respect to ECE_sweep is not clearly described, suggesting that it amounts to autotuning a hyperparameter. The reviewer provides a logical explanation, stating that this approach is not fundamentally different from other estimators. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the contribution from the reviewer\"s reasoning, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep, noting that it amounts to autotuning a hyperparameter. The reviewer suggests that the paper should be more upfront about its contribution, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific suggestions on how to clarify the contribution or examples of how to present it more clearly. Overall, the feedback is 4 as it directs the authors to improve the clarity of their contribution, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors should investigate the resilience of the metric to the choice of random projection. While the comment implies that the authors should conduct an analysis to demonstrate the robustness of their metric, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the results, namely the variability in results with the chosen random projection matrix. It suggests that the authors should investigate the resilience of their metric to the choice of random projection, which is a specific concern. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or the appendix, but this is not clearly specified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors should investigate the resilience of their metric to the choice of random projection. While the reviewer acknowledges that this is unlikely with random projections, they suggest that it would be helpful to see this resilience demonstrated. The comment is 3 as it provides a logical reasoning for the concern but lacks specific examples or references to support the claim fully. The authors would need to infer the exact nature of the concern and how to address it, making the comment 3.", "helpfulness_rationale": "The review comment raises a valid concern about the variability in results with the chosen random projection matrix and suggests that the authors should investigate the resilience of their metric to the choice of random projection. This is a constructive suggestion that could help the authors demonstrate the robustness of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the metric\"s resilience should be examined. Overall, the comment is 4 as it identifies an important area for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just being used in the ablation study. While the comment implies that the authors should consider using FGT for performance evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the use of FGT for performance evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just in the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just in the ablation study. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the evaluation. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the proposed method, specifically regarding the use of FGT. It suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just in the ablation study. This feedback is 3 as it points out a potential limitation in the evaluation process and offers a suggestion for improvement. However, the comment could be more helpful if it provided specific guidance on how to implement this suggestion or examples of how it could be applied. Overall, the comment provides a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the originality of their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate the novelty of their approach or findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the originality of the paper, specifically questioning the novelty of using the winnertakeall property, which has been widely used in previous works. It highlights that most of the findings have been reported in previous works, particularly in Sec 5. However, the comment does not specify which part of the paper discusses the winnertakeall property or the findings in Sec 5, making it weakly grounded. The comment is specific in questioning the originality of the paper\"s contribution, but without explicit references to sections or findings, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the winnertakeall property has been widely used in previous works, such as NNbased clustering algorithms, and questions the novelty of the paper\"s contribution in understanding this behavior with its simplified settings. The comment provides a logical reasoning by referencing previous works and suggesting that most findings have been reported before. However, it lacks specific examples or references to the previous works, making it 3. The authors would need to provide additional context or references to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it identifies a potential issue, it lacks actionable feedback, making it 2. The authors are left to infer that they need to demonstrate the novelty of their approach or findings, but without explicit guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being discussed. The comment is specific in pointing out the issue with the approach but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, the comment lacks specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach taken by the authors, specifically regarding the complexity of checking on the Witness oracle, which is polynomial time in the tabular case. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the comment does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it provides some insight but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the description of experimental details is lacking and that it would benefit from increased clarity to allow the user to better judge the results. It also provides a reference to \"Questions\" for further details, which implies that the authors should address these questions to improve the clarity of the experimental description. This feedback is clear and direct, providing the authors with a specific action to take. The inclusion of \"Questions\" suggests that the authors should address these specific points, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of detail in the experimental description, which makes it difficult for the user to judge the results. The comment further provides a reference to \"Questions\" for further details, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details is lacking, making it difficult for the user to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the assertion that the experimental description is insufficient. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the lack of detail in the experimental description. It highlights that increased clarity in the experimental details would significantly benefit the user\"s ability to judge the results. The comment is clear and actionable, providing a direct suggestion for improvement. However, it could be more helpful if it offered specific examples or guidance on how to enhance the clarity of the experimental description. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this confusion or what steps they should take to clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the varianceregularized problem. This feedback is 3 as it points out a potential issue that the authors might need to address. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might clarify or address this confusion. To be more helpful, the comment could include specific suggestions or examples to help the authors better understand and resolve the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper does not provide insight into this aspect and assumes morphological segmentation to be invariant. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to conduct a thorough analysis. The action is implicit and somewhat vague, as the authors can infer that they need to explore the differences in morphological segmentation across domains, but the comment lacks concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper does not provide insight into this aspect and assumes morphological segmentation to be invariant. However, the comment does not specify which part of the paper discusses morphological segmentation or where these questions should be addressed. The authors can infer that it relates to the domain adaptation section, but this inference is not explicit. The comment is specific in detailing the issues with the assumption of invariant morphological segmentation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It suggests that the paper assumes morphological segmentation to be invariant, which is a claim that requires justification. The comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the use of morphological segmentation across domains and whether it should be conducted differently for different domains. It highlights a potential gap in the paper\"s analysis, suggesting that the authors did not provide insight into this aspect and assumed morphological segmentation to be invariant. This feedback is valuable as it prompts the authors to consider the implications of domainspecific segmentation and encourages them to explore this area further. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue, such as recommending additional experiments or analyses. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the object detection or attention mechanisms discussed in the paper. The authors can infer that it relates to sections where these concepts are introduced or discussed, but the comment does not provide explicit references. The specificity is clear as it specifies the need for clarification on the attention process and rescaling. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the object detectionbased attention process and the rescaling based on the receptive field. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area for clarification, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their work, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this omission. The comment suggests that the authors should include a discussion of these related works, but it does not specify which aspects of the discussion should be included or how to integrate this information into the paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for a discussion on related works, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide specific examples or references to these works, nor does it explain why this omission is problematic or how it affects the paper\"s contribution. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the absence of a discussion about the Set Transformer and other related works that use summary tokens. This is a valuable observation as it highlights a potential gap in the paper\"s analysis and context. However, the comment does not provide specific suggestions or guidance on how the authors might address this omission, such as which related works to discuss or how to integrate this discussion into the paper. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the closeness of the numbers when comparing the proposed method with baselines and suggests that the authors might have performed a statistical significance test. However, the comment does not explicitly instruct the authors to conduct a statistical significance test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform a statistical significance test but are not given specific instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, it does not specify which part of the paper this comparison is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to perform a statistical significance test, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that a statistical significance test is necessary. Without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. This feedback is 3 as it points out a potential issue that could affect the interpretation of the results. However, the comment lacks specificity and does not provide guidance on how the authors might conduct a statistical significance test or what specific results might be affected. To be more helpful, the comment could include suggestions on how to perform the test or what specific results might be affected by the closeness of the numbers. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, to compare samples generated from the same input. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to make this change. The action is somewhat implicit, as the authors can infer that they should explore the use of a paired test setting, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the testing is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a change in the testing approach, but without grounding, it is difficult for the authors to know where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, the comment does not provide specific reasoning or evidence to support why the current choice of testing is incorrect or why the proposed test setting is more appropriate. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. This feedback is 3 as it points out a specific area for improvement in the methodology section of the paper. However, the comment lacks depth and does not provide detailed guidance on why the current choice of testing might be incorrect or how the proposed test setting would address this issue. To be more helpful, the comment could include a rationale for why the current choice is problematic and how the proposed test setting would enhance the analysis. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their demonstration. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific claim made by the authors, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the strength of the demonstration of capability, particularly regarding the claim that replacing procedure steps with a random mechanism led to a performance drop. However, it does not provide detailed guidance on how to strengthen the demonstration or what specific aspects need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks specific details or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or evidence for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. While it identifies a potential issue with the demonstration, it does not provide any specific suggestions or guidance on how the authors might strengthen their argument or address the concern. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While the comment implies that these actions should be taken, it does not specify which sections or parts of the paper need particular attention or how the authors should structure this information. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it difficult for the authors to identify the exact areas that require attention. The lack of specific guidance on where to make these changes makes the comment weakly grounded. Additionally, the comment lacks specificity in terms of what exactly needs to be addressed in terms of background knowledge or related literature. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes are necessary or how they would enhance the paper. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While this feedback acknowledges a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve these improvements. The authors are left with a general idea of what needs to be addressed but without actionable steps or examples. Therefore, the comment is 3, as it identifies a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the related work section. Without explicit references to specific sections or elements, the authors may find it challenging to pinpoint where the comparison is lacking. Additionally, the comment lacks specificity regarding what aspects of these models should be compared or how they should be integrated into the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included or why their exclusion is problematic. Without additional context or explanation, the authors may find it difficult to understand the significance of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s comparison by pointing out that certain panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is valuable as it highlights an area where the authors can enhance the comprehensiveness and relevance of their work. However, the comment lacks specific guidance on how to incorporate these models or what aspects of their performance should be compared. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their model to enforce diversity. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the paper\"s focus on diversity, as indicated by the title, but it does not specify which part of the paper this concern relates to. The authors can infer that it pertains to the introduction or the methodology section, but this inference is not explicit. The comment is specific in detailing the issue of diversity not being enforced explicitly, which is a clear and actionable point for the authors to address. However, the lack of explicit grounding makes it weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, as indicated by the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the model does not enforce diversity. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s focus on diversity, as indicated by the title, but the lack of explicit enforcement of diversity in the model. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s methodology that the authors need to address. By pointing out this inconsistency, the reviewer provides a clear direction for the authors to improve their draft, specifically by suggesting that they should explicitly enforce diversity in their model. This constructive feedback is valuable as it guides the authors in enhancing the rigor and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are supposed to be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence impacts the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the absence of experiments involving contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments to enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these experiments effectively. Overall, the comment is 4 as it highlights a critical gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that introducing inverse triples could be used in other embedding models besides CP, but the authors did not test such cases in their experiments. While the comment identifies a potential area for further exploration, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should conduct additional experiments to test the use of inverse triples in other embedding models. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests that introducing inverse triples might be applicable to other embedding models besides CP, but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or experiment this comment refers to, making the comment weakly grounded. However, it is specific in pointing out a potential area for further exploration that the authors did not test in their experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples could be used in other embedding models besides CP, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific references or detailed explanations, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or guidance for the authors to improve their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential area for further exploration by suggesting that introducing inverse triples might be applicable to other embedding models besides CP. However, it does not provide specific guidance or suggestions on how the authors could test this idea or what other embedding models might be relevant. While it identifies a potential avenue for expansion, the comment lacks actionable advice or detailed feedback, making it 3. The authors are given a direction for future work but without concrete steps on how to implement it, which limits the comment\"s usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. It suggests that the kernel height/width remaining the same would result in more parameters. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length, but they also emphasize the need for more details regarding parameters. While the comment identifies a potential issue and suggests an area for improvement, it does not provide explicit guidance on how to address this concern or what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that more details are needed but are not given a clear path to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters not changing despite the increase in depth, and it suggests that the kernel height/width remaining the same would result in more parameters. The comment also points out the need for more details regarding parameters and acknowledges the potential for efficiency improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. The reviewer agrees that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length. However, the comment lacks specific evidence, examples, or references to support the claim that the number of parameters should change or to explain why it remains constant. Without detailed reasoning or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a specific question about the S2D structure, questioning why the number of parameters does not change despite the increase in depth. It points out that if the kernel height/width remains the same, the depth would increase, leading to more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic relationship between FLOPs and activation side length but emphasizes the need for more details regarding parameters. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how to address this issue or what additional details should be included. The feedback is 3 as it highlights a potential weakness but could be more actionable with more detailed advice or examples."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. It suggests that this makes it difficult to interpret the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, analyze them differently, or provide additional context. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game results are limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. This observation is relevant as it suggests that the results may not be generalizable or comprehensive. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the interpretation of the results. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is explicit and provides a clear action for the authors to take, which is to quantify and clarify the claim. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying a claim about the effectiveness of ReLUs in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides full grounding as it explicitly mentions the AlexNet paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, quantifying and clarifying the claim about ReLUs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides a logical basis for the claim, as it references a wellknown paper and its practices. However, the comment could be strengthened by including specific references or data to support the claim further. Therefore, the comment is 4, as it offers a reasonable basis for the claim but lacks full detail.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to support their claim. By doing so, the authors can strengthen their argument and improve the clarity of their draft. Therefore, the comment is 5, as it offers a specific and actionable suggestion for enhancing the paper\"s quality and comprehensiveness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue with the hyperparameters, it does not provide explicit guidance on how to address this problem or suggest specific actions to take. The authors are left to infer that they need to consider the availability of the environment or a good OPE method for finetuning, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance.", "grounding_specificity_rationale": "The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks explicit grounding. It is specific in identifying the need for finetuning and the potential dependencies, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method for this finetuning. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out a potential weakness, it does not provide actionable steps or detailed feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue or what specific changes need to be made. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the reviewer does not understand the figure or if the labels are incorrect. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not contain any claims, opinions, or suggestions that require verification. Instead, it presents a factual observation about the figure, which is descriptive and does not require evidence or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, either stating that the reviewer does not understand it or that the labels are incorrect. This feedback is clear and actionable, as it highlights a potential area of confusion or error that the authors need to address. By pointing out this issue, the reviewer provides the authors with a clear direction for improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to clarify the figure or correct the labels. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the minimal performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It also references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly instruct the authors to address these issues or suggest specific actions to improve their work. The feedback is somewhat vague, as it does not provide detailed guidance on how to resolve the identified problems or enhance the paper\"s performance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or discussion, but this inference is not precise. The comment is specific in detailing the issue with the performance differences and suggesting a potential solution, making it specific. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal and suggests that the benchmarks are outdated and likely saturated. The comment provides a logical reasoning by noting that the performance differences are less than 1 percentage point, which could be attributed to random variation. Additionally, it references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. This level of detail and reference to external work supports the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed reasoning about the saturation of the benchmarks, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the performance differences between methods, noting that they are minimal across evaluations, typically less than 1 percentage point. It suggests that this could be due to random variation and highlights the need for more robust benchmarks. The comment also references a specific paper, LoRA Learns Less and Forgets Less(https://arxiv.org/abs/2405.09673), which provides a potential solution. This feedback is valuable as it points out a critical area for improvement and offers a relevant reference for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested additional steps to enhance the paper\"s performance. Overall, the comment is 4, as it directs the authors\" attention to a significant weakness and offers a potential solution, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, and the absence of comparison with other stateoftheart methods that might not rely on gyrostructures. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and comparisons, but the comment lacks concrete suggestions on what specific aspects to focus on or how to structure these additions. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issues with the related discussion, such as the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights into why the proposed gyrostructures outperform existing methods and that the paper lacks comparison with other stateoftheart methods. The comment provides a logical reasoning by suggesting that the absence of such comparisons makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the comparison that should be made, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the experimental section of the paper. It points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, suggesting that more detailed explanations are needed. Additionally, the comment highlights the absence of comparison with other stateoftheart methods that might not rely on gyrostructures, questioning the paper\"s claim of outperforming simpler or commonly used techniques in manifoldbased learning. By addressing these points, the authors can enhance the clarity and robustness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to improve the interpretive insights or which stateoftheart methods should be included in the comparison. Overall, the comment is 4 as it directs the authors to areas that need further development but lacks detailed guidance on execution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\"s performance, suggesting that the finetuning without earlystopping may lead to high variances. It implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a potential issue, it does not explicitly instruct the authors to conduct ablation studies or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the potential regularization effects influencing the improvements observed in the teacher\"s performance. It explicitly mentions the case where the student distills knowledge to the teacher, which is a clear reference to a specific part of the paper. The comment also specifies the issue with the finetuning process, noting that it is performed for 10 epochs without earlystopping, which could lead to high variances. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\"s performance, suggesting that the finetuning without earlystopping may lead to high variances. The reviewer provides a logical reasoning by pointing out that the finetuning process is performed for 10 epochs without earlystopping, which could result in high variances. However, the comment lacks specific examples or references to support the claim that the improvements are solely due to regularization effects rather than distillation. This makes the claim 3, as it provides a logical basis but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the interpretation of the results, suggesting that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation. It points out that the finetuning process is performed for 10 epochs without earlystopping, which could lead to high variances. The comment implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a critical area for further investigation, it does not provide specific guidance or suggestions on how to conduct these studies or what aspects to focus on. This limits its helpfulness, as it offers a direction for improvement but lacks detailed actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more insights into why this approach is valuable. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that more explanation is required but are not given concrete steps on how to address this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and questions the necessity of selfsupervised learning on 360 video data with spatial audio. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in questioning the need for selfsupervised learning, it lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of selfsupervised learning on 360 video data with spatial audio, suggesting that more insights are needed. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is valuable or why more insights are required. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of explanation regarding the necessity of selfsupervised learning on 360 video data with spatial audio. It questions why this approach is valuable and suggests that more insights are needed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of insights are required. While it identifies a gap in the paper, it lacks actionable feedback, making it 3. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that while the paper covers the SimCLR case, it lacks an analysis of the projection head, which is considered an important aspect of the approach (as evidenced by SimCLRv2 and other recent papers). However, the comment does not provide explicit guidance on how the authors should address this omission. It suggests that the authors should include an analysis of the projection head, but it does not specify how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of analysis on the projection head, a component that is considered important based on recent papers like SimCLRv2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the projection head, which is considered an important aspect of the SimCLR approach. However, the comment does not provide specific references or examples of recent papers that emphasize the importance of the projection head, nor does it explain why this omission is significant. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by pointing out that while the SimCLR case is covered, there is no analysis of the projection head, which is considered an important aspect of the approach. This feedback is clear and actionable, as it directs the authors to include an analysis of the projection head, which could enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct this analysis. Overall, the comment is 4 as it highlights a significant gap in the paper and offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, as they are explicitly told what types of experiments are needed to improve the draft. The comment is specific in identifying the types of experiments that should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the types of experiments that are missing, but without grounding, the authors may struggle to pinpoint where these experiments should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples or references to support why these experiments are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly informs the authors of specific areas where their work could be strengthened. By addressing these gaps, the authors can enhance the robustness and comprehensiveness of their study. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific comparisons or analyses would be beneficial. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It suggests that the comparison is unfair because it requires two representation models learned for each dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the extra complexity and cost of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the extra complexity and cost involved. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison of the proposed method is unfair because it requires two representation models learned for each dataset, which is not the case for the SOTA. The reviewer provides a logical explanation for why the comparison is unfair, stating that the proposed method\"s advantage is only realized when using prior knowledge. This reasoning is clear and supports the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a strong basis for the claim but lacks some detailed evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It highlights that the comparison is unfair because it requires two representation models learned for each dataset, which is not the case for the SOTA. The comment provides a clear and actionable suggestion for the authors to consider the extra complexity and cost involved in their method. However, it could be more helpful if it offered specific recommendations on how to address this issue or suggested alternative approaches to ensure a fair comparison. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics and justify their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, specifically mentioning that it seems adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explore alternative statistics is specific, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term appears adhoc and lacks theoretical support, suggesting that other statistics could be used to replace the mean and standard deviation. The reviewer provides a specific suggestion, such as using the median, which is not sensitive to outlier values. However, the comment lacks detailed reasoning or references to support why these statistics are more appropriate or why the current approach is insufficient. The suggestion is 3 as it offers a specific alternative, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, noting that it lacks theoretical support and suggesting that other statistics, such as the median, could be used to replace the mean and standard deviation. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for alternative approaches. However, the comment could be more helpful if it included specific references or examples of how these statistics are used in similar contexts, or if it offered guidance on how to implement the suggested changes. Overall, the comment provides a direction for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method. It also suggests that the authors should discuss the iteration cost of all related methods, including baseline methods. This provides a clear and direct action for the authors to take, specifying what needs to be included in their discussion. The feedback is explicit and concrete, allowing the authors to understand exactly what is expected of them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compares this with related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the iteration cost of all related methods, providing a clear direction for the authors to improve their draft. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compares this with related methods, including baseline methods. However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would benefit the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compares this with related methods, including baseline methods. This feedback is 3 as it identifies a specific area for improvement in terms of computational efficiency and provides a clear direction for the authors to enhance their discussion. However, the comment could be more helpful if it offered specific suggestions or examples of how to discuss the iteration cost or what aspects of computational efficiency are particularly relevant. Overall, the comment provides a good starting point for the authors to consider, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the description of the VAD (Voice Activity Detection) in the paper. It points out that the current approach, which discards TF bins with a magnitude less than epsilon, is not a typical VAD definition. The reviewer suggests that this approach is more akin to discarding TF bins with zero magnitude, which could lead to division by zero. The comment implies that the authors should reconsider their definition of VAD and provide a more accurate description. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise their VAD description. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which discards TF bins with a magnitude less than epsilon, questioning whether this is a typical VAD definition. The comment further explains that a VAD is supposed to look for the presence of speech and is usually defined over time, not frequency. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the VAD (Voice Activity Detection) description in the paper. It questions the approach of discarding TF bins with a magnitude less than epsilon, suggesting that this is not a typical VAD definition. The reviewer points out that a VAD is supposed to look for the presence of speech and is usually defined over time, not frequency. While the comment provides a logical argument and references common knowledge about VAD, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a basis for the critique but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a critical concern about the description of the VAD (Voice Activity Detection) in the paper. It points out that the current approach, which discards TF bins with a magnitude less than epsilon, is not a typical VAD definition. The reviewer suggests that this approach is more akin to discarding TF bins with zero magnitude, which could lead to division by zero. The comment provides a clear and actionable suggestion for the authors to reconsider their definition of VAD and provide a more accurate description. This feedback is valuable as it helps the authors identify a significant oversight in their paper and offers a clear path for improvement. However, the comment could be more helpful if it provided specific guidance on how to redefine the VAD or suggested alternative approaches. Overall, the comment is 4, as it effectively directs the authors to address a critical issue in their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit guidance on how to achieve this, such as which specific aspects of the method should be tested on ImageNet or how to present the results. The action is implicit and somewhat vague, as the authors need to infer that they should include ImageNet results but are not given clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion of the method. Without explicit references to specific sections or elements, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding what aspects of the method should be tested on ImageNet or how the results should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific reasoning, examples, or references to support why ImageNet results would be particularly relevant or how they would enhance the method\"s credibility. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide specific guidance on how to incorporate these results or what aspects of the method should be tested on ImageNet. The feedback is vague and lacks actionable advice, leaving the authors with a general idea of what could be improved but without clear steps to take. Therefore, the comment is 2, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. It suggests that the paper could be more insightful or provide possible solutions. While the comment identifies a gap in the study, it does not explicitly instruct the authors on how to address this issue or what specific aspects to focus on. The feedback is somewhat vague, as it provides a general direction but lacks concrete guidance on how to improve the contribution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the insufficiency of the contribution, particularly regarding the lack of exploration into leveraging the connection between complementary and model robustness to improve model robustness. It highlights that while the paper could be the first to study this connection, the conclusion is easily and intuitively obtained. The comment is fully grounded as it explicitly mentions the \"complementary and robustness\" connection and the need for more insightful findings or solutions. However, it lacks specificity in terms of suggesting how the authors might address this issue or what specific areas to explore. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, implying that the paper lacks depth or originality. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution is insufficient. It also does not provide references or detailed explanations to substantiate the assertion that the conclusion is easily obtained. As a result, the claim is 3, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. This feedback is clear and actionable, as it directs the authors to consider additional studies or insights that could enhance the contribution. The comment also points out that the conclusion is easily and intuitively obtained, suggesting that the authors should provide more indepth analysis or novel findings. While the comment highlights a critical area for improvement, it could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the feedback is 4 as it provides a clear direction for enhancing the contribution, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the authors may not have demonstrated how their method enhances the generalization for distant nodes. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and vague, as the authors are left to infer that they need to strengthen the connection between theory and practice or provide more detailed explanations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the PACBayesian bound for GNNs in the transductive setting. It also questions the connection between the theoretical analysis and the proposed method, suggesting that the method seems to adopt the idea of the selfattention mechanism from the transformer and apply it to the graph. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The authors can infer that it relates to the theoretical analysis section, but this inference is not explicit. The comment is specific in detailing the issue with the connection between theory and practice, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the authors may not have demonstrated how their method enhances the generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The authors are left to infer that the connection is weak, but without explicit evidence or examples, it is difficult for the authors to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances the generalization for distant nodes. This feedback is 3 as it points out a gap in the paper\"s argumentation, prompting the authors to clarify or strengthen their theoretical framework. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing additional examples or references to support the connection. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific error in the authors\" claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It references a specific section of a previous work, Wang et al., 2023, to provide evidence of the correct attention patterns. This feedback is explicit, as it directly points out the incorrect claim and provides a reference for the authors to correct it. The action is concrete, as it instructs the authors to revise their claim based on the information provided. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of their paper being addressed. It is also specific because it clearly specifies the error in the authors\" claim about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. The comment provides a clear reference to a previous work and details the specific issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the attention patterns of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit is incorrect, referencing a specific section of a previous work, Wang et al., 2023. This provides a clear and specific reference to support the claim, making it 5. The authors can easily verify the claim by reviewing the referenced section of Wang et al., 2023. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" claim about the attention patterns of certain heads in the base IOI circuit. It references a previous work, Wang et al., 2023, to provide evidence of the correct attention patterns. This feedback is 5 as it not only points out a factual error but also provides a clear and actionable correction. By referencing a specific source, the authors are given a direct path to correct their claim and improve the accuracy of their paper. This level of detail and specificity makes the comment highly valuable for enhancing the draft, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the reason why the eta_ri term is noncentral chisquared distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify this point. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distribution of the eta_ri term, specifically why it is noncentral chisquared. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact area needing clarification. While the comment is specific in questioning the distribution, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the distribution of the eta_ri term, specifically why it is noncentral chisquared. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the distribution of the eta_ri term, specifically why it is noncentral chisquared. While it identifies a potential area of confusion or lack of explanation, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to include this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a speed analysis and compare it with prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that comparing the inference speed between the proposed network and prior work would be more interesting, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments lack a speed analysis, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper\"s conclusions. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the analysis by pointing out the lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting than reducing FLOPs alone. This feedback is clear and actionable, as it provides a specific direction for improvement by emphasizing the importance of speed analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects of speed analysis would be most beneficial. Overall, the comment is 4 as it directs the authors to a significant area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and highlights the wellknown nature of representing the marginal score as the expectation of scores of distributions conditioned on inputs. It provides examples of previous works, such as the original denoising score matching objective and \"scoreinterpolation,\" which use this property. The reviewer suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not explicitly instruct them to do so or provide specific guidance on how to conduct the review. The action is implicit and somewhat vague, as the authors need to infer the need for a literature review and how to carry it out. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s positioning in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in previous works. It provides examples of these works, such as the original denoising score matching objective and \"scoreinterpolation.\" However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the wellknown nature of the idea and providing examples of its use in the literature. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and highlights the wellknown nature of representing the marginal score as the expectation of scores of distributions conditioned on inputs. It provides examples of previous works, such as the original denoising score matching objective and \"scoreinterpolation,\" which use this property. This provides a clear and specific justification for the claim, making it 5. The reviewer supports the claim with references to existing literature, which gives the authors a clear understanding of the context and allows them to address the critique effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s positioning in the literature, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in previous works, such as the original denoising score matching objective and \"scoreinterpolation.\" The reviewer suggests that the authors conduct a thorough literature review to identify additional works that utilize this property. This feedback is valuable as it points out a potential lack of novelty in the proposed method and encourages the authors to explore the broader context of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct the literature review or suggested additional works to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear direction for further exploration."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate or address this curiosity, nor is there any suggestion for how to incorporate this information into their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in its curiosity about the performance of a particular method, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric, but it does not contain any claims, opinions, or suggestions that require verification. It is a purely factual statement of interest, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric. While it identifies an area of interest, it does not provide any actionable feedback or suggestions for the authors to improve their draft. The comment lacks depth and does not offer any guidance on how the authors might explore or address this curiosity. As a result, it is not helpful to the authors in terms of improving their work. Therefore, the comment aligns with a score of 1, indicating that it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. While the comment implies that the authors should expand their discussion to include comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This provides clear guidance on what the authors need to address in their discussion of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. However, the comment does not provide specific examples or references to support the claim that a more detailed discussion is necessary. Without additional context or evidence, the authors may find it challenging to understand the extent of the improvement needed. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This feedback is 3 as it identifies a specific area for improvement in the paper, namely the need for a more nuanced and detailed discussion of related work. However, the comment lacks specificity in terms of what aspects of the related work should be discussed or how the differences should be highlighted. To be more helpful, the comment could provide examples or specific suggestions on how to enhance the discussion of related work. Therefore, the comment is rated as 3, as it points out a potential area for improvement but does not fully guide the authors in making the necessary changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that this would be an interesting addition, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the introduction. The authors might infer that it relates to the experimental setup, but this inference is not explicit. The comment is specific in its suggestion to explore other architectures and tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, the comment does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it could enhance the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it provides a direction for potential future work that could enhance the scope and applicability of the study. However, the comment lacks specificity and does not offer guidance on how to conduct these additional experiments or what specific tasks or architectures should be explored. To be more helpful, the comment could include suggestions on which tasks or architectures might be particularly relevant or how to structure the additional experiments. Therefore, the comment is 3, as it points out an area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data are processed. It explicitly suggests that this aspect should be clarified. However, the comment does not provide specific guidance on how to clarify this point or what aspects of the clarification are necessary. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the output of the algorithm depending on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, specifically noting that it depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how to address this issue or clarify the output\"s dependence on data order. Without actionable suggestions or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it highlights an important area for clarification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to clarify the impact of the mitigation strategies on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and questions whether these strategies significantly impair the model\"s utility. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of the mitigation strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these strategies or how they are implemented, making it weakly grounded. The comment is specific in its concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The suggestion that these strategies might impair the model\"s utility is not substantiated with evidence or references, leaving the authors without a clear path to improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies discussed in the paper, specifically questioning their impact on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is a critical consideration for the authors to address. The comment suggests that these strategies might significantly impair the model\"s utility, which could deter their adoption. While the comment points out an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the implications of their mitigation strategies, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of understanding regarding the reason for using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is necessary for their problem. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the crossvalidation method should be explained. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the use of 6fold crossvalidation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper and questions the necessity of this method, given that other papers in the comparison did not use it. However, it does not specify which part of the paper discusses the crossvalidation or where the comparison to other papers is made. This lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in questioning the reason for using 6fold crossvalidation, but it is 1 because it does not provide a clear reference to the relevant sections. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. The reviewer provides a logical reasoning by pointing out the absence of crossvalidation in other papers, which raises a question about the justification for its use in the current study. However, the comment lacks specific references or examples to support the claim that other papers did not use crossvalidation, making it 3. The authors would need to provide additional context or references to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the necessity of using 6fold crossvalidation, given that other papers in the comparison did not use it. It suggests that the authors should clarify why this method is required for their problem. This feedback is 3 as it points out a gap in the paper\"s justification and encourages the authors to provide a rationale for their choice of crossvalidation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other papers justify their use of crossvalidation. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the improvement in performance and computation speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific method, ODA, and its application in solving the MOIP problem. It highlights a gap in the explanation regarding how the presented method improves performance and computation speed compared to using ODA alone. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the lack of clarity on the improvement over ODA. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method ODA, used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA alone. The comment provides a logical reasoning by pointing out the lack of clarity in the explanation, which is a valid observation. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact areas where clarification is needed, which limits the comment\"s usefulness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. This feedback is clear and actionable, as it directs the authors to clarify the improvement in performance and computation speed. However, the comment could be more helpful if it provided suggestions on how to achieve this clarification or examples of how other methods have improved performance. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not thoroughly evaluated experimentally on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct additional experiments or provide specific guidance on how to evaluate sampling more thoroughly. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section or supplementary material, but the lack of explicit mention of specific sections or figures makes it difficult to pinpoint. The comment is specific in detailing what is missing in the evaluation of sampling, but the lack of grounding makes it challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling process used to obtain different initializations x_0 is important for convergence to the optimum, but it is not evaluated carefully on the proposed benchmarks. The comment provides a specific example by mentioning that this aspect is only compared to sampling from a uniform distribution in Table 1 of the supplementary material. While the comment highlights a potential area for improvement, it lacks detailed reasoning or evidence to fully substantiate the claim. The authors are left to infer that more comprehensive evaluation is needed, but the lack of specific guidance or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by pointing out that the sampling process used to obtain different initializations x_0 is important for convergence to the optimum. It notes that this aspect is not evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is 3 as it highlights a specific area where the authors could enhance their experimental evaluation. However, the comment could be more helpful if it provided suggestions on how to conduct a more thorough evaluation or additional experiments to support the claim. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multimodal data. While the comment implies that this could be an interesting direction, it does not explicitly instruct the authors to include this aspect in their work. The suggestion is vague and lacks concrete guidance on how to implement this idea, making it 3. The authors can infer that they might want to explore this direction, but the comment does not provide specific steps or examples on how to do so. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests exploring the use of tabular data as a modality, which is another popular form of multimodal data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors might infer that it relates to the discussion of multimodal data, but this inference is not explicit. The comment is specific in suggesting an interesting direction for the model, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that tabular data is another popular form of multimodal data and proposes exploring how the model works for tabular data. However, it does not provide any specific reasoning, examples, or references to support why this is an interesting direction or how it could be relevant to the paper. The claim lacks depth and context, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for the authors to explore, which is the use of tabular data as a modality in their multimodal model. This suggestion could potentially expand the scope of the paper and provide additional insights into the model\"s capabilities. However, the comment does not provide specific guidance or examples on how to incorporate this idea into the draft, nor does it offer detailed feedback on how this could enhance the paper. While it identifies a potential area of interest, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While the action is explicit, it lacks concrete guidance on what specific details should be included or how they should be presented. The authors are aware of the need for more information on attention, but the comment does not provide detailed instructions on how to implement this suggestion. Therefore, the comment is 3, as it identifies a need for additional information but does not specify how to address it.", "grounding_specificity_rationale": "The comment suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in its suggestion to include more details on attention, but without grounding, the authors may struggle to identify the exact sections where this information should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While this feedback acknowledges the need for additional information, it lacks specificity and does not provide guidance on what specific details should be included or how they might enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance or actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudocode of the proposed method is missing. The first part of the comment suggests that the authors should provide an explanation for the observed performance difference, but it does not offer specific guidance on how to address this issue. The second part of the comment is explicit in stating that the pseudocode is missing, but it does not provide any suggestions on how to include it or why it is necessary. The authors are left with a clear action to provide an explanation for the performance difference and a vague action to include the missing pseudocode. Therefore, the comment is 3, as it identifies specific areas for improvement but lacks detailed guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in its questions about the performance difference and the need for pseudocode, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises two issues: the performance of explicit methods compared to implicit methods on locomotion tasks and the absence of pseudocode for the proposed method. The first part of the comment questions the performance difference without providing specific evidence or reasoning, making it difficult for the authors to address the claim. The second part of the comment references external sources, which could provide some context or justification for the claim, but the lack of specific examples or detailed reasoning makes the claim 3. Therefore, the comment is rated as 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises two important issues. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a critical aspect of the paper\"s methodology and results. This question prompts the authors to provide a detailed explanation or analysis of this observation, which could enhance the paper\"s understanding and contribution. Second, the comment points out the absence of pseudocode for the proposed method, which is crucial for reproducibility and clarity. This feedback is actionable and provides clear guidance for the authors to include the missing pseudocode, ensuring that their work is more accessible and verifiable. Overall, the comment is 4 as it identifies specific areas for improvement and offers clear suggestions for enhancing the paper\"s clarity and reproducibility. However, it could be more helpful if it provided additional context or examples to support the claim about the performance difference between explicit and implicit methods."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a convoluted description of results and suggests that the authors need to simplify their language. It also provides specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication. The comment includes explicit references to external works, which provides concrete guidance on how to address the issue. This level of detail and specificity makes the feedback 5, as the authors know exactly what changes to make and where to find additional information. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the convoluted description of results, specifically mentioning the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This provides some grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or figure this description is found in. The comment is specific in suggesting that the authors simplify their language and provides references to related work, which helps the authors understand the context and potential improvements. However, the lack of explicit section or figure reference makes the comment weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the convoluted description of results, suggesting that it could be simplified. It provides references to related work, such as 1 and 2, which could be used to improve the clarity of the results. However, the comment lacks specific examples or detailed reasoning to explain why the description is convoluted or how the references relate to the issue. While the references provide some context, the lack of detailed justification or examples makes the claim 3, as the authors would need to infer the exact nature of the convoluted description and how the references might help clarify it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted description of results, providing a clear example of where the language could be simplified. It suggests referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication, which is a constructive suggestion for improving the clarity and coherence of the results section. The comment also provides specific references to external works, which can guide the authors in further exploring and refining their approach. However, the comment could be more helpful if it offered more detailed guidance on how to simplify the language or if it included additional suggestions for improving the clarity of the results. Overall, the feedback is 4 as it provides actionable advice and references to support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the paper\"s positioning with respect to related works. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental setup to include deeper networks and provide more details about the optimization strategy. The suggestion about layer redundancy is specific but does not offer detailed guidance on how to incorporate this into the paper. Therefore, the comment is 3, as it provides some direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation, including the consideration of only shallow networks and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the paper\"s positioning with respect to related works, specifically pointing out the consideration of layer redundancy in the context of network pruning. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experimental validation and the related work, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises several concerns about the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. The comment also points out a minor issue regarding the paper\"s positioning with respect to related works, mentioning layer redundancy as a relevant aspect. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claims. The references to related works are helpful but do not fully address the concerns about the experimental validation. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the experimental validation. It points out that only shallow networks (2 or 3 layers) are considered, which may limit the scope of the study. Additionally, the comment notes that the optimization strategy, including the grid search strategy for hyperparameters selection, is not described, which is crucial for replicating the results. The comment also highlights a minor issue with the paper\"s positioning with respect to related works, mentioning layer redundancy as a relevant aspect. While the comment provides specific points for improvement, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to expand the experimental setup or describe the optimization strategy. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, given that it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to other tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1 of bAbI. This provides some grounding as it allows the authors to identify the part of the paper being addressed, which is the testing methodology or results. However, the comment does not specify what needs to be addressed or improved in terms of testing on other tasks. It lacks specificity regarding the details of the testing or the potential issues that might arise from only testing on a single supporting fact dataset. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. However, it does not provide any evidence, reasoning, or references to support the claim that only Task 1 was tested or that testing on other tasks is necessary. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer any insights or recommendations for expanding the testing or exploring other tasks, leaving the authors with a general question that lacks actionable feedback. Therefore, the comment is 2, as it provides a starting point for consideration but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the authors improve it by providing more illustrations and examples. While the action is explicit, the comment does not specify which parts of the section are particularly confusing or how the illustrations and examples should be incorporated. This lack of detail makes the action somewhat vague, as the authors know they need to improve the section but may not know exactly how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the section is difficult to follow and recommending the inclusion of more illustrations and examples. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is difficult to follow and recommends improvements by providing more illustrations and examples. However, the comment does not provide any specific examples or reasoning to support why the section is unclear or how the suggested improvements would enhance understanding. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending the inclusion of more illustrations and examples to enhance understanding. This feedback is actionable and provides a concrete direction for the authors to improve the clarity of their work. However, the comment could be more helpful if it offered specific examples of what types of illustrations or examples would be beneficial. Overall, the comment is 4 as it guides the authors toward a clear area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. Additionally, the comment mentions a minor point about the low jailbreaking percentage for certain LLMs, which is also a specific suggestion for improvement. Therefore, the comment is 5, as it provides both explicit and concrete actions for the authors to take.", "grounding_specificity_rationale": "The comment suggests including a comparison of the authors\" approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. It also mentions a minor point about the low jailbreaking percentage for certain LLMs. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or results section where the authors present their approach and its transferability. The authors can infer that it relates to the sections where the results are discussed, but the comment lacks explicit grounding. The suggestion to include a comparison is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. It also mentions a minor point about the low jailbreaking percentage for certain LLMs. The claim about the low jailbreaking percentage is 3 as it provides a specific observation, but it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion to include a comparison is logical and reasonable, but it could be strengthened with more detailed examples or references to support the need for such a comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two pieces of feedback. First, it suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is a clear and actionable suggestion that could enhance the paper\"s comprehensiveness and impact. Second, it mentions a minor point about the low jailbreaking percentage for certain LLMs, which could be relevant for the authors to address if it affects the overall results or conclusions. While the comment identifies specific areas for improvement, it could be more helpful if it provided additional context or suggestions on how to address these issues. Overall, the comment is 4 as it offers clear guidance on how to enhance the paper\"s content and analysis."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or action for the authors to take, such as recommending a specific method or approach to determine the parameter S. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about setting the parameter S, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper this comment pertains to, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of setting the parameter S, leaving the authors without clear direction. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any specific reasoning, examples, or references to support why this is a problem or how it affects the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The comment raises a concern about setting the parameter S, which is a critical aspect of the paper. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their approach. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is not helpful, as it lacks the depth and specificity needed to guide the authors in improving their work. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or rephrase the claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" noting that the choice of employing specific constraints can be considered a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction\"s statement about shape constraints not requiring tuning a free parameter is technically true but suggests that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. This claim is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these constraints are indeed hyperparameters. The comment could be strengthened by providing more detailed examples or references to substantiate the claim, making it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and potentially revise it to accurately reflect the nature of the constraints. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to rephrase the claim. Overall, the comment is 4 as it guides the authors towards a more accurate representation of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and model coverage to include other biases and stateoftheart generative models. However, the comment lacks concrete details on how to implement these changes, such as suggesting specific datasets or models to include. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on other important biases and stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as other biases and stateoftheart models, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these omissions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to expand the dataset or model coverage or provided examples of other biases and datasets that could be included. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. However, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the figure more understandable. The authors are left to infer that they need to clarify the workflow, improve the captions, and possibly rework the representation of communication modes, but the comment lacks concrete steps or examples. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issues with the figure, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and the representation of communication modes. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the workflow, captions, and representation of communication modes are unclear. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity of their figure, which is crucial for effectively communicating their workflow and findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending specific changes to the layout or labeling. Overall, the comment is 4 as it highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify or address this issue, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in questioning the meaning of a term, it lacks grounding, as the authors cannot confidently determine where to address this issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to clarify the issue or suggest why this term is unclear. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a potential area of confusion, it does not provide any further context or suggestions for clarification. The comment lacks depth and actionable guidance, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a gap in understanding but does not offer constructive feedback or suggestions for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. It also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. This feedback is explicit and concrete, giving the authors a clear direction on what to include in their paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this is not explicitly mentioned. The comment is specific in its suggestion to conduct error analysis and provide detailed explanations, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. This feedback is logical and provides a clear rationale for why error analysis is important, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim that error analysis is essential for guiding improvements in the field of ERC research. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues in the paper. It provides a clear and actionable suggestion for the authors to conduct error analysis and offers guidance on how to provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it directs the authors to a critical area for improvement and offers a concrete way to enhance the paper. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" claim that their work is NLPspecific, suggesting that it lacks specificity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be clarified. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim that their work is NLPspecific, suggesting that it lacks specificity. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the claim but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges the authors\" claim that their work is NLPspecific by questioning the lack of NLPspecificity in their approach. However, the comment does not provide specific examples or evidence to support this claim, making it difficult for the authors to understand or address the critique. The lack of detailed reasoning or references leaves the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It questions the lack of NLPspecificity in the approach, suggesting that the authors should clarify this point. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of their approach should be clarified to better align with NLPspecific applications. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a new, largescale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of dataset size on their results and potentially adjust their comparison accordingly. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a new, largescale dataset (209M) compared to existing methods that use smaller datasets. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison and suggesting that the superior performance may be due to the dataset size, rather than the method itself. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods is unfair due to the use of a new, largescale dataset (209M) compared to existing methods that use smaller datasets. The reviewer provides a specific example, mentioning GEM, which uses only 20M unlabeled data. This provides some logical reasoning and a specific example to support the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or references to further substantiate the claim about the impact of dataset size on accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a new, largescale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. This feedback is 3 as it identifies a potential issue with the comparison and provides a rationale for why the results might be biased. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparison. To be more helpful, the comment could include recommendations for alternative methods or datasets to ensure a fair comparison. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment implies that the authors should include references to existing studies that discuss these factors. While the action is explicit, it lacks concrete details on which specific references to include or how to integrate them into the paper. The authors know they need to add references but may not have a clear idea of which ones to use, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to add supportive references for claims that may be inspired from existing studies. The comment provides a clear example of the lines in question, making it easy for the authors to understand and address the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment implies that the authors should include references to existing studies that discuss these factors. While the suggestion is logical and based on the authors\" discussion, it lacks specific references or detailed reasoning to fully substantiate the claim. This makes the comment 3, as it provides a basis for the claim but requires additional evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims, suggesting that some may be inspired from existing studies. It provides a specific example, mentioning Lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment implies that the authors should include supportive references to substantiate these claims. While the feedback highlights an important area for improvement, it lacks detailed guidance on which specific references to include or how to integrate them into the paper. The comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the first paragraph of the Introduction, stating that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a specific issue with the introduction, it does not provide explicit guidance on how the authors should revise or restructure this paragraph. The action is implicit and somewhat vague, as the authors can infer that they need to reorganize the introduction to better align with the paper\"s focus, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, which is that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a potential issue with the introduction, it lacks specific examples or references to support the claim that the paragraph is not valuable. The reasoning is based on the reviewer\"s perception of the paper\"s focus, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. This feedback is clear and actionable, as it directs the authors to revise their introduction to better align with the paper\"s focus on drift detection. However, the comment could be more helpful if it provided suggestions on how to integrate the DNN introduction with the drift focus or offered alternative ways to present the information. Overall, the comment is 4 as it highlights a significant issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to fully utilize the potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment implies that the authors should consider using more sophisticated prompting techniques, it does not provide specific guidance on how to implement this suggestion or what constitutes a \"carefully curated\" prompt. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their prompting technique. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of a basic prompting technique in the study, suggesting that it fails to leverage the full potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or how it could be improved. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to use carefully curated prompts, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of large language models (LLMs). However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with other studies or detailed explanations of how the current technique limits the potential of LLMs. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, noting that the prompting technique used is basic and fails to fully leverage the potential of large language models (LLMs). It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance or examples on how to implement the suggested changes. The authors are left with a general idea of what could be improved but without detailed steps or examples to follow. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to test the method on larger backbones. The action is implicit and somewhat vague, as the authors need to infer that they should explore the method\"s performance on larger backbones. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not specify which part of the paper discusses the experimental results or the proposed methods, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issue with the relative gains and suggesting a potential area for further exploration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed methods are not very strong, particularly on a small backbone ResNet50, where only a 1% gain is achieved. The reviewer suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to its global pooling structure. However, the comment lacks specific evidence or detailed reasoning to support the claim that the method would perform better on larger backbones. The suggestion is based on a logical assumption about the structure of the proposed method, but without further justification or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL, which could be an area for further exploration. While the comment highlights a concern, it does not provide specific guidance or suggestions on how the authors might address this issue or conduct additional experiments. The feedback is 3 as it points out a potential limitation but lacks detailed actionable advice, leaving the authors with a general direction to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" response, which includes the provision of a repository and clarification on the novelty of the datasets. However, the comment does not explicitly instruct the authors to take any specific action, such as adding more datasets or explaining the rationale behind the dataset selection. While the authors may infer that they need to address the dataset issue, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the adequacy of the datasets used for evaluation, specifically mentioning the number of datasets for each task. It raises a concern about the potential insufficiency of the datasets, particularly if some are too large for certain algorithms. The reviewer acknowledges the authors\" response, which includes the provision of a repository and clarification on the novelty of the datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The feedback is specific in identifying the concern about dataset adequacy and the need for more information, but it lacks explicit references to specific sections of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be enough for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" response, which includes the provision of a repository and clarification on the novelty of the datasets, as well as the motivations for the number and choice of datasets. This feedback is 4 as it provides some justification for the concern and acknowledges the authors\" efforts to address it. However, it could be strengthened by more detailed reasoning or examples of how the dataset size affects evaluation rigor. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" response, which includes the provision of a repository and clarification on the novelty of the datasets, as well as the motivations for the number and choice of datasets. This feedback is 3 as it identifies a potential weakness in the evaluation process and provides some context through the authors\" response. However, it could be more helpful if it offered suggestions on how to address the dataset issue or provided additional context on the evaluation criteria. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific guidance or suggestions on how to address these issues. The authors are left without clear instructions on what changes to make or how to improve their draft. The lack of actionable details makes it difficult for the authors to know how to proceed, leaving the comment 1.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes\" in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding the nature of the confusing mistakes or what aspects of the discussion and comparison are missing. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence or justification renders the claim 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies two main issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific examples or detailed guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights areas for improvement, it lacks depth and specificity, making it 2. The authors are left with a general understanding of what needs to be improved but without clear steps to take, which limits the usefulness of the feedback. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the unclear motivation for using an adversarial network in the model and the unfair comparison of experimental results due to the proposed model\"s larger size. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The lack of actionable suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the motivation for using an adversarial network and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\"s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two concerns: the motivation for using an adversarial network and the fairness of the experimental results comparison. The first claim about the motivation is 3 as it questions the necessity of the adversarial network, but it lacks specific examples or references to support this claim. The second claim about the fairness of the experimental results comparison is 3, as it points out that the proposed model is larger than others, which could affect the comparison. However, the comment does not provide detailed reasoning or evidence to substantiate these claims, making them 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the comparison is biased due to the proposed model\"s larger size, even when using pretrained models. This feedback is clear and actionable, as it provides the authors with specific areas to address to improve the clarity and fairness of their work. However, the comment could be more helpful if it offered suggestions on how to clarify the motivation or how to make the comparison more fair. Overall, the comment is 4 as it directs the authors\" attention to critical areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. While it points out a potential issue, it does not provide explicit guidance on how the authors should address this concern or what steps they should take to improve the reliability of their results. The comment lacks concrete suggestions or actions for the authors to take, making it difficult for them to know how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, particularly the concern about the reliability of the results due to the MSE being significantly smaller than the MAE. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the reliability and validity of the results. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the reliability of their results. While it points out a potential problem, it does not provide the authors with a clear path forward, making it 3. The feedback could be more beneficial with additional details or suggestions on how to investigate and resolve the discrepancy."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what kind of adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a particular section, figure, or table. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what needs to be addressed regarding the adversarial loss or how it should be implemented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is no adversarial loss to guarantee the perturbed data being similar to the authentic data. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. This is a critical point that could significantly impact the effectiveness of the proposed method. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without additional context or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not provide actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters when solving optimization on a samplebysample basis. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to explore the variability in hyperparameters or consider alternative approaches to mitigate this issue. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters when solving optimization on a samplebysample basis. However, it does not specify which part of the paper discusses these hyperparameters or how they are tuned, making it weakly grounded. The comment is specific in identifying the issue of hyperparameter variability, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the need to tune multiple hyperparameters and questions the variability in optimal hyperparameters when solving optimization on a samplebysample basis. However, the comment lacks specific examples or references to support the claim about the variability in optimal hyperparameters. While it highlights a potential issue, the lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies a critical issue related to the tuning of multiple hyperparameters, such as step size, N, and delta t, which are essential for the optimization process. It highlights the potential variability in optimal hyperparameters when solving optimization on a samplebysample basis, which is a valid concern for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might tackle this issue, such as proposing alternative methods or strategies for hyperparameter tuning. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what needs to be improved, but the action is not directly stated, making it 3. The authors know what needs to be done but may need to infer the exact steps to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the practical significance of the verylongterm forecasting task and suggests improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in suggesting improvements to the discussion, such as conducting additional experiments and using the correct forecast horizon. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, the comment does not provide specific examples or references to support the claim about the task\"s practical significance or the need for additional experiments. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim and determine the extent of the suggested improvements. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical significance of the verylongterm forecasting task and suggests that the discussion could be improved by conducting additional experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is 3 as it points out a specific area for improvement in the paper\"s discussion section. However, it could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific datasets and forecast horizons should be considered. Overall, the comment offers a direction for enhancing the paper\"s discussion, but it lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (privacy protection) of the proposed framework. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting specific methods or techniques to analyze security or privacy. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific area that the authors have not addressed, namely the security (privacy protection) of the proposed framework. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing (security analysis), it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (privacy protection) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the authors have not analyzed the security (privacy protection) of the proposed framework. This is a critical aspect that should be addressed, as it could impact the credibility and applicability of the framework. However, the comment lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects of security they should focus on. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This implies that the authors should include a reference to the stateoftheart work, \"Memb,\" to provide context and support for their claim. However, the comment does not explicitly instruct the authors to include a reference or specify which reference to use. The action is implicit and somewhat vague, as the authors need to infer that they should add a reference but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the mention of \"Memb\" as the previous stateoftheart without providing a reference. However, it does not specify which part of the paper this issue pertains to, such as a section, table, or figure. The authors can infer that it relates to the discussion or conclusion section, but this inference is not explicit. The comment is specific in identifying the need for a reference but lacks grounding, as it does not specify the exact part of the paper where this issue is present. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Memb is apparently the previous stateoftheart,\" but it lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"Memb is apparently the previous stateoftheart,\" but there is no mention of any reference. This feedback highlights a gap in the paper\"s literature review or discussion section, as it lacks proper attribution and context for the claim. However, the comment does not provide any guidance on how the authors might address this issue or suggest specific references to include. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a gap but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, as presented in the paper and supplement. It also highlights weaknesses of the proposed FSR metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these weaknesses or improve the clarity of the examples. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, as presented in the paper and supplement. It also highlights weaknesses of the proposed FSR metric. However, it does not specify which part of the paper these examples are discussed in or where the weaknesses of the FSR metric are elaborated. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is weakly grounded because it does not provide specific references or details about the parts of the paper being addressed, and it is not specific in terms of what needs to be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, as presented in the paper and supplement. It also highlights weaknesses of the proposed FSR metric. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim about the difficulty of finding such examples or the weaknesses of the FSR metric. Without specific references, logical reasoning, or detailed examples, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, as presented in the paper and supplement. It also highlights weaknesses of the proposed FSR metric. However, the comment does not provide specific suggestions or guidance on how to address these weaknesses or improve the clarity of the examples. While it identifies an area for improvement, it lacks actionable feedback, making it difficult for the authors to effectively use this comment to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of ensuring that the paraphrases generated for the training data are significantly different from the original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, such as suggesting methods to ensure significant differences or how to measure this difference. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of generating paraphrases for the training data, specifically mentioning the need for these paraphrases to be significantly different from the original sentences. This provides some grounding as it relates to the data generation process, but it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the importance of the paraphrases and their impact on the model\"s reliance on the quality of the data. However, it lacks explicit references to sections or figures, which could help the authors pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases used in the training data, noting that the difference between paraphrases and original sentences is crucial for the model\"s performance. The comment explains that if the difference is not significant, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of paraphrase quality on model performance. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the data generation process, specifically the need for significant differences between paraphrases and original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should consider ensuring significant differences between paraphrases and original sentences to improve the quality of the training data. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this, such as techniques for generating diverse paraphrases. Overall, the comment is 4 as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what changes or clarifications are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the concatenation of text input with four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context where this issue might be relevant. Additionally, the comment lacks specificity as it does not provide any context or details about the four text elements or the concatenation process. Without this information, the authors cannot effectively address the question or understand what needs to be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text input with four text elements of an object. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry that does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the concatenation of text input with four text elements of an object. While it identifies a potential area for clarification, it does not provide any context, explanation, or suggestions on how the authors might address this issue or why it is important. Without additional guidance or context, the authors are left without a clear understanding of what needs to be improved or how to address the question. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, the comment does not specify what aspects of the motivation should be improved or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the importance of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to improve the motivation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should explain why their work is important or relevant. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the motivation. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the domainspecific model is trained and evaluated on the same dataset, Pix3D, which makes the comparisons to zeroshot singleimage 3D reconstruction models unfair. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their comparisons. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the domainspecific model, noting that it is trained and evaluated on the same dataset, Pix3D, which could lead to unfair comparisons with zeroshot singleimage 3D reconstruction models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the unfairness of the comparisons, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair because both are trained and evaluated on the same dataset, Pix3D. This claim is 3 as it provides a logical reasoning for the unfairness of the comparisons. However, the comment lacks specific examples or references to other studies that might support the claim of unfairness, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models, noting that both are trained and evaluated on the same dataset, Pix3D. This observation is relevant and could help the authors understand the limitations of their experimental setup. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the fairness of the comparisons. While it highlights an important consideration, the feedback is 3 as it provides a direction for potential improvement but does not offer detailed actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the action is explicit, it is somewhat vague as it does not specify which aspects of the C2D method should be tested or how the experiments should be designed. The authors are given a clear direction to improve their work, but the comment lacks detailed guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments on a particular dataset to support the method, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is 3 as it identifies a specific area where the authors could enhance the robustness and applicability of their findings. However, the comment lacks detailed guidance on how to design these experiments or what specific results should be expected, which limits its usefulness. The authors are given a direction for improvement but would benefit from more detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the methodology used in the grid search for learning rate, specifically whether it is conducted on the validation set. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the grid search for learning rate is conducted on the validation set. While it identifies a potential issue or area for clarification, it does not provide any further context, suggestions, or guidance on how the authors might address this concern. The comment lacks depth and specificity, leaving the authors without actionable feedback or insights into how to improve their work. Therefore, it is rated as 2, as it provides a starting point for the authors but does not fully support their efforts to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalizability of the results to different groups, specifically marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity, and its implications for generalizability. While the comment does not explicitly instruct the authors to address this issue, it does provide a clear direction for further exploration. The action is implicit but concrete, as the authors can infer that they need to consider the diversity of their sample and its impact on generalizability. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the results to different groups, particularly marginalized groups, and asks about the diversity of the sample, including racial and economic diversity. This provides clear guidance on what aspect of the paper needs further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the results to different groups, specifically marginalized groups, and the diversity of the sample, including racial and economic diversity. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to external studies that might address the issue of generalizability, making it difficult for the authors to understand the basis of the concern. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion.", "helpfulness_rationale": "The review comment raises a critical question about the generalizability of the results, specifically regarding the diversity of the sample, including racial and economic diversity. This is an important consideration for the authors to address, as it impacts the applicability of their findings to broader populations. By prompting the authors to think about the generalizability of their results, the comment provides a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how to assess generalizability. Overall, the comment is 4 as it identifies a significant area for consideration but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific properties of function Z are relevant. The comment lacks actionable details, leaving the authors uncertain about how to incorporate this feedback into their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the potential nonconvexity issue and its relation to the convergence of SGD. The comment specifies that the function Z should have certain good properties to mitigate this issue, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to justify why these properties would make nonconvexity less of an issue. Without additional context or explanation, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the nonconvexity of the function Z, suggesting that it may not be a concern for the SGD to converge. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or what specific properties of function Z are relevant. Without actionable advice or detailed suggestions, the comment does not offer the authors a clear path to improve their draft. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue regarding the experimental settings, specifically noting that the results are not reproducible due to missing code. It explicitly instructs the authors to provide the code, which is a clear and direct action. This feedback is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of experimental settings and result reproducibility, specifically mentioning that the results are not reproducible due to missing code. However, it does not specify which part of the paper discusses the experimental settings or results, making it weakly grounded. The comment is specific in identifying the need for code to ensure reproducibility, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which affects the reproducibility of the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed justification or references to substantiate the assertion that the experimental settings are not mentioned properly. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, specifically noting that the results are not reproducible due to missing code. This feedback is 5, as it directly instructs the authors to provide the code necessary for reproducibility. By highlighting this specific area for improvement, the comment offers a clear path for the authors to enhance the verifiability and replicability of their work. However, it could be more helpful if it provided additional guidance on how to ensure the code is comprehensive or suggested specific steps for addressing the reproducibility issue. Overall, the comment is 4, as it effectively directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its suggestion to provide a clearer explanation, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the motivation for applying CMD in federated learning is unclear. It implies that the authors should provide a more explicit demonstration or explanation to clarify this aspect. While the comment highlights an area that needs improvement, it lacks specific guidance or suggestions on how to address the issue. The authors are left with a general understanding of what needs clarification but without detailed steps to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain, suggesting that comparisons to UNets are necessary. The reviewer implies that the authors should include comparisons to UNets to clarify the performance boost. While the comment explicitly states that comparisons to UNets are necessary, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is implicit but concrete, as the authors know what needs to be done to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a clear direction for the authors to address the issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a logical reasoning by comparing the UNet operation to pointwise multiplication as done in FNOs, which is a common practice in the field. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to conduct additional research or provide specific comparisons to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the CoNO model, specifically the use of a complex UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain, suggesting that comparisons to UNets are necessary to clarify the performance boost. The comment provides a logical reasoning by comparing the UNet operation to pointwise multiplication as done in FNOs, which is a common practice in the field. However, it lacks specific suggestions or guidance on how to conduct these comparisons or what aspects to focus on. While the comment highlights an important area for clarification, it could be more helpful with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not include any explicit or implicit actions for the authors to take. The comment mentions that the reviewer did not read additional experiments in the Appendix due to time constraints, but this does not provide any guidance or suggestions for improvement. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not specify which parts of the paper are being addressed or what specific issues are being discussed. The mention of \"additional experiments described in the Appendix\" provides some context, but it does not allow the authors to pinpoint the exact sections or elements being discussed. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not contain any claims, opinions, or suggestions that require verification. It is a statement of appreciation and does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not offer any specific feedback or suggestions for improvement, nor does it highlight any particular areas that need attention or clarification. The comment lacks actionable guidance or insights that could help the authors enhance their draft. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that W1 and W2 are not defined in the paper, suggesting that they might denote the Encoder and the Decoder network. It also mentions that W and V are not defined in Eq. 3, which is similar to the issue with W1 and W2. However, the comment does not provide explicit instructions on how the authors should define these terms or where they should be defined. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms in the appropriate sections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides explicit references to page 3, line A4, and Eq. 3, allowing the authors to accurately identify the parts of the paper being addressed. This level of detail ensures full grounding. Additionally, the comment specifies what needs to be addressed, namely the need for definitions of these terms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that W1 and W2 are not defined in the paper, and it suggests that they might denote the Encoder and the Decoder network. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides clear and actionable feedback by suggesting that these terms might denote the Encoder and the Decoder network, which could help the authors clarify their notation. However, the comment could be more helpful if it offered suggestions on how to define these terms or where they should be defined in the paper. Overall, the comment is 4 as it directs the authors to address a critical issue in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides an understanding of the integral in Equation (1) as a bag observation model or spatial aggregation process. It highlights a potential issue with the authors\" assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their formulation. The action is implicit and vague, as the authors are left to infer that they need to consider alternative aggregation methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation (1), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, suggesting that the observations might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides a clear explanation of the potential discrepancy between the authors\" assumption and the actual aggregation methods used in practice. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to a bag observation model or spatial aggregation process, referencing specific works. It then questions the authors\" assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides a logical reasoning based on the referenced works and a clear explanation of the potential discrepancy in the aggregation method. However, it lacks specific examples or references to support the claim about the actual aggregation methods used in practice, which could strengthen the verifiability. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be further strengthened with additional evidence.", "helpfulness_rationale": "The review comment provides a detailed analysis of the integral in Equation (1), explaining its correspondence to bag observation models or spatial aggregation processes. It highlights a potential issue with the authors\" assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. This feedback is valuable as it encourages the authors to consider alternative aggregation methods, which could enhance the accuracy and applicability of their model. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement these alternative methods. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider a more complex setting where the policy is not fixed, which would allow them to compare with a reinforcement learning algorithm baseline. While the comment implies that the authors should explore a more challenging scenario, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to expand the scope of their work, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring a more complex setting where the policy is not fixed, which would allow the authors to compare with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider a more challenging scenario, but without explicit references to the paper, the authors may struggle to identify the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. However, the comment does not provide specific examples or references to support the claim that tasks could become more complicated. The suggestion to compare with a reinforcement learning algorithm baseline is a logical extension of the proposed setting, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. This suggestion could be valuable for the authors as it opens up a new direction for exploration and comparison with reinforcement learning algorithms. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the policy should be varied to make the tasks more complex. While it provides a direction for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors should investigate or establish this relationship, nor are there suggestions for additional experiments or analyses that could be conducted. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights an issue with the study, specifically mentioning that the relationship between the top selected patches and the disease is not yet established. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the missing relationship, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, specifically noting that the relationship between the top selected patches and the disease is not yet established. This feedback is important as it highlights a critical area that needs further investigation or clarification. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional steps they could take to strengthen their study. While it points out a significant weakness, it does not provide actionable advice or detailed recommendations, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. While the comment identifies a potential issue with the evaluation, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for improvement, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. As a result, the authors are left without a clear path to follow, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem addressed by 5. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the evaluation and the potential unfairness of the comparison, but it lacks grounding as it does not reference a specific section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the evaluation being conducted only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. The comment provides a logical reasoning for the claim, explaining the limitations of the evaluation and the potential unfairness of the comparison. However, it lacks specific examples or references to 5 to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the numerical evaluation of the method, noting that it is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. This feedback highlights a potential weakness in the evaluation process, which is crucial for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might improve the evaluation or address the fairness of the comparison. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a valid concern but does not provide explicit guidance on how the authors should address this issue. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u to demonstrate the difference. While the second part is 3, the first part lacks explicit guidance, making the overall comment barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the use of rejection sampling with an arbitrary parameter beta instead of importance sampling, and the differentiation between QRS and RS in Algorithm 1. The first part of the comment is fully grounded as it explicitly mentions the use of rejection sampling and the parameter beta, allowing the authors to accurately identify the part of the paper being addressed. The second part is also fully grounded, as it refers to Algorithm 1 and the specific elements QRS and RS. The comment is specific in detailing what needs to be addressed in each part, providing clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a logical question but lacks specific reasoning or evidence to support the claim that importance sampling would be more appropriate. The second part of the comment points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, suggesting that the authors should provide a specific value of u to clarify the difference. While this part is 3, it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment raises two points for the authors to consider. First, it questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta, suggesting that importance sampling might be a more appropriate choice. This raises a valid concern about the methodology and could prompt the authors to reconsider their approach. Second, the comment points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, asking the authors to clarify this by providing a specific value of u. This feedback is 3 as it identifies areas for improvement and suggests specific actions for the authors to take, but it could be more helpful with additional guidance or examples. Overall, the comment provides some actionable insights but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison in terms of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to consider. Without any actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in asking about the comparison of computation cost or running time, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question asking for clarification about the comparison in terms of computation cost or running time. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison they should focus on. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of comparison against baselines in the paper, specifically mentioning the absence of baselines in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architectureagnostic similarity comparison or codesearch tasks. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include baseline comparisons to enhance the comprehensiveness of their study, but the comment lacks concrete details on which specific baselines to consider or how to implement them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of baseline comparisons, noting that many papers have developed architectureagnostic similarity comparison or codesearch tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, which is a widely understood binary analysis application. It references other papers that have developed architectureagnostic similarity comparison or codesearch tasks, providing a logical basis for the claim. However, the comment could be strengthened by providing specific examples or references to these papers, which would enhance its verifiability. Overall, the comment is 4 as it offers a reasonable basis for the claim but lacks detailed references or examples to fully substantiate it. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architectureagnostic similarity comparison or codesearch tasks, which are similar in nature. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it provided specific suggestions on which baselines to consider or how to incorporate them into the study. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the requirement mentioned in the abstract and the clarification provided in the text. It explicitly states that the requirement is not true, as the authors themselves clarify elsewhere. However, the comment does not provide any guidance or suggestions on how the authors should address this discrepancy or clarify the abstract. The action is implicit and lacks concrete details, making it 3. The authors know that the abstract needs to be corrected, but the comment does not specify how to do so, leaving them with a vague understanding of what needs to be done.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the requirement mentioned in the abstract, which is not true as the authors clarify in the text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the requirement mentioned in the abstract is not true, as it contradicts the clarification provided in the text. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the requirement mentioned in the abstract and the clarification provided in the text. It points out that the requirement is not true, as the authors themselves clarify elsewhere. This feedback is 3 as it highlights a potential inconsistency that the authors need to address. However, the comment lacks depth and does not provide specific guidance on how the authors should resolve this issue or improve the clarity of their presentation. Therefore, the comment is rated as 3, as it provides a starting point for the authors to consider but does not fully support their efforts to enhance the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this issue or improve the section. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the intent of Section 5.2, but it does not specify which part of the paper this section is located in. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in questioning the intent of the section, but without clear grounding, it is challenging for the authors to understand the context or what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid inquiry that could help the authors clarify the purpose and focus of this section. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the section. Without actionable feedback or specific advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It also mentions that the paper delves into technical details without providing a clear overview of the approach. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The feedback is vague and lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It mentions that the paper delves into technical details without providing a clear overview of the approach. However, the comment does not specify which part of the paper is unclear or lacks explanation, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in identifying the issue of clarity and the need for better explanation, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the nature of the issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. While the comment points out a critical area for improvement, it lacks specific suggestions or actionable steps for the authors to enhance clarity and address the issue of reporting bias. The feedback is 3 as it directs the authors\" attention to a specific area needing clarification, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It suggests including discourse relation information in prompts, possibly using a ChainofThought style, which could improve the results. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should enhance their baseline and consider the suggested approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and lacks testing for a fewshot approach. It also recommends including discourse relation information in prompts, possibly using a ChainofThought style, which could improve the results. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in its suggestions, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It also suggests that including discourse relation information in prompts could yield good results, which would enhance the paper\"s evaluation. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to include discourse relation information is a logical extension, but without further elaboration, it remains a vague suggestion. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a weakness in the paper\"s baseline, specifically noting that the chatgpt baseline is rudimentary and lacks testing for a fewshot approach. It also suggests that including discourse relation information in prompts, possibly using a ChainofThought style, could improve the results. This feedback is 3 as it points out a specific area for improvement and provides a potential solution. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or if it provided examples of how this could enhance the paper\"s evaluation. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the number of parameters used in each approach in Section B.3. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting they clarify the numbers or provide additional details. The comment lacks specificity and does not offer guidance on how to address the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the number of parameters used in each approach, specifically in Section B.3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach, particularly in Section B.3. This feedback is valuable as it highlights a potential issue that could affect the understanding of the paper by readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the section. While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, which are based on only three trials for each case. It suggests that reporting deviations is not justified due to the lack of statistical significance. The reviewer provides a clear explanation of why the reported deviations are not meaningful and questions the validity of statements comparing the performance to the next best baseline. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting additional trials or statistical tests to improve the significance of the results. While the action is implied, it lacks concrete details on how to implement the suggested changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the evaluation results, noting that the reported deviations are not statistically significant due to the limited number of trials. The comment further explains why statements comparing performance to the next best baseline are not meaningful, providing a clear rationale for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically not significant. The reviewer provides a logical explanation for why reporting deviations is not justified due to the lack of statistical significance. This reasoning is clear and supports the claim, making it 4. However, the comment could be strengthened by providing specific statistical tests or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that the results are based on only three trials for each case, which is statistically not significant. The reviewer explains that reporting deviations is not justified due to the lack of statistical significance, and this is why the deviations are often zero in many cases. The comment also questions the validity of statements comparing the performance to the next best baseline, suggesting that such claims are not meaningful. This feedback is clear and actionable, as it provides specific guidance on the statistical significance of the results and the need to address this issue. However, the comment could be more helpful if it offered suggestions on how to improve the statistical analysis or provide additional context for the evaluation results. Overall, the comment is 4, as it effectively identifies a critical weakness and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors should provide a more detailed explanation of the architecture within the paper itself, rather than relying solely on external references. However, the comment does not explicitly instruct the authors to include this information or how to do so, leaving the action somewhat implicit. The authors can infer that they need to provide a clearer explanation of the architecture, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This provides some grounding as it mentions a specific reference, but it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the architecture, which is a clear issue for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, and the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The claim is supported by the observation that the paper lacks a detailed explanation of the architecture, which is a critical aspect of the work. However, the comment could be strengthened by providing specific examples or details of what is missing or unclear in the explanation. The reference to Jiang et al. (2019) provides some context, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors refer to Jiang et al. (2019) for details. This feedback highlights a gap in the paper\"s selfcontainment, as it relies on external references for crucial information. The comment is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should include a more detailed explanation of the architecture within the paper itself. This feedback is valuable as it guides the authors in enhancing the comprehensibility and selfsufficiency of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to improve the presentation quality, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not provide clear guidance on execution.", "grounding_specificity_rationale": "The comment provides a list of specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not explicitly mention which sections or figures are being discussed, making it weakly grounded. The comment is specific in detailing the issues, but without explicit references, the authors may find it challenging to pinpoint the exact parts of the paper needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, citing specific examples such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, the comment does not provide detailed reasoning or evidence to support these claims, such as how these issues impact the overall quality of the publication. Without specific examples or references, the authors may find it challenging to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, and the lack of information in the \"Dataset\" columns. However, it does not provide actionable suggestions or guidance on how to address these issues. While the comment highlights areas for improvement, it lacks depth and specificity, leaving the authors with a general understanding of what needs to be fixed but without clear steps to take. Therefore, the comment is 3, as it points out weaknesses but does not offer comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, noting that their impact on idiomatic vs random data is similar for most language and score combinations. It suggests that the results imply that better NMT systems are also better at idiomatic translations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methods. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs random data is similar for most language and score combinations. This provides clear guidance on what needs to be addressed, namely the need for the methods to be more effective in distinguishing between idiomatic and random data. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods have a similar impact on idiomatic vs random data, suggesting that the methods are not idiomspecific. This claim is 3 as it provides a logical reasoning based on the observation of similar impacts in Figure 3. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it 3. The authors would need to further explore the data or provide additional context to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed methods, noting that the impact of the upweighing and KNN methods on idiomatic vs random data is similar for most language and score combinations. This observation suggests that the methods may not be as effective in distinguishing between idiomatic and nonidiomatic translations as initially proposed. The comment provides a clear and actionable insight, prompting the authors to reconsider the effectiveness of their methods and potentially revise their approach. However, the comment could be more helpful if it offered suggestions on how to address this issue or further explored the implications of this finding. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"cite and discuss\" certain references related to domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, specifying what needs to be added and how to implement the change. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment highlights the lack of important references for domain adaptation in the paper, suggesting that the authors should cite and discuss these references in the revised manuscript. However, it does not specify which references are missing or what specific domain adaptationrelated references should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are important. This lack of detail makes it difficult for the authors to understand the scope of the issue and how to address it effectively. As a result, the claim is considered 1, as it lacks sufficient evidence or justification to support the assertion.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks important references related to domain adaptation. It provides a clear and actionable suggestion for the authors to include and discuss these references in the revised manuscript. This feedback is valuable as it directs the authors to a critical aspect of their work that needs improvement, offering a concrete step for enhancing the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided specific examples of the missing references or guidance on how to integrate them effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim that the proposed PACE treats climate emulation as a diagnostictype prediction, which is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the distinction between their work and existing approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about PACE treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of misrepresentation by not clarifying that prior work already addresses this aspect. The comment provides a clear direction for the authors to address the claim, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about PACE treating climate emulation as a diagnostictype prediction is misleading without providing clear evidence or references to prior work (such as ClimateBench or ClimateSet) that already addresses this aspect. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that the proposed PACE treats climate emulation as a diagnostictype prediction, suggesting that this claim is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already addresses this aspect. This feedback is 3 as it points out a potential confusion or lack of clarity in the paper. However, it does not provide specific guidance on how the authors might address this issue or improve the clarity of their claims. The comment could be more helpful with additional suggestions or examples to help the authors enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential confusion in notation, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is explicit in identifying the issue, but it does not provide specific guidance on how to resolve the confusion. The authors are left to infer that they should clarify the notation or provide a consistent explanation for the use of \"r\" in different contexts. While the action is implied, it is concrete enough for the authors to understand the need for clarification. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed, which is the notation used throughout the document. The comment is also specific because it clearly specifies the issue with the notation, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems is confusing. This is a subjective observation that lacks specific examples or detailed reasoning to support the claim. The comment does not provide any logical reasoning or references to substantiate why this notation is confusing. As a result, the claim is not verifiable, as it lacks the necessary evidence or explanation to be understood or acted upon by the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity of their notation. By addressing this issue, the authors can enhance the readability and understanding of their work for readers. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion, such as proposing alternative notation or explaining the rationale behind the current notation. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that presenting factors in a table does not convey more information than pure text, implying that the authors should consider alternative ways to present information. However, the comment does not provide specific guidance on what those alternative ways might be or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different presentation methods but are not given concrete suggestions on what those might be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique, as it clearly identifies the problem with the current presentation method. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that presenting factors in a table does not convey more information than pure text, suggesting that there is no additional information provided. However, the comment lacks specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of factors in a table, suggesting that it does not convey more information than pure text. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might improve the presentation or convey more information. Without actionable feedback or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it points out a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific steps to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly modify their approach to account for this potential necessity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to pruning, particularly in the context of large networks trained in distributed settings. It highlights the potential necessity of finding global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of pruning or related techniques, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential impact on acceleration techniques, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is 3 as it provides a logical reasoning for the necessity of this consideration, but it lacks specific examples or references to support the claim fully. The authors would need to explore this further to understand the potential impact on acceleration techniques like quantization and sparsification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could impact acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate this consideration into their work. While it points out a potential area for improvement, the feedback is 3 as it provides a direction for the authors to explore but does not offer detailed actionable steps. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a general observation about the existence of multiple entities in sentences and documents, including the case of relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should be addressed or incorporated into the paper. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a general observation about the existence of multiple entities in sentences and documents, including relation classification. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a general observation about the existence of multiple entities in sentences and documents, including relation classification. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general observation about the presence of multiple entities in sentences and documents, including relation classification. However, it does not provide specific guidance or suggestions on how this observation could be addressed or integrated into the paper. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method compares with prior art. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the comparison should be addressed or how the authors should approach this comparison. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method compares with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the discussion section or the conclusion, but this inference is not explicit. The comment is specific in asking for a comparison with prior art, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question asking for clarification on how the proposed method compares with prior art. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art. While it identifies a gap in the paper\"s discussion, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the comparison should be emphasized. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it provides a starting point for the authors but does not offer detailed or comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, which is how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. This suggestion is explicit and provides a clear direction for the authors to consider in their analysis. However, the comment does not specify how to incorporate this analysis into the paper or which sections to address, leaving some room for interpretation. Overall, the comment is 4 as it provides a clear direction for improvement but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the redundancy of RQ1 and suggests an alternative focus for analysis, such as the impact of explicit hate information on implicit hate speech detection performance. However, it does not specify which part of the paper discusses RQ1, making it weakly grounded. The comment is specific in suggesting a different focus for analysis, which provides some guidance on what could be improved. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information for the audience. It suggests that the performance should be evaluated across multiple HS datasets in a crossdata setting and proposes an interesting point to analyze, such as the impact of explicit hate information on implicit hate speech detection performance. The comment provides a reference to support the suggestion, which is a step towards verifiability. However, the claim could be strengthened by providing more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is 4, as it offers a logical basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a redundancy in the RQ1 mentioned in the paper, suggesting that it does not provide additional information for the audience. It proposes an alternative focus for analysis, specifically how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa. This suggestion is clear and actionable, as it provides a specific direction for the authors to consider in their analysis. By offering a more focused and relevant research question, the comment helps the authors improve the depth and relevance of their study. However, the comment could be more helpful if it included specific examples or guidance on how to incorporate this analysis into the paper. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This comment provides a clear and explicit action for the authors to take, which is to clarify the objective for the LSTM part and add a head for value function computation in the finetuning stage. The suggestion is concrete, as it specifies what needs to be done and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network computing the value functions for the states. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the LSTM part, but this inference is not explicit. The comment is specific in its suggestion to clarify the objective and add a head for value function computation, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and that in the finetuning stage, the authors should add another head to the network computing the value functions for the states. This comment provides a logical suggestion based on the current framework, but it lacks specific references or examples to fully substantiate the claim. The reasoning is clear, but the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion regarding the objective for the LSTM part, specifically noting that it remains the same for both pretraining and finetuning stages. It further suggests that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This feedback is specific and offers a concrete way for the authors to improve their draft by clarifying the objective and suggesting a method for implementation. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4 as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in their related works section. While it implies that the authors should include these older works, it does not explicitly instruct them to do so or provide specific examples of which older works should be acknowledged. The action is implicit and somewhat vague, as the authors need to infer that they should include older works but are not given guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in their related works section. However, it does not provide any specific examples or reasoning to support why these older works should be included. Without additional context or justification, the claim lacks verifiability, as it does not provide the authors with a clear understanding of why these older works are relevant or necessary. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in their related works section, which is a valuable piece of feedback. It highlights the importance of including a comprehensive review of the literature, which can help strengthen the paper\"s foundation and context. However, the comment does not provide specific examples or guidance on which older works should be acknowledged, leaving the authors with a general suggestion. While the feedback is 3, it could be more actionable with additional details, making it a 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that the authors\" argument about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming predicted architectures. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their results or analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly revise their results or analysis to align with the suggested argument. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling, and questions the authors\" argument about the predictor being accurate on the good subregion. The comment suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" argument about the predictor being accurate on the good subregion and suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance. However, the comment lacks specific examples or detailed reasoning to support the claim that the predictor is accurate or that increasing the sampling probability would indeed lead to better performance. Without additional evidence or analysis, the claim remains 3, as it provides a logical basis for questioning but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern with the results presented in Table 2, particularly regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" argument about the predictor being accurate on the good subregion and suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance. However, the comment lacks detailed guidance on how the authors might address this issue or what specific changes they should make to their analysis or results. While it points out a potential weakness, it does not provide actionable steps or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to explain how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what they have achieved. This feedback is clear and direct, providing a concrete action for the authors to take. The comment also includes a reference to a previous work, \"Neural architecture search with gBdt,\" which could serve as a model for the authors to follow. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SE framework\" and references a specific work, \"Neural architecture search with gBdt,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for a detailed explanation of how the SE framework can help improve the work, similar to the previous comment. The authors are given a clear direction on what needs to be addressed, making this comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" explanation of how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what they have achieved. The comment references a previous work, \"Neural architecture search with gBdt,\" which could serve as a model for the authors to follow. However, the comment does not provide specific examples or detailed reasoning to support the claim that the authors\" explanation is insufficient. While the reference to the previous work is a step towards verification, the lack of detailed justification or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the lack of explanation of how the SE framework can help improve the work. It provides a clear and actionable suggestion for the authors to explain the benefits and mechanisms of their framework, which is crucial for readers to understand the value of their approach. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the explanation. Overall, the feedback is clear and provides a direction for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It suggests that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or whether they should consider alternative metrics. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not specify which part of the paper discusses these metrics or where they are used, making it weakly grounded. The comment is specific in identifying the limitations of the metrics, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, specifically loss after switch and recovery time after switch, may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. This claim is 3 as it provides a logical reasoning for the potential limitations of these metrics in certain contexts. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to further explore the implications of this limitation to fully address the feedback.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. This feedback is 3 as it highlights an important consideration for the authors to address when evaluating their results. However, the comment could be more helpful if it provided suggestions on alternative metrics or approaches that could be used in such settings. Overall, the comment provides a useful insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The reviewer suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem and highlights areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to address these concerns but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its potential impact, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors may find it challenging to address the issue without additional context or examples. Therefore, the comment is 3, as it provides a logical argument but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing process, specifically noting the need to know the statistical dimension d_lambda of the design matrix A. It points out that accurately computing this dimension would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment highlights that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment raises an important point about the limitations of the approach, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a potential weakness but does not provide detailed actionable advice, leaving the authors to infer the necessary steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing, and it suggests that other researchers need to know which cases the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis on the movie dataset. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of an error analysis on the movie dataset to provide information on cases where the model fails. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual statement rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the draft could be improved, namely the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers to understand the model\"s performance and potential limitations. This feedback is clear and actionable, providing a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to conduct or present the error analysis. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be done, namely, to provide a detailed plan for addressing the limitations, making it 5.", "grounding_specificity_rationale": "The comment addresses the limitations section of the paper, which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the part being addressed. The comment is also specific because it suggests that the authors should provide a more detailed plan on how they plan to address these limitations in their future work. This feedback is clear and actionable, allowing the authors to understand exactly what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment does not provide any specific examples or reasoning to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks sufficiency, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a vague suggestion without sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs further development. By addressing this suggestion, the authors can enhance the comprehensiveness and future direction of their research. However, the comment could be more helpful if it provided examples or specific suggestions on how to develop this plan. Overall, the feedback is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion to conduct a comparison or provide details on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology section or results. The authors may infer that it pertains to the computational aspects discussed in the paper, but this inference is not explicit. The comment lacks specificity as it does not detail what needs to be addressed regarding the computation cost or how to compare it with other methods. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the comment provides a potential solution, it lacks explicit instructions on how the authors should implement this suggestion or address the confusion in the writing. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to resolve the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses issues 1) and 2) and suggests using a generic external knowledge base, as shown in Figure 3. However, it does not specify which parts of the paper these issues are found in, making it weakly grounded. The comment is specific in suggesting a solution to the issues, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as shown in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the suggestion is logical and supported by the reference to Figure 3, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the confusion in the writing. This makes the claim 3, as it provides a potential solution but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two issues (1) and (2) that can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. This provides a clear and actionable suggestion for improvement, offering a potential solution to the problems mentioned. However, the comment also notes that the writing is confusing, which is a separate issue that could impact the clarity of the paper. While the suggestion is helpful, the comment could be more comprehensive by addressing the confusion in the writing or providing specific examples of where it occurs. Overall, the feedback is 4 as it guides the authors towards a solution for the identified issues, but it could be more detailed for full effectiveness. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a discrepancy in the definition of perplexity, stating that it is not what perplexity is and that Eq1 does not resemble perplexity. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should correct this issue or what steps they should follow to address it. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of perplexity and crossentropy, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the definitions of perplexity and crossentropy, which are clear and unambiguous. The reviewer provides specific references to the equations mentioned, \"L259\" and \"Eq1,\" allowing the authors to easily identify the parts of the paper that need clarification. This provides a clear and logical basis for the claim, making it 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a discrepancy in the definition of perplexity, pointing out that the explanation provided does not accurately describe what perplexity is. It also notes that Eq1 does not resemble perplexity, suggesting that it might be a different measure, such as crossentropy. This feedback is specific and actionable, as it directs the authors to revisit their explanation of perplexity and potentially clarify or correct the definition. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or offered alternative ways to present the information. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they provide the missing hyperparameters or clarify their implementation in the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the model, noting that it has many components with unspecified hyperparameters. However, it does not specify which parts of the paper discuss these components or provide details on the hyperparameters. The authors can infer that the issue relates to the model description or implementation, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the need for more detailed information on hyperparameters, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that it has many components with unspecified hyperparameters. This is a relevant observation that could impact the reproducibility and replicability of the model. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing the missing hyperparameters or clarifying their implementation in the paper. Without actionable steps or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, as it highlights a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point critiques a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It explicitly states that the claim is incorrect and provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime or for a finite linear combination of arbitrary random variables. This feedback is explicit and provides concrete details on how the authors can address the issue by correcting the claim or providing a more accurate explanation. The authors are given a clear path to improve their draft by addressing the specific points of contention. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides detailed reasoning and references to support the claim that the statement is incorrect, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a claim made in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This critique is supported by logical reasoning and specific references to the limitations of the CLT, making the claim 5. The authors are given a clear understanding of the issue and the basis for the critique, allowing them to address the concern effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper regarding the Central Limit Theorem (CLT) and its application to a finite linear combination of random variables. It critiques the claim by explaining that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a detailed explanation of why their claim is incorrect and offers a basis for correcting it. By addressing this critique, the authors can improve the accuracy and rigor of their paper. Therefore, the comment is 5, as it provides clear guidance for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It suggests that the proposed framework, FFAEVAL, and similar systems like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to reconsider the relevance of their method to their motivations and the evaluation systems used. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically mentioning the use of automatic scores and human evaluation scores. It also questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the abstract section or the methodology, but this is not explicitly stated. The comment is specific in detailing the concerns about the relevance of the proposed method to the authors\" motivations and the evaluation systems used. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment lacks specific examples or references to support the claim that these systems are not suitable for evaluating a single dialogue system. While the reviewer provides a logical argument based on the current state of evaluation systems, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. This feedback is 3 as it identifies a potential limitation in the proposed method\"s applicability and suggests that the current evaluation systems may not be suitable for evaluating a single dialogue system. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. To be more helpful, the comment could provide alternative approaches or suggestions for evaluating a single dialogue system. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to explore this possibility. As a result, the authors are left without a clear understanding of what actions to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper would benefit from using a better encoder or how this change could be implemented. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations to substantiate the suggestion, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might explore this question or what specific aspects to consider when using a better encoder. Without actionable advice or detailed feedback, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without significantly impacting the performance of the predictive model. While the comment implies that the authors should include this demonstration, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide this demonstration, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method description. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the proposed method or fair policy learning are being discussed. Without clear grounding and specific details, the authors may struggle to understand and address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it could be achieved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. This feedback is 3 as it identifies a specific area for improvement, namely the need to balance fairness with performance. However, the comment lacks depth and does not provide detailed guidance on how to achieve this balance or what specific aspects of the method should be addressed. To be more helpful, the comment could include suggestions on how to measure fairness and performance, or examples of how other methods have successfully achieved this balance. Overall, the feedback is 3 as it points out a potential area for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear understanding of what steps to take to resolve the problem. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a pervasive use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace\" on line 280, which is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the word \"to meet\" in a sentence on line 280, noting that it is difficult to understand. While it points out a potential clarity issue, it does not provide any suggestions or guidance on how the authors might address this problem or improve the sentence. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it highlights a potential issue but does not offer actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, rather than connecting with the Images Masked by Second Masks. This provides a clear and direct action for the authors to take, which is to correct the connections in the figure. The comment is explicit and concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the connections in the figure, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the connections in Figure 2 should be between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This is a factual observation that does not require any supporting evidence or reasoning. The comment is descriptive and does not express an opinion, judgment, or suggestion that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the connections in Figure 2, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific correction to make in their draft. By addressing this detail, the authors can improve the clarity and accuracy of their visual representation. However, the comment could be more helpful if it explained why this correction is important or how it affects the overall interpretation of the results. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Fig 1 and Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This feedback is explicit in identifying the inconsistency between the figures, but it does not provide specific guidance on how the authors should address this issue. The authors are left to infer that they need to clarify or correct the figures to align with the description in the text. While the action is implied, it is concrete in terms of what needs to be done, making the comment 4.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the inconsistency between the figures, noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This is a factual observation that does not require verification, as it is a direct comparison between two figures. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency between two figures, Fig 1 and Fig 2, regarding the representation of encoderdecoder structures for auxiliary tasks. By pointing out this discrepancy, the comment highlights an area where the paper\"s clarity could be improved. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or enhance the clarity of their figures. While it points out a potential problem, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the main contribution of the paper and the proposed method\"s ability to cope with dynamic largescale multitasking. It also questions the applicability of the method and the process of automation. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically mentioning the proposed method\"s novel properties and the main idea of coping with dynamic largescale multitasking. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the main contribution and the proposed method\"s applicability and automation. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability and applicability are overstated or not wellsupported. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references to other works or detailed explanations of what aspects are unclear or overstated. As a result, the claim is difficult for the authors to verify and address, making it 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the proposed method\"s novel properties are either overstated or not wellsupported. It also points out that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear, and the process of automation is not wellexplained. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out critical areas that need clarification, but it could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The suggestion is vague and lacks concrete guidance on how to implement these ideas. The authors are left to infer that they should explore these directions, but without specific instructions, the action remains implicit and somewhat vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, it does not specify which part of the paper this feedback pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestions for alternative approaches but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, the comment does not provide specific evidence, examples, or references to support the claim that training a large number of models is impractical or that the suggested alternatives are more effective. The reasoning is based on a general observation rather than detailed analysis or evidence, making the claim 3. The authors would need to explore these suggestions themselves to fully understand their implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. This feedback is 3 as it identifies a potential limitation of the current approach and provides suggestions for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback offers a direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional experiments, updating the compared methods, or expanding the types of teacher architectures. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The mention of \"Tab.\" suggests that the issue might be related to a table, but it is not explicitly mentioned, leaving the authors to infer the relevant part. While the comment is specific in detailing the issues, it lacks grounding as it does not clearly identify the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient due to limited types of teacher architectures and outdated compared methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not provide any suggestions or guidance on how the authors might address these issues or improve their experiments. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. The authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparison in Table 2, specifically regarding the use of different amounts of data in various comparisons. It suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H. However, the comment does not explicitly instruct the authors to make these comparisons or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparisons to ensure they are made on equal footing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in the table, noting that comparisons should be made between using the same amount of data. The reviewer provides examples of comparisons that are not made on equal footing, such as H>N and H>B, or H>N>H and H>N>H. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparison in Table 2, specifically questioning the use of different amounts of data in various comparisons. The reviewer suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H. However, the comment lacks specific examples or references to support the claim that these comparisons are not being made on equal footing. While the suggestion is logical, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2, questioning the comparison of results that use different amounts of data. It suggests that comparisons should be made between using the same amount of data, such as comparing H>N and H>B, or H>N>H and H>N>H. This feedback is clear and actionable, as it provides a specific area for improvement by recommending that the authors ensure consistent data usage in their comparisons. However, the comment could be more helpful if it included suggestions on how to adjust the table or provide additional context for the comparisons. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which is to use known causal relationships between features. It highlights that prior knowledge is not always available and might be inaccurate for specific subpopulations, leading most researchers to focus on mining causal relationships from data automatically. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of prior knowledge and explore alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a concern about the practicality of using known causal relationships between features, as it acknowledges that prior knowledge is not always available and might be inaccurate for specific subpopulations. However, it does not specify which part of the paper discusses this approach or where the authors might need to address this concern. The authors can infer that it relates to the methodology or discussion sections, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on what aspects of the paper need to be revised or improved to address the concern about practicality. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the practicality of using known causal relationships between features, noting that prior knowledge is not always available and might be inaccurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that prior knowledge is inaccurate or unavailable. The reasoning is based on general observations about the field, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s approach, which is the reliance on known causal relationships between features. It points out that prior knowledge is not always available and might be inaccurate for specific subpopulations, which is a common challenge in many research fields. The reviewer suggests that most researchers focus on mining causal relationships from data automatically, implying that the proposed approach might be impractical. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the practicality of their work. The feedback is 3 as it points out a potential issue, but it could be more actionable with additional insights or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several issues with the paper\"s empirical findings, including the lack of polishing of figures and empirical results, which impede clarity and confidence in the results. It specifies specific areas for improvement, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. Additionally, it notes that the core findings in section one are conducted on two smallscale datasets and a single architecture type. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address these issues. The authors are left to infer that they should improve the clarity and confidence in their empirical results by addressing these specific points. Therefore, the comment is 3, as it provides a clear action but lacks explicit guidance on execution.", "grounding_specificity_rationale": "The comment addresses the lack of polishing in figures and empirical results, which affects the clarity and confidence in the paper\"s findings. It specifies issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. However, the comment does not explicitly mention which sections or figures are affected, making it weakly grounded. The authors can infer that the issues are related to the figures and empirical results discussed in the paper, but they cannot pinpoint specific sections. The comment is specific in detailing what needs to be addressed, such as improving the clarity of figures and empirical results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks confidence in its empirical findings due to issues with the figures and empirical results. The reviewer provides specific examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s empirical findings, including the lack of polishing in figures and empirical results, which impede clarity and confidence in the results. It provides detailed examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. This feedback is 5 as it offers clear and actionable suggestions for improvement, allowing the authors to address these specific concerns and enhance the clarity and robustness of their empirical results. By providing detailed guidance, the comment empowers the authors to significantly improve their draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2 in Section 4.3. It suggests that including these comparisons would provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. This feedback is clear and direct, providing the authors with a specific action to take: conduct additional comparative experiments. The comment is explicit and concrete, offering a clear path for improvement. Therefore, it is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides a clear direction for the authors to enhance their paper by including these comparisons, which would provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, which could provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. However, the comment does not provide specific examples or references to support the claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by highlighting the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s comprehensiveness and depth by including these comparisons. By addressing this feedback, the authors can better showcase the unique advantages or potential shortcomings of their proposed method in a broader context. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion around equation (10) is very brief and not wellexplained. However, it does not provide any explicit or implicit actions for the authors to take to improve this section. There is no guidance on how to expand or clarify the discussion, nor are there suggestions for what specific aspects need more explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment does not specify what is unclear or missing in the discussion around this equation, making it underspecific. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is very terse and not clearly explained. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the discussion around equation (10), noting that it is very brief and not wellexplained. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity and depth of their discussion. However, the comment could be more helpful if it provided suggestions on how to enhance the explanation or what specific aspects need further elaboration. Overall, the comment is 4 as it highlights a specific area for improvement but lacks detailed guidance for implementation."}
